{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k-medias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = pd.read_csv('House_Price_Regression.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>price</th>\n",
       "      <th>size_in_m_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25.113208</td>\n",
       "      <td>55.138932</td>\n",
       "      <td>2700000</td>\n",
       "      <td>100.242337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25.106809</td>\n",
       "      <td>55.151201</td>\n",
       "      <td>2850000</td>\n",
       "      <td>146.972546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25.063302</td>\n",
       "      <td>55.137728</td>\n",
       "      <td>1150000</td>\n",
       "      <td>181.253753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25.227295</td>\n",
       "      <td>55.341761</td>\n",
       "      <td>2850000</td>\n",
       "      <td>187.664060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25.114275</td>\n",
       "      <td>55.139764</td>\n",
       "      <td>1729200</td>\n",
       "      <td>47.101821</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    latitude  longitude    price  size_in_m_2\n",
       "0  25.113208  55.138932  2700000   100.242337\n",
       "1  25.106809  55.151201  2850000   146.972546\n",
       "2  25.063302  55.137728  1150000   181.253753\n",
       "3  25.227295  55.341761  2850000   187.664060\n",
       "4  25.114275  55.139764  1729200    47.101821"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data = Data.loc[:, ['latitude', 'longitude', 'price', 'size_in_m_2']]\n",
    "\n",
    "Data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Configuracion inicial aleatoria de los clusters:\n",
    "\n",
    "n=len(Data)\n",
    "\n",
    "k=4\n",
    "\n",
    "elementos_clusterizados = []\n",
    "\n",
    "m = resample(range(0, n), n_samples=math.floor(n/k) , replace=False, random_state=123)\n",
    "\n",
    "Cluster_0 = Data.loc[m,:]\n",
    "\n",
    "elementos_clusterizados.append(m)\n",
    "\n",
    "\n",
    "###################################################################################\n",
    "\n",
    "\n",
    "if k >= 2:\n",
    "\n",
    "# Si los elementos que quedan por clusterizar menos el tamaño de los clusters es menor que el propio tamaño de los clusters,\n",
    "#  se meten todos los elementos que quedan por clusterizar en un mimsmo cluster que será ademas el ultimo.\n",
    "\n",
    "\n",
    "    if len(np.delete(range(0,n), elementos_clusterizados)) - n/k  < n/k : \n",
    "\n",
    "        Cluster_1 = Data.loc[np.delete(range(0,n), elementos_clusterizados),:]\n",
    "\n",
    "        elementos_clusterizados.append(m)\n",
    "\n",
    "    else:\n",
    "\n",
    "        m = resample(np.delete(range(0,n), elementos_clusterizados), n_samples=math.floor(n/k) , replace=False, random_state=123)\n",
    "\n",
    "        Cluster_1 = Data.loc[m,:]\n",
    "\n",
    "        elementos_clusterizados.append(m)\n",
    "\n",
    "elif k < 2 :\n",
    "\n",
    "    pass\n",
    "\n",
    "###################################################################################\n",
    "\n",
    "if k >= 3:\n",
    "\n",
    "# Si los elementos que quedan por clusterizar menos el tamaño de los clusters es menor que el propio tamaño de los clusters,\n",
    "#  se meten todos los elementos que quedan por clusterizar en un mimsmo cluster que será ademas el ultimo.\n",
    "\n",
    "\n",
    "    if len(np.delete(range(0,n), elementos_clusterizados)) - n/k  < n/k : \n",
    "\n",
    "        Cluster_2 = Data.loc[np.delete(range(0,n), elementos_clusterizados),:]\n",
    "\n",
    "        elementos_clusterizados.append(m)\n",
    "\n",
    "    else:\n",
    "\n",
    "        m = resample(np.delete(range(0,n), elementos_clusterizados), n_samples=math.floor(n/k) , replace=False, random_state=123)\n",
    "\n",
    "        Cluster_2 = Data.loc[m,:]\n",
    "\n",
    "        elementos_clusterizados.append(m)\n",
    "\n",
    "elif k < 3 :\n",
    "\n",
    "    pass\n",
    "\n",
    "###################################################################################\n",
    "\n",
    "if k >= 4:\n",
    "\n",
    "# Si los elementos que quedan por clusterizar menos el tamaño de los clusters es menor que el propio tamaño de los clusters,\n",
    "#  se meten todos los elementos que quedan por clusterizar en un mimsmo cluster que será ademas el ultimo.\n",
    "\n",
    "\n",
    "    if len(np.delete(range(0,n), elementos_clusterizados)) - n/k  < n/k : \n",
    "\n",
    "        Cluster_3 = Data.loc[np.delete(range(0,n), elementos_clusterizados),:]\n",
    "\n",
    "        elementos_clusterizados.append(m)\n",
    "\n",
    "    else:\n",
    "\n",
    "        m = resample(np.delete(range(0,n), elementos_clusterizados), n_samples=math.floor(n/k) , replace=False, random_state=123)\n",
    "\n",
    "        Cluster_3 = Data.loc[m ,:]\n",
    "\n",
    "        elementos_clusterizados.append(m)\n",
    "\n",
    "elif k < 4 :\n",
    "\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None, None, None]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista_clusters = [None] * 4\n",
    "\n",
    "lista_clusters[0] = Cluster_0\n",
    "lista_clusters[1] = Cluster_1\n",
    "lista_clusters[2] = Cluster_2\n",
    "lista_clusters[3] = Cluster_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculo de centroides iniciales\n",
    "\n",
    "centroide_0 = lista_clusters[0].mean()\n",
    "centroide_1 = lista_clusters[1].mean()\n",
    "centroide_2 = lista_clusters[2].mean()\n",
    "centroide_3 = lista_clusters[3].mean()\n",
    "\n",
    "# Calculo de distancias Euclideas para la observacion x_1\n",
    "\n",
    "x_1 = Data.iloc[0,:]\n",
    "\n",
    "distancia_0 = sum((x_1 - centroide_0)**2)\n",
    "distancia_1 = sum((x_1 - centroide_1)**2)\n",
    "distancia_2 = sum((x_1 - centroide_2)**2)\n",
    "distancia_3 = sum((x_1 - centroide_3)**2)\n",
    "\n",
    "# Calculo de cluster optimo para x_1\n",
    "\n",
    "df_distancias = pd.DataFrame({'Distancias' : [distancia_0, distancia_1 , distancia_2 , distancia_3], 'Cluster': [0,1,2,3]})\n",
    "\n",
    "df_distancias_sort = df_distancias.sort_values(by='Distancias', ascending=False)\n",
    "\n",
    "j_star = df_distancias_sort.iloc[0]['Cluster']\n",
    "\n",
    "j_star = int(j_star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_list = []\n",
    "i = 1\n",
    "\n",
    "while i <= n-2 :\n",
    "\n",
    "    for j in range(0, k) :\n",
    "\n",
    "\n",
    "        # Si x_i no esta en el cluster j --> pasamos a analizar otro cluster j\n",
    "\n",
    "        if sum(lista_clusters[j].index == i-1) ==  0 :\n",
    "\n",
    "            pass\n",
    "\n",
    "\n",
    "        # Si x_i esta en el cluster j y es el cluster optimo de x_i --> pasamos a x_i+1\n",
    "\n",
    "        if ( sum(lista_clusters[j].index == i-1) != 0 )  & ( j_star == j ) :\n",
    "\n",
    "            # Actualizamos i a i+1\n",
    "\n",
    "            i = i + 1\n",
    "\n",
    "            i_list.append(i)\n",
    "\n",
    "            # calculamos las distancias entre x_i+1 y los centroides\n",
    "\n",
    "            x_i = Data.iloc[ i ,:] # x_i+1\n",
    "\n",
    "            distancia_0 = sum((x_i - centroide_0)**2)\n",
    "            distancia_1 = sum((x_i - centroide_1)**2)\n",
    "            distancia_2 = sum((x_i - centroide_2)**2)\n",
    "            distancia_3 = sum((x_i - centroide_3)**2)\n",
    "\n",
    "\n",
    "            # Calculo de cluster optimo para x_1\n",
    "\n",
    "            df_distancias = pd.DataFrame({'Distancias' : [distancia_0 , distancia_1 , distancia_2, distancia_3], 'Cluster': [0,1,2,3]})\n",
    "\n",
    "            df_distancias_sort = df_distancias.sort_values(by='Distancias', ascending=False)\n",
    "\n",
    "            j_star = df_distancias_sort.iloc[0]['Cluster']\n",
    "\n",
    "            j_star = int(j_star)\n",
    "\n",
    "\n",
    "\n",
    "        # Si x_i esta en el cluster j pero ese no es el cluster optimo de x_i \n",
    "\n",
    "        if ( sum(lista_clusters[j].index == i-1) != 0 )  & ( j_star != j ) : \n",
    "\n",
    "            ## Actualizamos los clusters:\n",
    "\n",
    "            #Añadimos x_i al cluster j_star :\n",
    "\n",
    "            lista_clusters[j_star] = pd.concat( [ lista_clusters[j_star] , lista_clusters[j].loc[i-1,:].to_frame().T ]  )  \n",
    "\n",
    "            \n",
    "            # Eliminamos x_1 del cluster j :\n",
    "\n",
    "            lista_clusters[j] = lista_clusters[j].drop(i-1)   \n",
    "\n",
    "\n",
    "            # Recalculo de centroides para la nueva configuracion de clusters\n",
    "\n",
    "            centroide_0 = lista_clusters[0].mean()\n",
    "            centroide_1 = lista_clusters[1].mean()\n",
    "            centroide_2 = lista_clusters[2].mean()\n",
    "            centroide_3 = lista_clusters[3].mean()\n",
    "\n",
    "            # Recalculo de distancias de x_i respecto los centroides:\n",
    "\n",
    "            x_i = Data.iloc[i-1,:]\n",
    "\n",
    "            distancia_0 = sum((x_1 - centroide_0)**2)\n",
    "            distancia_1 = sum((x_1 - centroide_1)**2)\n",
    "            distancia_2 = sum((x_1 - centroide_2)**2)\n",
    "            distancia_3 = sum((x_1 - centroide_3)**2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[       latitude  longitude      price  size_in_m_2\n",
       " 1241  25.096869  55.175364   400000.0    27.499288\n",
       " 1242  25.079501  55.151503  1350000.0   153.289950\n",
       " 1243  25.068730  55.128758   795000.0    54.998576\n",
       " 1288  25.180861  55.279295  1602000.0   125.326147\n",
       " 1326  25.075974  55.135687  1050000.0    71.349504\n",
       " ...         ...        ...        ...          ...\n",
       " 1847  25.190137  55.264937  2950000.0   282.332217\n",
       " 1848  25.091311  55.378277   270000.0    42.735380\n",
       " 1858  25.078148  55.148277   760888.0    83.984312\n",
       " 1860  25.078148  55.148277  1550888.0   140.933851\n",
       " 1866  25.089833  55.150625  1975000.0   276.758037\n",
       " \n",
       " [435 rows x 4 columns],\n",
       "        latitude  longitude      price  size_in_m_2\n",
       " 1476  25.081955  55.138863   690000.0    66.332742\n",
       " 1904  25.079130  55.154713   760887.0    74.322400\n",
       " 1456  25.074958  55.138542   780000.0    50.353426\n",
       " 1463  25.010572  55.289786  1010888.0   153.754465\n",
       " 1469  25.240419  55.252770  1271000.0    68.004996\n",
       " ...         ...        ...        ...          ...\n",
       " 1898  25.104330  55.148769  2700000.0    99.963628\n",
       " 1899  25.037477  55.221942   550000.0    78.688841\n",
       " 1900  25.176892  55.310712  1500000.0   100.985561\n",
       " 1902  25.206500  55.345056  2900000.0   179.302790\n",
       " 1903  25.073858  55.229844   675000.0    68.748220\n",
       " \n",
       " [481 rows x 4 columns],\n",
       "        latitude  longitude      price  size_in_m_2\n",
       " 1472  25.064191  55.216245   380000.0    63.081137\n",
       " 1438  25.189020  55.282216  1500000.0   161.744123\n",
       " 911   25.202965  55.260897  4949999.0   224.825260\n",
       " 1470  25.240419  55.252770  4127000.0   182.647298\n",
       " 951   25.076620  55.135006  2900000.0   287.070270\n",
       " ...         ...        ...        ...          ...\n",
       " 1889  25.106668  55.149275  1400000.0   108.975219\n",
       " 1890  25.072954  55.128089  3800000.0   167.875721\n",
       " 1895  25.081243  55.145120  1350000.0   146.600934\n",
       " 1897  25.153080  55.254242   360000.0    55.741800\n",
       " 1901  25.166145  55.276684  1230000.0    70.606280\n",
       " \n",
       " [614 rows x 4 columns],\n",
       "        latitude  longitude       price  size_in_m_2\n",
       " 1     25.106809  55.151201   2850000.0   146.972546\n",
       " 3     25.227295  55.341761   2850000.0   187.664060\n",
       " 128   25.111902  55.138103    655888.0    35.303140\n",
       " 129   25.109367  55.247980   2300000.0   181.439559\n",
       " 130   25.204462  55.262161   3200000.0   170.012490\n",
       " ...         ...        ...         ...          ...\n",
       " 1877  25.072573  55.131009   1499000.0   175.029252\n",
       " 1879  25.203553  55.345554    890000.0    70.606280\n",
       " 1883  25.072569  55.126527   1970000.0    81.940446\n",
       " 1884  25.072569  55.126527   3300000.0   109.625540\n",
       " 1885  25.103972  55.149621  31440000.0   607.771426\n",
       " \n",
       " [375 rows x 4 columns]]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clusters finales\n",
    "\n",
    "lista_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "latitude       2.511432e+01\n",
       "longitude      5.521145e+01\n",
       "price          2.113728e+06\n",
       "size_in_m_2    1.305061e+02\n",
       "dtype: float64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista_clusters[0].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "latitude       2.511547e+01\n",
       "longitude      5.521166e+01\n",
       "price          2.185737e+06\n",
       "size_in_m_2    1.368620e+02\n",
       "dtype: float64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista_clusters[1].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "latitude       2.511792e+01\n",
       "longitude      5.521418e+01\n",
       "price          1.983616e+06\n",
       "size_in_m_2    1.289294e+02\n",
       "dtype: float64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista_clusters[2].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "latitude       2.511822e+01\n",
       "longitude      5.521123e+01\n",
       "price          2.092679e+06\n",
       "size_in_m_2    1.307373e+02\n",
       "dtype: float64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista_clusters[3].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k-medoids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Configuracion inicial aleatoria de los clusters:\n",
    "\n",
    "n=len(Data)\n",
    "\n",
    "k=4\n",
    "\n",
    "elementos_clusterizados = []\n",
    "\n",
    "m = resample(range(0, n), n_samples=math.floor(n/k) , replace=False, random_state=123)\n",
    "\n",
    "Cluster_0 = Data.loc[m,:]\n",
    "\n",
    "elementos_clusterizados.append(m)\n",
    "\n",
    "\n",
    "###################################################################################\n",
    "\n",
    "\n",
    "if k >= 2:\n",
    "\n",
    "# Si los elementos que quedan por clusterizar menos el tamaño de los clusters es menor que el propio tamaño de los clusters,\n",
    "#  se meten todos los elementos que quedan por clusterizar en un mimsmo cluster que será ademas el ultimo.\n",
    "\n",
    "\n",
    "    if len(np.delete(range(0,n), elementos_clusterizados)) - n/k  < n/k : \n",
    "\n",
    "        Cluster_1 = Data.loc[np.delete(range(0,n), elementos_clusterizados),:]\n",
    "\n",
    "        elementos_clusterizados.append(m)\n",
    "\n",
    "    else:\n",
    "\n",
    "        m = resample(np.delete(range(0,n), elementos_clusterizados), n_samples=math.floor(n/k) , replace=False, random_state=123)\n",
    "\n",
    "        Cluster_1 = Data.loc[m,:]\n",
    "\n",
    "        elementos_clusterizados.append(m)\n",
    "\n",
    "elif k < 2 :\n",
    "\n",
    "    pass\n",
    "\n",
    "###################################################################################\n",
    "\n",
    "if k >= 3:\n",
    "\n",
    "# Si los elementos que quedan por clusterizar menos el tamaño de los clusters es menor que el propio tamaño de los clusters,\n",
    "#  se meten todos los elementos que quedan por clusterizar en un mimsmo cluster que será ademas el ultimo.\n",
    "\n",
    "\n",
    "    if len(np.delete(range(0,n), elementos_clusterizados)) - n/k  < n/k : \n",
    "\n",
    "        Cluster_2 = Data.loc[np.delete(range(0,n), elementos_clusterizados),:]\n",
    "\n",
    "        elementos_clusterizados.append(m)\n",
    "\n",
    "    else:\n",
    "\n",
    "        m = resample(np.delete(range(0,n), elementos_clusterizados), n_samples=math.floor(n/k) , replace=False, random_state=123)\n",
    "\n",
    "        Cluster_2 = Data.loc[m,:]\n",
    "\n",
    "        elementos_clusterizados.append(m)\n",
    "\n",
    "elif k < 3 :\n",
    "\n",
    "    pass\n",
    "\n",
    "###################################################################################\n",
    "\n",
    "if k >= 4:\n",
    "\n",
    "# Si los elementos que quedan por clusterizar menos el tamaño de los clusters es menor que el propio tamaño de los clusters,\n",
    "#  se meten todos los elementos que quedan por clusterizar en un mimsmo cluster que será ademas el ultimo.\n",
    "\n",
    "\n",
    "    if len(np.delete(range(0,n), elementos_clusterizados)) - n/k  < n/k : \n",
    "\n",
    "        Cluster_3 = Data.loc[np.delete(range(0,n), elementos_clusterizados),:]\n",
    "\n",
    "        elementos_clusterizados.append(m)\n",
    "\n",
    "    else:\n",
    "\n",
    "        m = resample(np.delete(range(0,n), elementos_clusterizados), n_samples=math.floor(n/k) , replace=False, random_state=123)\n",
    "\n",
    "        Cluster_3 = Data.loc[m ,:]\n",
    "\n",
    "        elementos_clusterizados.append(m)\n",
    "\n",
    "elif k < 4 :\n",
    "\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_clusters = [None] * 4\n",
    "\n",
    "lista_clusters[0] = Cluster_0\n",
    "lista_clusters[1] = Cluster_1\n",
    "lista_clusters[2] = Cluster_2\n",
    "lista_clusters[3] = Cluster_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "distancias_clusters_0 =  np.empty((len(lista_clusters[0]), len(lista_clusters[0])))\n",
    "\n",
    "distancias_clusters_0[:] = 0\n",
    "\n",
    "for i in range(0, len(lista_clusters[0])) :\n",
    "\n",
    "    for r in  range(0, len(lista_clusters[0])) :\n",
    "\n",
    "            distancias_clusters_0[i,r] = sum( (lista_clusters[0].iloc[i , :] - lista_clusters[0].iloc[r , :])**2 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculamos la suma de la distancia entre x_i y el resto de observaciones, para cada i=1,..,n\n",
    "\n",
    "suma_distancias_cluster_0 = []\n",
    "\n",
    "for i in range(0, distancias_clusters_0.shape[0]):\n",
    "\n",
    "    suma_distancias_cluster_0.append( distancias_clusters_0[i,:].sum() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4883106009973739.0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min( suma_distancias_cluster_0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([409], dtype=int64),)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(suma_distancias_cluster_0 == min( suma_distancias_cluster_0 ) )\n",
    "\n",
    "# La observacion medioid del cluster 0 es la que ocupa la fila 409 de la matriz de distancias del cluster, que es la 1002 del cluster 0 (ver mas abajo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4883106009973739.0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suma_distancias_cluster_0[409]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1002"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista_clusters[0].iloc[409,].name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobamos que la observacion 1002 del cluster0 es la de la fila 409 d ela matriz de distancias, y por tanto es el medoid del cluster 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista=[]\n",
    "\n",
    "for r in lista_clusters[0].index :\n",
    "\n",
    "    lista.append( sum( (lista_clusters[0].loc[1002 , :] - lista_clusters[0].loc[r , :])**2 ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4883106009973739.0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(lista) # coincide con suma_distancias_cluster_0[409]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Usuario\\Documents\\fabio\\Fabio\\Estadistica4all.github.io\\Notebooks\\k-medias\\k-medias.ipynb Celda 32\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Usuario/Documents/fabio/Fabio/Estadistica4all.github.io/Notebooks/k-medias/k-medias.ipynb#Y262sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39mlen\u001b[39m(lista_clusters[\u001b[39m0\u001b[39m])) :\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Usuario/Documents/fabio/Fabio/Estadistica4all.github.io/Notebooks/k-medias/k-medias.ipynb#Y262sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39mfor\u001b[39;00m r \u001b[39min\u001b[39;00m  \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39mlen\u001b[39m(lista_clusters[\u001b[39m0\u001b[39m])) :\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Usuario/Documents/fabio/Fabio/Estadistica4all.github.io/Notebooks/k-medias/k-medias.ipynb#Y262sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m             distancias_clusters_0[i,r] \u001b[39m=\u001b[39m \u001b[39msum\u001b[39m( (lista_clusters[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49miloc[i , :] \u001b[39m-\u001b[39m lista_clusters[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39miloc[r , :])\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Usuario/Documents/fabio/Fabio/Estadistica4all.github.io/Notebooks/k-medias/k-medias.ipynb#Y262sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m# Calculamos la suma de la distancia entre x_i y el resto de observaciones, para cada i=1,..,n\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Usuario/Documents/fabio/Fabio/Estadistica4all.github.io/Notebooks/k-medias/k-medias.ipynb#Y262sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m suma_distancias_cluster_0 \u001b[39m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexing.py:961\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    959\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_scalar_access(key):\n\u001b[0;32m    960\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_get_value(\u001b[39m*\u001b[39mkey, takeable\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_takeable)\n\u001b[1;32m--> 961\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_tuple(key)\n\u001b[0;32m    962\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    963\u001b[0m     \u001b[39m# we by definition only have the 0th axis\u001b[39;00m\n\u001b[0;32m    964\u001b[0m     axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39mor\u001b[39;00m \u001b[39m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexing.py:1463\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_tuple\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m   1461\u001b[0m tup \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_tuple_indexer(tup)\n\u001b[0;32m   1462\u001b[0m \u001b[39mwith\u001b[39;00m suppress(IndexingError):\n\u001b[1;32m-> 1463\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_lowerdim(tup)\n\u001b[0;32m   1465\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_tuple_same_dim(tup)\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexing.py:867\u001b[0m, in \u001b[0;36m_LocationIndexer._getitem_lowerdim\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m    863\u001b[0m \u001b[39mfor\u001b[39;00m i, key \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(tup):\n\u001b[0;32m    864\u001b[0m     \u001b[39mif\u001b[39;00m is_label_like(key):\n\u001b[0;32m    865\u001b[0m         \u001b[39m# We don't need to check for tuples here because those are\u001b[39;00m\n\u001b[0;32m    866\u001b[0m         \u001b[39m#  caught by the _is_nested_tuple_indexer check above.\u001b[39;00m\n\u001b[1;32m--> 867\u001b[0m         section \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_axis(key, axis\u001b[39m=\u001b[39;49mi)\n\u001b[0;32m    869\u001b[0m         \u001b[39m# We should never have a scalar section here, because\u001b[39;00m\n\u001b[0;32m    870\u001b[0m         \u001b[39m#  _getitem_lowerdim is only called after a check for\u001b[39;00m\n\u001b[0;32m    871\u001b[0m         \u001b[39m#  is_scalar_access, which that would be.\u001b[39;00m\n\u001b[0;32m    872\u001b[0m         \u001b[39mif\u001b[39;00m section\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mndim:\n\u001b[0;32m    873\u001b[0m             \u001b[39m# we're in the middle of slicing through a MultiIndex\u001b[39;00m\n\u001b[0;32m    874\u001b[0m             \u001b[39m# revise the key wrt to `section` by inserting an _NS\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "distancias_clusters_0 =  np.empty((len(lista_clusters[0]), len(lista_clusters[0])))\n",
    "\n",
    "distancias_clusters_0[:] = 0\n",
    "\n",
    "for i in range(0, len(lista_clusters[0])) :\n",
    "\n",
    "    for r in  range(0, len(lista_clusters[0])) :\n",
    "\n",
    "            distancias_clusters_0[i,r] = sum( (lista_clusters[0].iloc[i , :] - lista_clusters[0].iloc[r , :])**2 )\n",
    "\n",
    "\n",
    "# Para el cluster 0 : calculamos la suma de la distancia entre x_i y el resto de observaciones, para cada i=1,..,n \n",
    "\n",
    "suma_distancias_cluster_0 = []\n",
    "\n",
    "for i in range(0, distancias_clusters_0.shape[0]):\n",
    "\n",
    "    suma_distancias_cluster_0.append( distancias_clusters_0[i,:].sum() )\n",
    "\n",
    "\n",
    "\n",
    "lista_clusters[0].iloc[ np.where(suma_distancias_cluster_0 == min( suma_distancias_cluster_0 ) ) , :].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distancias_clusters_1 =  np.empty((len(lista_clusters[1]), len(lista_clusters[1])))\n",
    "\n",
    "distancias_clusters_1[:] = 0\n",
    "\n",
    "for i in range(0, len(lista_clusters[1])) :\n",
    "\n",
    "    for r in  range(0, len(lista_clusters[1])) :\n",
    "\n",
    "            distancias_clusters_1[i,r] = sum( (lista_clusters[1].iloc[i , :] - lista_clusters[1].iloc[r , :])**2 )\n",
    "\n",
    "\n",
    "\n",
    "# Para el cluster 1 : calculamos la suma de la distancia entre x_i y el resto de observaciones, para cada i=1,..,n \n",
    "\n",
    "suma_distancias_cluster_1 = []\n",
    "\n",
    "for i in range(0, distancias_clusters_1.shape[0]):\n",
    "\n",
    "    suma_distancias_cluster_1.append( distancias_clusters_1[i,:].sum() )\n",
    "\n",
    "\n",
    "\n",
    "lista_clusters[1].iloc[ np.where(suma_distancias_cluster_1 == min( suma_distancias_cluster_1 ) ) , :].name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculo de centroides iniciales\n",
    "\n",
    "centroide_0 = lista_clusters[0].mean()\n",
    "centroide_1 = lista_clusters[1].mean()\n",
    "centroide_2 = lista_clusters[2].mean()\n",
    "centroide_3 = lista_clusters[3].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculo de distancias Euclideas para la observacion x_1\n",
    "\n",
    "x_1 = Data.iloc[0,:]\n",
    "\n",
    "distancia_0 = sum((x_1 - centroide_0)**2)\n",
    "distancia_1 = sum((x_1 - centroide_1)**2)\n",
    "distancia_2 = sum((x_1 - centroide_2)**2)\n",
    "distancia_3 = sum((x_1 - centroide_3)**2)\n",
    "\n",
    "# Calculo de cluster optimo para x_1\n",
    "\n",
    "df_distancias = pd.DataFrame({'Distancias' : [distancia_0, distancia_1 , distancia_2 , distancia_3], 'Cluster': [0,1,2,3]})\n",
    "\n",
    "df_distancias_sort = df_distancias.sort_values(by='Distancias', ascending=False)\n",
    "\n",
    "j_star = df_distancias_sort.iloc[0]['Cluster']\n",
    "\n",
    "j_star = int(j_star)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c63d8c7d738c2960218a10995aedf0a7f67a49a231e71037adf0440953cdb45b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
