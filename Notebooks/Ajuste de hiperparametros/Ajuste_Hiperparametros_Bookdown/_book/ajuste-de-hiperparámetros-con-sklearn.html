<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 4 Ajuste de hiperparámetros con sklearn | Ajuste de Hiperparámetros</title>
  <meta name="description" content="Introducción a los algoritmos de ajuste de hiperparámetro, aplicados a modelos de aprendizaje supervisado." />
  <meta name="generator" content="bookdown 0.32 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 4 Ajuste de hiperparámetros con sklearn | Ajuste de Hiperparámetros" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="Introducción a los algoritmos de ajuste de hiperparámetro, aplicados a modelos de aprendizaje supervisado." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 4 Ajuste de hiperparámetros con sklearn | Ajuste de Hiperparámetros" />
  
  <meta name="twitter:description" content="Introducción a los algoritmos de ajuste de hiperparámetro, aplicados a modelos de aprendizaje supervisado." />
  

<meta name="author" content="Fabio Scielzo Ortiz" />


<meta name="date" content="2023-03-15" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="grid-search-y-random-search-programados-en-python.html"/>
<link rel="next" href="bibliografía.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Ajuste de Hiperparámetros</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introducción</a></li>
<li class="chapter" data-level="2" data-path="grid-search-y-random-search.html"><a href="grid-search-y-random-search.html"><i class="fa fa-check"></i><b>2</b> Grid Search y Random Search</a>
<ul>
<li class="chapter" data-level="2.1" data-path="grid-search-y-random-search.html"><a href="grid-search-y-random-search.html#algoritmo-grid-search"><i class="fa fa-check"></i><b>2.1</b> Algoritmo Grid Search</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="grid-search-y-random-search.html"><a href="grid-search-y-random-search.html#cómo-definir-el-espacio-de-búsqueda-hspace0.03cmshspace0.03cm"><i class="fa fa-check"></i><b>2.1.1</b> ¿ Cómo definir el espacio de búsqueda <span class="math inline">\(\hspace{0.03cm}S\hspace{0.03cm}\)</span> ?</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="grid-search-y-random-search-programados-en-python.html"><a href="grid-search-y-random-search-programados-en-python.html"><i class="fa fa-check"></i><b>3</b> Grid Search y Random Search programados en <code>Python</code></a>
<ul>
<li class="chapter" data-level="3.1" data-path="grid-search-y-random-search-programados-en-python.html"><a href="grid-search-y-random-search-programados-en-python.html#algoritmos-de-validación-en-python"><i class="fa fa-check"></i><b>3.1</b> Algoritmos de validación en <code>Python</code></a></li>
<li class="chapter" data-level="3.2" data-path="grid-search-y-random-search-programados-en-python.html"><a href="grid-search-y-random-search-programados-en-python.html#grid-search-y-random-search-en-python"><i class="fa fa-check"></i><b>3.2</b> Grid Search y Random Search en <code>Python</code></a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="grid-search-y-random-search-programados-en-python.html"><a href="grid-search-y-random-search-programados-en-python.html#grid-search---k-fold---regression"><i class="fa fa-check"></i><b>3.2.1</b> Grid Search - K-Fold - Regression</a></li>
<li class="chapter" data-level="3.2.2" data-path="grid-search-y-random-search-programados-en-python.html"><a href="grid-search-y-random-search-programados-en-python.html#random-search---k-fold---regression"><i class="fa fa-check"></i><b>3.2.2</b> Random Search - K-Fold - Regression</a></li>
<li class="chapter" data-level="3.2.3" data-path="grid-search-y-random-search-programados-en-python.html"><a href="grid-search-y-random-search-programados-en-python.html#grid-search---k-fold---classification"><i class="fa fa-check"></i><b>3.2.3</b> Grid Search - K-Fold - Classification</a></li>
<li class="chapter" data-level="3.2.4" data-path="grid-search-y-random-search-programados-en-python.html"><a href="grid-search-y-random-search-programados-en-python.html#random-search---k-fold---classification"><i class="fa fa-check"></i><b>3.2.4</b> Random Search - K-Fold - Classification</a></li>
<li class="chapter" data-level="3.2.5" data-path="grid-search-y-random-search-programados-en-python.html"><a href="grid-search-y-random-search-programados-en-python.html#grid-search---repeated-k-fold---regression"><i class="fa fa-check"></i><b>3.2.5</b> Grid Search - Repeated K-Fold - Regression</a></li>
<li class="chapter" data-level="3.2.6" data-path="grid-search-y-random-search-programados-en-python.html"><a href="grid-search-y-random-search-programados-en-python.html#random-search---repeated-k-fold---regression"><i class="fa fa-check"></i><b>3.2.6</b> Random Search - Repeated K-Fold - Regression</a></li>
<li class="chapter" data-level="3.2.7" data-path="grid-search-y-random-search-programados-en-python.html"><a href="grid-search-y-random-search-programados-en-python.html#grid-search---repeted-k-fold---classification"><i class="fa fa-check"></i><b>3.2.7</b> Grid Search - Repeted K-Fold - Classification</a></li>
<li class="chapter" data-level="3.2.8" data-path="grid-search-y-random-search-programados-en-python.html"><a href="grid-search-y-random-search-programados-en-python.html#random-search---repeated-k-fold---classification"><i class="fa fa-check"></i><b>3.2.8</b> Random Search - Repeated K-Fold - Classification</a></li>
<li class="chapter" data-level="3.2.9" data-path="grid-search-y-random-search-programados-en-python.html"><a href="grid-search-y-random-search-programados-en-python.html#grid-search---repeated-random-simple-validation---regression"><i class="fa fa-check"></i><b>3.2.9</b> Grid Search - Repeated Random Simple Validation - Regression</a></li>
<li class="chapter" data-level="3.2.10" data-path="grid-search-y-random-search-programados-en-python.html"><a href="grid-search-y-random-search-programados-en-python.html#random-search---repeated-simple-validation---regression"><i class="fa fa-check"></i><b>3.2.10</b> Random Search - Repeated Simple Validation - Regression</a></li>
<li class="chapter" data-level="3.2.11" data-path="grid-search-y-random-search-programados-en-python.html"><a href="grid-search-y-random-search-programados-en-python.html#grid-search---repeated-simple-validation---classification"><i class="fa fa-check"></i><b>3.2.11</b> Grid Search - Repeated Simple Validation - Classification</a></li>
<li class="chapter" data-level="3.2.12" data-path="grid-search-y-random-search-programados-en-python.html"><a href="grid-search-y-random-search-programados-en-python.html#random-search---repeated-simple-validation---classification"><i class="fa fa-check"></i><b>3.2.12</b> Random Search - Repeated Simple Validation - Classification</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="grid-search-y-random-search-programados-en-python.html"><a href="grid-search-y-random-search-programados-en-python.html#visualización-de-resultados"><i class="fa fa-check"></i><b>3.3</b> Visualización de resultados</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="ajuste-de-hiperparámetros-con-sklearn.html"><a href="ajuste-de-hiperparámetros-con-sklearn.html"><i class="fa fa-check"></i><b>4</b> Ajuste de hiperparámetros con <code>sklearn</code></a>
<ul>
<li class="chapter" data-level="4.1" data-path="ajuste-de-hiperparámetros-con-sklearn.html"><a href="ajuste-de-hiperparámetros-con-sklearn.html#grid-search-con-sklearn"><i class="fa fa-check"></i><b>4.1</b> Grid search con <code>sklearn</code></a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="ajuste-de-hiperparámetros-con-sklearn.html"><a href="ajuste-de-hiperparámetros-con-sklearn.html#gridsearchcv---regression"><i class="fa fa-check"></i><b>4.1.1</b> GridSearchCV - Regression</a></li>
<li class="chapter" data-level="4.1.2" data-path="ajuste-de-hiperparámetros-con-sklearn.html"><a href="ajuste-de-hiperparámetros-con-sklearn.html#gridsearchcv---classification"><i class="fa fa-check"></i><b>4.1.2</b> GridSearchCV - Classification</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="ajuste-de-hiperparámetros-con-sklearn.html"><a href="ajuste-de-hiperparámetros-con-sklearn.html#random-search-con-sklearn"><i class="fa fa-check"></i><b>4.2</b> Random search con <code>sklearn</code></a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="ajuste-de-hiperparámetros-con-sklearn.html"><a href="ajuste-de-hiperparámetros-con-sklearn.html#randomizedsearchcv---regression"><i class="fa fa-check"></i><b>4.2.1</b> <code>RandomizedSearchCV</code> - Regression</a></li>
<li class="chapter" data-level="4.2.2" data-path="ajuste-de-hiperparámetros-con-sklearn.html"><a href="ajuste-de-hiperparámetros-con-sklearn.html#randomizedsearchcv---classification"><i class="fa fa-check"></i><b>4.2.2</b> <code>RandomizedSearchCV</code> - Classification</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="ajuste-de-hiperparámetros-con-sklearn.html"><a href="ajuste-de-hiperparámetros-con-sklearn.html#visualización-de-resultados-1"><i class="fa fa-check"></i><b>4.3</b> Visualización de resultados</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="bibliografía.html"><a href="bibliografía.html"><i class="fa fa-check"></i><b>5</b> Bibliografía</a></li>
<li class="divider"></li>
<li><a href="https://estadistica4all.com" target="blank">Estadistica4all.com</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Ajuste de Hiperparámetros</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="ajuste-de-hiperparámetros-con-sklearn" class="section level1 hasAnchor" number="4">
<h1><span class="header-section-number">Chapter 4</span> Ajuste de hiperparámetros con <code>sklearn</code><a href="ajuste-de-hiperparámetros-con-sklearn.html#ajuste-de-hiperparámetros-con-sklearn" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="grid-search-con-sklearn" class="section level2 hasAnchor" number="4.1">
<h2><span class="header-section-number">4.1</span> Grid search con <code>sklearn</code><a href="ajuste-de-hiperparámetros-con-sklearn.html#grid-search-con-sklearn" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>La función que vamos a utilizar para aplicar el algoritmo de ajuste de hiper-parámetros Grid Search es <code>GridSearchCV</code>, de la libreria <code>sklearn</code>.</p>
<p>Esta función tiene, entre otros, los siguientes parámetros:</p>
<ul>
<li><p>estimator: es el modelo que cuyos hiper-parámetros quieren ajustarse.</p></li>
<li><p>param_grid: es un diccionario con los valores considerados para cada uno de los hiper-parámetros del modelo.</p></li>
<li><p>cv: esta función utiliza como algoritmo de validación el K-Fold. cv es el parámetro K, es decir, el número de folds.</p></li>
<li><p>scoring: es la métrica de validación que usará el algoritmo.</p></li>
</ul>
<p><br></p>
<p>Importamos la función <code>GridSearchCV</code>:</p>
<div class="sourceCode" id="cb49"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb49-1"><a href="ajuste-de-hiperparámetros-con-sklearn.html#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> GridSearchCV</span></code></pre></div>
<p><br></p>
<div id="gridsearchcv---regression" class="section level3 hasAnchor" number="4.1.1">
<h3><span class="header-section-number">4.1.1</span> GridSearchCV - Regression<a href="ajuste-de-hiperparámetros-con-sklearn.html#gridsearchcv---regression" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>En este primer ejemplo vamos a utilizar como modelo el KNN para <em>regresión</em>.</p>
<div class="sourceCode" id="cb50"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb50-1"><a href="ajuste-de-hiperparámetros-con-sklearn.html#cb50-1" aria-hidden="true" tabindex="-1"></a>knn_regression <span class="op">=</span> sklearn.neighbors.KNeighborsRegressor( )</span></code></pre></div>
<p><br></p>
<p>Inicializamos la función <code>GridSearchCV</code> con los siguientes parametros:</p>
<div class="sourceCode" id="cb51"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb51-1"><a href="ajuste-de-hiperparámetros-con-sklearn.html#cb51-1" aria-hidden="true" tabindex="-1"></a>grid_search <span class="op">=</span> GridSearchCV(estimator <span class="op">=</span> knn_regression, param_grid <span class="op">=</span> {<span class="st">&#39;n_neighbors&#39;</span>: <span class="bu">range</span>(<span class="dv">1</span>,<span class="dv">200</span>), <span class="st">&#39;metric&#39;</span>: [<span class="st">&#39;euclidean&#39;</span>,<span class="st">&#39;cosine&#39;</span>,<span class="st">&#39;cityblock&#39;</span>,<span class="st">&#39;manhattan&#39;</span>]}, cv <span class="op">=</span> <span class="dv">10</span>, scoring<span class="op">=</span><span class="st">&#39;neg_mean_squared_error&#39;</span>)</span></code></pre></div>
<p><br></p>
<p>Creamos un array con la variable respuesta, que en este caso es <em>price</em>, y un data-frame con los predictores, que serán el resto de variables del data-set con el que estamos trabajando:</p>
<div class="sourceCode" id="cb52"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb52-1"><a href="ajuste-de-hiperparámetros-con-sklearn.html#cb52-1" aria-hidden="true" tabindex="-1"></a>Y <span class="op">=</span> Data.loc[:,<span class="st">&#39;price&#39;</span>]</span>
<span id="cb52-2"><a href="ajuste-de-hiperparámetros-con-sklearn.html#cb52-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-3"><a href="ajuste-de-hiperparámetros-con-sklearn.html#cb52-3" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> Data.loc[:, Data.columns <span class="op">!=</span> <span class="st">&#39;price&#39;</span>]</span></code></pre></div>
<p><br></p>
<p>Ajustamos la función <code>GridSearchCV</code> con los datos de <code>Y</code> y <code>X</code> usando el método <code>fit</code></p>
<div class="sourceCode" id="cb53"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb53-1"><a href="ajuste-de-hiperparámetros-con-sklearn.html#cb53-1" aria-hidden="true" tabindex="-1"></a>grid_search.fit(X,Y)</span></code></pre></div>
<p><br></p>
<p>Podemos acceder a alguna información relevante tras ajustar la función con los datos.</p>
<ul>
<li>La combinación de hiper-parámetros óptimos:</li>
</ul>
<div class="sourceCode" id="cb54"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb54-1"><a href="ajuste-de-hiperparámetros-con-sklearn.html#cb54-1" aria-hidden="true" tabindex="-1"></a>grid_search.best_params_</span></code></pre></div>
<pre><code>{&#39;metric&#39;: &#39;cosine&#39;, &#39;n_neighbors&#39;: 17}</code></pre>
<p><br></p>
<ul>
<li>El valor de la métrica que se ha considerado para esa combinación de hiper-parámetros óptimos:</li>
</ul>
<div class="sourceCode" id="cb56"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb56-1"><a href="ajuste-de-hiperparámetros-con-sklearn.html#cb56-1" aria-hidden="true" tabindex="-1"></a>grid_search.best_score_</span></code></pre></div>
<pre><code>-2278523570223.8994</code></pre>
<p><br></p>
<p>Podemos crear un data-frame con las distintas combinaciones de valores de los hiper-parámetros que han sido utilizadas y el valor de la métrica de validación que se ha obtenido para cada una de esas combinaciones. Esto es justamente lo que nos devolvía nuestra función programada en la sección anterior.</p>
<div class="sourceCode" id="cb58"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb58-1"><a href="ajuste-de-hiperparámetros-con-sklearn.html#cb58-1" aria-hidden="true" tabindex="-1"></a>df_grid_search_sklearn <span class="op">=</span> pd.DataFrame({<span class="st">&#39;k&#39;</span>: grid_search.cv_results_[<span class="st">&#39;param_n_neighbors&#39;</span>], <span class="st">&#39;distance&#39;</span>: grid_search.cv_results_[<span class="st">&#39;param_metric&#39;</span>] , <span class="st">&#39;ECM&#39;</span>: <span class="op">-</span> grid_search.cv_results_[<span class="st">&#39;mean_test_score&#39;</span>]})</span>
<span id="cb58-2"><a href="ajuste-de-hiperparámetros-con-sklearn.html#cb58-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-3"><a href="ajuste-de-hiperparámetros-con-sklearn.html#cb58-3" aria-hidden="true" tabindex="-1"></a>df_grid_search_sklearn <span class="op">=</span> df_grid_search_sklearn.sort_values(by<span class="op">=</span><span class="st">&#39;ECM&#39;</span>, ascending<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb58-4"><a href="ajuste-de-hiperparámetros-con-sklearn.html#cb58-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-5"><a href="ajuste-de-hiperparámetros-con-sklearn.html#cb58-5" aria-hidden="true" tabindex="-1"></a>df_grid_search_sklearn</span></code></pre></div>
<div style="width: 100%; overflow-x: auto;">
<table border="1" class="dataframe">
<thead>
<tr style="text-align: left;">
<th>
</th>
<th style="text-align: left;">
k
</th>
<th style="text-align: left;">
distance
</th>
<th style="text-align: left;">
ECM
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
215
</th>
<td>
17
</td>
<td>
cosine
</td>
<td>
2.278524e+12
</td>
</tr>
<tr>
<th>
209
</th>
<td>
11
</td>
<td>
cosine
</td>
<td>
2.287579e+12
</td>
</tr>
<tr>
<th>
214
</th>
<td>
16
</td>
<td>
cosine
</td>
<td>
2.300468e+12
</td>
</tr>
<tr>
<th>
216
</th>
<td>
18
</td>
<td>
cosine
</td>
<td>
2.305225e+12
</td>
</tr>
<tr>
<th>
210
</th>
<td>
12
</td>
<td>
cosine
</td>
<td>
2.308334e+12
</td>
</tr>
<tr>
<th>
…
</th>
<td>
…
</td>
<td>
…
</td>
<td>
…
</td>
</tr>
<tr>
<th>
794
</th>
<td>
198
</td>
<td>
manhattan
</td>
<td>
5.264590e+12
</td>
</tr>
<tr>
<th>
197
</th>
<td>
198
</td>
<td>
euclidean
</td>
<td>
5.266036e+12
</td>
</tr>
<tr>
<th>
198
</th>
<td>
199
</td>
<td>
euclidean
</td>
<td>
5.272047e+12
</td>
</tr>
<tr>
<th>
596
</th>
<td>
199
</td>
<td>
cityblock
</td>
<td>
5.273960e+12
</td>
</tr>
<tr>
<th>
795
</th>
<td>
199
</td>
<td>
manhattan
</td>
<td>
5.273960e+12
</td>
</tr>
</tbody>
</table>
<p>
796 rows × 3 columns
</p>
</div>
<p><br></p>
<p>Realizamos algunos cambios orientados a una mejor visualización gráfica posterior.</p>
<div class="sourceCode" id="cb59"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb59-1"><a href="ajuste-de-hiperparámetros-con-sklearn.html#cb59-1" aria-hidden="true" tabindex="-1"></a>df_grid_search_sklearn[<span class="st">&#39;k&#39;</span>] <span class="op">=</span> df_grid_search_sklearn[<span class="st">&#39;k&#39;</span>].astype(<span class="bu">str</span>) </span>
<span id="cb59-2"><a href="ajuste-de-hiperparámetros-con-sklearn.html#cb59-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-3"><a href="ajuste-de-hiperparámetros-con-sklearn.html#cb59-3" aria-hidden="true" tabindex="-1"></a>df_grid_search_sklearn[<span class="st">&#39;distance&#39;</span>] <span class="op">=</span> df_grid_search_sklearn[<span class="st">&#39;distance&#39;</span>].astype(<span class="bu">str</span>)</span>
<span id="cb59-4"><a href="ajuste-de-hiperparámetros-con-sklearn.html#cb59-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-5"><a href="ajuste-de-hiperparámetros-con-sklearn.html#cb59-5" aria-hidden="true" tabindex="-1"></a>df_grid_search_sklearn[<span class="st">&#39;k-distance&#39;</span>] <span class="op">=</span> df_grid_search_sklearn[[<span class="st">&#39;k&#39;</span>, <span class="st">&#39;distance&#39;</span>]].agg(<span class="st">&#39;-&#39;</span>.join, axis<span class="op">=</span><span class="dv">1</span>)</span></code></pre></div>
<p><br></p>
</div>
<div id="gridsearchcv---classification" class="section level3 hasAnchor" number="4.1.2">
<h3><span class="header-section-number">4.1.2</span> GridSearchCV - Classification<a href="ajuste-de-hiperparámetros-con-sklearn.html#gridsearchcv---classification" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Ahora vamos a aplicar la función <code>GridSearchCV</code> al modelo KNN para clasificación.</p>
<div class="sourceCode" id="cb60"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb60-1"><a href="ajuste-de-hiperparámetros-con-sklearn.html#cb60-1" aria-hidden="true" tabindex="-1"></a>knn_classification <span class="op">=</span> sklearn.neighbors.KNeighborsClassifier( )</span></code></pre></div>
<p>Inicializamos los parámetros de la función <code>GridSearchCV</code>:</p>
<div class="sourceCode" id="cb61"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb61-1"><a href="ajuste-de-hiperparámetros-con-sklearn.html#cb61-1" aria-hidden="true" tabindex="-1"></a>grid_search <span class="op">=</span> GridSearchCV(estimator <span class="op">=</span> knn_classification, param_grid <span class="op">=</span> {<span class="st">&#39;n_neighbors&#39;</span>: <span class="bu">range</span>(<span class="dv">1</span>,<span class="dv">200</span>), <span class="st">&#39;metric&#39;</span>: [<span class="st">&#39;euclidean&#39;</span>,<span class="st">&#39;cosine&#39;</span>,<span class="st">&#39;cityblock&#39;</span>,<span class="st">&#39;manhattan&#39;</span>]}, cv <span class="op">=</span> <span class="dv">10</span>, scoring<span class="op">=</span><span class="st">&#39;accuracy&#39;</span>)</span></code></pre></div>
<p>Creamos un array con la variable respuesta, que en este caso es <em>quality_recode</em>, y un data-frame con los predictores, que serán el resto de variables del data-set con el que estamos trabajando:</p>
<div class="sourceCode" id="cb62"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb62-1"><a href="ajuste-de-hiperparámetros-con-sklearn.html#cb62-1" aria-hidden="true" tabindex="-1"></a>Y <span class="op">=</span> Data.loc[:,<span class="st">&#39;quality_recode&#39;</span>]</span>
<span id="cb62-2"><a href="ajuste-de-hiperparámetros-con-sklearn.html#cb62-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-3"><a href="ajuste-de-hiperparámetros-con-sklearn.html#cb62-3" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> Data.loc[:, Data.columns <span class="op">!=</span> <span class="st">&#39;quality_recode&#39;</span>]</span></code></pre></div>
<p>Podemos acceder a alguna información relevante tras ajustar la función con los datos.</p>
<p>La combinación de hiper-parámetros óptimos:</p>
<div class="sourceCode" id="cb63"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb63-1"><a href="ajuste-de-hiperparámetros-con-sklearn.html#cb63-1" aria-hidden="true" tabindex="-1"></a>grid_search.fit(X,Y)</span></code></pre></div>
<div class="sourceCode" id="cb64"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb64-1"><a href="ajuste-de-hiperparámetros-con-sklearn.html#cb64-1" aria-hidden="true" tabindex="-1"></a>grid_search.best_estimator_</span></code></pre></div>
<pre><code>{&#39;metric&#39;: &#39;euclidean&#39;, &#39;n_neighbors&#39;: 34}</code></pre>
<p>El valor de la métrica que se ha considerado para esa combinación de hiper-parámetros óptimos:</p>
<div class="sourceCode" id="cb66"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb66-1"><a href="ajuste-de-hiperparámetros-con-sklearn.html#cb66-1" aria-hidden="true" tabindex="-1"></a>grid_search.best_params_</span></code></pre></div>
<pre><code>0.6036731882061174</code></pre>
<p>Podemos crear un data-frame con las distintas combinaciones de valores de los hiper-parámetros que han sido utilizadas y el valor de la métrica de validación que se ha obtenido para cada una de esas combinaciones. Esto es justamente lo que nos devolvía nuestra función programada en la sección anterior.</p>
<div class="sourceCode" id="cb68"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb68-1"><a href="ajuste-de-hiperparámetros-con-sklearn.html#cb68-1" aria-hidden="true" tabindex="-1"></a>df_grid_search_sklearn <span class="op">=</span> pd.DataFrame({<span class="st">&#39;k&#39;</span>: grid_search.cv_results_[<span class="st">&#39;param_n_neighbors&#39;</span>], <span class="st">&#39;distance&#39;</span>: grid_search.cv_results_[<span class="st">&#39;param_metric&#39;</span>] , <span class="st">&#39;TAC&#39;</span>: grid_search.cv_results_[<span class="st">&#39;mean_test_score&#39;</span>]})</span>
<span id="cb68-2"><a href="ajuste-de-hiperparámetros-con-sklearn.html#cb68-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-3"><a href="ajuste-de-hiperparámetros-con-sklearn.html#cb68-3" aria-hidden="true" tabindex="-1"></a>df_grid_search_sklearn <span class="op">=</span> df_grid_search_sklearn.sort_values(by<span class="op">=</span><span class="st">&#39;TAC&#39;</span>, ascending<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb68-4"><a href="ajuste-de-hiperparámetros-con-sklearn.html#cb68-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-5"><a href="ajuste-de-hiperparámetros-con-sklearn.html#cb68-5" aria-hidden="true" tabindex="-1"></a>df_grid_search_sklearn</span></code></pre></div>
<div style="width: 100%; overflow-x: auto;">
<table border="1" class="dataframe">
<thead>
<tr style="text-align: left;">
<th>
</th>
<th style="text-align: left;">
k
</th>
<th style="text-align: left;">
distance
</th>
<th style="text-align: left;">
ECM
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
33
</th>
<td>
34
</td>
<td>
euclidean
</td>
<td>
0.603673
</td>
</tr>
<tr>
<th>
160
</th>
<td>
161
</td>
<td>
euclidean
</td>
<td>
0.601573
</td>
</tr>
<tr>
<th>
158
</th>
<td>
159
</td>
<td>
euclidean
</td>
<td>
0.601573
</td>
</tr>
<tr>
<th>
157
</th>
<td>
158
</td>
<td>
euclidean
</td>
<td>
0.601573
</td>
</tr>
<tr>
<th>
156
</th>
<td>
157
</td>
<td>
euclidean
</td>
<td>
0.601573
</td>
</tr>
<tr>
<th>
…
</th>
<td>
…
</td>
<td>
…
</td>
<td>
…
</td>
</tr>
<tr>
<th>
600
</th>
<td>
4
</td>
<td>
manhattan
</td>
<td>
0.460890
</td>
</tr>
<tr>
<th>
200
</th>
<td>
2
</td>
<td>
cosine
</td>
<td>
0.410485
</td>
</tr>
<tr>
<th>
598
</th>
<td>
2
</td>
<td>
manhattan
</td>
<td>
0.394762
</td>
</tr>
<tr>
<th>
399
</th>
<td>
2
</td>
<td>
cityblock
</td>
<td>
0.394762
</td>
</tr>
<tr>
<th>
1
</th>
<td>
2
</td>
<td>
euclidean
</td>
<td>
0.384260
</td>
</tr>
</tbody>
</table>
<p>
796 rows × 3 columns
</p>
</div>
<p>Hacemos algunos cambios orientados a una mejor visualización gráfica posterior:</p>
<div class="sourceCode" id="cb69"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb69-1"><a href="ajuste-de-hiperparámetros-con-sklearn.html#cb69-1" aria-hidden="true" tabindex="-1"></a>df_grid_search_sklearn[<span class="st">&#39;k&#39;</span>] <span class="op">=</span> df_grid_search_sklearn[<span class="st">&#39;k&#39;</span>].astype(<span class="bu">str</span>) </span>
<span id="cb69-2"><a href="ajuste-de-hiperparámetros-con-sklearn.html#cb69-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-3"><a href="ajuste-de-hiperparámetros-con-sklearn.html#cb69-3" aria-hidden="true" tabindex="-1"></a>df_grid_search_sklearn[<span class="st">&#39;distance&#39;</span>] <span class="op">=</span> df_grid_search_sklearn[<span class="st">&#39;distance&#39;</span>].astype(<span class="bu">str</span>)</span>
<span id="cb69-4"><a href="ajuste-de-hiperparámetros-con-sklearn.html#cb69-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-5"><a href="ajuste-de-hiperparámetros-con-sklearn.html#cb69-5" aria-hidden="true" tabindex="-1"></a>df_grid_search_sklearn[<span class="st">&#39;k-distance&#39;</span>] <span class="op">=</span> df_grid_search_sklearn[[<span class="st">&#39;k&#39;</span>, <span class="st">&#39;distance&#39;</span>]].agg(<span class="st">&#39;-&#39;</span>.join, axis<span class="op">=</span><span class="dv">1</span>)</span></code></pre></div>
<p><br></p>
</div>
</div>
<div id="random-search-con-sklearn" class="section level2 hasAnchor" number="4.2">
<h2><span class="header-section-number">4.2</span> Random search con <code>sklearn</code><a href="ajuste-de-hiperparámetros-con-sklearn.html#random-search-con-sklearn" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>La función que vamos a utilizar para aplicar el algoritmo de ajuste de hiper-parámetros Grid Search es <code>RandomizedSearchCV</code>, de la libreria <code>sklearn</code>.</p>
<p>Esta función tiene, entre otros, los siguientes parámetros:</p>
<ul>
<li><p>estimator: es el modelo que cuyos hiper-parámetros quieren ajustarse.</p></li>
<li><p>param_distributions: es un diccionario con los valores considerados para cada uno de los hiper-parámetros del modelo.</p></li>
<li><p>cv: esta función utiliza como algoritmo de validación el K-Fold. cv es el parámetro K, es decir, el número de folds.</p></li>
<li><p>scoring: es la métrica de validación que usará el algoritmo.</p></li>
<li><p>n_iter: es el número de combinaciones de hiper-paramétros que se van a seleccionar aleatoriamente.</p></li>
<li><p>random_state: es la semilla aleatoria de la parte aleatoria que tiene el algoritmo Random Search.</p></li>
</ul>
<p><br></p>
<p>Importamos la función <code>RandomizedSearchCV</code> de la librería <code>sklearn</code>:</p>
<div class="sourceCode" id="cb70"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb70-1"><a href="ajuste-de-hiperparámetros-con-sklearn.html#cb70-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> RandomizedSearchCV</span></code></pre></div>
<p><br></p>
<div id="randomizedsearchcv---regression" class="section level3 hasAnchor" number="4.2.1">
<h3><span class="header-section-number">4.2.1</span> <code>RandomizedSearchCV</code> - Regression<a href="ajuste-de-hiperparámetros-con-sklearn.html#randomizedsearchcv---regression" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Inicializamos algunos parámetros de la función <code>RandomizedSearchCV</code>:</p>
<div class="sourceCode" id="cb71"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb71-1"><a href="ajuste-de-hiperparámetros-con-sklearn.html#cb71-1" aria-hidden="true" tabindex="-1"></a>random_search <span class="op">=</span> RandomizedSearchCV(estimator <span class="op">=</span> knn_regression, param_distributions <span class="op">=</span> {<span class="st">&#39;n_neighbors&#39;</span>: <span class="bu">range</span>(<span class="dv">1</span>,<span class="dv">200</span>), <span class="st">&#39;metric&#39;</span>: [<span class="st">&#39;euclidean&#39;</span>,<span class="st">&#39;cosine&#39;</span>,<span class="st">&#39;cityblock&#39;</span>,<span class="st">&#39;manhattan&#39;</span>]}, cv <span class="op">=</span> <span class="dv">10</span>, n_iter<span class="op">=</span><span class="dv">100</span>, random_state<span class="op">=</span><span class="dv">123</span>, scoring<span class="op">=</span><span class="st">&#39;neg_mean_squared_error&#39;</span>)</span></code></pre></div>
<p><br></p>
<p>Creamos un array con la variable respuesta, que en este caso es <em>price</em>, y un data-frame con los predictores, que serán el resto de variables del data-set con el que estamos trabajando:</p>
<div class="sourceCode" id="cb72"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb72-1"><a href="ajuste-de-hiperparámetros-con-sklearn.html#cb72-1" aria-hidden="true" tabindex="-1"></a>Y <span class="op">=</span> Data.loc[:,<span class="st">&#39;price&#39;</span>]</span>
<span id="cb72-2"><a href="ajuste-de-hiperparámetros-con-sklearn.html#cb72-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-3"><a href="ajuste-de-hiperparámetros-con-sklearn.html#cb72-3" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> Data.loc[:, Data.columns <span class="op">!=</span> <span class="st">&#39;price&#39;</span>]</span></code></pre></div>
<p><br></p>
<p>Entrenamos la función <code>RandomizedSearchCV</code> con los datos :</p>
<div class="sourceCode" id="cb73"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb73-1"><a href="ajuste-de-hiperparámetros-con-sklearn.html#cb73-1" aria-hidden="true" tabindex="-1"></a>random_search.fit(X,Y)</span></code></pre></div>
<p><br></p>
<p>Podemos crear un data-frame con las distintas combinaciones de valores de los hiper-parámetros que han sido utilizadas y el valor de la métrica de validación que se ha obtenido para cada una de esas combinaciones. Esto es justamente lo que nos devolvía nuestra función programada en la sección anterior.</p>
<div class="sourceCode" id="cb74"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb74-1"><a href="ajuste-de-hiperparámetros-con-sklearn.html#cb74-1" aria-hidden="true" tabindex="-1"></a>df_random_search_sklearn <span class="op">=</span> pd.DataFrame({<span class="st">&#39;k&#39;</span>: random_search.cv_results_[<span class="st">&#39;param_n_neighbors&#39;</span>], <span class="st">&#39;distance&#39;</span>: random_search.cv_results_[<span class="st">&#39;param_metric&#39;</span>] , <span class="st">&#39;ECM&#39;</span>: <span class="op">-</span> random_search.cv_results_[<span class="st">&#39;mean_test_score&#39;</span>]})</span>
<span id="cb74-2"><a href="ajuste-de-hiperparámetros-con-sklearn.html#cb74-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-3"><a href="ajuste-de-hiperparámetros-con-sklearn.html#cb74-3" aria-hidden="true" tabindex="-1"></a>df_random_search_sklearn <span class="op">=</span> df_random_search_sklearn.sort_values(by<span class="op">=</span><span class="st">&#39;ECM&#39;</span>, ascending<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb74-4"><a href="ajuste-de-hiperparámetros-con-sklearn.html#cb74-4" aria-hidden="true" tabindex="-1"></a>df_random_search_sklearn</span></code></pre></div>
<div style="width: 100%; overflow-x: auto;">
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th style="text-align: left;">
k
</th>
<th style="text-align: left;">
distance
</th>
<th style="text-align: left;">
ECM
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
18
</th>
<td>
11
</td>
<td>
cosine
</td>
<td>
2.287579e+12
</td>
</tr>
<tr>
<th>
38
</th>
<td>
11
</td>
<td>
manhattan
</td>
<td>
2.321534e+12
</td>
</tr>
<tr>
<th>
91
</th>
<td>
14
</td>
<td>
euclidean
</td>
<td>
2.334281e+12
</td>
</tr>
<tr>
<th>
84
</th>
<td>
19
</td>
<td>
cosine
</td>
<td>
2.337300e+12
</td>
</tr>
<tr>
<th>
78
</th>
<td>
12
</td>
<td>
euclidean
</td>
<td>
2.339571e+12
</td>
</tr>
<tr>
<th>
…
</th>
<td>
…
</td>
<td>
…
</td>
<td>
…
</td>
</tr>
<tr>
<th>
60
</th>
<td>
189
</td>
<td>
cityblock
</td>
<td>
5.180324e+12
</td>
</tr>
<tr>
<th>
43
</th>
<td>
189
</td>
<td>
euclidean
</td>
<td>
5.182189e+12
</td>
</tr>
<tr>
<th>
46
</th>
<td>
190
</td>
<td>
cityblock
</td>
<td>
5.187852e+12
</td>
</tr>
<tr>
<th>
17
</th>
<td>
194
</td>
<td>
manhattan
</td>
<td>
5.227831e+12
</td>
</tr>
<tr>
<th>
27
</th>
<td>
196
</td>
<td>
euclidean
</td>
<td>
5.247368e+12
</td>
</tr>
</tbody>
</table>
<p>
100 rows × 3 columns
</p>
</div>
<p><br></p>
<p>Realizamos cambios para una posterior mejor visualización gráfica:</p>
<div class="sourceCode" id="cb75"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb75-1"><a href="ajuste-de-hiperparámetros-con-sklearn.html#cb75-1" aria-hidden="true" tabindex="-1"></a>df_random_search_sklearn[<span class="st">&#39;k&#39;</span>] <span class="op">=</span> df_random_search_sklearn[<span class="st">&#39;k&#39;</span>].astype(<span class="bu">str</span>) </span>
<span id="cb75-2"><a href="ajuste-de-hiperparámetros-con-sklearn.html#cb75-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-3"><a href="ajuste-de-hiperparámetros-con-sklearn.html#cb75-3" aria-hidden="true" tabindex="-1"></a>df_random_search_sklearn[<span class="st">&#39;distance&#39;</span>] <span class="op">=</span> df_random_search_sklearn[<span class="st">&#39;distance&#39;</span>].astype(<span class="bu">str</span>)</span>
<span id="cb75-4"><a href="ajuste-de-hiperparámetros-con-sklearn.html#cb75-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-5"><a href="ajuste-de-hiperparámetros-con-sklearn.html#cb75-5" aria-hidden="true" tabindex="-1"></a>df_random_search_sklearn[<span class="st">&#39;k-distance&#39;</span>] <span class="op">=</span> df_random_search_sklearn[[<span class="st">&#39;k&#39;</span>, <span class="st">&#39;distance&#39;</span>]].agg(<span class="st">&#39;-&#39;</span>.join, axis<span class="op">=</span><span class="dv">1</span>)</span></code></pre></div>
<p><br></p>
</div>
<div id="randomizedsearchcv---classification" class="section level3 hasAnchor" number="4.2.2">
<h3><span class="header-section-number">4.2.2</span> <code>RandomizedSearchCV</code> - Classification<a href="ajuste-de-hiperparámetros-con-sklearn.html#randomizedsearchcv---classification" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Ahora vamos a aplicar la función <code>RandomizedSearchCV</code> al modelo KNN para clasificación.</p>
<p>Inicializamos algunos parámetros de la función <code>RandomizedSearchCV</code>:</p>
<div class="sourceCode" id="cb76"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb76-1"><a href="ajuste-de-hiperparámetros-con-sklearn.html#cb76-1" aria-hidden="true" tabindex="-1"></a>random_search <span class="op">=</span> RandomizedSearchCV(estimator <span class="op">=</span> knn_classification, param_distributions <span class="op">=</span> {<span class="st">&#39;n_neighbors&#39;</span>: <span class="bu">range</span>(<span class="dv">1</span>,<span class="dv">200</span>), <span class="st">&#39;metric&#39;</span>: [<span class="st">&#39;euclidean&#39;</span>,<span class="st">&#39;cosine&#39;</span>,<span class="st">&#39;cityblock&#39;</span>,<span class="st">&#39;manhattan&#39;</span>]}, cv <span class="op">=</span> <span class="dv">10</span>, n_iter<span class="op">=</span><span class="dv">100</span>, random_state<span class="op">=</span><span class="dv">123</span>, scoring<span class="op">=</span><span class="st">&#39;accuracy&#39;</span>)</span></code></pre></div>
<p>Creamos un array con la variable respuesta, que en este caso es <em>quality_recode</em>, y un data-frame con los predictores, que serán el resto de variables del data-set con el que estamos trabajando:</p>
<div class="sourceCode" id="cb77"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb77-1"><a href="ajuste-de-hiperparámetros-con-sklearn.html#cb77-1" aria-hidden="true" tabindex="-1"></a>Y <span class="op">=</span> Data.loc[:,<span class="st">&#39;quality_recode&#39;</span>]</span>
<span id="cb77-2"><a href="ajuste-de-hiperparámetros-con-sklearn.html#cb77-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb77-3"><a href="ajuste-de-hiperparámetros-con-sklearn.html#cb77-3" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> Data.loc[:, Data.columns <span class="op">!=</span> <span class="st">&#39;quality_recode&#39;</span>]</span></code></pre></div>
<p>Entrenamos la función con los datos:</p>
<div class="sourceCode" id="cb78"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb78-1"><a href="ajuste-de-hiperparámetros-con-sklearn.html#cb78-1" aria-hidden="true" tabindex="-1"></a>random_search.fit(X,Y)</span></code></pre></div>
<p>Podemos crear un data-frame con las distintas combinaciones de valores de los hiper-parámetros que han sido utilizadas y el valor de la métrica de validación que se ha obtenido para cada una de esas combinaciones. Esto es justamente lo que nos devolvía nuestra función programada en la sección anterior.</p>
<div class="sourceCode" id="cb79"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb79-1"><a href="ajuste-de-hiperparámetros-con-sklearn.html#cb79-1" aria-hidden="true" tabindex="-1"></a>df_random_search_sklearn <span class="op">=</span> pd.DataFrame({<span class="st">&#39;k&#39;</span>: random_search.cv_results_[<span class="st">&#39;param_n_neighbors&#39;</span>], <span class="st">&#39;distance&#39;</span>: random_search.cv_results_[<span class="st">&#39;param_metric&#39;</span>] , <span class="st">&#39;TAC&#39;</span>: random_search.cv_results_[<span class="st">&#39;mean_test_score&#39;</span>]})</span>
<span id="cb79-2"><a href="ajuste-de-hiperparámetros-con-sklearn.html#cb79-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb79-3"><a href="ajuste-de-hiperparámetros-con-sklearn.html#cb79-3" aria-hidden="true" tabindex="-1"></a>df_random_search_sklearn <span class="op">=</span> df_random_search_sklearn.sort_values(by<span class="op">=</span><span class="st">&#39;TAC&#39;</span>, ascending<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb79-4"><a href="ajuste-de-hiperparámetros-con-sklearn.html#cb79-4" aria-hidden="true" tabindex="-1"></a>df_random_search_sklearn</span></code></pre></div>
<div style="width: 100%; overflow-x: auto;">
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th style="text-align: left;">
k
</th>
<th style="text-align: left;">
distance
</th>
<th style="text-align: left;">
TAC
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
50
</th>
<td>
101
</td>
<td>
cityblock
</td>
<td>
0.601573
</td>
</tr>
<tr>
<th>
69
</th>
<td>
92
</td>
<td>
euclidean
</td>
<td>
0.601573
</td>
</tr>
<tr>
<th>
32
</th>
<td>
156
</td>
<td>
cityblock
</td>
<td>
0.601573
</td>
</tr>
<tr>
<th>
33
</th>
<td>
173
</td>
<td>
euclidean
</td>
<td>
0.601573
</td>
</tr>
<tr>
<th>
80
</th>
<td>
97
</td>
<td>
manhattan
</td>
<td>
0.601573
</td>
</tr>
<tr>
<th>
…
</th>
<td>
…
</td>
<td>
…
</td>
<td>
…
</td>
</tr>
<tr>
<th>
57
</th>
<td>
5
</td>
<td>
euclidean
</td>
<td>
0.517093
</td>
</tr>
<tr>
<th>
70
</th>
<td>
5
</td>
<td>
cosine
</td>
<td>
0.515999
</td>
</tr>
<tr>
<th>
14
</th>
<td>
4
</td>
<td>
cosine
</td>
<td>
0.482937
</td>
</tr>
<tr>
<th>
4
</th>
<td>
4
</td>
<td>
manhattan
</td>
<td>
0.460890
</td>
</tr>
<tr>
<th>
94
</th>
<td>
2
</td>
<td>
cosine
</td>
<td>
0.410485
</td>
</tr>
</tbody>
</table>
<p>
100 rows × 3 columns
</p>
</div>
<p>Realizamos algunos cambios orientados a una mejor visualización gráfica posterior:</p>
<div class="sourceCode" id="cb80"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb80-1"><a href="ajuste-de-hiperparámetros-con-sklearn.html#cb80-1" aria-hidden="true" tabindex="-1"></a>df_random_search_sklearn[<span class="st">&#39;k&#39;</span>] <span class="op">=</span> df_random_search_sklearn[<span class="st">&#39;k&#39;</span>].astype(<span class="bu">str</span>) </span>
<span id="cb80-2"><a href="ajuste-de-hiperparámetros-con-sklearn.html#cb80-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-3"><a href="ajuste-de-hiperparámetros-con-sklearn.html#cb80-3" aria-hidden="true" tabindex="-1"></a>df_random_search_sklearn[<span class="st">&#39;distance&#39;</span>] <span class="op">=</span> df_random_search_sklearn[<span class="st">&#39;distance&#39;</span>].astype(<span class="bu">str</span>)</span>
<span id="cb80-4"><a href="ajuste-de-hiperparámetros-con-sklearn.html#cb80-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-5"><a href="ajuste-de-hiperparámetros-con-sklearn.html#cb80-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-6"><a href="ajuste-de-hiperparámetros-con-sklearn.html#cb80-6" aria-hidden="true" tabindex="-1"></a>df_random_search_sklearn[<span class="st">&#39;k-distance&#39;</span>] <span class="op">=</span> df_random_search_sklearn[[<span class="st">&#39;k&#39;</span>, <span class="st">&#39;distance&#39;</span>]].agg(<span class="st">&#39;-&#39;</span>.join, axis<span class="op">=</span><span class="dv">1</span>)</span></code></pre></div>
<p><br></p>
</div>
</div>
<div id="visualización-de-resultados-1" class="section level2 hasAnchor" number="4.3">
<h2><span class="header-section-number">4.3</span> Visualización de resultados<a href="ajuste-de-hiperparámetros-con-sklearn.html#visualización-de-resultados-1" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Vamos a visualizar los resultados obtenidos aplicando las funciones <code>GridSearchCV</code> y <code>RandomizedSearchCV</code> al algoritmo <strong>KNN para regresión</strong>:</p>
<div class="sourceCode" id="cb81"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb81-1"><a href="ajuste-de-hiperparámetros-con-sklearn.html#cb81-1" aria-hidden="true" tabindex="-1"></a>fig, axs <span class="op">=</span> plt.subplots()</span>
<span id="cb81-2"><a href="ajuste-de-hiperparámetros-con-sklearn.html#cb81-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-3"><a href="ajuste-de-hiperparámetros-con-sklearn.html#cb81-3" aria-hidden="true" tabindex="-1"></a>p1 <span class="op">=</span> sns.lineplot(y<span class="op">=</span><span class="st">&quot;ECM&quot;</span>, x<span class="op">=</span><span class="st">&#39;k-distance&#39;</span> , data<span class="op">=</span>df_grid_search_sklearn.iloc[<span class="dv">0</span>:<span class="dv">30</span>, :], color<span class="op">=</span><span class="st">&#39;red&#39;</span>)</span>
<span id="cb81-4"><a href="ajuste-de-hiperparámetros-con-sklearn.html#cb81-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-5"><a href="ajuste-de-hiperparámetros-con-sklearn.html#cb81-5" aria-hidden="true" tabindex="-1"></a>plt.setp(p1.get_xticklabels(), rotation<span class="op">=</span><span class="dv">90</span>)</span>
<span id="cb81-6"><a href="ajuste-de-hiperparámetros-con-sklearn.html#cb81-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-7"><a href="ajuste-de-hiperparámetros-con-sklearn.html#cb81-7" aria-hidden="true" tabindex="-1"></a>p1.title.set_text(<span class="st">&#39;KNN regression - Grid search - K fold (K=10)&#39;</span>)</span>
<span id="cb81-8"><a href="ajuste-de-hiperparámetros-con-sklearn.html#cb81-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-9"><a href="ajuste-de-hiperparámetros-con-sklearn.html#cb81-9" aria-hidden="true" tabindex="-1"></a>fig.savefig(<span class="st">&#39;pp1.jpg&#39;</span>, <span class="bu">format</span><span class="op">=</span><span class="st">&#39;jpg&#39;</span>, dpi<span class="op">=</span><span class="dv">1200</span>)</span>
<span id="cb81-10"><a href="ajuste-de-hiperparámetros-con-sklearn.html#cb81-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-11"><a href="ajuste-de-hiperparámetros-con-sklearn.html#cb81-11" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="sourceCode" id="cb82"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb82-1"><a href="ajuste-de-hiperparámetros-con-sklearn.html#cb82-1" aria-hidden="true" tabindex="-1"></a>fig, axs <span class="op">=</span> plt.subplots()</span>
<span id="cb82-2"><a href="ajuste-de-hiperparámetros-con-sklearn.html#cb82-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb82-3"><a href="ajuste-de-hiperparámetros-con-sklearn.html#cb82-3" aria-hidden="true" tabindex="-1"></a>p2 <span class="op">=</span> sns.lineplot(y<span class="op">=</span><span class="st">&quot;ECM&quot;</span>, x<span class="op">=</span><span class="st">&#39;k-distance&#39;</span> , data<span class="op">=</span>df_random_search_sklearn.iloc[<span class="dv">0</span>:<span class="dv">30</span>, :], color<span class="op">=</span><span class="st">&#39;red&#39;</span>)</span>
<span id="cb82-4"><a href="ajuste-de-hiperparámetros-con-sklearn.html#cb82-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb82-5"><a href="ajuste-de-hiperparámetros-con-sklearn.html#cb82-5" aria-hidden="true" tabindex="-1"></a>plt.setp(p2.get_xticklabels(), rotation<span class="op">=</span><span class="dv">90</span>)</span>
<span id="cb82-6"><a href="ajuste-de-hiperparámetros-con-sklearn.html#cb82-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb82-7"><a href="ajuste-de-hiperparámetros-con-sklearn.html#cb82-7" aria-hidden="true" tabindex="-1"></a>p2.title.set_text(<span class="st">&#39;KNN regression - Random search - K fold (K=10)&#39;</span>)</span>
<span id="cb82-8"><a href="ajuste-de-hiperparámetros-con-sklearn.html#cb82-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb82-9"><a href="ajuste-de-hiperparámetros-con-sklearn.html#cb82-9" aria-hidden="true" tabindex="-1"></a>fig.savefig(<span class="st">&#39;pp2.jpg&#39;</span>, <span class="bu">format</span><span class="op">=</span><span class="st">&#39;jpg&#39;</span>, dpi<span class="op">=</span><span class="dv">1200</span>)</span>
<span id="cb82-10"><a href="ajuste-de-hiperparámetros-con-sklearn.html#cb82-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb82-11"><a href="ajuste-de-hiperparámetros-con-sklearn.html#cb82-11" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<center>
<p><img src="pp1.jpg" style="width:80.0%" /></p>
<p><img src="pp2.jpg" style="width:80.0%" /></p>
</center>
<p>Como puede verse, la combinación óptima de hiper-parámetros varía en función de la versión utilizada del algoritmo de ajuste de hiper-parámetros.</p>
<p><br></p>
<hr />
<p><br></p>
<p>Ahora vamos a visualizar los resultados obtenidos aplicando las funciones <code>GridSearchCV</code> y <code>RandomizedSearchCV</code> al algoritmo <strong>KNN para clasificación</strong>:</p>
<div class="sourceCode" id="cb83"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb83-1"><a href="ajuste-de-hiperparámetros-con-sklearn.html#cb83-1" aria-hidden="true" tabindex="-1"></a>fig, axs <span class="op">=</span> plt.subplots()</span>
<span id="cb83-2"><a href="ajuste-de-hiperparámetros-con-sklearn.html#cb83-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-3"><a href="ajuste-de-hiperparámetros-con-sklearn.html#cb83-3" aria-hidden="true" tabindex="-1"></a>p1 <span class="op">=</span> sns.lineplot(y<span class="op">=</span><span class="st">&quot;TAC&quot;</span>, x<span class="op">=</span><span class="st">&#39;k-distance&#39;</span> , data<span class="op">=</span>df_grid_search_sklearn.iloc[<span class="dv">0</span>:<span class="dv">30</span>, :], color<span class="op">=</span><span class="st">&#39;red&#39;</span>)</span>
<span id="cb83-4"><a href="ajuste-de-hiperparámetros-con-sklearn.html#cb83-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-5"><a href="ajuste-de-hiperparámetros-con-sklearn.html#cb83-5" aria-hidden="true" tabindex="-1"></a>plt.setp(p1.get_xticklabels(), rotation<span class="op">=</span><span class="dv">90</span>)</span>
<span id="cb83-6"><a href="ajuste-de-hiperparámetros-con-sklearn.html#cb83-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-7"><a href="ajuste-de-hiperparámetros-con-sklearn.html#cb83-7" aria-hidden="true" tabindex="-1"></a>p1.title.set_text(<span class="st">&#39;KNN classification - Grid search - K fold (K=10)&#39;</span>)</span>
<span id="cb83-8"><a href="ajuste-de-hiperparámetros-con-sklearn.html#cb83-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-9"><a href="ajuste-de-hiperparámetros-con-sklearn.html#cb83-9" aria-hidden="true" tabindex="-1"></a>fig.savefig(<span class="st">&#39;pp3.jpg&#39;</span>, <span class="bu">format</span><span class="op">=</span><span class="st">&#39;jpg&#39;</span>, dpi<span class="op">=</span><span class="dv">1200</span>)</span>
<span id="cb83-10"><a href="ajuste-de-hiperparámetros-con-sklearn.html#cb83-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-11"><a href="ajuste-de-hiperparámetros-con-sklearn.html#cb83-11" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="sourceCode" id="cb84"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb84-1"><a href="ajuste-de-hiperparámetros-con-sklearn.html#cb84-1" aria-hidden="true" tabindex="-1"></a>fig, axs <span class="op">=</span> plt.subplots()</span>
<span id="cb84-2"><a href="ajuste-de-hiperparámetros-con-sklearn.html#cb84-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb84-3"><a href="ajuste-de-hiperparámetros-con-sklearn.html#cb84-3" aria-hidden="true" tabindex="-1"></a>p2 <span class="op">=</span> sns.lineplot(y<span class="op">=</span><span class="st">&quot;TAC&quot;</span>, x<span class="op">=</span><span class="st">&#39;k-distance&#39;</span> , data<span class="op">=</span>df_random_search_sklearn.iloc[<span class="dv">0</span>:<span class="dv">30</span>, :], color<span class="op">=</span><span class="st">&#39;red&#39;</span>)</span>
<span id="cb84-4"><a href="ajuste-de-hiperparámetros-con-sklearn.html#cb84-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb84-5"><a href="ajuste-de-hiperparámetros-con-sklearn.html#cb84-5" aria-hidden="true" tabindex="-1"></a>plt.setp(p2.get_xticklabels(), rotation<span class="op">=</span><span class="dv">90</span>)</span>
<span id="cb84-6"><a href="ajuste-de-hiperparámetros-con-sklearn.html#cb84-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb84-7"><a href="ajuste-de-hiperparámetros-con-sklearn.html#cb84-7" aria-hidden="true" tabindex="-1"></a>p2.title.set_text(<span class="st">&#39;KNN classification - Random search - K fold (K=10)&#39;</span>)</span>
<span id="cb84-8"><a href="ajuste-de-hiperparámetros-con-sklearn.html#cb84-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb84-9"><a href="ajuste-de-hiperparámetros-con-sklearn.html#cb84-9" aria-hidden="true" tabindex="-1"></a>fig.savefig(<span class="st">&#39;pp4.jpg&#39;</span>, <span class="bu">format</span><span class="op">=</span><span class="st">&#39;jpg&#39;</span>, dpi<span class="op">=</span><span class="dv">1200</span>)</span>
<span id="cb84-10"><a href="ajuste-de-hiperparámetros-con-sklearn.html#cb84-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb84-11"><a href="ajuste-de-hiperparámetros-con-sklearn.html#cb84-11" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<center>
<p><img src="pp3.jpg" style="width:80.0%" /></p>
<p><img src="pp4.jpg" style="width:80.0%" /></p>
</center>
<p>La combinación óptima de hiper-parámetros varía en función de la versión utilizada del algoritmo de ajuste de hiper-parámetros.</p>
<p>Cabe destacar que en el segundo caso, las 30 combinaciones de hiper-parámetros representadas tienen el mismo valor de la métrica TAC, que es además el máximo alcanzado, por tanto son todas igual de óptimas.</p>
<p><br></p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="grid-search-y-random-search-programados-en-python.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="bibliografía.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://estadistica4all.com/index.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["_main.pdf", "_main.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
