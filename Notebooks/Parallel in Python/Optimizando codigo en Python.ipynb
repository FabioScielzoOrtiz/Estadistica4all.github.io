{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizando código en `Python`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a ilustrar como paralelizar bucles for en Python con un ejemplo:\n",
    "\n",
    "La idea es paralelizar el siguiente algoritmo KNN para clasificacion basado en la distancia de Gower-BQ (una variante de la distancia de Gower aplicable a conjunto de datos binarios-cuantitativos).\n",
    "\n",
    "Aqui lo importante no es el funcionamiento del algoritmo en si, si no que hay una parte de este que genera unos costes computacionales altos, lo que se traduce en que al aplicar el algoritmo a un data-set de 5000 variables, este tarde mas de 13 minutos en compilarse por completo. La idea de paralelizarlo es reducir este tiempo de cómputo, para asi hacerlo mas aplicable en contextos reales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El algoritmo original (sin paralelizar):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN_classification( X , Y , x_new, k, distance = \"Gower-BQ\" ,  p1=0, p2=0 ):\n",
    "\n",
    " \n",
    "####################################################################################################################################################################################################################################################\n",
    "\n",
    "    X = pd.concat([X, x_new.to_frame().T], ignore_index=True)\n",
    "\n",
    "    distances = []\n",
    "\n",
    "    groups_knn = []\n",
    "\n",
    "######################################################################################################################################\n",
    "\n",
    "\n",
    "    if distance == \"Gower-BQ\":\n",
    "\n",
    "        def a(Binary_Data) :\n",
    "\n",
    "            X = Binary_Data\n",
    "\n",
    "            a = X @ X.T\n",
    "\n",
    "            return(a)\n",
    "\n",
    "##########################################################################################\n",
    "\n",
    "        def d(Binary_Data):\n",
    "\n",
    "            X = Binary_Data\n",
    "\n",
    "            ones_matrix = np.ones(( X.shape[0] , X.shape[1])) \n",
    "\n",
    "            d = (ones_matrix - X) @ (ones_matrix - X).T\n",
    "\n",
    "            return(d)\n",
    "\n",
    "##########################################################################################\n",
    "\n",
    "        def GowerBQ_Similarity_Python(i,j, BQ_Data_Set, p1, p2):\n",
    "\n",
    "            X = BQ_Data_Set\n",
    "\n",
    "   # The data matrix X have to be order in the following way:\n",
    "   # The p1 first are quantitative, the following p2 are binary categorical \n",
    "\n",
    "##########################################################################################\n",
    "            def G(k, X):\n",
    "\n",
    "                range = X.iloc[:,k].max() - X.iloc[:,k].min() \n",
    "\n",
    "                return(range)\n",
    "\n",
    "            G_vector = np.repeat(0, p1)\n",
    "\n",
    "            for r in range(0, p1): \n",
    "\n",
    "                G_vector[r] = G(r, X)\n",
    "##########################################################################################\n",
    "    \n",
    "            ones = np.repeat(1, p1)\n",
    "\n",
    "            Quantitative_Data = X.iloc[: , 0:p1]\n",
    "\n",
    "            Binary_Data = X.iloc[: , (p1):(p1+p2)]\n",
    "         \n",
    " \n",
    "##########################################################################################\n",
    "\n",
    "            numerator_part_1 = ( ones - ( (Quantitative_Data.iloc[i-1,:] - Quantitative_Data.iloc[j-1,:]).abs() / G_vector ) ).sum() \n",
    "\n",
    "            numerator_part_2 = a(Binary_Data).iloc[i-1,j-1] \n",
    "     \n",
    "            numerator = numerator_part_1 + numerator_part_2\n",
    "\n",
    "            denominator = p1 + (p2 - d(Binary_Data).iloc[i-1,j-1])  \n",
    "\n",
    "            Similarity_Gower = numerator / denominator  \n",
    "\n",
    "            return(Similarity_Gower)\n",
    "\n",
    "##########################################################################################\n",
    "\n",
    "\n",
    "        def Dist_GowerBQ_Py(i, j, BQ_Data ,  p1, p2):\n",
    "\n",
    "            Dist_Gower = np.sqrt( 1 - GowerBQ_Similarity_Python(i, j, BQ_Data , p1, p2) )\n",
    "\n",
    "            return(Dist_Gower)\n",
    "\n",
    "##########################################################################################\n",
    "\n",
    "        for i in range(1, len(X)):\n",
    "\n",
    "            distances.append( Dist_GowerBQ_Py( len(X), i , X, p1, p2) )\n",
    "\n",
    "\n",
    "######################################################################################################################################\n",
    "\n",
    "######################################################################################################################################\n",
    "    \n",
    "    distances = pd.DataFrame({'distances': distances})\n",
    "\n",
    "    distances = distances.sort_values(by=[\"distances\"]).reset_index(drop=False)\n",
    "        \n",
    "    knn = distances.iloc[0:k , :]\n",
    "\n",
    "    for i in knn.iloc[:,0]:\n",
    "\n",
    "        groups_knn.append(Y.iloc[i,:])\n",
    "\n",
    "    unique, counts = np.unique(groups_knn , return_counts=True)\n",
    "\n",
    "    unique_Y , counts_Y = np.unique(Y , return_counts=True)\n",
    "\n",
    "    if len(unique) == len(unique_Y) :\n",
    "\n",
    "        proportions_groups_knn = pd.DataFrame({'proportions_groups': counts/k, 'groups': unique_Y })\n",
    "    \n",
    "    elif len(unique) < len(unique_Y) :\n",
    "\n",
    "        proportions_groups_knn = pd.DataFrame({'proportions_groups': counts/k, 'groups': unique })\n",
    "\n",
    "\n",
    "\n",
    "    prediction_group = proportions_groups_knn.sort_values(by=[\"proportions_groups\"], ascending=False).iloc[0,:]['groups']\n",
    "\n",
    "    message = print( \"x_new is classify in the group\", prediction_group , \". So KNN algorithm predict y_new =\",  prediction_group )                                      \n",
    "                                       \n",
    "\n",
    "    return proportions_groups_knn , message  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a probar el algoritmo con un mismo data-set pero con distintos tamaños de filas (observaciones)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparamos los datos para la prueba:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gender_classification = pd.read_csv('gender_classification.csv')\n",
    "\n",
    "x_new = pd.Series({'long_hair': 1, 'forehead_width_cm': 4, 'forehead_height_cm': 6, 'nose_wide': 1 , 'nose_long': 1 , 'nose_long': 1 , 'lips_thin':1, 'distance_nose_to_lip_long': 1 })\n",
    "\n",
    "Y = Gender_classification.loc[: , ['gender']]\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "ord_enc = OrdinalEncoder()\n",
    "\n",
    "Y['gender'] = ord_enc.fit_transform(Y[['gender']])\n",
    "\n",
    "X = Gender_classification.loc[: , ['forehead_width_cm', 'forehead_height_cm',   # Quantitative (2)\n",
    "\n",
    "                   'long_hair', 'nose_wide', 'nose_long', 'lips_thin', 'distance_nose_to_lip_long'     # Binary (5)\n",
    "                 \n",
    "                            ]] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_small_1 = X.iloc[0:1000,:]\n",
    "Y_small_1 = Y.iloc[0:1000,:]\n",
    "\n",
    "X_small_2 = X.iloc[0:2000,:]\n",
    "Y_small_2 = Y.iloc[0:2000,:]\n",
    "\n",
    "X_small_3 = X.iloc[0:3000,:]\n",
    "Y_small_3 = Y.iloc[0:3000,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_new is classify in the group 1.0 . So KNN algorithm predict y_new = 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(   proportions_groups  groups\n",
       " 0                 1.0     1.0,\n",
       " None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNN_classification( X_small_1 , Y_small_1  , x_new, 5 , distance = \"Gower-BQ\" , p1=2, p2=5 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "20seg / 27seg / 26.8seg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_new is classify in the group 1.0 . So KNN algorithm predict y_new = 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(   proportions_groups  groups\n",
       " 0                 1.0     1.0,\n",
       " None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNN_classification( X_small_2 , Y_small_2  , x_new, 5 , distance = \"Gower-BQ\" , p1=2, p2=5 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.47min  / 2.35 / 2.29min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_new is classify in the group 1.0 . So KNN algorithm predict y_new = 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(   proportions_groups  groups\n",
       " 0                 1.0     1.0,\n",
       " None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNN_classification( X_small_3 , Y_small_3  , x_new, 5 , distance = \"Gower-BQ\" , p1=2, p2=5 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8.51min , 8.38min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_new is classify in the group 1.0 . So KNN algorithm predict y_new = 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(   proportions_groups  groups\n",
       " 0                 1.0     1.0,\n",
       " None)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNN_classification( X , Y  , x_new, 5 , distance = \"Gower-BQ\" , p1=2, p2=5 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "38.48min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN_classification_parallel( X , Y , x_new, k, distance = \"Gower-BQ\" ,  p1=0, p2=0 ):\n",
    "\n",
    " \n",
    "####################################################################################################################################################################################################################################################\n",
    "\n",
    "    X = pd.concat([X, x_new.to_frame().T], ignore_index=True)\n",
    "\n",
    "    distances = []\n",
    "\n",
    "    groups_knn = []\n",
    "\n",
    "######################################################################################################################################\n",
    "\n",
    "\n",
    "    if distance == \"Gower-BQ\":\n",
    "\n",
    "        def a(Binary_Data) :\n",
    "\n",
    "            X = Binary_Data\n",
    "\n",
    "            a = X @ X.T\n",
    "\n",
    "            return(a)\n",
    "\n",
    "##########################################################################################\n",
    "\n",
    "        def d(Binary_Data):\n",
    "\n",
    "            X = Binary_Data\n",
    "\n",
    "            ones_matrix = np.ones(( X.shape[0] , X.shape[1])) \n",
    "\n",
    "            d = (ones_matrix - X) @ (ones_matrix - X).T\n",
    "\n",
    "            return(d)\n",
    "\n",
    "##########################################################################################\n",
    "\n",
    "        def GowerBQ_Similarity_Python(i,j, BQ_Data_Set, p1, p2):\n",
    "\n",
    "            X = BQ_Data_Set\n",
    "\n",
    "   # The data matrix X have to be order in the following way:\n",
    "   # The p1 first are quantitative, the following p2 are binary categorical \n",
    "\n",
    "##########################################################################################\n",
    "            def G(k, X):\n",
    "\n",
    "                range = X.iloc[:,k].max() - X.iloc[:,k].min() \n",
    "\n",
    "                return(range)\n",
    "\n",
    "            G_vector = np.repeat(0, p1)\n",
    "\n",
    "            for r in range(0, p1): \n",
    "\n",
    "                G_vector[r] = G(r, X)\n",
    "##########################################################################################\n",
    "    \n",
    "            ones = np.repeat(1, p1)\n",
    "\n",
    "            Quantitative_Data = X.iloc[: , 0:p1]\n",
    "\n",
    "            Binary_Data = X.iloc[: , (p1):(p1+p2)]\n",
    "         \n",
    " \n",
    "##########################################################################################\n",
    "\n",
    "            numerator_part_1 = ( ones - ( (Quantitative_Data.iloc[i-1,:] - Quantitative_Data.iloc[j-1,:]).abs() / G_vector ) ).sum() \n",
    "\n",
    "            numerator_part_2 = a(Binary_Data).iloc[i-1,j-1] \n",
    "     \n",
    "            numerator = numerator_part_1 + numerator_part_2\n",
    "\n",
    "            denominator = p1 + (p2 - d(Binary_Data).iloc[i-1,j-1])  \n",
    "\n",
    "            Similarity_Gower = numerator / denominator  \n",
    "\n",
    "            return(Similarity_Gower)\n",
    "\n",
    "##########################################################################################\n",
    "\n",
    "        def Dist_GowerBQ_Py(i, j, BQ_Data ,  p1, p2):\n",
    "\n",
    "            Dist_Gower = np.sqrt( 1 - GowerBQ_Similarity_Python(i, j, BQ_Data , p1, p2) )\n",
    "\n",
    "            return(Dist_Gower)\n",
    "\n",
    "##########################################################################################\n",
    "\n",
    "# ESTA ES LA PARTE CRITICA DEL ALGORITMO, LA QUE LO HACE LENTO. ESTE BUCLE FOR ES EL QUE DEBEMOS PARALELIZAR.\n",
    "\n",
    "\n",
    "        # for i in range(1, len(X)):\n",
    "\n",
    "           # distances.append( Dist_GowerBQ_Py( len(X), i , X, p1, p2) )\n",
    "\n",
    "        n_jobs  = multiprocessing.cpu_count()\n",
    "\n",
    "\n",
    "        distances = Parallel(n_jobs=n_jobs)( delayed(Dist_GowerBQ_Py)( len(X), i , X, p1, p2) for i in range(1, len(X)) )\n",
    "\n",
    "\n",
    "######################################################################################################################################\n",
    "\n",
    "######################################################################################################################################\n",
    "    \n",
    "    distances = pd.DataFrame({'distances': distances})\n",
    "\n",
    "    distances = distances.sort_values(by=[\"distances\"]).reset_index(drop=False)\n",
    "        \n",
    "    knn = distances.iloc[0:k , :]\n",
    "\n",
    "    for i in knn.iloc[:,0]:\n",
    "\n",
    "        groups_knn.append(Y.iloc[i,:])\n",
    "\n",
    "    unique, counts = np.unique(groups_knn , return_counts=True)\n",
    "\n",
    "    unique_Y , counts_Y = np.unique(Y , return_counts=True)\n",
    "\n",
    "    if len(unique) == len(unique_Y) :\n",
    "\n",
    "        proportions_groups_knn = pd.DataFrame({'proportions_groups': counts/k, 'groups': unique_Y })\n",
    "    \n",
    "    elif len(unique) < len(unique_Y) :\n",
    "\n",
    "        proportions_groups_knn = pd.DataFrame({'proportions_groups': counts/k, 'groups': unique })\n",
    "\n",
    "\n",
    "\n",
    "    prediction_group = proportions_groups_knn.sort_values(by=[\"proportions_groups\"], ascending=False).iloc[0,:]['groups']\n",
    "\n",
    "    message = print( \"x_new is classify in the group\", prediction_group , \". So KNN algorithm predict y_new =\",  prediction_group )                                      \n",
    "                                       \n",
    "\n",
    "    return proportions_groups_knn , message  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probamos ahora el algoritmo paralelizado con los mismos ejemplos que antes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_new is classify in the group 1.0 . So KNN algorithm predict y_new = 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(   proportions_groups  groups\n",
       " 0                 1.0     1.0,\n",
       " None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNN_classification_parallel( X_small_1 , Y_small_1  , x_new, 5 , distance = \"Gower-BQ\" , p1=2, p2=5 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15.5 seg , 16.3seg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_new is classify in the group 1.0 . So KNN algorithm predict y_new = 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(   proportions_groups  groups\n",
       " 0                 1.0     1.0,\n",
       " None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNN_classification_parallel( X_small_2 , Y_small_2  , x_new, 5 , distance = \"Gower-BQ\" , p1=2, p2=5 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1min , 1.03min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_new is classify in the group 1.0 . So KNN algorithm predict y_new = 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(   proportions_groups  groups\n",
       " 0                 1.0     1.0,\n",
       " None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNN_classification_parallel( X_small_3 , Y_small_3  , x_new, 5 , distance = \"Gower-BQ\" , p1=2, p2=5 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.33min , 3.17min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_new is classify in the group 1.0 . So KNN algorithm predict y_new = 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(   proportions_groups  groups\n",
       " 0                 1.0     1.0,\n",
       " None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNN_classification_parallel( X , Y  , x_new, 5 , distance = \"Gower-BQ\" , p1=2, p2=5 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14.56min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La funcion KNN_classification original tarda mas de 25 mins en hacer validacion cruzada sumple con un set de train de 1000 observaciones. Hay que paralelozarla para hacer viable cross validation con ella !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Codigo sin optimizar:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La justificacion principal de optimizar nuestros codigos en ciencia de datos, poder implementar procedimientos en caso reales que exigen un alto rendimiento computacional.\n",
    "\n",
    "Si para ejecutar un procedimiento en un caso real el ordenador tarda horas, dias o es incluso intratable computacionalemente, directamente no podremos aplicar dicho procedimiento (por bueno que sea) en casos reales, y tendremos que limitarnos a usar procedimientos quiza peores desde un punto de vista estadistico, pero mejores a nivel de coste computacional.\n",
    "\n",
    "La idea de optimizar codigo es no tener que desechar buenos procedimientos a nivel estadistico porque sean malos a nivel computacional (sean ineficientes computacionalmente), la idea es hacerlos mas eficientes, para reducir sus costes de computacion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El siguiente codigo es el que usaremos como ejemplo a lo largo de este articulo, la idea es medir su rendimiento original y posteriormente aplicarle diferentes tecnicas para optimizarlo y ver como cambia su rendimiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La siguiente funcion es una implementacion de KNN para regresion usando la distancia de Gower, que es una metrica computacionalmente muy costosa.\n",
    "\n",
    "La idea es usar la funcion KNN_regresion dentro de una rutina de validacion cruzada, como ejemplo de procedimiento que supone un alto coste computacional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN_regression( X , Y , x_new, k, distance = \"Minkowski\" , q = 0, p1=0, p2=0, p3=0 ):\n",
    "\n",
    "    \n",
    " \n",
    "\n",
    "####################################################################################################################################################################################################################################################\n",
    "\n",
    "    # Y tiene que ser una variable respuesta cuantitativa\n",
    "\n",
    "    # X tiene que ser un panda data frame con los predictotres (X1,...,Xp). \n",
    "\n",
    "    # x_new tiene que ser un vector. \n",
    "\n",
    "####################################################################################################################################################################################################################################################\n",
    "\n",
    "    X = pd.concat([X, x_new.to_frame().T], ignore_index=True)\n",
    "\n",
    "    distances = []\n",
    "\n",
    "    Y_values_knn = []\n",
    "\n",
    "\n",
    "####################################################################################################################################################################################################################################################\n",
    "    \n",
    "    \n",
    "    \n",
    "    if distance == \"Gower\":\n",
    "\n",
    "        # The data matrix X have to be order in the following way:\n",
    "        # The p1 first are quantitative, the following p2 are binary categorical, and the following p3 are multiple categorical.\n",
    "\n",
    "\n",
    "        def a(Binary_Data) :\n",
    "\n",
    "            X = Binary_Data\n",
    "\n",
    "            a = X @ X.T\n",
    "\n",
    "            return(a)\n",
    "\n",
    "##########################################################################################\n",
    "\n",
    "        def d(Binary_Data):\n",
    "\n",
    "            X = Binary_Data\n",
    "\n",
    "            ones_matrix = np.ones(( X.shape[0] , X.shape[1])) \n",
    "\n",
    "            d = (ones_matrix - X) @ (ones_matrix - X).T\n",
    "\n",
    "            return(d)\n",
    "\n",
    "##########################################################################################\n",
    "\n",
    "        def alpha_py(i,j, Multiple_Categorical_Data):\n",
    "\n",
    "                X = Multiple_Categorical_Data\n",
    "\n",
    "                alpha = np.repeat(0, X.shape[1])\n",
    "\n",
    "                for k in range(0, X.shape[1]) :\n",
    "\n",
    "                    if X.iloc[i-1, k] == X.iloc[j-1, k] :\n",
    "\n",
    "                        alpha[k] = 1\n",
    "\n",
    "                    else :\n",
    "\n",
    "                        alpha[k] = 0\n",
    "\n",
    "\n",
    "                alpha = alpha.sum()\n",
    "\n",
    "                return(alpha)\n",
    "\n",
    "   ##########################################################################################\n",
    "\n",
    "\n",
    "        def Gower_Similarity_Python(i,j, Mixed_Data_Set, p1, p2, p3):\n",
    "\n",
    "            X = Mixed_Data_Set\n",
    "\n",
    "   # The data matrix X have to be order in the following way:\n",
    "   # The p1 first are quantitative, the following p2 are binary categorical, and the following p3 are multiple categorical.\n",
    "\n",
    "   #####################################################################################\n",
    "        \n",
    "            def G(k, X):\n",
    "\n",
    "                range = X.iloc[:,k].max() - X.iloc[:,k].min() \n",
    "\n",
    "                return(range)\n",
    "\n",
    "            G_vector = np.repeat(0, p1)\n",
    "\n",
    "            for r in range(0, p1):\n",
    "\n",
    "                G_vector[r] = G(r, X)\n",
    "                \n",
    "      \n",
    "    ##########################################################################################\n",
    "    \n",
    "            ones = np.repeat(1, p1)\n",
    "\n",
    "            Quantitative_Data = X.iloc[: , 0:p1]\n",
    "\n",
    "            Binary_Data = X.iloc[: , (p1):(p1+p2)]\n",
    "            \n",
    "            Multiple_Categorical_Data = X.iloc[: , (p1+p2):(p1+p2+p3) ]\n",
    "\n",
    "    ##########################################################################################\n",
    "\n",
    "            numerator_part_1 = ( ones - ( (Quantitative_Data.iloc[i-1,:] - Quantitative_Data.iloc[j-1,:]).abs() / G_vector ) ).sum() \n",
    "\n",
    "            numerator_part_2 = a(Binary_Data).iloc[i-1,j-1] + alpha_py(i,j, Multiple_Categorical_Data)\n",
    "\n",
    "            numerator = numerator_part_1 + numerator_part_2\n",
    " \n",
    "            denominator = p1 + (p2 - d(Binary_Data).iloc[i-1,j-1]) + p3\n",
    "\n",
    "            Similarity_Gower = numerator / denominator  \n",
    "\n",
    "            return(Similarity_Gower)\n",
    "\n",
    "##########################################################################################\n",
    "\n",
    "        def Dist_Gower_Py(i, j, Mixed_Data , p1, p2, p3):\n",
    "\n",
    "            Dist_Gower = np.sqrt( 1 - Gower_Similarity_Python(i, j, Mixed_Data , p1, p2, p3) )\n",
    "\n",
    "            return(Dist_Gower)    \n",
    "\n",
    "    ###################################################################\n",
    "\n",
    "        for i in range(1, len(X)):\n",
    "\n",
    "            distances.append( Dist_Gower_Py( len(X), i , X, p1, p2, p3) )\n",
    "\n",
    "        \n",
    "######################################################################################################################################\n",
    "    \n",
    "    distances = pd.DataFrame({'distances': distances})\n",
    "\n",
    "    distances = distances.sort_values(by=[\"distances\"]).reset_index(drop=False)\n",
    "        \n",
    "    knn = distances.iloc[0:k , :]\n",
    "\n",
    "    for i in knn.iloc[:,0]:\n",
    "\n",
    "        Y_values_knn.append(Y.iloc[i , ])\n",
    "\n",
    "\n",
    "    y_predict = sum(Y_values_knn)/k\n",
    "\n",
    "\n",
    "                                     \n",
    "    return y_predict   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los datos con los que haremos las pruebas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "House_Prices_Data = pd.read_csv('House_Price_Regression.csv')\n",
    "\n",
    "House_Prices_Data = House_Prices_Data.loc[:, ['price', 'size_in_m_2', 'no_of_bedrooms', 'no_of_bathrooms', 'quality_recode', 'latitude', 'private_garden_recode', 'private_pool_recode', 'longitude']]\n",
    "\n",
    "House_Prices_Data['quality_recode'] = House_Prices_Data['quality_recode'].astype('object')\n",
    "House_Prices_Data['private_garden_recode'] = House_Prices_Data['private_garden_recode'].astype('object')\n",
    "House_Prices_Data['private_pool_recode'] = House_Prices_Data['private_pool_recode'].astype('object')\n",
    "\n",
    "House_Prices_Data = House_Prices_Data.rename({'price': 'Y'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_Houses_Prices_Train = House_Prices_Data.sample(frac=0.8, replace=False, weights=None, random_state=555, axis=None, ignore_index=True)\n",
    "\n",
    "Data_Houses_Prices_Test = House_Prices_Data.drop( Data_Houses_Prices_Train.index , )\n",
    "\n",
    "X = Data_Houses_Prices_Train.loc[: , ['size_in_m_2', 'no_of_bedrooms', 'no_of_bathrooms','latitude', 'longitude', 'private_garden_recode', 'private_pool_recode',  'quality_recode']]\n",
    "\n",
    "Y = Data_Houses_Prices_Train.loc[: , 'Y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La siguiente rutina de validacion simple usando la funcion KNN_regression es la que usaremos como ejemplo a lo largo de este artuiculo, ahora podremos ver cuanto tarda en ejecutarse con el algoritmo original sin haber sido optimizado de ningun modo, despues repetiremos el proceso habiendo optimizado el algoritmo con diferentes procedimientos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validacion_simple(Data_Test, X_train, Y_train):\n",
    "\n",
    "    ##########################\n",
    "\n",
    "    def prediction(i, Data_Test, X_train, Y_train ):\n",
    "\n",
    "     x_new = Data_Test.iloc[ i , range(1,Data_Test.shape[1])]\n",
    " \n",
    "     y_new_predict = KNN_regression( X_train  , Y_train , x_new, k=10, distance = \"Gower\" , p1=5, p2=2, p3=1  )\n",
    "\n",
    "     return(y_new_predict)\n",
    "\n",
    "    ##########################\n",
    "\n",
    "    y_predictions_vector = []\n",
    "\n",
    "    for i in  range(0, len(Data_Test)):\n",
    "\n",
    "        y_new_predict = prediction(i, Data_Test, X_train, Y_train )\n",
    "\n",
    "        y_predictions_vector.append( y_new_predict )\n",
    "\n",
    "    ##########################\n",
    "\n",
    "    ECM = ( (y_predictions_vector - Data_Test.loc[: , 'Y'])**2 ).sum() \n",
    "\n",
    " \n",
    "    return(y_predictions_vector , ECM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predictions_vector, ECM = validacion_simple(Data_Houses_Prices_Test, X.iloc[0:100] , Y.iloc[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3987208098987757.5"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ECM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El tiempo de computacion usando solo las 100 primeras filas de X e Y es de  5.30 / 5.14 mins minutos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si usasemos X e Y enteras (que tienen  1524 filas) el tiempo de computacion seria demasiado grande como para usar el algoritmo en la practica. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paralelizacion de bucles for"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usaremos la libreria `joblib` para paralelizar los bucles for del algoritmo KNN_regression, tambien haremos lo mismo con el bloque de codigo con el que hacemos la validacion simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN_regression_Parallel( X , Y , x_new, k, distance = \"Minkowski\" , q = 0, p1=0, p2=0, p3=0 ):\n",
    "\n",
    "##########################################################################################################\n",
    "\n",
    "## Para paralelizar el algoritmo \n",
    "\n",
    "    from joblib import Parallel, delayed\n",
    "    import multiprocessing\n",
    "\n",
    "####################################################################################################################################################################################################################################################\n",
    "\n",
    "    # Y tiene que ser una variable respuesta cuantitativa\n",
    "\n",
    "    # X tiene que ser un panda data frame con los predictotres (X1,...,Xp). \n",
    "\n",
    "    # x_new tiene que ser un vector. \n",
    "\n",
    "####################################################################################################################################################################################################################################################\n",
    "\n",
    "    X = pd.concat([X, x_new.to_frame().T], ignore_index=True)\n",
    "\n",
    "    distances = []\n",
    "\n",
    "    Y_values_knn = []\n",
    "\n",
    "\n",
    "####################################################################################################################################################################################################################################################\n",
    "    \n",
    "    \n",
    "    \n",
    "    if distance == \"Gower\":\n",
    "\n",
    "        # The data matrix X have to be order in the following way:\n",
    "        # The p1 first are quantitative, the following p2 are binary categorical, and the following p3 are multiple categorical.\n",
    "\n",
    "\n",
    "        def a(Binary_Data) :\n",
    "\n",
    "            X = Binary_Data\n",
    "\n",
    "            a = X @ X.T\n",
    "\n",
    "            return(a)\n",
    "\n",
    "##########################################################################################\n",
    "\n",
    "        def d(Binary_Data):\n",
    "\n",
    "            X = Binary_Data\n",
    "\n",
    "            ones_matrix = np.ones(( X.shape[0] , X.shape[1])) \n",
    "\n",
    "            d = (ones_matrix - X) @ (ones_matrix - X).T\n",
    "\n",
    "            return(d)\n",
    "\n",
    "##########################################################################################\n",
    "\n",
    "        def alpha_py(i,j, Multiple_Categorical_Data):\n",
    "\n",
    "                X = Multiple_Categorical_Data\n",
    "\n",
    "                alpha = np.repeat(0, X.shape[1])\n",
    "\n",
    "                for k in range(0, X.shape[1]) :\n",
    "\n",
    "                    if X.iloc[i-1, k] == X.iloc[j-1, k] :\n",
    "\n",
    "                        alpha[k] = 1\n",
    "\n",
    "                    else :\n",
    "\n",
    "                        alpha[k] = 0\n",
    "\n",
    "\n",
    "                alpha = alpha.sum()\n",
    "\n",
    "                return(alpha)\n",
    "\n",
    "   ##########################################################################################\n",
    "\n",
    "\n",
    "        def Gower_Similarity_Python(i,j, Mixed_Data_Set, p1, p2, p3):\n",
    "\n",
    "            X = Mixed_Data_Set\n",
    "\n",
    "   # The data matrix X have to be order in the following way:\n",
    "   # The p1 first are quantitative, the following p2 are binary categorical, and the following p3 are multiple categorical.\n",
    "\n",
    "   #####################################################################################\n",
    "        \n",
    "            def G(k, X):\n",
    "\n",
    "                range = X.iloc[:,k].max() - X.iloc[:,k].min() \n",
    "\n",
    "                return(range)\n",
    "\n",
    "            G_vector = np.repeat(0, p1)\n",
    "\n",
    "            for r in range(0, p1):\n",
    "\n",
    "                G_vector[r] = G(r, X)\n",
    "                \n",
    "      \n",
    "    ##########################################################################################\n",
    "    \n",
    "            ones = np.repeat(1, p1)\n",
    "\n",
    "            Quantitative_Data = X.iloc[: , 0:p1]\n",
    "\n",
    "            Binary_Data = X.iloc[: , (p1):(p1+p2)]\n",
    "            \n",
    "            Multiple_Categorical_Data = X.iloc[: , (p1+p2):(p1+p2+p3) ]\n",
    "\n",
    "    ##########################################################################################\n",
    "\n",
    "            numerator_part_1 = ( ones - ( (Quantitative_Data.iloc[i-1,:] - Quantitative_Data.iloc[j-1,:]).abs() / G_vector ) ).sum() \n",
    "\n",
    "            numerator_part_2 = a(Binary_Data).iloc[i-1,j-1] + alpha_py(i,j, Multiple_Categorical_Data)\n",
    "\n",
    "            numerator = numerator_part_1 + numerator_part_2\n",
    " \n",
    "            denominator = p1 + (p2 - d(Binary_Data).iloc[i-1,j-1]) + p3\n",
    "\n",
    "            Similarity_Gower = numerator / denominator  \n",
    "\n",
    "            return(Similarity_Gower)\n",
    "\n",
    "##########################################################################################\n",
    "\n",
    "        def Dist_Gower_Py(i, j, Mixed_Data , p1, p2, p3):\n",
    "\n",
    "            Dist_Gower = np.sqrt( 1 - Gower_Similarity_Python(i, j, Mixed_Data , p1, p2, p3) )\n",
    "\n",
    "            return(Dist_Gower)    \n",
    "\n",
    "    ###################################################################\n",
    "\n",
    "    ## PARTE DEL CODIGO A PARALELIZAR\n",
    "\n",
    "        # for i in range(1, len(X)):\n",
    "\n",
    "            # distances.append( Dist_Gower_Py( len(X), i , X, p1, p2, p3) )\n",
    "\n",
    "        n_jobs  = multiprocessing.cpu_count()\n",
    "\n",
    "        distances = Parallel(n_jobs=n_jobs)( delayed(Dist_Gower_Py)( len(X), i , X, p1, p2, p3) for i in range(1, len(X)) )\n",
    "\n",
    "######################################################################################################################################\n",
    "    \n",
    "    distances = pd.DataFrame({'distances': distances})\n",
    "\n",
    "    distances = distances.sort_values(by=[\"distances\"]).reset_index(drop=False)\n",
    "        \n",
    "    knn = distances.iloc[0:k , :]\n",
    "\n",
    "    for i in knn.iloc[:,0]:\n",
    "\n",
    "        Y_values_knn.append(Y.iloc[i , ])\n",
    "\n",
    "\n",
    "    y_predict = sum(Y_values_knn)/k\n",
    "\n",
    "                                     \n",
    "    return y_predict   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validacion_simple_Parallel(Data_Test, X_train, Y_train):\n",
    "\n",
    "    ##########################\n",
    "\n",
    "    from joblib import Parallel, delayed\n",
    "    import multiprocessing\n",
    "\n",
    "    n_jobs  = multiprocessing.cpu_count()\n",
    "\n",
    "    ##########################\n",
    "\n",
    "    def prediction(i, Data_Test, X_train, Y_train ):\n",
    "\n",
    "     x_new = Data_Test.iloc[ i , range(1,Data_Test.shape[1])]\n",
    "\n",
    "     # Usamos KNN_regression_Parallel en vez de KNN_regression\n",
    " \n",
    "     y_new_predict = KNN_regression_Parallel( X_train  , Y_train , x_new, k=10, distance = \"Gower\" , p1=5, p2=2, p3=1  )\n",
    "\n",
    "     return(y_new_predict)\n",
    "\n",
    "    ##########################\n",
    "\n",
    "    y_predictions_vector = []\n",
    "\n",
    "    # Paralelizamos el siguiente bucle for :\n",
    "\n",
    "    # for i in  range(0, len(Data_Test)):\n",
    "\n",
    "        # y_new_predict = prediction(i, Data_Test, X_train, Y_train )\n",
    "\n",
    "        # y_predictions_vector.append( y_new_predict )\n",
    "\n",
    "    \n",
    "    y_predictions_vector = Parallel(n_jobs=n_jobs)( delayed(prediction)( i, Data_Test, X_train, Y_train) for i in range(0, len(Data_Test)) )\n",
    "\n",
    "    #########################\n",
    "\n",
    "    ECM = ( (y_predictions_vector - Data_Test.loc[: , 'Y'])**2 ).sum() \n",
    "\n",
    "\n",
    "    return(y_predictions_vector, ECM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predictions_vector, ECM = validacion_simple_Parallel(Data_Houses_Prices_Test, X.iloc[0:100], Y.iloc[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3987208098987757.5"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ECM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso, tras paralelizar los algoritmos el tiempo de computacion se reduce de 5.30 mins a 1.42 mins , lo cual es bastante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usar `Numpy` en vez de `Pandas`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Data_Houses_Prices_Train.loc[: , ['size_in_m_2', 'no_of_bedrooms', 'no_of_bathrooms','latitude', 'longitude', 'private_garden_recode', 'private_pool_recode',  'quality_recode']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = Data_Houses_Prices_Train.loc[: , 'Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'to_numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Usuario\\Documents\\fabio\\Fabio\\Estadistica4all.github.io\\Notebooks\\Parallel in Python\\Optimizando codigo en Python.ipynb Celda 67\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Usuario/Documents/fabio/Fabio/Estadistica4all.github.io/Notebooks/Parallel%20in%20Python/Optimizando%20codigo%20en%20Python.ipynb#Y252sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m Y \u001b[39m=\u001b[39m Y\u001b[39m.\u001b[39;49mto_numpy()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'to_numpy'"
     ]
    }
   ],
   "source": [
    "Y = Y.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'type'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Usuario\\Documents\\fabio\\Fabio\\Estadistica4all.github.io\\Notebooks\\Parallel in Python\\Optimizando codigo en Python.ipynb Celda 68\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Usuario/Documents/fabio/Fabio/Estadistica4all.github.io/Notebooks/Parallel%20in%20Python/Optimizando%20codigo%20en%20Python.ipynb#Y253sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m Y\u001b[39m.\u001b[39;49mtype\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'type'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.to_numpy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[337.981114, 4, 3, ..., 0.0, 0.0, 2.0],\n",
       "       [214.977542, 2, 2, ..., 0.0, 0.0, 2.0],\n",
       "       [167.875721, 3, 3, ..., 0.0, 0.0, 2.0],\n",
       "       ...,\n",
       "       [162.673153, 2, 3, ..., 0.0, 0.0, 2.0],\n",
       "       [241.826509, 3, 4, ..., 0.0, 0.0, 2.0],\n",
       "       [70.141765, 1, 2, ..., 0.0, 0.0, 2.0]], dtype=object)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_new = Data_Houses_Prices_Test.iloc[ 1 , range(1, Data_Houses_Prices_Test.shape[1])].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([128.020334, 2, 3, 0.0, 25.078148, 0.0, 0.0, 55.148277],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate((X, [x_new]), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[337.981114, 4, 3, ..., 0.0, 0.0, 2.0],\n",
       "       [214.977542, 2, 2, ..., 0.0, 0.0, 2.0],\n",
       "       [167.875721, 3, 3, ..., 0.0, 0.0, 2.0],\n",
       "       ...,\n",
       "       [241.826509, 3, 4, ..., 0.0, 0.0, 2.0],\n",
       "       [70.141765, 1, 2, ..., 0.0, 0.0, 2.0],\n",
       "       [128.020334, 2, 3, ..., 0.0, 0.0, 55.148277]], dtype=object)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = []\n",
    "\n",
    "Y_values_knn = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1=5\n",
    "p2=2\n",
    "p3=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def a(Binary_Data) :\n",
    "\n",
    "            X = Binary_Data\n",
    "\n",
    "            a = X @ X.T\n",
    "\n",
    "            return(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d(Binary_Data):\n",
    "\n",
    "            X = Binary_Data\n",
    "\n",
    "            ones_matrix = np.ones(( X.shape[0] , X.shape[1])) \n",
    "\n",
    "            d = (ones_matrix - X) @ (ones_matrix - X).T\n",
    "\n",
    "            return(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha_py_Parallel(i,j, Multiple_Categorical_Data):\n",
    "\n",
    "    X = Multiple_Categorical_Data\n",
    "\n",
    "    alpha = np.repeat(0, X.shape[1])\n",
    "\n",
    "    def prueba(k):\n",
    "\n",
    "        if X[i-1, k] == X[j-1, k] :\n",
    "\n",
    "            alpha[k] = 1\n",
    "\n",
    "        else :\n",
    "\n",
    "            alpha[k] = 0\n",
    "\n",
    "        return(alpha)\n",
    "\n",
    "    \n",
    "    from joblib import Parallel, delayed\n",
    "    import multiprocessing\n",
    "\n",
    "    n_jobs  = multiprocessing.cpu_count()\n",
    "    \n",
    "    alpha=Parallel(n_jobs=n_jobs)( delayed(prueba)( k ) for k in range(0, X.shape[1]) )\n",
    "    \n",
    "    alpha = sum(alpha)\n",
    "\n",
    "    return(alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gower_Similarity_Python(i,j, Mixed_Data_Set, p1, p2, p3):\n",
    "\n",
    "            X = Mixed_Data_Set\n",
    "\n",
    "   # The data matrix X have to be order in the following way:\n",
    "   # The p1 first are quantitative, the following p2 are binary categorical, and the following p3 are multiple categorical.\n",
    "\n",
    "   #####################################################################################\n",
    "        \n",
    "            def G(k, X):\n",
    "\n",
    "                range = X[:,k].max() - X[:,k].min() \n",
    "\n",
    "                return(range)\n",
    "\n",
    "            G_vector = np.repeat(0, p1)\n",
    "\n",
    "            for r in range(0, p1):\n",
    "\n",
    "                G_vector[r] = G(r, X)\n",
    "                \n",
    "      \n",
    "    ##########################################################################################\n",
    "    \n",
    "            ones = np.repeat(1, p1)\n",
    "\n",
    "            Quantitative_Data = X[: , 0:p1]\n",
    "\n",
    "            Binary_Data = X[: , (p1):(p1+p2)]\n",
    "            \n",
    "            Multiple_Categorical_Data = X[: , (p1+p2):(p1+p2+p3) ]\n",
    "\n",
    "    ##########################################################################################\n",
    "\n",
    "            numerator_part_1 = ( ones - ( abs(Quantitative_Data[i-1,:] - Quantitative_Data[j-1,:]) / G_vector ) ).sum() \n",
    "\n",
    "            numerator_part_2 = a(Binary_Data)[i-1,j-1] + alpha_py_Parallel(i,j, Multiple_Categorical_Data)\n",
    "\n",
    "            numerator = numerator_part_1 + numerator_part_2\n",
    " \n",
    "            denominator = p1 + (p2 - d(Binary_Data)[i-1,j-1]) + p3\n",
    "\n",
    "            Similarity_Gower = numerator / denominator  \n",
    "\n",
    "            return(Similarity_Gower)\n",
    "\n",
    "##########################################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Dist_Gower_Py(i, j, Mixed_Data , p1, p2, p3):\n",
    "\n",
    "        Dist_Gower = np.sqrt( 1 - Gower_Similarity_Python(i, j, Mixed_Data , p1, p2, p3) )\n",
    "\n",
    "        return(Dist_Gower)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN_regression_Parallel_Numpy( X , Y , x_new, k, distance = \"Minkowski\" , q = 0, p1=0, p2=0, p3=0 ):\n",
    "\n",
    "##########################################################################################################\n",
    "\n",
    "## Para paralelizar el algoritmo \n",
    "\n",
    "    from joblib import Parallel, delayed\n",
    "    import multiprocessing\n",
    "\n",
    "####################################################################################################################################################################################################################################################\n",
    "\n",
    "    # Y tiene que ser un array vector de Numpy con la variable respuesta\n",
    "\n",
    "    # X tiene que ser un array matrix de Numpy con los predictotres (X1,...,Xp). \n",
    "\n",
    "    # x_new tiene que ser un array vector de Numpy \n",
    "\n",
    "####################################################################################################################################################################################################################################################\n",
    "\n",
    "    X = pd.concat([X, x_new.to_frame().T], ignore_index=True)\n",
    "\n",
    "    distances = []\n",
    "\n",
    "    Y_values_knn = []\n",
    "\n",
    "\n",
    "####################################################################################################################################################################################################################################################\n",
    "    \n",
    "    \n",
    "    \n",
    "    if distance == \"Gower\":\n",
    "\n",
    "        # The data matrix X have to be order in the following way:\n",
    "        # The p1 first are quantitative, the following p2 are binary categorical, and the following p3 are multiple categorical.\n",
    "\n",
    "\n",
    "        def a(Binary_Data) :\n",
    "\n",
    "            X = Binary_Data\n",
    "\n",
    "            a = X @ X.T\n",
    "\n",
    "            return(a)\n",
    "\n",
    "##########################################################################################\n",
    "\n",
    "        def d(Binary_Data):\n",
    "\n",
    "            X = Binary_Data\n",
    "\n",
    "            ones_matrix = np.ones(( X.shape[0] , X.shape[1])) \n",
    "\n",
    "            d = (ones_matrix - X) @ (ones_matrix - X).T\n",
    "\n",
    "            return(d)\n",
    "\n",
    "##########################################################################################\n",
    "\n",
    "        def alpha_py(i,j, Multiple_Categorical_Data):\n",
    "\n",
    "                X = Multiple_Categorical_Data\n",
    "\n",
    "                alpha = np.repeat(0, X.shape[1])\n",
    "\n",
    "                for k in range(0, X.shape[1]) :\n",
    "\n",
    "                    if X.iloc[i-1, k] == X.iloc[j-1, k] :\n",
    "\n",
    "                        alpha[k] = 1\n",
    "\n",
    "                    else :\n",
    "\n",
    "                        alpha[k] = 0\n",
    "\n",
    "\n",
    "                alpha = alpha.sum()\n",
    "\n",
    "                return(alpha)\n",
    "\n",
    "   ##########################################################################################\n",
    "\n",
    "\n",
    "        def Gower_Similarity_Python(i,j, Mixed_Data_Set, p1, p2, p3):\n",
    "\n",
    "            X = Mixed_Data_Set\n",
    "\n",
    "   # The data matrix X have to be order in the following way:\n",
    "   # The p1 first are quantitative, the following p2 are binary categorical, and the following p3 are multiple categorical.\n",
    "\n",
    "   #####################################################################################\n",
    "        \n",
    "            def G(k, X):\n",
    "\n",
    "                range = X.iloc[:,k].max() - X.iloc[:,k].min() \n",
    "\n",
    "                return(range)\n",
    "\n",
    "            G_vector = np.repeat(0, p1)\n",
    "\n",
    "            for r in range(0, p1):\n",
    "\n",
    "                G_vector[r] = G(r, X)\n",
    "                \n",
    "      \n",
    "    ##########################################################################################\n",
    "    \n",
    "            ones = np.repeat(1, p1)\n",
    "\n",
    "            Quantitative_Data = X.iloc[: , 0:p1]\n",
    "\n",
    "            Binary_Data = X.iloc[: , (p1):(p1+p2)]\n",
    "            \n",
    "            Multiple_Categorical_Data = X.iloc[: , (p1+p2):(p1+p2+p3) ]\n",
    "\n",
    "    ##########################################################################################\n",
    "\n",
    "            numerator_part_1 = ( ones - ( (Quantitative_Data.iloc[i-1,:] - Quantitative_Data.iloc[j-1,:]).abs() / G_vector ) ).sum() \n",
    "\n",
    "            numerator_part_2 = a(Binary_Data).iloc[i-1,j-1] + alpha_py(i,j, Multiple_Categorical_Data)\n",
    "\n",
    "            numerator = numerator_part_1 + numerator_part_2\n",
    " \n",
    "            denominator = p1 + (p2 - d(Binary_Data).iloc[i-1,j-1]) + p3\n",
    "\n",
    "            Similarity_Gower = numerator / denominator  \n",
    "\n",
    "            return(Similarity_Gower)\n",
    "\n",
    "##########################################################################################\n",
    "\n",
    "        def Dist_Gower_Py(i, j, Mixed_Data , p1, p2, p3):\n",
    "\n",
    "            Dist_Gower = np.sqrt( 1 - Gower_Similarity_Python(i, j, Mixed_Data , p1, p2, p3) )\n",
    "\n",
    "            return(Dist_Gower)    \n",
    "\n",
    "    ###################################################################\n",
    "\n",
    "    ## PARTE DEL CODIGO A PARALELIZAR\n",
    "\n",
    "        # for i in range(1, len(X)):\n",
    "\n",
    "            # distances.append( Dist_Gower_Py( len(X), i , X, p1, p2, p3) )\n",
    "\n",
    "        n_jobs  = multiprocessing.cpu_count()\n",
    "\n",
    "        distances = Parallel(n_jobs=n_jobs)( delayed(Dist_Gower_Py)( len(X), i , X, p1, p2, p3) for i in range(1, len(X)) )\n",
    "\n",
    "######################################################################################################################################\n",
    "    \n",
    "    distances = pd.DataFrame({'distances': distances})\n",
    "\n",
    "    distances = distances.sort_values(by=[\"distances\"]).reset_index(drop=False)\n",
    "        \n",
    "    knn = distances.iloc[0:k , :]\n",
    "\n",
    "    for i in knn.iloc[:,0]:\n",
    "\n",
    "        Y_values_knn.append(Y[i , ])\n",
    "\n",
    "\n",
    "    y_predict = sum(Y_values_knn)/k\n",
    "\n",
    "                                     \n",
    "    return y_predict   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##########################################################################################\n",
    "\n",
    "        def alpha_py(i,j, Multiple_Categorical_Data):\n",
    "\n",
    "                X = Multiple_Categorical_Data\n",
    "\n",
    "                alpha = np.repeat(0, X.shape[1])\n",
    "\n",
    "                for k in range(0, X.shape[1]) :\n",
    "\n",
    "                    if X.iloc[i-1, k] == X.iloc[j-1, k] :\n",
    "\n",
    "                        alpha[k] = 1\n",
    "\n",
    "                    else :\n",
    "\n",
    "                        alpha[k] = 0\n",
    "\n",
    "\n",
    "                alpha = alpha.sum()\n",
    "\n",
    "                return(alpha)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "   ##########################################################################################\n",
    "\n",
    "\n",
    "        def Gower_Similarity_Python(i,j, Mixed_Data_Set, p1, p2, p3):\n",
    "\n",
    "            X = Mixed_Data_Set\n",
    "\n",
    "   # The data matrix X have to be order in the following way:\n",
    "   # The p1 first are quantitative, the following p2 are binary categorical, and the following p3 are multiple categorical.\n",
    "\n",
    "   #####################################################################################\n",
    "        \n",
    "            def G(k, X):\n",
    "\n",
    "                range = X.iloc[:,k].max() - X.iloc[:,k].min() \n",
    "\n",
    "                return(range)\n",
    "\n",
    "            G_vector = np.repeat(0, p1)\n",
    "\n",
    "            for r in range(0, p1):\n",
    "\n",
    "                G_vector[r] = G(r, X)\n",
    "                \n",
    "      \n",
    "    ##########################################################################################\n",
    "    \n",
    "            ones = np.repeat(1, p1)\n",
    "\n",
    "            Quantitative_Data = X.iloc[: , 0:p1]\n",
    "\n",
    "            Binary_Data = X.iloc[: , (p1):(p1+p2)]\n",
    "            \n",
    "            Multiple_Categorical_Data = X.iloc[: , (p1+p2):(p1+p2+p3) ]\n",
    "\n",
    "    ##########################################################################################\n",
    "\n",
    "            numerator_part_1 = ( ones - ( (Quantitative_Data.iloc[i-1,:] - Quantitative_Data.iloc[j-1,:]).abs() / G_vector ) ).sum() \n",
    "\n",
    "            numerator_part_2 = a(Binary_Data).iloc[i-1,j-1] + alpha_py(i,j, Multiple_Categorical_Data)\n",
    "\n",
    "            numerator = numerator_part_1 + numerator_part_2\n",
    " \n",
    "            denominator = p1 + (p2 - d(Binary_Data).iloc[i-1,j-1]) + p3\n",
    "\n",
    "            Similarity_Gower = numerator / denominator  \n",
    "\n",
    "            return(Similarity_Gower)\n",
    "\n",
    "##########################################################################################\n",
    "\n",
    "        def Dist_Gower_Py(i, j, Mixed_Data , p1, p2, p3):\n",
    "\n",
    "            Dist_Gower = np.sqrt( 1 - Gower_Similarity_Python(i, j, Mixed_Data , p1, p2, p3) )\n",
    "\n",
    "            return(Dist_Gower)    \n",
    "\n",
    "    ###################################################################\n",
    "\n",
    "    ## PARTE DEL CODIGO A PARALELIZAR\n",
    "\n",
    "        # for i in range(1, len(X)):\n",
    "\n",
    "            # distances.append( Dist_Gower_Py( len(X), i , X, p1, p2, p3) )\n",
    "\n",
    "        n_jobs  = multiprocessing.cpu_count()\n",
    "\n",
    "        distances = Parallel(n_jobs=n_jobs)( delayed(Dist_Gower_Py)( len(X), i , X, p1, p2, p3) for i in range(1, len(X)) )\n",
    "\n",
    "######################################################################################################################################\n",
    "    \n",
    "    distances = pd.DataFrame({'distances': distances})\n",
    "\n",
    "    distances = distances.sort_values(by=[\"distances\"]).reset_index(drop=False)\n",
    "        \n",
    "    knn = distances.iloc[0:k , :]\n",
    "\n",
    "    for i in knn.iloc[:,0]:\n",
    "\n",
    "        Y_values_knn.append(Y.iloc[i , ])\n",
    "\n",
    "\n",
    "    y_predict = sum(Y_values_knn)/k\n",
    "\n",
    "                                     \n",
    "    return y_predict   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.cienciadedatos.net/documentos/py12-paralelizar-con-python.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c63d8c7d738c2960218a10995aedf0a7f67a49a231e71037adf0440953cdb45b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
