[["index.html", "Introduction to Pandas Chapter 1 Data-frame as data-matrix", " Introduction to Pandas Fabio Scielzo Ortiz 2023-03-06 Chapter 1 Data-frame as data-matrix We are going to consider data-frames as data matrix. Given a data-frame \\(\\hspace{0.05cm}df\\hspace{0.05cm}\\) with \\(\\hspace{0.05cm}p\\hspace{0.05cm}\\) columns and \\(\\hspace{0.05cm}n\\hspace{0.05cm}\\) rows, we can represent it as data-matrix as follows: \\[D(df) \\hspace{0.05cm} = \\hspace{0.05cm} \\begin{pmatrix} x_1^t \\\\ x_2^t \\\\ ... \\\\ x_n^t \\end{pmatrix} \\hspace{0.05cm} =\\hspace{0.05cm} \\begin{pmatrix} x_{11} &amp; x_{12} &amp; ... &amp; x_{1p}\\\\ x_{21} &amp; x_{22} &amp; ... &amp; x_{2p}\\\\ ... &amp; ... &amp; ... &amp; ... \\\\ x_{n1} &amp; x_{n2} &amp; ... &amp; x_{np} \\end{pmatrix} \\hspace{0.05cm} =\\hspace{0.05cm} \\left( X_1 X_2 ... X_p \\right)\\] Where \\(\\hspace{0.05cm}x_i=(x_{i1},..., x_{ip})^t\\hspace{0.05cm}\\) represent the \\(\\hspace{0.05cm}i\\)-th row and \\(\\hspace{0.05cm}X_j\\hspace{0.05cm}\\) the \\(\\hspace{0.05cm}j\\)-th column of the data-frame \\(\\hspace{0.05cm}df\\). "],["create-a-new-data-frame.html", "Chapter 2 Create a new data-frame", " Chapter 2 Create a new data-frame We can create a new data-frame using Pandas as follows: import pandas as pd ClienteID = pd.Series([&#39;C1&#39;, &#39;C2&#39;, &#39;C3&#39;, &#39;C4&#39;, &#39;C5&#39;, &#39;C6&#39;, &#39;C7&#39;, &#39;C8&#39;, &#39;C9&#39;, &#39;C10&#39;,&#39;C11&#39;,&#39;C12&#39;]) Nombre = pd.Series([&#39;Orlando&#39;, &#39;Keith&#39;, &#39;Donna&#39;, &#39;Janet&#39;, &#39;Fabio&#39;, &#39;Juan&#39;, &#39;Lucia&#39;, &#39;Pedro&#39;, &#39;Sergio&#39;, &#39;Grecia&#39;, &#39;Ismael&#39;, &#39;Luis&#39;]) Pais = pd.Series([&#39;Australia&#39;, &#39;India&#39;, &#39;Germany&#39;, &#39;United States&#39;, &#39;España&#39;, &#39;España&#39;, &#39;España&#39;, &#39;Italia&#39;, &#39;United States&#39;, &#39;Peru&#39;,&#39;España&#39;,&#39;España&#39;]) Ciudad = pd.Series([&#39;&#39;,&#39;&#39;,&#39;Berlin&#39;,&#39;California&#39;,&#39;Madrid&#39;, &#39;Sevilla&#39;, &#39;&#39;, &#39;Roma&#39;, &#39;New York&#39;, &#39;Lima&#39;, &#39;Madrid&#39;, &#39;Murcia&#39;]) Email = pd.Series([&#39;&#39;,&#39;keith0@adventure-works.com&#39;,&#39;donna0@adventure-works.com&#39;,&#39;janet1@adventure-works.com&#39;,&#39;fabio10@gmail.com&#39;, &#39;&#39;, &#39;LuciaPerez@hotmail.com&#39;, &#39;Pedro99@gmail.com&#39;, &#39;sergio_as@gmail.com&#39;, &#39;Grecia89@gmail.com&#39;, &#39;Isma98@gmail.com&#39;, &#39;Luismiguel123@gmail.com&#39;]) Telefono = pd.Series([&#39;917755028&#39;, &#39;&#39;, &#39;915547890&#39;, &#39;&#39;, &#39;&#39;, &#39;915869028&#39;, &#39;&#39;, &#39;910007890&#39;, &#39;&#39;, &#39;&#39;, &#39;912234543&#39;, &#39;&#39;]) Clientes = pd.DataFrame({&#39;ClienteID&#39;: ClienteID , &#39;Nombre&#39;: Nombre, &#39;Pais&#39;:Pais , &#39;Ciudad&#39;:Ciudad, &#39;Email&#39;:Email, &#39;Telefono&#39;:Telefono}) Clientes ClienteID Nombre Pais Ciudad Email Telefono 0 C1 Orlando Australia 917755028 1 C2 Keith India keith0@adventure-works.com 2 C3 Donna Germany Berlin donna0@adventure-works.com 915547890 3 C4 Janet United States California janet1@adventure-works.com 4 C5 Fabio España Madrid fabio10@gmail.com 5 C6 Juan España Sevilla 915869028 6 C7 Lucia España LuciaPerez@hotmail.com 7 C8 Pedro Italia Roma Pedro99@gmail.com 910007890 8 C9 Sergio United States New York sergio_as@gmail.com 9 C10 Grecia Peru Lima Grecia89@gmail.com 10 C11 Ismael España Madrid Isma98@gmail.com 912234543 11 C12 Luis España Murcia Luismiguel123@gmail.com Now we are going to create two additional data-frames: VentasId = pd.Series([&#39;V1&#39;, &#39;V2&#39;, &#39;V3&#39;, &#39;V4&#39;, &#39;V5&#39;, &#39;V6&#39;, &#39;V7&#39;, &#39;V8&#39;, &#39;V9&#39;, &#39;V10&#39;, &#39;V11&#39;, &#39;V12&#39;, &#39;V13&#39;, &#39;V14&#39;, &#39;V15&#39;]) Producto = pd.Series([&#39;Alfombra&#39;, &#39;Killim&#39;, &#39;Killim&#39;, &#39;Alfombra&#39;, &#39;Killim&#39;, &#39;Killim&#39;, &#39;Alfombra&#39;, &#39;Killim&#39;, &#39;Killim&#39;, &#39;Alfombra&#39;, &#39;Killim&#39;, &#39;Killim&#39;]) Precio = pd.Series([1500, 699.50, 475, 5000, 499.50, 55, 2500, 299.5, 600, 1200, 500, 650, 3500, 1000, 350]) ClienteID = pd.Series([&#39;C1&#39;,&#39;C3&#39;,&#39;C9&#39;,&#39;C4&#39;,&#39;C8&#39;, &#39;C5&#39;, &#39;C2&#39;, &#39;C10&#39;, &#39;C2&#39;, &#39;C7&#39;, &#39;C8&#39;, &#39;C9&#39;, &#39;C7&#39;, &#39;C6&#39;, &#39;C10&#39;]) Proveedor = pd.Series([&#39;P1&#39;, &#39;P1&#39;, &#39;P3&#39;, &#39;P1&#39;, &#39;P1&#39;, &#39;P3&#39;, &#39;P1&#39;, &#39;P1&#39;, &#39;P3&#39;, &#39;P1&#39;, &#39;P1&#39;, &#39;P3&#39;, &#39;P1&#39;, &#39;P1&#39;, &#39;P3&#39;]) Ventas = pd.DataFrame({&#39;VentasId&#39;: VentasId, &#39;Producto&#39;: Producto, &#39;Precio&#39;:Precio , &#39;ClienteID&#39;:Cliente, &#39;Proveedor&#39;:Proveedor}) Ventas VentasId Producto Precio Cliente Proveedor 0 V1 Alfombra 1500.0 C1 P1 1 V2 Killim 699.5 C3 P1 2 V3 Killim 475.0 C9 P3 3 V4 Alfombra 5000.0 C4 P1 4 V5 Killim 499.5 C8 P1 5 V6 Killim 55.0 C5 P3 6 V7 Alfombra 2500.0 C2 P1 7 V8 Killim 299.5 C10 P1 8 V9 Killim 600.0 C2 P3 9 V10 Alfombra 1200.0 C7 P1 10 V11 Killim 500.0 C8 P1 11 V12 Killim 650.0 C9 P3 12 V13 NaN 3500.0 C7 P1 13 V14 NaN 1000.0 C6 P1 14 V15 NaN 350.0 C10 P3 ProveedorID = pd.Series([&#39;P1&#39;, &#39;P2&#39;, &#39;P3&#39;]) Nombre = pd.Series([&#39;Intertrade&#39;, &#39;SaidKarpet&#39;, &#39;OrientKillim&#39; ]) Email = pd.Series([&#39;Intertrade@gmail.com&#39;, &#39;SaidKarpet@gmail.com&#39;, &#39;OrientKillim@gmail.com&#39;]) Telefono = pd.Series([&#39;912223344&#39;, &#39;912783794&#39;, &#39;9100155475&#39;]) Proveedores = pd.DataFrame({&#39;ProveedorID&#39;: ProveedorID, &#39;Nombre&#39;: Nombre, &#39;Email&#39;:Email, &#39;Telefono&#39;:Telefono}) Proveedores ProveedorID Nombre Email Telefono 0 P1 Intertrade Intertrade@gmail.com 912223344 1 P2 SaidKarpet SaidKarpet@gmail.com 912783794 2 P3 OrientKillim OrientKillim@gmail.com 9100155475 "],["import-a-csv-as-a-data-frame.html", "Chapter 3 Import a CSV as a data-frame", " Chapter 3 Import a CSV as a data-frame The most common way to work is not to manually create a data frame, as we saw in the previous section. Instead, we often import CSV as data frames. House_Price_Data = pd.read_csv(&#39;House_Price_Regression.csv&#39;) House_Price_Data neighborhood_recode latitude longitude price no_of_bedrooms no_of_bathrooms quality_recode maid_room_recode unfurnished_recode balcony_recode … private_garden_recode private_gym_recode private_jacuzzi_recode private_pool_recode security_recode shared_gym_recode shared_pool_recode shared_spa_recode view_of_water_recode size_in_m_2 0 46.0 25.113208 55.138932 2700000 1 2 2.0 0.0 0.0 1.0 … 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0 100.242337 1 46.0 25.106809 55.151201 2850000 2 2 2.0 0.0 0.0 1.0 … 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 1.0 146.972546 2 36.0 25.063302 55.137728 1150000 3 5 2.0 1.0 1.0 1.0 … 0.0 0.0 1.0 0.0 1.0 1.0 1.0 0.0 1.0 181.253753 3 11.0 25.227295 55.341761 2850000 2 3 1.0 0.0 1.0 1.0 … 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 187.664060 4 46.0 25.114275 55.139764 1729200 0 1 2.0 0.0 0.0 0.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 47.101821 … … … … … … … … … … … … … … … … … … … … … … 1900 42.0 25.176892 55.310712 1500000 2 2 3.0 0.0 1.0 1.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 100.985561 1901 42.0 25.166145 55.276684 1230000 1 2 2.0 0.0 0.0 1.0 … 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 1.0 70.606280 1902 16.0 25.206500 55.345056 2900000 3 5 2.0 1.0 1.0 1.0 … 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 179.302790 1903 37.0 25.073858 55.229844 675000 1 2 2.0 0.0 1.0 1.0 … 1.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 1.0 68.748220 1904 36.0 25.079130 55.154713 760887 1 2 0.0 0.0 0.0 1.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 74.322400 1905 rows × 29 columns "],["export-a-csv.html", "Chapter 4 Export a CSV", " Chapter 4 Export a CSV We can also export a data-frame as CSV as follows: data_frame.to_csv(&#39;filename.csv&#39;, index=False) "],["number-of-rows-and-columns.html", "Chapter 5 Number of rows and columns", " Chapter 5 Number of rows and columns We can get the number of rows and columns of a data-frame: House_Price_Data.shape (1905, 29) The number of rows: House_Price_Data.shape[0] 1905 Another way to get the number of rows: len(House_Price_Data) 1905 The number of columns: House_Price_Data.shape[1] 29 "],["head-and-tail.html", "Chapter 6 Head and Tail 6.1 Head 6.2 Tail", " Chapter 6 Head and Tail 6.1 Head We can also view the first rows of a data-frame using head() method: House_Price_Data.head() neighborhood_recode latitude longitude price no_of_bedrooms no_of_bathrooms quality_recode maid_room_recode unfurnished_recode balcony_recode … private_garden_recode private_gym_recode private_jacuzzi_recode private_pool_recode security_recode shared_gym_recode shared_pool_recode shared_spa_recode view_of_water_recode size_in_m_2 0 46.0 25.113208 55.138932 2700000 1 2 2.0 0.0 0.0 1.0 … 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0 100.242337 1 46.0 25.106809 55.151201 2850000 2 2 2.0 0.0 0.0 1.0 … 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 1.0 146.972546 2 36.0 25.063302 55.137728 1150000 3 5 2.0 1.0 1.0 1.0 … 0.0 0.0 1.0 0.0 1.0 1.0 1.0 0.0 1.0 181.253753 3 11.0 25.227295 55.341761 2850000 2 3 1.0 0.0 1.0 1.0 … 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 187.664060 4 46.0 25.114275 55.139764 1729200 0 1 2.0 0.0 0.0 0.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 47.101821 5 rows × 29 columns House_Price_Data.head(10) neighborhood_recode latitude longitude price no_of_bedrooms no_of_bathrooms quality_recode maid_room_recode unfurnished_recode balcony_recode … private_garden_recode private_gym_recode private_jacuzzi_recode private_pool_recode security_recode shared_gym_recode shared_pool_recode shared_spa_recode view_of_water_recode size_in_m_2 0 46.0 25.113208 55.138932 2700000 1 2 2.0 0.0 0.0 1.0 … 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0 100.242337 1 46.0 25.106809 55.151201 2850000 2 2 2.0 0.0 0.0 1.0 … 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 1.0 146.972546 2 36.0 25.063302 55.137728 1150000 3 5 2.0 1.0 1.0 1.0 … 0.0 0.0 1.0 0.0 1.0 1.0 1.0 0.0 1.0 181.253753 3 11.0 25.227295 55.341761 2850000 2 3 1.0 0.0 1.0 1.0 … 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 187.664060 4 46.0 25.114275 55.139764 1729200 0 1 2.0 0.0 0.0 0.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 47.101821 5 46.0 25.114275 55.139764 3119900 1 2 2.0 0.0 0.0 0.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 94.296545 6 46.0 25.114275 55.139764 8503600 2 3 0.0 1.0 0.0 0.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 191.565986 7 46.0 25.114275 55.139764 3119900 1 2 2.0 0.0 0.0 0.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 94.296545 8 46.0 25.106668 55.149275 2100000 3 3 1.0 0.0 0.0 0.0 … 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 203.085958 9 15.0 25.194935 55.282665 2690000 2 3 2.0 0.0 0.0 1.0 … 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 1.0 141.305463 10 rows × 29 columns Mathematically \\(head()\\) operation could be formalized as follows: \\(\\\\[0.3cm]\\) Let \\(\\hspace{0.05cm} D(df) \\hspace{0.05cm}=\\hspace{0.05cm} \\begin{pmatrix} x_1^t \\\\ x_2^t \\\\ ... \\\\ x_n^t \\end{pmatrix}\\hspace{0.1cm}\\) be the data matrix that represent the data-frame \\(\\hspace{0.05cm}df\\hspace{0.05cm}\\), then: \\[df.head(k) \\hspace{0.1cm}=\\hspace{0.1cm} D[\\hspace{0.1cm}1:k \\hspace{0.1cm},\\hspace{0.1cm} : \\hspace{0.1cm}] \\hspace{0.1cm} = \\hspace{0.1cm} \\begin{pmatrix} x_1^t \\\\ x_2^t \\\\ ... \\\\ x_k^t \\end{pmatrix}\\] 6.2 Tail We can also view the last rows of a data-frame using tail() method: House_Price_Data.tail() neighborhood_recode latitude longitude price no_of_bedrooms no_of_bathrooms quality_recode maid_room_recode unfurnished_recode balcony_recode … private_garden_recode private_gym_recode private_jacuzzi_recode private_pool_recode security_recode shared_gym_recode shared_pool_recode shared_spa_recode view_of_water_recode size_in_m_2 1900 42.0 25.176892 55.310712 1500000 2 2 3.0 0.0 1.0 1.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 100.985561 1901 42.0 25.166145 55.276684 1230000 1 2 2.0 0.0 0.0 1.0 … 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 1.0 70.606280 1902 16.0 25.206500 55.345056 2900000 3 5 2.0 1.0 1.0 1.0 … 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 179.302790 1903 37.0 25.073858 55.229844 675000 1 2 2.0 0.0 1.0 1.0 … 1.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 1.0 68.748220 1904 36.0 25.079130 55.154713 760887 1 2 0.0 0.0 0.0 1.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 74.322400 5 rows × 29 columns House_Price_Data.tail(7) neighborhood_recode latitude longitude price no_of_bedrooms no_of_bathrooms quality_recode maid_room_recode unfurnished_recode balcony_recode … private_garden_recode private_gym_recode private_jacuzzi_recode private_pool_recode security_recode shared_gym_recode shared_pool_recode shared_spa_recode view_of_water_recode size_in_m_2 1898 46.0 25.104330 55.148769 2700000 1 2 2.0 0.0 1.0 1.0 … 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 1.0 99.963628 1899 27.0 25.037477 55.221942 550000 1 2 2.0 0.0 1.0 1.0 … 0.0 0.0 0.0 1.0 0.0 1.0 1.0 0.0 0.0 78.688841 1900 42.0 25.176892 55.310712 1500000 2 2 3.0 0.0 1.0 1.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 100.985561 1901 42.0 25.166145 55.276684 1230000 1 2 2.0 0.0 0.0 1.0 … 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 1.0 70.606280 1902 16.0 25.206500 55.345056 2900000 3 5 2.0 1.0 1.0 1.0 … 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 179.302790 1903 37.0 25.073858 55.229844 675000 1 2 2.0 0.0 1.0 1.0 … 1.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 1.0 68.748220 1904 36.0 25.079130 55.154713 760887 1 2 0.0 0.0 0.0 1.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 74.322400 7 rows × 29 columns Mathematically \\(\\hspace{0.05cm} tail() \\hspace{0.05cm}\\) operation could be formalized as follows: Let \\(\\hspace{0.1cm} D= \\begin{pmatrix} x_1^t \\\\ x_2^t \\\\ ... \\\\ x_n^t \\end{pmatrix}\\hspace{0.1cm}\\) be the data matrix that represent the data-frame \\(\\hspace{0.05cm}df\\hspace{0.05cm}\\), then: \\[df.tail(k) \\hspace{0.1cm}=\\hspace{0.1cm} D[\\hspace{0.1cm}(n-k+1):n \\hspace{0.1cm},\\hspace{0.1cm} : \\hspace{0.1cm}] \\hspace{0.1cm} = \\hspace{0.1cm} \\begin{pmatrix} x_{n-k+1}^t \\\\ x_{n-k+2}^t \\\\ ... \\\\ x_n^t \\end{pmatrix}\\] "],["column-names.html", "Chapter 7 Column Names", " Chapter 7 Column Names We can get the column names of a data-frame: House_Price_Data.columns Index([&#39;neighborhood_recode&#39;, &#39;latitude&#39;, &#39;longitude&#39;, &#39;price&#39;, &#39;no_of_bedrooms&#39;, &#39;no_of_bathrooms&#39;, &#39;quality_recode&#39;, &#39;maid_room_recode&#39;, &#39;unfurnished_recode&#39;, &#39;balcony_recode&#39;, &#39;barbecue_area_recode&#39;, &#39;central_ac_recode&#39;, &#39;childrens_play_area_recode&#39;, &#39;childrens_pool_recode&#39;, &#39;concierge_recode&#39;, &#39;covered_parking_recode&#39;, &#39;kitchen_appliances_recode&#39;, &#39;maid_service_recode&#39;, &#39;pets_allowed_recode&#39;, &#39;private_garden_recode&#39;, &#39;private_gym_recode&#39;, &#39;private_jacuzzi_recode&#39;, &#39;private_pool_recode&#39;, &#39;security_recode&#39;, &#39;shared_gym_recode&#39;, &#39;shared_pool_recode&#39;, &#39;shared_spa_recode&#39;, &#39;view_of_water_recode&#39;, &#39;size_in_m_2&#39;], dtype=&#39;object&#39;) We will denote \\(\\hspace{0.05cm} X_j\\hspace{0.05cm}\\) column name as \\(\\hspace{0.05cm}name(X_j) \\hspace{0.05cm}\\). "],["selecting-columns-from-a-data-frame.html", "Chapter 8 Selecting columns from a data-frame 8.1 loc method 8.2 iloc method", " Chapter 8 Selecting columns from a data-frame 8.1 loc method With loc method we can select rows from a data-frame using the column names: House_Price_Data.loc[ : , [&#39;latitude&#39;, &#39;price&#39;, &#39;no_of_bathrooms&#39;, &#39;quality_recode&#39;, &#39;balcony_recode&#39;]] latitude price no_of_bathrooms quality_recode balcony_recode 0 25.113208 2700000 2 2.0 1.0 1 25.106809 2850000 2 2.0 1.0 2 25.063302 1150000 5 2.0 1.0 3 25.227295 2850000 3 1.0 1.0 4 25.114275 1729200 1 2.0 0.0 … … … … … … 1900 25.176892 1500000 2 3.0 1.0 1901 25.166145 1230000 2 2.0 1.0 1902 25.206500 2900000 5 2.0 1.0 1903 25.073858 675000 2 2.0 1.0 1904 25.079130 760887 2 0.0 1.0 1905 rows × 5 columns Mathematically loc[]select operation could be define as: \\(\\\\[0.4cm]\\) \\[df.loc\\hspace{0.1cm} [\\hspace{0.1cm} : \\hspace{0.1cm} , \\hspace{0.1cm} [\\hspace{0.1cm}name(X_1), name(X_3), name(X_6) \\hspace{0.1cm}]\\hspace{0.1cm}] \\hspace{0.1cm}=\\hspace{0.1cm} D\\hspace{0.1cm} [\\hspace{0.1cm} : \\hspace{0.1cm}, \\hspace{0.1cm} [\\hspace{0.1cm} name(X_1),name(X_3),name(X_6) \\hspace{0.1cm}] \\hspace{0.1cm}] \\hspace{0.1cm}= \\\\[0.7cm] = \\hspace{0.1cm} \\left( X_1 , X_3 , X_6 \\right) \\hspace{0.1cm}=\\hspace{0.1cm} \\left( \\hspace{0.1cm} (x_{i1} , x_{i3}, x_{i6}) \\hspace{0.1cm}:\\hspace{0.1cm} i = 1,...,n \\hspace{0.1cm}\\right) \\hspace{0.1cm}= \\hspace{0.1cm}\\left(\\hspace{0.1cm} x_{i}[1,3,6] \\hspace{0.1cm}:\\hspace{0.1cm} i = 1,...,n \\hspace{0.1cm}\\right) \\hspace{0.1cm}=\\hspace{0.1cm} \\begin{pmatrix} x_{11} &amp; x_{13} &amp; x_{16} \\\\ x_{21} &amp; x_{23} &amp; x_{26} \\\\ ... &amp; ... &amp; ... \\\\ x_{n1} &amp; x_{n3} &amp; x_{n6} \\end{pmatrix} \\\\[1cm]\\] Where: \\(\\hspace{0.1cm}x_{i}[1,3,6] \\hspace{0.1cm}=\\hspace{0.1cm} (x_{i1} , x_{i3}, x_{i6})\\) 8.2 iloc method With iloc method we can select columns from a data-frame using the index of the columns: House_Price_Data.iloc[ : , 0:6] neighborhood_recode latitude longitude price no_of_bedrooms no_of_bathrooms 0 46.0 25.113208 55.138932 2700000 1 2 1 46.0 25.106809 55.151201 2850000 2 2 2 36.0 25.063302 55.137728 1150000 3 5 3 11.0 25.227295 55.341761 2850000 2 3 4 46.0 25.114275 55.139764 1729200 0 1 … … … … … … … 1900 42.0 25.176892 55.310712 1500000 2 2 1901 42.0 25.166145 55.276684 1230000 1 2 1902 16.0 25.206500 55.345056 2900000 3 5 1903 37.0 25.073858 55.229844 675000 1 2 1904 36.0 25.079130 55.154713 760887 1 2 1905 rows × 6 columns House_Price_Data.iloc[ : , [0,3,5]] neighborhood_recode price no_of_bathrooms 0 46.0 2700000 2 1 46.0 2850000 2 2 36.0 1150000 5 3 11.0 2850000 3 4 46.0 1729200 1 … … … … 1900 42.0 1500000 2 1901 42.0 1230000 2 1902 16.0 2900000 5 1903 37.0 675000 2 1904 36.0 760887 2 1905 rows × 3 columns Mathematically iloc[]select operation could be formalized as follows: \\(\\\\[0.4cm]\\) \\[df.iloc[\\hspace{0.1cm} : \\hspace{0.1cm} , \\hspace{0.1cm} 2:5 \\hspace{0.1cm}] \\hspace{0.1cm}=\\hspace{0.1cm} D[\\hspace{0.1cm} : \\hspace{0.1cm}, \\hspace{0.1cm} 2:5 \\hspace{0.1cm}] \\hspace{0.1cm}=\\hspace{0.1cm} \\left( X_2 , X_3 , X_4, X_5 \\right) \\hspace{0.1cm}=\\hspace{0.1cm} \\left( \\hspace{0.1cm} X_j \\hspace{0.1cm}:\\hspace{0.1cm} j = 1,...,5 \\hspace{0.1cm}\\right)\\hspace{0.1cm}=\\hspace{0.1cm} \\begin{pmatrix} x_{12} &amp; x_{13} &amp; x_{14} &amp; x_{15} \\\\ x_{22} &amp; x_{23} &amp; x_{24} &amp; x_{25} \\\\ ... &amp; ... &amp; ... \\\\ x_{n2} &amp; x_{n3} &amp; x_{n4} &amp; x_{n5} \\end{pmatrix} \\\\[2cm]\\] \\[df.iloc[\\hspace{0.1cm} : \\hspace{0.1cm} , \\hspace{0.1cm} [1,3,6] \\hspace{0.1cm}] \\hspace{0.1cm}=\\hspace{0.1cm} D[\\hspace{0.1cm} : \\hspace{0.1cm} , [1,3,6] [1,3,6] \\hspace{0.1cm}] \\hspace{0.1cm}=\\hspace{0.1cm} \\left( X_1 , X_3 , X_6 \\right) \\hspace{0.1cm}=\\hspace{0.1cm} \\left( \\hspace{0.1cm} X_j \\hspace{0.1cm}:\\hspace{0.1cm} j =1,3,6 \\hspace{0.1cm}\\right)\\hspace{0.1cm}=\\hspace{0.1cm} \\begin{pmatrix} x_{11} &amp; x_{13} &amp; x_{16} \\\\ x_{21} &amp; x_{23} &amp; x_{26} \\\\ ... &amp; ... &amp; ... \\\\ x_{n1} &amp; x_{n3} &amp; x_{n6} \\end{pmatrix}\\] "],["filter-rows-of-a-data-frame.html", "Chapter 9 Filter rows of a data-frame 9.1 loc method 9.2 iloc method", " Chapter 9 Filter rows of a data-frame 9.1 loc method With loc method we can filter rows that meet a condition related to their values for some columns: House_Price_Data.loc[ House_Price_Data.price &lt; 500000 , : ] neighborhood_recode latitude longitude price no_of_bedrooms no_of_bathrooms quality_recode maid_room_recode unfurnished_recode balcony_recode … private_garden_recode private_gym_recode private_jacuzzi_recode private_pool_recode security_recode shared_gym_recode shared_pool_recode shared_spa_recode view_of_water_recode size_in_m_2 49 12.0 25.016736 55.251010 365000 0 1 2.0 0.0 1.0 1.0 … 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 0.0 41.899253 55 36.0 25.065736 55.137452 375000 0 1 2.0 0.0 1.0 1.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 1.0 41.806350 146 27.0 25.044572 55.218948 390000 1 2 2.0 0.0 0.0 1.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 78.874647 160 27.0 25.042264 55.217360 410000 1 2 2.0 0.0 1.0 1.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 90.023007 194 38.0 25.043352 55.193510 310000 0 1 1.0 0.0 1.0 1.0 … 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 39.483775 … … … … … … … … … … … … … … … … … … … … … … 1848 24.0 25.091311 55.378277 270000 0 1 1.0 0.0 1.0 1.0 … 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 0.0 42.735380 1849 36.0 25.071246 55.140806 499000 1 1 2.0 0.0 1.0 1.0 … 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 0.0 62.430816 1857 36.0 25.078148 55.148277 400888 0 1 2.0 0.0 0.0 1.0 … 0.0 0.0 1.0 0.0 0.0 1.0 1.0 0.0 0.0 37.439909 1874 50.0 25.003730 55.297034 488888 1 2 2.0 0.0 1.0 1.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 64.846294 1897 4.0 25.153080 55.254242 360000 0 1 2.0 0.0 0.0 1.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 55.741800 114 rows × 29 columns House_Price_Data.loc[ House_Price_Data.price &lt;= 1000000 , : ] neighborhood_recode latitude longitude price no_of_bedrooms no_of_bathrooms quality_recode maid_room_recode unfurnished_recode balcony_recode … private_garden_recode private_gym_recode private_jacuzzi_recode private_pool_recode security_recode shared_gym_recode shared_pool_recode shared_spa_recode view_of_water_recode size_in_m_2 19 9.0 25.180301 55.263892 950000 1 2 2.0 0.0 1.0 1.0 … 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 1.0 83.055282 34 6.0 25.060310 55.241403 750000 1 1 0.0 0.0 1.0 1.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 73.950788 35 6.0 25.060310 55.241403 991000 2 2 0.0 0.0 1.0 1.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 107.953286 49 12.0 25.016736 55.251010 365000 0 1 2.0 0.0 1.0 1.0 … 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 0.0 41.899253 55 36.0 25.065736 55.137452 375000 0 1 2.0 0.0 1.0 1.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 1.0 41.806350 … … … … … … … … … … … … … … … … … … … … … … 1894 15.0 25.191107 55.269910 980888 1 1 2.0 0.0 1.0 1.0 … 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 0.0 101.078464 1897 4.0 25.153080 55.254242 360000 0 1 2.0 0.0 0.0 1.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 55.741800 1899 27.0 25.037477 55.221942 550000 1 2 2.0 0.0 1.0 1.0 … 0.0 0.0 0.0 1.0 0.0 1.0 1.0 0.0 0.0 78.688841 1903 37.0 25.073858 55.229844 675000 1 2 2.0 0.0 1.0 1.0 … 1.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 1.0 68.748220 1904 36.0 25.079130 55.154713 760887 1 2 0.0 0.0 0.0 1.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 74.322400 591 rows × 29 columns House_Price_Data.loc[ House_Price_Data.price &gt; 1000000 , : ] neighborhood_recode latitude longitude price no_of_bedrooms no_of_bathrooms quality_recode maid_room_recode unfurnished_recode balcony_recode … private_garden_recode private_gym_recode private_jacuzzi_recode private_pool_recode security_recode shared_gym_recode shared_pool_recode shared_spa_recode view_of_water_recode size_in_m_2 0 46.0 25.113208 55.138932 2700000 1 2 2.0 0.0 0.0 1.0 … 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0 100.242337 1 46.0 25.106809 55.151201 2850000 2 2 2.0 0.0 0.0 1.0 … 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 1.0 146.972546 2 36.0 25.063302 55.137728 1150000 3 5 2.0 1.0 1.0 1.0 … 0.0 0.0 1.0 0.0 1.0 1.0 1.0 0.0 1.0 181.253753 3 11.0 25.227295 55.341761 2850000 2 3 1.0 0.0 1.0 1.0 … 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 187.664060 4 46.0 25.114275 55.139764 1729200 0 1 2.0 0.0 0.0 0.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 47.101821 … … … … … … … … … … … … … … … … … … … … … … 1896 15.0 25.196489 55.272126 18040888 4 4 2.0 1.0 1.0 1.0 … 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 0.0 488.019459 1898 46.0 25.104330 55.148769 2700000 1 2 2.0 0.0 1.0 1.0 … 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 1.0 99.963628 1900 42.0 25.176892 55.310712 1500000 2 2 3.0 0.0 1.0 1.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 100.985561 1901 42.0 25.166145 55.276684 1230000 1 2 2.0 0.0 0.0 1.0 … 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 1.0 70.606280 1902 16.0 25.206500 55.345056 2900000 3 5 2.0 1.0 1.0 1.0 … 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 179.302790 1314 rows × 29 columns House_Price_Data.loc[ House_Price_Data.no_of_bedrooms == 2 , : ] neighborhood_recode latitude longitude price no_of_bedrooms no_of_bathrooms quality_recode maid_room_recode unfurnished_recode balcony_recode … private_garden_recode private_gym_recode private_jacuzzi_recode private_pool_recode security_recode shared_gym_recode shared_pool_recode shared_spa_recode view_of_water_recode size_in_m_2 1 46.0 25.106809 55.151201 2850000 2 2 2.0 0.0 0.0 1.0 … 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 1.0 146.972546 3 11.0 25.227295 55.341761 2850000 2 3 1.0 0.0 1.0 1.0 … 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 187.664060 6 46.0 25.114275 55.139764 8503600 2 3 0.0 1.0 0.0 0.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 191.565986 9 15.0 25.194935 55.282665 2690000 2 3 2.0 0.0 0.0 1.0 … 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 1.0 141.305463 11 22.0 25.075017 55.137997 2094999 2 3 1.0 0.0 1.0 1.0 … 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 0.0 98.291374 … … … … … … … … … … … … … … … … … … … … … … 1881 49.0 25.088903 55.171065 1850000 2 2 2.0 0.0 1.0 1.0 … 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 0.0 130.064200 1882 22.0 25.080542 55.140343 2090000 2 2 2.0 0.0 1.0 1.0 … 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 1.0 98.570083 1884 34.0 25.072569 55.126527 3300000 2 3 1.0 0.0 1.0 0.0 … 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 109.625540 1895 22.0 25.081243 55.145120 1350000 2 4 1.0 0.0 0.0 0.0 … 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 146.600934 1900 42.0 25.176892 55.310712 1500000 2 2 3.0 0.0 1.0 1.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 100.985561 729 rows × 29 columns House_Price_Data.loc[ House_Price_Data.no_of_bedrooms != 2 , : ] neighborhood_recode latitude longitude price no_of_bedrooms no_of_bathrooms quality_recode maid_room_recode unfurnished_recode balcony_recode … private_garden_recode private_gym_recode private_jacuzzi_recode private_pool_recode security_recode shared_gym_recode shared_pool_recode shared_spa_recode view_of_water_recode size_in_m_2 0 46.0 25.113208 55.138932 2700000 1 2 2.0 0.0 0.0 1.0 … 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0 100.242337 2 36.0 25.063302 55.137728 1150000 3 5 2.0 1.0 1.0 1.0 … 0.0 0.0 1.0 0.0 1.0 1.0 1.0 0.0 1.0 181.253753 4 46.0 25.114275 55.139764 1729200 0 1 2.0 0.0 0.0 0.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 47.101821 5 46.0 25.114275 55.139764 3119900 1 2 2.0 0.0 0.0 0.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 94.296545 7 46.0 25.114275 55.139764 3119900 1 2 2.0 0.0 0.0 0.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 94.296545 … … … … … … … … … … … … … … … … … … … … … … 1899 27.0 25.037477 55.221942 550000 1 2 2.0 0.0 1.0 1.0 … 0.0 0.0 0.0 1.0 0.0 1.0 1.0 0.0 0.0 78.688841 1901 42.0 25.166145 55.276684 1230000 1 2 2.0 0.0 0.0 1.0 … 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 1.0 70.606280 1902 16.0 25.206500 55.345056 2900000 3 5 2.0 1.0 1.0 1.0 … 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 179.302790 1903 37.0 25.073858 55.229844 675000 1 2 2.0 0.0 1.0 1.0 … 1.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 1.0 68.748220 1904 36.0 25.079130 55.154713 760887 1 2 0.0 0.0 0.0 1.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 74.322400 1176 rows × 29 columns House_Price_Data.loc[ House_Price_Data[&#39;no_of_bedrooms&#39;] != 2 , : ] neighborhood_recode latitude longitude price no_of_bedrooms no_of_bathrooms quality_recode maid_room_recode unfurnished_recode balcony_recode … private_garden_recode private_gym_recode private_jacuzzi_recode private_pool_recode security_recode shared_gym_recode shared_pool_recode shared_spa_recode view_of_water_recode size_in_m_2 0 46.0 25.113208 55.138932 2700000 1 2 2.0 0.0 0.0 1.0 … 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0 100.242337 2 36.0 25.063302 55.137728 1150000 3 5 2.0 1.0 1.0 1.0 … 0.0 0.0 1.0 0.0 1.0 1.0 1.0 0.0 1.0 181.253753 4 46.0 25.114275 55.139764 1729200 0 1 2.0 0.0 0.0 0.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 47.101821 5 46.0 25.114275 55.139764 3119900 1 2 2.0 0.0 0.0 0.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 94.296545 7 46.0 25.114275 55.139764 3119900 1 2 2.0 0.0 0.0 0.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 94.296545 … … … … … … … … … … … … … … … … … … … … … … 1899 27.0 25.037477 55.221942 550000 1 2 2.0 0.0 1.0 1.0 … 0.0 0.0 0.0 1.0 0.0 1.0 1.0 0.0 0.0 78.688841 1901 42.0 25.166145 55.276684 1230000 1 2 2.0 0.0 0.0 1.0 … 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 1.0 70.606280 1902 16.0 25.206500 55.345056 2900000 3 5 2.0 1.0 1.0 1.0 … 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 179.302790 1903 37.0 25.073858 55.229844 675000 1 2 2.0 0.0 1.0 1.0 … 1.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 1.0 68.748220 1904 36.0 25.079130 55.154713 760887 1 2 0.0 0.0 0.0 1.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 74.322400 1176 rows × 29 columns We can use isin() method to filter rows that have a value for some column that belongs to a specific set of values. House_Price_Data.loc[ House_Price_Data[&#39;no_of_bedrooms&#39;].isin([2,4]) , : ] neighborhood_recode latitude longitude price no_of_bedrooms no_of_bathrooms quality_recode maid_room_recode unfurnished_recode balcony_recode … private_garden_recode private_gym_recode private_jacuzzi_recode private_pool_recode security_recode shared_gym_recode shared_pool_recode shared_spa_recode view_of_water_recode size_in_m_2 1 46.0 25.106809 55.151201 2850000 2 2 2.0 0.0 0.0 1.0 … 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 1.0 146.972546 3 11.0 25.227295 55.341761 2850000 2 3 1.0 0.0 1.0 1.0 … 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 187.664060 6 46.0 25.114275 55.139764 8503600 2 3 0.0 1.0 0.0 0.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 191.565986 9 15.0 25.194935 55.282665 2690000 2 3 2.0 0.0 0.0 1.0 … 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 1.0 141.305463 11 22.0 25.075017 55.137997 2094999 2 3 1.0 0.0 1.0 1.0 … 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 0.0 98.291374 … … … … … … … … … … … … … … … … … … … … … … 1885 46.0 25.103972 55.149621 31440000 4 6 0.0 1.0 0.0 1.0 … 0.0 0.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 607.771426 1891 11.0 25.226946 55.343628 7000000 4 6 1.0 0.0 0.0 0.0 … 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 377.929404 1895 22.0 25.081243 55.145120 1350000 2 4 1.0 0.0 0.0 0.0 … 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 146.600934 1896 15.0 25.196489 55.272126 18040888 4 4 2.0 1.0 1.0 1.0 … 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 0.0 488.019459 1900 42.0 25.176892 55.310712 1500000 2 2 3.0 0.0 1.0 1.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 100.985561 799 rows × 29 columns We can also use isin() method to filter out rows that have a value for a certain column that doesn’t belong to a specific set of values. House_Price_Data.loc[ House_Price_Data[&#39;no_of_bedrooms&#39;].isin([2,4]) == False , : ] neighborhood_recode latitude longitude price no_of_bedrooms no_of_bathrooms quality_recode maid_room_recode unfurnished_recode balcony_recode … private_garden_recode private_gym_recode private_jacuzzi_recode private_pool_recode security_recode shared_gym_recode shared_pool_recode shared_spa_recode view_of_water_recode size_in_m_2 0 46.0 25.113208 55.138932 2700000 1 2 2.0 0.0 0.0 1.0 … 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0 100.242337 2 36.0 25.063302 55.137728 1150000 3 5 2.0 1.0 1.0 1.0 … 0.0 0.0 1.0 0.0 1.0 1.0 1.0 0.0 1.0 181.253753 4 46.0 25.114275 55.139764 1729200 0 1 2.0 0.0 0.0 0.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 47.101821 5 46.0 25.114275 55.139764 3119900 1 2 2.0 0.0 0.0 0.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 94.296545 7 46.0 25.114275 55.139764 3119900 1 2 2.0 0.0 0.0 0.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 94.296545 … … … … … … … … … … … … … … … … … … … … … … 1899 27.0 25.037477 55.221942 550000 1 2 2.0 0.0 1.0 1.0 … 0.0 0.0 0.0 1.0 0.0 1.0 1.0 0.0 0.0 78.688841 1901 42.0 25.166145 55.276684 1230000 1 2 2.0 0.0 0.0 1.0 … 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 1.0 70.606280 1902 16.0 25.206500 55.345056 2900000 3 5 2.0 1.0 1.0 1.0 … 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 179.302790 1903 37.0 25.073858 55.229844 675000 1 2 2.0 0.0 1.0 1.0 … 1.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 1.0 68.748220 1904 36.0 25.079130 55.154713 760887 1 2 0.0 0.0 0.0 1.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 74.322400 1106 rows × 29 columns House_Price_Data.loc[ ( (House_Price_Data.price &gt; 1000000) &amp; (House_Price_Data.no_of_bedrooms &gt; 2 ) ) | House_Price_Data.quality_recode == 0 , : ] neighborhood_recode latitude longitude price no_of_bedrooms no_of_bathrooms quality_recode maid_room_recode unfurnished_recode balcony_recode … private_garden_recode private_gym_recode private_jacuzzi_recode private_pool_recode security_recode shared_gym_recode shared_pool_recode shared_spa_recode view_of_water_recode size_in_m_2 6 46.0 25.114275 55.139764 8503600 2 3 0.0 1.0 0.0 0.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 191.565986 34 6.0 25.060310 55.241403 750000 1 1 0.0 0.0 1.0 1.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 73.950788 35 6.0 25.060310 55.241403 991000 2 2 0.0 0.0 1.0 1.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 107.953286 80 37.0 25.066791 55.203684 714000 1 1 0.0 0.0 1.0 1.0 … 1.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 68.004996 90 15.0 25.197316 55.274196 2100000 1 1 0.0 0.0 0.0 0.0 … 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 1.0 105.444905 … … … … … … … … … … … … … … … … … … … … … … 1829 37.0 25.066252 55.207929 370000 0 1 0.0 0.0 1.0 1.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 34.559916 1838 36.0 25.079130 55.154713 400888 0 1 0.0 0.0 0.0 1.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 38.554745 1839 36.0 25.079130 55.154713 400888 0 1 0.0 0.0 0.0 1.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 38.554745 1841 34.0 25.076319 55.133627 1500000 1 2 0.0 0.0 0.0 1.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 1.0 98.291374 1904 36.0 25.079130 55.154713 760887 1 2 0.0 0.0 0.0 1.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 74.322400 95 rows × 29 columns Mathematically, loc[] filter operation could be formalized as follows: \\(\\\\[0.4cm]\\) \\[df.loc \\hspace{0.1cm} [ \\hspace{0.1cm} ( df.name(X_2) &lt; k_2 \\hspace{0.25cm}\\&amp;\\hspace{0.25cm} df.name(X_4) &gt;= k_4 ) \\hspace{0.25cm} | \\hspace{0.25cm} (df.name(X_3) == k_3) \\hspace{0.15cm},\\hspace{0.15cm} : \\hspace{0.1cm} ] \\hspace{0.1cm}= \\\\[0.7cm] = \\hspace{0.1cm} D \\hspace{0.1cm} [ \\hspace{0.1cm} ( \\hspace{0.1cm} X_2 &lt; k_2 \\hspace{0.25cm} y \\hspace{0.25cm} X_4 \\geq k_4 ) \\hspace{0.25cm} o \\hspace{0.25cm} X_3 = k_3 \\hspace{0.2cm} , \\hspace{0.2cm} : \\hspace{0.1cm}] \\hspace{0.1cm} = \\hspace{0.1cm} (\\hspace{0.15cm} x_i \\hspace{0.15cm} : \\hspace{0.15cm} ( x_{i2} &lt; k_2 \\hspace{0.25cm} y \\hspace{0.25cm} x_{i4} \\geq k_4 ) \\hspace{0.25cm} o \\hspace{0.25cm} x_{i3} = k_3 \\hspace{0.2cm} , \\hspace{0.2cm} i = 1,...,n \\hspace{0.15cm} ) \\\\[07cm]\\] \\[df.loc \\hspace{0.1cm} [ \\hspace{0.1cm} ( \\hspace{0.1cm} df \\hspace{0.1cm} [ \\hspace{0.1cm} name(X_2) \\hspace{0.1cm}].isin(\\hspace{0.1cm}[k_1, k_2, k_3]\\hspace{0.1cm}) \\hspace{0.15cm} , \\hspace{0.15cm} : \\hspace{0.1cm} ] \\hspace{0.1cm} = \\hspace{0.1cm} D \\hspace{0.1cm} [ \\hspace{0.1cm} X_2 \\in \\lbrace k_1 , k_2, k_3 \\rbrace \\hspace{0.15cm} , \\hspace{0.15cm} : \\hspace{0.1cm}] \\hspace{0.1cm} = \\hspace{0.1cm} \\left( \\hspace{0.1cm} x_i \\hspace{0.1cm} : \\hspace{0.1cm} x_{i2} \\in \\lbrace k_1 , k_2, k_3 \\rbrace \\hspace{0.1cm} , \\hspace{0.1cm} i = 1,...,n \\hspace{0.1cm} \\right)\\] We can also filter rows and select columns at the same time using the loc method: House_Price_Data.loc[ House_Price_Data.price &gt; 1000000 , [&#39;price&#39;, &#39;no_of_bedrooms&#39;, &#39;quality_recode&#39;] ] price no_of_bedrooms quality_recode 0 2700000 1 2.0 1 2850000 2 2.0 2 1150000 3 2.0 3 2850000 2 1.0 4 1729200 0 2.0 … … … … 1896 18040888 4 2.0 1898 2700000 1 2.0 1900 1500000 2 3.0 1901 1230000 1 2.0 1902 2900000 3 2.0 1314 rows × 3 columns We can also filter rows and select columns at the same time using the loc method: \\[df.loc\\hspace{0.1cm}[\\hspace{0.1cm} df.name(X_2) &lt; k_2 \\hspace{0.2cm}\\&amp;\\hspace{0.2cm} df.name(X_4) &gt;= k_4 ) \\hspace{0.2cm} | \\hspace{0.2cm} (df.name(X_3) == k_3) \\hspace{0.15cm} , \\hspace{0.15cm} [name(X_1) , name(X_4)] \\hspace{0.1cm}] \\hspace{0.1cm}= \\\\[0.8cm] = \\hspace{0.1cm} D[ (X_2 &lt; k_2 \\hspace{0.2cm} y \\hspace{0.2cm} X_4 \\geq k_4 ) \\hspace{0.2cm} o \\hspace{0.2cm} X_3 = k_3 \\hspace{0.1cm},\\hspace{0.1cm} [X_2 , X_4] \\hspace{0.1cm}] \\hspace{0.1cm} =\\hspace{0.1cm} (\\hspace{0.1cm} x_i[1,4] \\hspace{0.1cm} : \\hspace{0.1cm} ( x_{i2} &lt; k_2 \\hspace{0.25cm} y \\hspace{0.25cm} x_{i4} \\geq k_4 ) \\hspace{0.25cm} o \\hspace{0.25cm} x_{i3} = k_3 \\hspace{0.15cm},\\hspace{0.15cm} i = 1,...,n \\hspace{0.1cm} ) \\hspace{0.1cm} = \\\\[0.8cm] = \\hspace{0.1cm} ( \\hspace{0.1cm} (x_{i1},x_{i4}) \\hspace{0.1cm} : \\hspace{0.1cm} ( x_{i2} &lt; k_2 \\hspace{0.25cm} y \\hspace{0.25cm} x_{i4} \\geq k_4 ) \\hspace{0.25cm} o \\hspace{0.25cm} x_{i3} = k_3 \\hspace{0.15cm} , \\hspace{0.15cm} i = 1,...,n \\hspace{0.1cm} )\\] 9.2 iloc method With iloc method we can filter rows using the index of those rows: House_Price_Data.iloc[15:120 , :] neighborhood_recode latitude longitude price no_of_bedrooms no_of_bathrooms quality_recode maid_room_recode unfurnished_recode balcony_recode … private_garden_recode private_gym_recode private_jacuzzi_recode private_pool_recode security_recode shared_gym_recode shared_pool_recode shared_spa_recode view_of_water_recode size_in_m_2 15 46.0 25.132021 55.151405 2349990 1 1 2.0 0.0 0.0 1.0 … 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 1.0 103.029427 16 46.0 25.132021 55.151405 3499000 2 2 2.0 0.0 1.0 1.0 … 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 1.0 151.710599 17 15.0 25.198316 55.270758 2700000 2 3 2.0 0.0 1.0 1.0 … 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 125.233244 18 15.0 25.197020 55.271023 1490000 2 2 2.0 0.0 0.0 1.0 … 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 0.0 108.417801 19 9.0 25.180301 55.263892 950000 1 2 2.0 0.0 1.0 1.0 … 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 1.0 83.055282 … … … … … … … … … … … … … … … … … … … … … … 115 15.0 25.196398 55.271002 2100000 2 3 2.0 0.0 1.0 1.0 … 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 0.0 125.790662 116 15.0 25.191753 55.272818 1400000 1 2 1.0 0.0 1.0 1.0 … 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 79.896580 117 45.0 25.189554 55.273783 2300000 2 3 1.0 0.0 1.0 0.0 … 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 124.304214 118 9.0 25.185823 55.291922 2300000 2 3 2.0 0.0 0.0 1.0 … 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 0.0 133.966126 119 49.0 25.090953 55.169542 1335000 2 2 1.0 0.0 0.0 0.0 … 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 124.118408 105 rows × 29 columns House_Price_Data.iloc[[6,10,15] , :] neighborhood_recode latitude longitude price no_of_bedrooms no_of_bathrooms quality_recode maid_room_recode unfurnished_recode balcony_recode … private_garden_recode private_gym_recode private_jacuzzi_recode private_pool_recode security_recode shared_gym_recode shared_pool_recode shared_spa_recode view_of_water_recode size_in_m_2 6 46.0 25.114275 55.139764 8503600 2 3 0.0 1.0 0.0 0.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 191.565986 10 15.0 25.198796 55.271342 3550000 3 4 1.0 0.0 1.0 1.0 … 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 1.0 178.187954 15 46.0 25.132021 55.151405 2349990 1 1 2.0 0.0 0.0 1.0 … 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 1.0 103.029427 3 rows × 29 columns Mathematically, the iloc[] filter operation could be formalized as follows: \\(\\\\[0.4cm]\\) \\[df.iloc \\hspace{0.1cm} [ \\hspace{0.1cm} 15:120 \\hspace{0.1cm} , \\hspace{0.1cm} : \\hspace{0.1cm} ] \\hspace{0.1cm} = \\hspace{0.1cm} D\\hspace{0.1cm} [ \\hspace{0.1cm} 15:120 \\hspace{0.1cm},\\hspace{0.1cm} : \\hspace{0.1cm}] \\hspace{0.1cm}=\\hspace{0.1cm} (x_i \\hspace{0.1cm}:\\hspace{0.1cm} i = 15,...,120 \\hspace{0.1cm}) \\hspace{0.1cm} = \\hspace{0.1cm} \\begin{pmatrix} x_{15}^t \\\\ x_{16}^t \\\\ ... \\\\ x_{120}^t \\end{pmatrix} \\\\[0.7cm]\\] \\[df.iloc[ \\hspace{0.1cm} [6,10,15] \\hspace{0.1cm} , \\hspace{0.1cm} : \\hspace{0.1cm} ] \\hspace{0.1cm} = D\\hspace{0.1cm} [ \\hspace{0.1cm} [6,10,15] \\hspace{0.1cm} , \\hspace{0.1cm} : \\hspace{0.1cm} ] \\hspace{0.1cm} = \\hspace{0.1cm} ( \\hspace{0.1cm} x_i \\hspace{0.1cm} : \\hspace{0.1cm} i =6,10,15 \\hspace{0.1cm}) \\hspace{0.1cm} = \\hspace{0.1cm} \\begin{pmatrix} x_{6}^t \\\\ x_{10}^t \\\\ x_{15}^t \\end{pmatrix} \\] We can filter rows and select columns at the same time using the iloc method as follows: House_Price_Data.iloc[3:15 , 2:5] longitude price no_of_bedrooms 3 55.341761 2850000 2 4 55.139764 1729200 0 5 55.139764 3119900 1 6 55.139764 8503600 2 7 55.139764 3119900 1 8 55.149275 2100000 3 9 55.282665 2690000 2 10 55.271342 3550000 3 11 55.137997 2094999 2 12 55.137997 1049999 1 13 55.151574 1849000 1 14 55.152216 2089999 1 House_Price_Data.iloc[[3,5,6] , [2,8]] longitude unfurnished_recode 3 55.341761 1.0 5 55.139764 0.0 6 55.139764 0.0 Mathematically, the iloc[] filter operation could be formalized as follows: \\(\\\\[0.4cm]\\) \\[df.iloc\\hspace{0.1cm}[\\hspace{0.1cm}3:15 \\hspace{0.1cm},\\hspace{0.1cm} 2:5\\hspace{0.1cm}]\\hspace{0.1cm} =\\hspace{0.1cm} D[\\hspace{0.1cm}3:15 \\hspace{0.1cm},\\hspace{0.1cm} 2:5\\hspace{0.1cm}] \\hspace{0.1cm}=\\hspace{0.1cm} (\\hspace{0.1cm}x_i[2:5] \\hspace{0.1cm}:\\hspace{0.1cm} i = 3,...,15 \\hspace{0.1cm}) \\hspace{0.1cm}=\\hspace{0.1cm} ( \\hspace{0.1cm}(x_{i2} , x_{i5} ) \\hspace{0.1cm}:\\hspace{0.1cm} i = 3,...,15 \\hspace{0.1cm}) \\hspace{0.1cm} = \\hspace{0.1cm} \\begin{pmatrix} x_{32} &amp; x_{33} &amp; x_{34} &amp; x_{35}\\\\ x_{42} &amp; x_{43} &amp; x_{44} &amp; x_{45}\\\\ ... &amp; ... &amp; ... &amp; ... \\\\ x_{15 2} &amp; x_{15 3} &amp; x_{15 4} &amp; x_{15 5} \\end{pmatrix} \\\\[0.7cm]\\] \\[df.iloc\\hspace{0.1cm}[\\hspace{0.1cm}[3,5,6] \\hspace{0.1cm},\\hspace{0.1cm} [2,8]\\hspace{0.1cm}] \\hspace{0.1cm}=\\hspace{0.1cm} D[\\hspace{0.1cm}[3,5,6]\\hspace{0.1cm} , \\hspace{0.1cm}[2,8]\\hspace{0.1cm}] \\hspace{0.1cm}=\\hspace{0.1cm} (\\hspace{0.1cm} x_i[2,8] \\hspace{0.1cm} : \\hspace{0.1cm} i = 3,5,6 \\hspace{0.1cm} ) \\hspace{0.1cm} = \\hspace{0.1cm} ( \\hspace{0.1cm} (x_{i2} , x_{i8} ) \\hspace{0.1cm} : \\hspace{0.1cm} i = 3,5,6 \\hspace{0.1cm} ) \\hspace{0.1cm} = \\hspace{0.1cm} \\begin{pmatrix} x_{32} &amp; x_{38} \\\\ x_{52} &amp; x_{58} \\\\ x_{6 2} &amp; x_{6 8} \\end{pmatrix} \\] "],["traspose-a-data-frame.html", "Chapter 10 Traspose a data-frame", " Chapter 10 Traspose a data-frame We can traspose a data-frame using T method: House_Price_Data.T 0 1 2 3 4 5 6 7 8 9 … 1895 1896 1897 1898 1899 1900 1901 1902 1903 1904 neighborhood_recode 4.600000e+01 4.600000e+01 3.600000e+01 1.100000e+01 4.600000e+01 4.600000e+01 4.600000e+01 4.600000e+01 4.600000e+01 1.500000e+01 … 2.200000e+01 1.500000e+01 4.000000 4.600000e+01 27.000000 4.200000e+01 4.200000e+01 1.600000e+01 37.000000 36.000000 latitude 2.511321e+01 2.510681e+01 2.506330e+01 2.522730e+01 2.511427e+01 2.511427e+01 2.511427e+01 2.511427e+01 2.510667e+01 2.519494e+01 … 2.508124e+01 2.519649e+01 25.153080 2.510433e+01 25.037477 2.517689e+01 2.516615e+01 2.520650e+01 25.073858 25.079130 longitude 5.513893e+01 5.515120e+01 5.513773e+01 5.534176e+01 5.513976e+01 5.513976e+01 5.513976e+01 5.513976e+01 5.514928e+01 5.528267e+01 … 5.514512e+01 5.527213e+01 55.254242 5.514877e+01 55.221942 5.531071e+01 5.527668e+01 5.534506e+01 55.229844 55.154713 price 2.700000e+06 2.850000e+06 1.150000e+06 2.850000e+06 1.729200e+06 3.119900e+06 8.503600e+06 3.119900e+06 2.100000e+06 2.690000e+06 … 1.350000e+06 1.804089e+07 360000.000000 2.700000e+06 550000.000000 1.500000e+06 1.230000e+06 2.900000e+06 675000.000000 760887.000000 no_of_bedrooms 1.000000e+00 2.000000e+00 3.000000e+00 2.000000e+00 0.000000e+00 1.000000e+00 2.000000e+00 1.000000e+00 3.000000e+00 2.000000e+00 … 2.000000e+00 4.000000e+00 0.000000 1.000000e+00 1.000000 2.000000e+00 1.000000e+00 3.000000e+00 1.000000 1.000000 no_of_bathrooms 2.000000e+00 2.000000e+00 5.000000e+00 3.000000e+00 1.000000e+00 2.000000e+00 3.000000e+00 2.000000e+00 3.000000e+00 3.000000e+00 … 4.000000e+00 4.000000e+00 1.000000 2.000000e+00 2.000000 2.000000e+00 2.000000e+00 5.000000e+00 2.000000 2.000000 quality_recode 2.000000e+00 2.000000e+00 2.000000e+00 1.000000e+00 2.000000e+00 2.000000e+00 0.000000e+00 2.000000e+00 1.000000e+00 2.000000e+00 … 1.000000e+00 2.000000e+00 2.000000 2.000000e+00 2.000000 3.000000e+00 2.000000e+00 2.000000e+00 2.000000 0.000000 maid_room_recode 0.000000e+00 0.000000e+00 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 … 0.000000e+00 1.000000e+00 0.000000 0.000000e+00 0.000000 0.000000e+00 0.000000e+00 1.000000e+00 0.000000 0.000000 unfurnished_recode 0.000000e+00 0.000000e+00 1.000000e+00 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 … 0.000000e+00 1.000000e+00 0.000000 1.000000e+00 1.000000 1.000000e+00 0.000000e+00 1.000000e+00 1.000000 0.000000 balcony_recode 1.000000e+00 1.000000e+00 1.000000e+00 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 1.000000e+00 … 0.000000e+00 1.000000e+00 1.000000 1.000000e+00 1.000000 1.000000e+00 1.000000e+00 1.000000e+00 1.000000 1.000000 barbecue_area_recode 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 … 0.000000e+00 0.000000e+00 0.000000 0.000000e+00 0.000000 1.000000e+00 0.000000e+00 0.000000e+00 0.000000 1.000000 central_ac_recode 1.000000e+00 1.000000e+00 0.000000e+00 0.000000e+00 1.000000e+00 1.000000e+00 1.000000e+00 1.000000e+00 0.000000e+00 1.000000e+00 … 0.000000e+00 1.000000e+00 1.000000 0.000000e+00 1.000000 1.000000e+00 1.000000e+00 1.000000e+00 1.000000 1.000000 childrens_play_area_recode 1.000000e+00 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 … 0.000000e+00 1.000000e+00 0.000000 0.000000e+00 0.000000 1.000000e+00 1.000000e+00 1.000000e+00 1.000000 1.000000 childrens_pool_recode 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 … 0.000000e+00 0.000000e+00 0.000000 0.000000e+00 0.000000 1.000000e+00 0.000000e+00 0.000000e+00 0.000000 1.000000 concierge_recode 1.000000e+00 0.000000e+00 0.000000e+00 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 … 0.000000e+00 0.000000e+00 0.000000 0.000000e+00 1.000000 1.000000e+00 1.000000e+00 0.000000e+00 0.000000 1.000000 covered_parking_recode 0.000000e+00 0.000000e+00 1.000000e+00 1.000000e+00 1.000000e+00 1.000000e+00 1.000000e+00 1.000000e+00 0.000000e+00 1.000000e+00 … 0.000000e+00 0.000000e+00 1.000000 1.000000e+00 1.000000 1.000000e+00 0.000000e+00 0.000000e+00 1.000000 1.000000 kitchen_appliances_recode 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 1.000000e+00 1.000000e+00 1.000000e+00 1.000000e+00 0.000000e+00 1.000000e+00 … 0.000000e+00 0.000000e+00 0.000000 1.000000e+00 0.000000 1.000000e+00 1.000000e+00 0.000000e+00 1.000000 1.000000 maid_service_recode 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 … 0.000000e+00 0.000000e+00 0.000000 0.000000e+00 0.000000 1.000000e+00 0.000000e+00 0.000000e+00 0.000000 0.000000 pets_allowed_recode 1.000000e+00 0.000000e+00 0.000000e+00 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 … 0.000000e+00 0.000000e+00 1.000000 0.000000e+00 1.000000 1.000000e+00 0.000000e+00 1.000000e+00 0.000000 0.000000 private_garden_recode 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 … 0.000000e+00 0.000000e+00 0.000000 0.000000e+00 0.000000 0.000000e+00 0.000000e+00 0.000000e+00 1.000000 0.000000 private_gym_recode 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 … 0.000000e+00 0.000000e+00 0.000000 0.000000e+00 0.000000 0.000000e+00 0.000000e+00 0.000000e+00 0.000000 0.000000 private_jacuzzi_recode 0.000000e+00 0.000000e+00 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 … 0.000000e+00 0.000000e+00 0.000000 0.000000e+00 0.000000 0.000000e+00 0.000000e+00 0.000000e+00 0.000000 0.000000 private_pool_recode 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 … 0.000000e+00 0.000000e+00 0.000000 0.000000e+00 1.000000 0.000000e+00 0.000000e+00 0.000000e+00 0.000000 0.000000 security_recode 0.000000e+00 0.000000e+00 1.000000e+00 0.000000e+00 1.000000e+00 1.000000e+00 1.000000e+00 1.000000e+00 0.000000e+00 0.000000e+00 … 0.000000e+00 0.000000e+00 1.000000 0.000000e+00 0.000000 1.000000e+00 0.000000e+00 0.000000e+00 1.000000 1.000000 shared_gym_recode 1.000000e+00 1.000000e+00 1.000000e+00 0.000000e+00 1.000000e+00 1.000000e+00 1.000000e+00 1.000000e+00 0.000000e+00 1.000000e+00 … 0.000000e+00 1.000000e+00 1.000000 1.000000e+00 1.000000 1.000000e+00 1.000000e+00 0.000000e+00 1.000000 1.000000 shared_pool_recode 0.000000e+00 1.000000e+00 1.000000e+00 0.000000e+00 1.000000e+00 1.000000e+00 1.000000e+00 1.000000e+00 0.000000e+00 1.000000e+00 … 0.000000e+00 1.000000e+00 1.000000 1.000000e+00 1.000000 1.000000e+00 1.000000e+00 1.000000e+00 1.000000 1.000000 shared_spa_recode 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 1.000000e+00 1.000000e+00 1.000000e+00 1.000000e+00 0.000000e+00 0.000000e+00 … 0.000000e+00 0.000000e+00 0.000000 0.000000e+00 0.000000 1.000000e+00 0.000000e+00 0.000000e+00 0.000000 1.000000 view_of_water_recode 1.000000e+00 1.000000e+00 1.000000e+00 0.000000e+00 1.000000e+00 1.000000e+00 1.000000e+00 1.000000e+00 0.000000e+00 1.000000e+00 … 0.000000e+00 0.000000e+00 0.000000 1.000000e+00 0.000000 1.000000e+00 1.000000e+00 0.000000e+00 1.000000 1.000000 size_in_m_2 1.002423e+02 1.469725e+02 1.812538e+02 1.876641e+02 4.710182e+01 9.429654e+01 1.915660e+02 9.429654e+01 2.030860e+02 1.413055e+02 … 1.466009e+02 4.880195e+02 55.741800 9.996363e+01 78.688841 1.009856e+02 7.060628e+01 1.793028e+02 68.748220 74.322400 29 rows × 1905 columns "],["data-frame-to-numpy.html", "Chapter 11 Data-frame to numpy", " Chapter 11 Data-frame to numpy We can convert a pandas data-frame to a numpy array using to_numpy() method: House_Price_Data.to_numpy() array([[ 46. , 25.113208, 55.138932, ..., 0. , 1. , 100.242337], [ 46. , 25.106809, 55.151201, ..., 0. , 1. , 146.972546], [ 36. , 25.063302, 55.137728, ..., 0. , 1. , 181.253753], ..., [ 16. , 25.2065 , 55.345056, ..., 0. , 0. , 179.30279 ], [ 37. , 25.073858, 55.229844, ..., 0. , 1. , 68.74822 ], [ 36. , 25.07913 , 55.154713, ..., 1. , 1. , 74.3224 ]]) "],["delete-columns-from-a-data-frame.html", "Chapter 12 Delete columns from a data-frame", " Chapter 12 Delete columns from a data-frame House_Price_Data.drop([&#39;price&#39;], axis=1) neighborhood_recode latitude longitude no_of_bedrooms no_of_bathrooms quality_recode maid_room_recode unfurnished_recode balcony_recode barbecue_area_recode … private_garden_recode private_gym_recode private_jacuzzi_recode private_pool_recode security_recode shared_gym_recode shared_pool_recode shared_spa_recode view_of_water_recode size_in_m_2 0 46.0 25.113208 55.138932 1 2 2.0 0.0 0.0 1.0 1.0 … 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0 100.242337 1 46.0 25.106809 55.151201 2 2 2.0 0.0 0.0 1.0 0.0 … 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 1.0 146.972546 2 36.0 25.063302 55.137728 3 5 2.0 1.0 1.0 1.0 0.0 … 0.0 0.0 1.0 0.0 1.0 1.0 1.0 0.0 1.0 181.253753 3 11.0 25.227295 55.341761 2 3 1.0 0.0 1.0 1.0 0.0 … 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 187.664060 4 46.0 25.114275 55.139764 0 1 2.0 0.0 0.0 0.0 0.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 47.101821 … … … … … … … … … … … … … … … … … … … … … … 1900 42.0 25.176892 55.310712 2 2 3.0 0.0 1.0 1.0 1.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 100.985561 1901 42.0 25.166145 55.276684 1 2 2.0 0.0 0.0 1.0 0.0 … 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 1.0 70.606280 1902 16.0 25.206500 55.345056 3 5 2.0 1.0 1.0 1.0 0.0 … 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 179.302790 1903 37.0 25.073858 55.229844 1 2 2.0 0.0 1.0 1.0 0.0 … 1.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 1.0 68.748220 1904 36.0 25.079130 55.154713 1 2 0.0 0.0 0.0 1.0 1.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 74.322400 1905 rows × 28 columns House_Price_Data.drop([&#39;price&#39;, &#39;longitude&#39;], axis=1) neighborhood_recode latitude no_of_bedrooms no_of_bathrooms quality_recode maid_room_recode unfurnished_recode balcony_recode barbecue_area_recode central_ac_recode … private_garden_recode private_gym_recode private_jacuzzi_recode private_pool_recode security_recode shared_gym_recode shared_pool_recode shared_spa_recode view_of_water_recode size_in_m_2 0 46.0 25.113208 1 2 2.0 0.0 0.0 1.0 1.0 1.0 … 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0 100.242337 1 46.0 25.106809 2 2 2.0 0.0 0.0 1.0 0.0 1.0 … 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 1.0 146.972546 2 36.0 25.063302 3 5 2.0 1.0 1.0 1.0 0.0 0.0 … 0.0 0.0 1.0 0.0 1.0 1.0 1.0 0.0 1.0 181.253753 3 11.0 25.227295 2 3 1.0 0.0 1.0 1.0 0.0 0.0 … 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 187.664060 4 46.0 25.114275 0 1 2.0 0.0 0.0 0.0 0.0 1.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 47.101821 … … … … … … … … … … … … … … … … … … … … … … 1900 42.0 25.176892 2 2 3.0 0.0 1.0 1.0 1.0 1.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 100.985561 1901 42.0 25.166145 1 2 2.0 0.0 0.0 1.0 0.0 1.0 … 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 1.0 70.606280 1902 16.0 25.206500 3 5 2.0 1.0 1.0 1.0 0.0 1.0 … 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 179.302790 1903 37.0 25.073858 1 2 2.0 0.0 1.0 1.0 0.0 1.0 … 1.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 1.0 68.748220 1904 36.0 25.079130 1 2 0.0 0.0 0.0 1.0 1.0 1.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 74.322400 1905 rows × 27 columns Mathematically drop() filter operation could be formalized as follows: \\(\\\\[0.4cm]\\) \\[df.drop(\\hspace{0.1cm} [name(X_3) , name(X_5)] \\hspace{0.1cm} , \\hspace{0.1cm} axis=1 \\hspace{0.1cm} ) \\hspace{0.1cm} = \\hspace{0.1cm} D \\hspace{0.1cm} [ \\hspace{0.1cm} : \\hspace{0.1cm} , \\hspace{0.1cm} - [X_3 , X_7] \\hspace{0.1cm} ] \\hspace{0.1cm}=\\hspace{0.1cm} (X_1,X_2,X_4,X_6,...,X_p)\\] "],["delete-rows-from-a-data-frame.html", "Chapter 13 Delete rows from a data-frame", " Chapter 13 Delete rows from a data-frame House_Price_Data.drop(3, axis=0) neighborhood_recode latitude longitude price no_of_bedrooms no_of_bathrooms quality_recode maid_room_recode unfurnished_recode balcony_recode … private_garden_recode private_gym_recode private_jacuzzi_recode private_pool_recode security_recode shared_gym_recode shared_pool_recode shared_spa_recode view_of_water_recode size_in_m_2 0 46.0 25.113208 55.138932 2700000 1 2 2.0 0.0 0.0 1.0 … 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0 100.242337 1 46.0 25.106809 55.151201 2850000 2 2 2.0 0.0 0.0 1.0 … 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 1.0 146.972546 2 36.0 25.063302 55.137728 1150000 3 5 2.0 1.0 1.0 1.0 … 0.0 0.0 1.0 0.0 1.0 1.0 1.0 0.0 1.0 181.253753 4 46.0 25.114275 55.139764 1729200 0 1 2.0 0.0 0.0 0.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 47.101821 5 46.0 25.114275 55.139764 3119900 1 2 2.0 0.0 0.0 0.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 94.296545 … … … … … … … … … … … … … … … … … … … … … … 1900 42.0 25.176892 55.310712 1500000 2 2 3.0 0.0 1.0 1.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 100.985561 1901 42.0 25.166145 55.276684 1230000 1 2 2.0 0.0 0.0 1.0 … 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 1.0 70.606280 1902 16.0 25.206500 55.345056 2900000 3 5 2.0 1.0 1.0 1.0 … 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 179.302790 1903 37.0 25.073858 55.229844 675000 1 2 2.0 0.0 1.0 1.0 … 1.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 1.0 68.748220 1904 36.0 25.079130 55.154713 760887 1 2 0.0 0.0 0.0 1.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 74.322400 1904 rows × 29 columns House_Price_Data.drop([2,3,1900], axis=0) neighborhood_recode latitude longitude price no_of_bedrooms no_of_bathrooms quality_recode maid_room_recode unfurnished_recode balcony_recode … private_garden_recode private_gym_recode private_jacuzzi_recode private_pool_recode security_recode shared_gym_recode shared_pool_recode shared_spa_recode view_of_water_recode size_in_m_2 0 46.0 25.113208 55.138932 2700000 1 2 2.0 0.0 0.0 1.0 … 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0 100.242337 1 46.0 25.106809 55.151201 2850000 2 2 2.0 0.0 0.0 1.0 … 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 1.0 146.972546 4 46.0 25.114275 55.139764 1729200 0 1 2.0 0.0 0.0 0.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 47.101821 5 46.0 25.114275 55.139764 3119900 1 2 2.0 0.0 0.0 0.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 94.296545 6 46.0 25.114275 55.139764 8503600 2 3 0.0 1.0 0.0 0.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 191.565986 … … … … … … … … … … … … … … … … … … … … … … 1899 27.0 25.037477 55.221942 550000 1 2 2.0 0.0 1.0 1.0 … 0.0 0.0 0.0 1.0 0.0 1.0 1.0 0.0 0.0 78.688841 1901 42.0 25.166145 55.276684 1230000 1 2 2.0 0.0 0.0 1.0 … 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 1.0 70.606280 1902 16.0 25.206500 55.345056 2900000 3 5 2.0 1.0 1.0 1.0 … 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 179.302790 1903 37.0 25.073858 55.229844 675000 1 2 2.0 0.0 1.0 1.0 … 1.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 1.0 68.748220 1904 36.0 25.079130 55.154713 760887 1 2 0.0 0.0 0.0 1.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 74.322400 1902 rows × 29 columns Mathematically drop() operation could be formalized as follows: \\(\\\\[0.4cm]\\) \\[df.drop( \\hspace{0.1cm} [2 , 5] \\hspace{0.1cm} , \\hspace{0.1cm} axis=0 \\hspace{0.1cm} ) \\hspace{0.1cm} =\\hspace{0.1cm} D \\hspace{0.1cm} [-[2,5] \\hspace{0.1cm} , \\hspace{0.1cm} : \\hspace{0.1cm} ] \\hspace{0.1cm} = \\hspace{0.1cm} \\begin{pmatrix} x_1^t \\\\ x_3^t \\\\ x_4^t \\\\ x_6^t \\\\ ... \\\\ x_n^t \\end{pmatrix} \\] "],["rename-columns-from-a-data-frame.html", "Chapter 14 Rename columns from a data-frame", " Chapter 14 Rename columns from a data-frame We can rename columns from a data-frame by several ways. For one thing, we can create a new data frame the same as the original, but with different names for some of its columns: House_Price_Data.rename(columns={&#39;neighborhood_recode&#39; : &#39;neighborhood&#39;}) neighborhood latitude longitude price no_of_bedrooms no_of_bathrooms quality_recode maid_room_recode unfurnished_recode balcony_recode … private_garden_recode private_gym_recode private_jacuzzi_recode private_pool_recode security_recode shared_gym_recode shared_pool_recode shared_spa_recode view_of_water_recode size_in_m_2 0 46.0 25.113208 55.138932 2700000 1 2 2.0 0.0 0.0 1.0 … 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0 100.242337 1 46.0 25.106809 55.151201 2850000 2 2 2.0 0.0 0.0 1.0 … 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 1.0 146.972546 2 36.0 25.063302 55.137728 1150000 3 5 2.0 1.0 1.0 1.0 … 0.0 0.0 1.0 0.0 1.0 1.0 1.0 0.0 1.0 181.253753 3 11.0 25.227295 55.341761 2850000 2 3 1.0 0.0 1.0 1.0 … 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 187.664060 4 46.0 25.114275 55.139764 1729200 0 1 2.0 0.0 0.0 0.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 47.101821 … … … … … … … … … … … … … … … … … … … … … … 1900 42.0 25.176892 55.310712 1500000 2 2 3.0 0.0 1.0 1.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 100.985561 1901 42.0 25.166145 55.276684 1230000 1 2 2.0 0.0 0.0 1.0 … 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 1.0 70.606280 1902 16.0 25.206500 55.345056 2900000 3 5 2.0 1.0 1.0 1.0 … 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 179.302790 1903 37.0 25.073858 55.229844 675000 1 2 2.0 0.0 1.0 1.0 … 1.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 1.0 68.748220 1904 36.0 25.079130 55.154713 760887 1 2 0.0 0.0 0.0 1.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 74.322400 1905 rows × 29 columns On the other hand, we can rename specific columns of a data-frame without the need to create a new additional data-frame setting the inplace parameter to True: House_Price_Data.rename(columns={&#39;neighborhood_recode&#39; : &#39;neighborhood&#39;}, inplace=True) "],["group-by.html", "Chapter 15 Group by", " Chapter 15 Group by We can group the rows of the data frame by the values ​​in one column and then compute within each group a statistic from some of the other columns: House_Price_Data.groupby(&#39;quality_recode&#39;).sum() neighborhood_recode latitude longitude price no_of_bedrooms no_of_bathrooms maid_room_recode unfurnished_recode balcony_recode barbecue_area_recode … private_garden_recode private_gym_recode private_jacuzzi_recode private_pool_recode security_recode shared_gym_recode shared_pool_recode shared_spa_recode view_of_water_recode size_in_m_2 quality_recode 0.0 3733.0 3364.807548 7397.947955 360303131 259 356 48.0 80.0 127.0 50.0 … 9.0 5.0 20.0 14.0 116.0 131.0 129.0 51.0 88.0 19662.548338 1.0 14463.0 13665.847174 30036.819722 1054059587 964 1351 10.0 223.0 140.0 4.0 … 2.0 1.0 5.0 5.0 15.0 87.0 151.0 2.0 36.0 70533.072436 2.0 30586.0 28786.683374 63272.825114 2484669505 2063 2876 163.0 887.0 1023.0 134.0 … 20.0 8.0 71.0 62.0 460.0 959.0 1043.0 62.0 452.0 152492.563551 3.0 2896.0 2029.667054 4471.911678 74473686 130 204 54.0 32.0 81.0 81.0 … 1.0 1.0 1.0 1.0 80.0 81.0 81.0 79.0 78.0 8101.699018 4 rows × 28 columns Mathematically groupby() operation could be formalized as follows: \\(\\\\[0.4cm]\\) \\[df.groupby( \\hspace{0.1cm} name(X_3) \\hspace{0.1cm} ).f() \\hspace{0.1cm}=\\hspace{0.1cm} \\begin{pmatrix} f\\hspace{0.1cm} ( \\hspace{0.1cm} x_{i1} \\hspace{0.1cm} : \\hspace{0.1cm} x_{i3}=0 \\hspace{0.1cm} , \\hspace{0.1cm} i=1,...,n \\hspace{0.1cm} ) &amp; f \\hspace{0.1cm} ( \\hspace{0.1cm} x_{i2} \\hspace{0.1cm} : \\hspace{0.1cm} x_{i3}=0 \\hspace{0.1cm} , \\hspace{0.1cm} i=1,...,n \\hspace{0.1cm} ) &amp; ... &amp; f \\hspace{0.1cm} ( \\hspace{0.1cm} x_{ip} \\hspace{0.1cm}:\\hspace{0.1cm} x_{i3}=0 \\hspace{0.1cm} , \\hspace{0.1cm} i=1,...,n \\hspace{0.1cm} ) \\\\ f \\hspace{0.1cm} ( \\hspace{0.1cm} x_{i1} \\hspace{0.1cm} : \\hspace{0.1cm} x_{i3}=1 \\hspace{0.1cm} , \\hspace{0.1cm} i=1,...,n \\hspace{0.1cm} ) &amp; f \\hspace{0.1cm}( \\hspace{0.1cm} x_{i2} \\hspace{0.1cm} : \\hspace{0.1cm} x_{i3}=1 \\hspace{0.1cm} , \\hspace{0.1cm} i=1,...,n \\hspace{0.1cm} ) &amp; ... &amp; f \\hspace{0.1cm} ( \\hspace{0.1cm} x_{ip} \\hspace{0.1cm} : \\hspace{0.1cm} x_{i3}=1 \\hspace{0.1cm} , \\hspace{0.1cm} i=1,...,n \\hspace{0.1cm} ) \\\\ f \\hspace{0.1cm} ( \\hspace{0.1cm} x_{i1} \\hspace{0.1cm} : \\hspace{0.1cm} x_{i3}=2 \\hspace{0.1cm} , \\hspace{0.1cm} i=1,...,n \\hspace{0.1cm}) &amp; f \\hspace{0.1cm} ( \\hspace{0.1cm} x_{i2} \\hspace{0.1cm} : \\hspace{0.1cm} x_{i3}=2 \\hspace{0.1cm} , \\hspace{0.1cm} i=1,...,n \\hspace{0.1cm} ) &amp; ... &amp; f \\hspace{0.1cm} ( \\hspace{0.1cm} x_{ip} \\hspace{0.1cm} : \\hspace{0.1cm} x_{i3}=2 \\hspace{0.1cm} , \\hspace{0.1cm} i=1,...,n \\hspace{0.1cm} ) \\\\ f \\hspace{0.1cm} ( \\hspace{0.1cm} x_{i1} \\hspace{0.1cm} : \\hspace{0.1cm} x_{i3}=3 \\hspace{0.1cm} , \\hspace{0.1cm} i=1,...,n \\hspace{0.1cm} ) &amp; f \\hspace{0.1cm} ( \\hspace{0.1cm} x_{i2} \\hspace{0.1cm} : \\hspace{0.1cm} x_{i3}=3 \\hspace{0.1cm} , \\hspace{0.1cm} i=1,...,n \\hspace{0.1cm} ) &amp; ... &amp; f \\hspace{0.1cm} (\\hspace{0.1cm} x_{ip} \\hspace{0.1cm} : \\hspace{0.1cm} x_{i3}=3 \\hspace{0.1cm} , \\hspace{0.1cm} i=1,...,n \\hspace{0.1cm} ) \\end{pmatrix} \\\\[0.5cm]\\] Where \\(\\hspace{0.1cm}Range(X_3) = \\lbrace 0,1,2,3 \\rbrace\\hspace{0.15cm}\\) and \\(\\hspace{0.12cm}f\\hspace{0.12cm}\\) is any function. House_Price_Data.groupby(&#39;quality_recode&#39;)[&#39;price&#39;].sum() quality_recode 0.0 360303131 1.0 1054059587 2.0 2484669505 3.0 74473686 Name: price, dtype: int64 House_Price_Data.groupby(&#39;quality_recode&#39;)[&#39;price&#39;].mean() quality_recode 0.0 2.688829e+06 1.0 1.937610e+06 2.0 2.168123e+06 3.0 9.194282e+05 Name: price, dtype: float64 House_Price_Data.groupby(&#39;quality_recode&#39;)[&#39;price&#39;].median() quality_recode 0.0 1400103.0 1.0 1465444.0 2.0 1470388.5 3.0 759502.0 Name: price, dtype: float64 House_Price_Data.groupby(&#39;quality_recode&#39;)[&#39;price&#39;].std() quality_recode 0.0 4.852033e+06 1.0 2.307412e+06 2.0 2.947205e+06 3.0 3.950463e+05 Name: price, dtype: float64 House_Price_Data.groupby([&#39;quality_recode&#39;, &#39;private_garden_recode&#39;])[&#39;price&#39;].mean() quality_recode private_garden_recode 0.0 0.0 2.530969e+06 1.0 4.881333e+06 1.0 0.0 1.932034e+06 1.0 3.448444e+06 2.0 0.0 2.162129e+06 1.0 2.505600e+06 3.0 0.0 9.213461e+05 1.0 7.660000e+05 Name: price, dtype: float64 Mathematically, groupby() operation could be formalized as follows: \\(\\\\[0.4cm]\\) \\[df.groupby( \\hspace{0.1cm} [ \\hspace{0.1cm}name(X_3)\\hspace{0.1cm} ,\\hspace{0.1cm} name(X_8)\\hspace{0.1cm}] \\hspace{0.1cm})[\\hspace{0.1cm} name(X_6) \\hspace{0.1cm}].f() \\hspace{0.1cm}= \\hspace{0.1cm} \\begin{pmatrix} f\\hspace{0.1cm}( \\hspace{0.1cm} x_{i6} \\hspace{0.1cm}:\\hspace{0.1cm} x_{i3}=0 \\hspace{0.15cm} , \\hspace{0.15cm} x_{i8}=0 \\hspace{0.1cm},\\hspace{0.1cm} i=1,...,n \\hspace{0.1cm} ) \\\\ f\\hspace{0.1cm}( \\hspace{0.1cm} x_{i6} \\hspace{0.1cm}:\\hspace{0.1cm} x_{i3}=0 \\hspace{0.15cm}, \\hspace{0.15cm} x_{i8}=1 \\hspace{0.1cm},\\hspace{0.1cm} i=1,...,n \\hspace{0.1cm} ) \\\\ f\\hspace{0.1cm}( \\hspace{0.1cm} x_{i6} \\hspace{0.1cm}:\\hspace{0.1cm} x_{i3}=1 \\hspace{0.15cm} , \\hspace{0.15cm} x_{i8}=0 \\hspace{0.1cm},\\hspace{0.1cm} i=1,...,n \\hspace{0.1cm} ) \\\\ f\\hspace{0.1cm}( \\hspace{0.1cm} x_{i6} \\hspace{0.1cm}:\\hspace{0.1cm} x_{i3}=1 \\hspace{0.15cm} , \\hspace{0.15cm} x_{i8}=1 \\hspace{0.1cm},\\hspace{0.1cm} i=1,...,n \\hspace{0.1cm} ) \\\\ f\\hspace{0.1cm}( \\hspace{0.1cm} x_{i6} \\hspace{0.1cm}:\\hspace{0.1cm} x_{i3}=2 \\hspace{0.15cm} , \\hspace{0.15cm} x_{i8}=0 \\hspace{0.1cm},\\hspace{0.1cm} i=1,...,n \\hspace{0.1cm} ) \\\\ f\\hspace{0.1cm}( \\hspace{0.1cm} x_{i6} \\hspace{0.1cm}:\\hspace{0.1cm} x_{i3}=2 \\hspace{0.15cm} , \\hspace{0.15cm} x_{i8}=1 \\hspace{0.1cm},\\hspace{0.1cm} i=1,...,n \\hspace{0.1cm} ) \\\\ f\\hspace{0.1cm}( \\hspace{0.1cm} x_{i6} \\hspace{0.1cm}:\\hspace{0.1cm} x_{i3}=3 \\hspace{0.15cm} , \\hspace{0.15cm} x_{i8}=0 \\hspace{0.1cm},\\hspace{0.1cm} i=1,...,n \\hspace{0.1cm} ) \\\\ f\\hspace{0.1cm}( \\hspace{0.1cm} x_{i6} \\hspace{0.1cm}:\\hspace{0.1cm} x_{i3}=3 \\hspace{0.15cm} , \\hspace{0.15cm} x_{i8}=1 \\hspace{0.1cm},\\hspace{0.1cm} i=1,...,n \\hspace{0.1cm} ) \\end{pmatrix} \\\\[0.5cm]\\] Where \\(\\hspace{0.1cm}Range(X_3) = \\lbrace 0,1,2,3 \\rbrace\\hspace{0.15cm}\\) , \\(\\hspace{0.1cm}Range(X_8) = \\lbrace 0,1 \\rbrace\\hspace{0.15cm}\\) and \\(\\hspace{0.12cm}f\\hspace{0.12cm}\\) is any function. import numpy as np House_Price_Data.groupby(&#39;quality_recode&#39;)[&#39;price&#39;].agg([np.min, np.max, np.median, np.sum, np.std]) amin amax median sum std quality_recode 0.0 360000 34340000 1400103.0 360303131 4.852033e+06 1.0 220000 35000000 1465444.0 1054059587 2.307412e+06 2.0 230000 34314000 1470388.5 2484669505 2.947205e+06 3.0 440500 2551888 759502.0 74473686 3.950463e+05 "],["concat-data-frames.html", "Chapter 16 Concat data-frames 16.1 Concat by rows 16.2 Concat by columns", " Chapter 16 Concat data-frames We can concat data-frames using concat() method. First, we are going to remember the Ventas, Proveedoresand Clientes data-frames, because we are going to use them in this section: Ventas.head() VentasId Producto Precio Cliente Proveedor 0 V1 Alfombra 1500.0 C1 P1 1 V2 Killim 699.5 C3 P1 2 V3 Killim 475.0 C9 P3 3 V4 Alfombra 5000.0 C4 P1 4 V5 Killim 499.5 C8 P1 Proveedores ProveedorID Nombre Email Telefono 0 P1 Intertrade Intertrade@gmail.com 912223344 1 P2 SaidKarpet SaidKarpet@gmail.com 912783794 2 P3 OrientKillim OrientKillim@gmail.com 9100155475 Clientes.head() ClienteID Nombre Pais Ciudad Email Telefono 0 C1 Orlando Australia 917755028 1 C2 Keith India keith0@adventure-works.com 2 C3 Donna Germany Berlin donna0@adventure-works.com 915547890 3 C4 Janet United States California janet1@adventure-works.com 4 C5 Fabio España Madrid fabio10@gmail.com from pandas import concat There are several ways to apply the concat method to a pair of data frames, each one giving different results. Let’s see some of them. 16.1 Concat by rows concat([Ventas,Clientes] axis=0) VentasId Producto Precio Cliente Proveedor ClienteID Nombre Pais Ciudad Email Telefono 0 V1 Alfombra 1500.0 C1 P1 NaN NaN NaN NaN NaN NaN 1 V2 Killim 699.5 C3 P1 NaN NaN NaN NaN NaN NaN 2 V3 Killim 475.0 C9 P3 NaN NaN NaN NaN NaN NaN 3 V4 Alfombra 5000.0 C4 P1 NaN NaN NaN NaN NaN NaN 4 V5 Killim 499.5 C8 P1 NaN NaN NaN NaN NaN NaN 5 V6 Killim 55.0 C5 P3 NaN NaN NaN NaN NaN NaN 6 V7 Alfombra 2500.0 C2 P1 NaN NaN NaN NaN NaN NaN 7 V8 Killim 299.5 C10 P1 NaN NaN NaN NaN NaN NaN 8 V9 Killim 600.0 C2 P3 NaN NaN NaN NaN NaN NaN 9 V10 Alfombra 1200.0 C7 P1 NaN NaN NaN NaN NaN NaN 10 V11 Killim 500.0 C8 P1 NaN NaN NaN NaN NaN NaN 11 V12 Killim 650.0 C9 P3 NaN NaN NaN NaN NaN NaN 12 V13 NaN 3500.0 C7 P1 NaN NaN NaN NaN NaN NaN 13 V14 NaN 1000.0 C6 P1 NaN NaN NaN NaN NaN NaN 14 V15 NaN 350.0 C10 P3 NaN NaN NaN NaN NaN NaN 0 NaN NaN NaN NaN NaN C1 Orlando Australia 917755028 1 NaN NaN NaN NaN NaN C2 Keith India keith0@adventure-works.com 2 NaN NaN NaN NaN NaN C3 Donna Germany Berlin donna0@adventure-works.com 915547890 3 NaN NaN NaN NaN NaN C4 Janet United States California janet1@adventure-works.com 4 NaN NaN NaN NaN NaN C5 Fabio España Madrid fabio10@gmail.com 5 NaN NaN NaN NaN NaN C6 Juan España Sevilla 915869028 6 NaN NaN NaN NaN NaN C7 Lucia España LuciaPerez@hotmail.com 7 NaN NaN NaN NaN NaN C8 Pedro Italia Roma Pedro99@gmail.com 910007890 8 NaN NaN NaN NaN NaN C9 Sergio United States New York sergio_as@gmail.com 9 NaN NaN NaN NaN NaN C10 Grecia Peru Lima Grecia89@gmail.com concat([Ventas,Clientes], axis=0 , ignore_index=True) VentasId Producto Precio Cliente Proveedor ClienteID Nombre Pais Ciudad Email Telefono 0 V1 Alfombra 1500.0 C1 P1 NaN NaN NaN NaN NaN NaN 1 V2 Killim 699.5 C3 P1 NaN NaN NaN NaN NaN NaN 2 V3 Killim 475.0 C9 P3 NaN NaN NaN NaN NaN NaN 3 V4 Alfombra 5000.0 C4 P1 NaN NaN NaN NaN NaN NaN 4 V5 Killim 499.5 C8 P1 NaN NaN NaN NaN NaN NaN 5 V6 Killim 55.0 C5 P3 NaN NaN NaN NaN NaN NaN 6 V7 Alfombra 2500.0 C2 P1 NaN NaN NaN NaN NaN NaN 7 V8 Killim 299.5 C10 P1 NaN NaN NaN NaN NaN NaN 8 V9 Killim 600.0 C2 P3 NaN NaN NaN NaN NaN NaN 9 V10 Alfombra 1200.0 C7 P1 NaN NaN NaN NaN NaN NaN 10 V11 Killim 500.0 C8 P1 NaN NaN NaN NaN NaN NaN 11 V12 Killim 650.0 C9 P3 NaN NaN NaN NaN NaN NaN 12 V13 NaN 3500.0 C7 P1 NaN NaN NaN NaN NaN NaN 13 V14 NaN 1000.0 C6 P1 NaN NaN NaN NaN NaN NaN 14 V15 NaN 350.0 C10 P3 NaN NaN NaN NaN NaN NaN 15 NaN NaN NaN NaN NaN C1 Orlando Australia 917755028 16 NaN NaN NaN NaN NaN C2 Keith India keith0@adventure-works.com 17 NaN NaN NaN NaN NaN C3 Donna Germany Berlin donna0@adventure-works.com 915547890 18 NaN NaN NaN NaN NaN C4 Janet United States California janet1@adventure-works.com 19 NaN NaN NaN NaN NaN C5 Fabio España Madrid fabio10@gmail.com 20 NaN NaN NaN NaN NaN C6 Juan España Sevilla 915869028 21 NaN NaN NaN NaN NaN C7 Lucia España LuciaPerez@hotmail.com 22 NaN NaN NaN NaN NaN C8 Pedro Italia Roma Pedro99@gmail.com 910007890 23 NaN NaN NaN NaN NaN C9 Sergio United States New York sergio_as@gmail.com 24 NaN NaN NaN NaN NaN C10 Grecia Peru Lima Grecia89@gmail.com We create two new data-frames that will have the same column names, to show how concat( , index=0) works in this case: X1 = pd.Series([ 2 , 4 , 3, 35, 23 ]) X2 = pd.Series([10, 12, 3, 3, -13]) X3 = pd.Series([22, 33, 1, 5, -3]) X4 = pd.Series([52, 2, 23, 6, -5]) X5 = pd.Series([ 22 , 34 , 13, 35, 23 ]) X6 = pd.Series([10, 12, 32, 30, -13]) X7 = pd.Series([22, 33, 1, 56, -13]) X8 = pd.Series([5, 12, 2, 66, -5]) df1 = pd.DataFrame( {&quot;X1&quot;: X1 , &quot;X2&quot;: X2 , &quot;X3&quot;: X3 , &quot;X4&quot;: X4} ) df2 = pd.DataFrame( {&quot;X1&quot;: X5 , &quot;X2&quot;: X6 , &quot;X3&quot;: X7 , &quot;X4&quot;: X8} ) df1 X1 X2 X3 X4 0 2 10 22 52 1 4 12 33 2 2 3 3 1 23 3 35 3 5 6 4 23 -13 -3 -5 df2 X1 X2 X3 X4 0 22 10 22 5 1 34 12 33 12 2 13 32 1 2 3 35 30 56 66 4 23 -13 -13 -5 concat([df1,df2] , axis=0) X1 X2 X3 X4 0 2 10 22 52 1 4 12 33 2 2 3 3 1 23 3 35 3 5 6 4 23 -13 -3 -5 0 22 10 22 5 1 34 12 33 12 2 13 32 1 2 3 35 30 56 66 4 23 -13 -13 -5 16.2 Concat by columns concat([Ventas,Clientes] , axis=1) VentasId Producto Precio Cliente Proveedor ClienteID Nombre Pais Ciudad Email Telefono 0 V1 Alfombra 1500.0 C1 P1 C1 Orlando Australia 917755028 1 V2 Killim 699.5 C3 P1 C2 Keith India keith0@adventure-works.com 2 V3 Killim 475.0 C9 P3 C3 Donna Germany Berlin donna0@adventure-works.com 915547890 3 V4 Alfombra 5000.0 C4 P1 C4 Janet United States California janet1@adventure-works.com 4 V5 Killim 499.5 C8 P1 C5 Fabio España Madrid fabio10@gmail.com 5 V6 Killim 55.0 C5 P3 C6 Juan España Sevilla 915869028 6 V7 Alfombra 2500.0 C2 P1 C7 Lucia España LuciaPerez@hotmail.com 7 V8 Killim 299.5 C10 P1 C8 Pedro Italia Roma Pedro99@gmail.com 910007890 8 V9 Killim 600.0 C2 P3 C9 Sergio United States New York sergio_as@gmail.com 9 V10 Alfombra 1200.0 C7 P1 C10 Grecia Peru Lima Grecia89@gmail.com 10 V11 Killim 500.0 C8 P1 NaN NaN NaN NaN NaN NaN 11 V12 Killim 650.0 C9 P3 NaN NaN NaN NaN NaN NaN 12 V13 NaN 3500.0 C7 P1 NaN NaN NaN NaN NaN NaN 13 V14 NaN 1000.0 C6 P1 NaN NaN NaN NaN NaN NaN 14 V15 NaN 350.0 C10 P3 NaN NaN NaN NaN NaN NaN Mathematically, concat() operation could be formalized as follows: Suppose we have two data frames \\(\\hspace{0.1cm} df1\\hspace{0.1cm}\\) and \\(\\hspace{0.1cm}df2\\hspace{0.1cm}\\) : \\(\\\\[0.4cm]\\) \\[df1 \\hspace{0.2cm}\\Rightarrow\\hspace{0.2cm} D_1 = \\begin{pmatrix} x_1 \\\\ ... \\\\ x_{n_1} \\end{pmatrix} = \\begin{pmatrix} X_1 &amp; ... &amp; X_{p_1} \\\\ \\end{pmatrix} \\\\[1cm]\\] \\[df2 \\hspace{0.2cm} \\Rightarrow \\hspace{0.2cm} D_2 = \\begin{pmatrix} y_1 \\\\ ... \\\\ y_{n_1} \\end{pmatrix} = \\begin{pmatrix} Y_1 &amp; ... &amp; Y_{p_2} \\\\ \\end{pmatrix} \\\\[0.5cm]\\] In addition, \\(\\hspace{0.08cm}NA \\hspace{0.1cm}=\\hspace{0.1cm} \\begin{pmatrix} NaN \\\\ ... \\\\ NaN \\end{pmatrix} \\hspace{0.1cm}\\) is a NaN vector with suitable dimensions. If all the column names of \\(\\hspace{0.1cm}df1\\hspace{0.1cm}\\) are different to all the column names of \\(\\hspace{0.1cm}df2\\hspace{0.1cm}\\) : \\(\\\\[0.4cm]\\) \\[concat \\hspace{0.1cm}( \\hspace{0.1cm} [df1\\hspace{0.1cm},\\hspace{0.1cm}df2] \\hspace{0.1cm}, \\hspace{0.1cm} axis=0 \\hspace{0.1cm}) \\hspace{0.1cm} = \\hspace{0.1cm} \\begin{pmatrix} X_1 &amp; ... &amp; X_{p_1} &amp; NA &amp; ... &amp; NA \\\\ NA &amp; ... &amp; NA &amp; Y_1 &amp; ... &amp; Y_{p_2} \\end{pmatrix} \\\\[1cm]\\] If \\(\\hspace{0.1cm}name(X_2)\\hspace{0.1cm} =\\hspace{0.1cm} name(Y_3)\\hspace{0.1cm}\\) but the rest of column names are different one each other: \\(\\\\[0.4cm]\\) \\[concat \\hspace{0.1cm} ( \\hspace{0.1cm}[df1 \\hspace{0.1cm},\\hspace{0.1cm}df2] \\hspace{0.1cm} , \\hspace{0.1cm} axis=0 \\hspace{0.1cm}) \\hspace{0.1cm} = \\hspace{0.1cm} \\begin{pmatrix} X_1 &amp; X_2 &amp; X_3 &amp; ... &amp; X_{p_1} &amp; NA &amp; NA &amp; NA &amp; ... &amp; NA \\\\ NA &amp; Y_3 &amp; NA &amp; ... &amp; NA &amp; Y_1 &amp; Y_2 &amp; Y_4 &amp; ... &amp; Y_{p_2} \\end{pmatrix} \\\\[1cm]\\] If all the column names of \\(\\hspace{0.1cm} df1\\hspace{0.1cm}\\) are equal to all the column names of \\(\\hspace{0.1cm}df2\\hspace{0.1cm}\\) : \\(\\\\[0.4cm]\\) \\[concat\\hspace{0.1cm}(\\hspace{0.1cm}[df1\\hspace{0.1cm},\\hspace{0.1cm}df2]\\hspace{0.1cm},\\hspace{0.1cm} axis=0\\hspace{0.1cm}) \\hspace{0.1cm}=\\hspace{0.1cm} \\begin{pmatrix} x_1 \\\\ ... \\\\ x_{n_1} \\\\ y_1 \\\\ ... \\\\ y_{n_2} \\end{pmatrix} = \\begin{pmatrix} X_1 &amp; ... &amp; X_p \\\\ Y_1 &amp; ... &amp; Y_p \\end{pmatrix}\\\\[1cm]\\] If \\(\\hspace{0.1cm}n_1 &gt; n_2\\hspace{0.1cm}\\) : \\[concat\\hspace{0.1cm}(\\hspace{0.1cm}[df1\\hspace{0.1cm},\\hspace{0.1cm}df2]\\hspace{0.1cm},\\hspace{0.1cm} axis=1\\hspace{0.1cm}) \\hspace{0.1cm} =\\hspace{0.1cm} \\begin{pmatrix} x_1 &amp; y_1 \\\\ x_2 &amp; y_2 \\\\ ... &amp; ... \\\\ x_{n_2} &amp; y_{n_2}\\\\ x_{n_2 +1} &amp; NA \\\\ ... &amp; ... \\\\ x_{n_1} &amp; NA \\end{pmatrix} \\\\[1cm]\\] if \\(\\hspace{0.1cm}n_1 = n_2\\hspace{0.1cm}\\) : \\[concat\\hspace{0.1cm}(\\hspace{0.1cm}[df1\\hspace{0.1cm},\\hspace{0.1cm}df2]\\hspace{0.1cm},\\hspace{0.1cm} axis=1\\hspace{0.1cm}) \\hspace{0.1cm} =\\hspace{0.1cm} \\begin{pmatrix} x_1 &amp; y_1 \\\\ x_2 &amp; y_2 \\\\ ... &amp; ... \\\\ x_{n_1} &amp; y_{n_2} \\end{pmatrix}\\] "],["join-data-frames.html", "Chapter 17 Join data-frames 17.1 Inner join 17.2 Outer join 17.3 Left join 17.4 Right join", " Chapter 17 Join data-frames We are going to remember the Ventas and Clientes data-frames, because we are going to use them in this section: Ventas VentasId Producto Precio ClienteID Proveedor 0 V1 Alfombra 1500.0 C1 P1 1 V2 Killim 699.5 C3 P1 2 V3 Killim 475.0 C9 P3 3 V4 Alfombra 5000.0 C4 P1 4 V5 Killim 499.5 C8 P1 5 V6 Killim 55.0 C5 P3 6 V7 Alfombra 2500.0 C2 P1 7 V8 Killim 299.5 C10 P1 8 V9 Killim 600.0 C2 P3 9 V10 Alfombra 1200.0 C7 P1 10 V11 Killim 500.0 C8 P1 11 V12 Killim 650.0 C9 P3 12 V13 NaN 3500.0 C7 P1 13 V14 NaN 1000.0 C6 P1 14 V15 NaN 350.0 C10 P3 Clientes ClienteID Nombre Pais Ciudad Email Telefono 0 C1 Orlando Australia 917755028 1 C2 Keith India keith0@adventure-works.com 2 C3 Donna Germany Berlin donna0@adventure-works.com 915547890 3 C4 Janet United States California janet1@adventure-works.com 4 C5 Fabio España Madrid fabio10@gmail.com 5 C6 Juan España Sevilla 915869028 6 C7 Lucia España LuciaPerez@hotmail.com 7 C8 Pedro Italia Roma Pedro99@gmail.com 910007890 8 C9 Sergio United States New York sergio_as@gmail.com 9 C10 Grecia Peru Lima Grecia89@gmail.com 10 C11 Ismael España Madrid Isma98@gmail.com 912234543 11 C12 Luis España Murcia Luismiguel123@gmail.com Suppose we have two data frames \\(\\hspace{0.1cm} df1\\hspace{0.1cm}\\) and \\(\\hspace{0.1cm}df2\\hspace{0.1cm}\\) : \\(\\\\[0.4cm]\\) \\[df1 \\hspace{0.2cm}\\Rightarrow\\hspace{0.2cm} D_1 = \\begin{pmatrix} x_1 \\\\ ... \\\\ x_{n_1} \\end{pmatrix} = \\begin{pmatrix} X_1 &amp; ... &amp; X_{p_1} \\\\ \\end{pmatrix} \\\\[1cm]\\] \\[df2 \\hspace{0.2cm} \\Rightarrow \\hspace{0.2cm} D_2 = \\begin{pmatrix} y_1 \\\\ ... \\\\ y_{n_1} \\end{pmatrix} = \\begin{pmatrix} Y_1 &amp; ... &amp; Y_{p_2} \\\\ \\end{pmatrix} \\\\[1cm]\\] where there is a column shared by both data frames, called the link column, through which they will be joined. Taking the above into account, we define: \\(\\\\[0.5cm]\\) \\[y(x_i) \\hspace{0.1cm}=\\hspace{0.1cm} \\lbrace \\hspace{0.1cm} y_i \\hspace{0.1cm} : \\hspace{0.1cm} i = 1,...,n_2 \\hspace{0.1cm} , \\hspace{0.1cm} y_i[link] = x_i[link] \\hspace{0.1cm} \\rbrace \\\\\\] \\[x(y_i) \\hspace{0.1cm} = \\hspace{0.1cm} \\lbrace \\hspace{0.1cm} x_i \\hspace{0.1cm} : \\hspace{0.1cm} i = 1,...,n_2 \\hspace{0.1cm} , \\hspace{0.1cm} x_i[link] =y_i[link] \\hspace{0.1cm} \\rbrace \\\\\\] where \\(\\hspace{0.1cm}x_i[link]\\hspace{0.1cm}\\) is the value of the link column in the row \\(\\hspace{0.1cm}i\\)-th row of \\(\\hspace{0.1cm}df1\\hspace{0.1cm}\\), that is, \\(\\hspace{0.1cm}x_i\\) . 17.1 Inner join In simple words, the inner join between \\(\\hspace{0.1cm}df1\\hspace{0.1cm}\\) and \\(\\hspace{0.1cm}df2\\hspace{0.1cm}\\) is an operation that consists of creating a new data frame that joins \\(\\hspace{0.1cm}df1\\hspace{0.1cm}\\) rows and \\(\\hspace{0.1cm}df2\\hspace{0.1cm}\\) rows through a link column, taking into account only the values of the link column appearing in both data frames. pd.merge(Ventas, Clientes, on=&#39;ClienteID&#39;, how=&#39;inner&#39;) VentasId Producto Precio ClienteID Proveedor Nombre Pais Ciudad Email Telefono 0 V1 Alfombra 1500.0 C1 P1 Orlando Australia 917755028 1 V2 Killim 699.5 C3 P1 Donna Germany Berlin donna0@adventure-works.com 915547890 2 V3 Killim 475.0 C9 P3 Sergio United States New York sergio_as@gmail.com 3 V12 Killim 650.0 C9 P3 Sergio United States New York sergio_as@gmail.com 4 V4 Alfombra 5000.0 C4 P1 Janet United States California janet1@adventure-works.com 5 V5 Killim 499.5 C8 P1 Pedro Italia Roma Pedro99@gmail.com 910007890 6 V11 Killim 500.0 C8 P1 Pedro Italia Roma Pedro99@gmail.com 910007890 7 V6 Killim 55.0 C5 P3 Fabio España Madrid fabio10@gmail.com 8 V7 Alfombra 2500.0 C2 P1 Keith India keith0@adventure-works.com 9 V9 Killim 600.0 C2 P3 Keith India keith0@adventure-works.com 10 V8 Killim 299.5 C10 P1 Grecia Peru Lima Grecia89@gmail.com 11 V15 NaN 350.0 C10 P3 Grecia Peru Lima Grecia89@gmail.com 12 V10 Alfombra 1200.0 C7 P1 Lucia España LuciaPerez@hotmail.com 13 V13 NaN 3500.0 C7 P1 Lucia España LuciaPerez@hotmail.com 14 V14 NaN 1000.0 C6 P1 Juan España Sevilla 915869028 Mathematically inner join can be formalized as follows: \\[pd.merge \\hspace{0.1cm} ( \\hspace{0.1cm} df1 \\hspace{0.1cm} , \\hspace{0.1cm} df2 \\hspace{0.1cm} , \\hspace{0.1cm} on=link \\hspace{0.1cm} , \\hspace{0.1cm} how=inner \\hspace{0.1cm} ) \\hspace{0.1cm}=\\hspace{0.1cm} \\left( \\hspace{0.1cm} c \\hspace{0.1cm} ( \\hspace{0.1cm} x_i \\hspace{0.1cm} , \\hspace{0.1cm} y_j \\hspace{0.1cm} ) \\hspace{0.13cm} : \\hspace{0.13cm} \\hspace{0.13cm} i=1,...,n_1 \\hspace{0.15cm} ,\\hspace{0.15cm} j=1,...,n_2 \\hspace{0.15cm}, \\hspace{0.2cm} y_j \\in y(x_i) \\hspace{0.1cm} \\right) \\\\\\] where: \\(c \\hspace{0.1cm} ( \\hspace{0.1cm} x_i \\hspace{0.1cm} , \\hspace{0.1cm} y_j \\hspace{0.1cm} ) \\hspace{0.1cm}\\) is the row resulting from concatenating \\(\\hspace{0.1cm}x_i \\hspace{0.1cm}\\) with \\(\\hspace{0.1cm}y_j \\hspace{0.1cm}\\) Note that in \\(\\hspace{0.1cm}c \\hspace{0.1cm} ( \\hspace{0.1cm} x_i \\hspace{0.1cm} , \\hspace{0.1cm} y_j \\hspace{0.1cm} ) \\hspace{0.1cm}\\) the link column appears two times, so in many software such as Pandas one of them is removed to avoid repetition. 17.2 Outer join In simple words, the outer join between \\(\\hspace{0.1cm}df1\\hspace{0.1cm}\\) and \\(\\hspace{0.1cm}df2\\hspace{0.1cm}\\) is an operation that consists of creating a new frame of data that joins \\(\\hspace{0.1cm}df1\\hspace{0.1cm}\\) rows and \\(\\hspace{0.1cm}df2\\hspace{0.1cm}\\) rows via a link column, taking into account all values of the link column, both those that appear in both data-frames, and those that appear in \\(df1\\) but not in \\(df2\\), and those that appear in \\(df2\\) but not in \\(df1\\). pd.merge(Ventas, Clientes, on=&#39;ClienteID&#39;, how=&#39;outer&#39;) VentasId Producto Precio ClienteID Proveedor Nombre Pais Ciudad Email Telefono 0 V1 Alfombra 1500.0 C1 P1 Orlando Australia 917755028 1 V2 Killim 699.5 C3 P1 Donna Germany Berlin donna0@adventure-works.com 915547890 2 V3 Killim 475.0 C9 P3 Sergio United States New York sergio_as@gmail.com 3 V12 Killim 650.0 C9 P3 Sergio United States New York sergio_as@gmail.com 4 V4 Alfombra 5000.0 C4 P1 Janet United States California janet1@adventure-works.com 5 V5 Killim 499.5 C8 P1 Pedro Italia Roma Pedro99@gmail.com 910007890 6 V11 Killim 500.0 C8 P1 Pedro Italia Roma Pedro99@gmail.com 910007890 7 V6 Killim 55.0 C5 P3 Fabio España Madrid fabio10@gmail.com 8 V7 Alfombra 2500.0 C2 P1 Keith India keith0@adventure-works.com 9 V9 Killim 600.0 C2 P3 Keith India keith0@adventure-works.com 10 V8 Killim 299.5 C10 P1 Grecia Peru Lima Grecia89@gmail.com 11 V15 NaN 350.0 C10 P3 Grecia Peru Lima Grecia89@gmail.com 12 V10 Alfombra 1200.0 C7 P1 Lucia España LuciaPerez@hotmail.com 13 V13 NaN 3500.0 C7 P1 Lucia España LuciaPerez@hotmail.com 14 V14 NaN 1000.0 C6 P1 Juan España Sevilla 915869028 15 NaN NaN NaN C11 NaN Ismael España Madrid Isma98@gmail.com 912234543 16 NaN NaN NaN C12 NaN Luis España Murcia Luismiguel123@gmail.com Mathematically outer join can be formalized as follows: \\[pd.merge \\hspace{0.1cm} ( \\hspace{0.1cm} df1 \\hspace{0.1cm} , \\hspace{0.1cm} df2 \\hspace{0.1cm} , \\hspace{0.1cm} on=link \\hspace{0.1cm} , \\hspace{0.1cm} how=outer \\hspace{0.1cm} ) \\hspace{0.1cm}=\\hspace{0.1cm} \\begin{pmatrix} \\hspace{0.1cm} c \\hspace{0.1cm} ( \\hspace{0.1cm} x_i \\hspace{0.1cm} , \\hspace{0.1cm} y_j \\hspace{0.1cm} ) \\hspace{0.15cm} : \\hspace{0.15cm} \\hspace{0.13cm} i=1,...,n_1 \\hspace{0.15cm} , \\hspace{0.15cm} j=1,...,n_2 \\hspace{0.15cm} , \\hspace{0.15cm} y_j \\in y(x_i) \\hspace{0.1cm} \\\\ \\hspace{0.1cm} c \\hspace{0.1cm} ( \\hspace{0.1cm} x_i \\hspace{0.1cm} , \\hspace{0.1cm} NA \\hspace{0.1cm} ) \\hspace{0.15cm} : \\hspace{0.15cm} \\hspace{0.13cm} i=1,...,n_1 \\hspace{0.15cm} , \\hspace{0.15cm} \\nexists \\hspace{0.1cm} j = 1,...,n_2 \\hspace{0.15cm},\\hspace{0.15cm} y_j \\in y(x_i) \\hspace{0.1cm}\\\\ \\hspace{0.1cm} c \\hspace{0.1cm} ( \\hspace{0.1cm} NA \\hspace{0.1cm} , \\hspace{0.1cm} y_j \\hspace{0.1cm} ) \\hspace{0.15cm} : \\hspace{0.15cm} \\hspace{0.13cm} j=1,...,n_2 \\hspace{0.15cm} , \\hspace{0.15cm} \\nexists \\hspace{0.1cm} i = 1,...,n_1 \\hspace{0.15cm}, \\hspace{0.15cm} x_i \\in x(y_j) \\\\ \\end{pmatrix} \\\\\\] where: \\(c \\hspace{0.1cm} ( \\hspace{0.1cm} x_i \\hspace{0.1cm} , \\hspace{0.1cm} y_j \\hspace{0.1cm} ) \\hspace{0.1cm}\\) is the row resulting from concatenating \\(\\hspace{0.1cm}x_i \\hspace{0.1cm}\\) with \\(\\hspace{0.1cm}y_j \\hspace{0.1cm}\\) Note that in \\(\\hspace{0.1cm}c \\hspace{0.1cm} ( \\hspace{0.1cm} x_i \\hspace{0.1cm} , \\hspace{0.1cm} y_j \\hspace{0.1cm} ) \\hspace{0.1cm}\\) the link column appears two times, so in many software such as Pandas one of them is removed to avoid repetition. 17.3 Left join In simple words, the left join between \\(\\hspace{0.1cm}df1\\hspace{0.1cm}\\) and \\(\\hspace{0.1cm}df2\\hspace{0.1cm}\\) is an operation that consists of creating a new frame of data that joins \\(\\hspace{0.1cm}df1\\hspace{0.1cm}\\) rows and \\(\\hspace{0.1cm}df2\\hspace{0.1cm}\\) rows via a link column, taking into account the values of the link column that appear in both data-frames, and those that appear in \\(\\hspace{0.1cm}df1\\hspace{0.1cm}\\) but not in \\(\\hspace{0.1cm}df2\\). pd.merge(Ventas, Clientes, on=&#39;ClienteID&#39;, how=&#39;left&#39;) VentasId Producto Precio ClienteID Proveedor Nombre Pais Ciudad Email Telefono 0 V1 Alfombra 1500.0 C1 P1 Orlando Australia 917755028 1 V2 Killim 699.5 C3 P1 Donna Germany Berlin donna0@adventure-works.com 915547890 2 V3 Killim 475.0 C9 P3 Sergio United States New York sergio_as@gmail.com 3 V4 Alfombra 5000.0 C4 P1 Janet United States California janet1@adventure-works.com 4 V5 Killim 499.5 C8 P1 Pedro Italia Roma Pedro99@gmail.com 910007890 5 V6 Killim 55.0 C5 P3 Fabio España Madrid fabio10@gmail.com 6 V7 Alfombra 2500.0 C2 P1 Keith India keith0@adventure-works.com 7 V8 Killim 299.5 C10 P1 Grecia Peru Lima Grecia89@gmail.com 8 V9 Killim 600.0 C2 P3 Keith India keith0@adventure-works.com 9 V10 Alfombra 1200.0 C7 P1 Lucia España LuciaPerez@hotmail.com 10 V11 Killim 500.0 C8 P1 Pedro Italia Roma Pedro99@gmail.com 910007890 11 V12 Killim 650.0 C9 P3 Sergio United States New York sergio_as@gmail.com 12 V13 NaN 3500.0 C7 P1 Lucia España LuciaPerez@hotmail.com 13 V14 NaN 1000.0 C6 P1 Juan España Sevilla 915869028 14 V15 NaN 350.0 C10 P3 Grecia Peru Lima Grecia89@gmail.com Mathematically left join can be formalized as follows: \\[pd.merge \\hspace{0.1cm} ( \\hspace{0.1cm} df1 \\hspace{0.1cm} , \\hspace{0.1cm} df2 \\hspace{0.1cm} , \\hspace{0.1cm} on=link \\hspace{0.1cm} , \\hspace{0.1cm} how=left \\hspace{0.1cm} ) \\hspace{0.1cm}=\\hspace{0.1cm} \\begin{pmatrix} \\hspace{0.1cm} c \\hspace{0.1cm} ( \\hspace{0.1cm} x_i \\hspace{0.1cm} , \\hspace{0.1cm} y_j \\hspace{0.1cm} ) \\hspace{0.15cm} : \\hspace{0.15cm} \\hspace{0.13cm} i=1,...,n_1 \\hspace{0.15cm} , \\hspace{0.15cm} j=1,...,n_2 \\hspace{0.15cm} , \\hspace{0.15cm} y_j \\in y(x_i) \\hspace{0.1cm} \\\\ \\hspace{0.1cm} c \\hspace{0.1cm} ( \\hspace{0.1cm} x_i \\hspace{0.1cm} , \\hspace{0.1cm} NA \\hspace{0.1cm} ) \\hspace{0.15cm} : \\hspace{0.15cm} \\hspace{0.13cm} i=1,...,n_1 \\hspace{0.15cm} , \\hspace{0.15cm} \\nexists \\hspace{0.1cm} j = 1,...,n_2 \\hspace{0.15cm},\\hspace{0.15cm} y_j \\in y(x_i) \\hspace{0.1cm} \\end{pmatrix}\\\\ \\] where: \\(c \\hspace{0.1cm} ( \\hspace{0.1cm} x_i \\hspace{0.1cm} , \\hspace{0.1cm} y_j \\hspace{0.1cm} ) \\hspace{0.1cm}\\) is the row resulting from concatenating \\(\\hspace{0.1cm}x_i \\hspace{0.1cm}\\) with \\(\\hspace{0.1cm}y_j \\hspace{0.1cm}\\) Note that in \\(\\hspace{0.1cm}c \\hspace{0.1cm} ( \\hspace{0.1cm} x_i \\hspace{0.1cm} , \\hspace{0.1cm} y_j \\hspace{0.1cm} ) \\hspace{0.1cm}\\) the link column appears two times, so in many software such as Pandas one of them is removed to avoid repetition. 17.4 Right join In simple words, the left join between \\(\\hspace{0.1cm}df1\\hspace{0.1cm}\\) and \\(\\hspace{0.1cm}df2\\hspace{0.1cm}\\) is an operation that consists of creating a new frame of data that joins \\(\\hspace{0.1cm}df1\\hspace{0.1cm}\\) rows and \\(\\hspace{0.1cm}df2\\hspace{0.1cm}\\) rows via a link column, taking into account the values of the link column that appear in both data-frames, and those that appear in \\(\\hspace{0.1cm}df2\\hspace{0.1cm}\\) but not in \\(\\hspace{0.1cm}df1\\). pd.merge(Ventas, Clientes, on=&#39;ClienteID&#39;, how=&#39;right&#39;) VentasId Producto Precio ClienteID Proveedor Nombre Pais Ciudad Email Telefono 0 V1 Alfombra 1500.0 C1 P1 Orlando Australia 917755028 1 V7 Alfombra 2500.0 C2 P1 Keith India keith0@adventure-works.com 2 V9 Killim 600.0 C2 P3 Keith India keith0@adventure-works.com 3 V2 Killim 699.5 C3 P1 Donna Germany Berlin donna0@adventure-works.com 915547890 4 V4 Alfombra 5000.0 C4 P1 Janet United States California janet1@adventure-works.com 5 V6 Killim 55.0 C5 P3 Fabio España Madrid fabio10@gmail.com 6 V14 NaN 1000.0 C6 P1 Juan España Sevilla 915869028 7 V10 Alfombra 1200.0 C7 P1 Lucia España LuciaPerez@hotmail.com 8 V13 NaN 3500.0 C7 P1 Lucia España LuciaPerez@hotmail.com 9 V5 Killim 499.5 C8 P1 Pedro Italia Roma Pedro99@gmail.com 910007890 10 V11 Killim 500.0 C8 P1 Pedro Italia Roma Pedro99@gmail.com 910007890 11 V3 Killim 475.0 C9 P3 Sergio United States New York sergio_as@gmail.com 12 V12 Killim 650.0 C9 P3 Sergio United States New York sergio_as@gmail.com 13 V8 Killim 299.5 C10 P1 Grecia Peru Lima Grecia89@gmail.com 14 V15 NaN 350.0 C10 P3 Grecia Peru Lima Grecia89@gmail.com 15 NaN NaN NaN C11 NaN Ismael España Madrid Isma98@gmail.com 912234543 16 NaN NaN NaN C12 NaN Luis España Murcia Luismiguel123@gmail.com Mathematically right join can be formalized as follows: \\[pd.merge \\hspace{0.1cm} ( \\hspace{0.1cm} df1 \\hspace{0.1cm} , \\hspace{0.1cm} df2 \\hspace{0.1cm} , \\hspace{0.1cm} on=link \\hspace{0.1cm} , \\hspace{0.1cm} how=right \\hspace{0.1cm} ) \\hspace{0.1cm}=\\hspace{0.1cm} \\begin{pmatrix} \\hspace{0.1cm} c \\hspace{0.1cm} ( \\hspace{0.1cm} x_i \\hspace{0.1cm} , \\hspace{0.1cm} y_j \\hspace{0.1cm} ) \\hspace{0.15cm} : \\hspace{0.15cm} \\hspace{0.13cm} i=1,...,n_1 \\hspace{0.15cm} , \\hspace{0.15cm} j=1,...,n_2 \\hspace{0.15cm} , \\hspace{0.15cm} y_j \\in y(x_i) \\hspace{0.1cm} \\\\ \\hspace{0.1cm} c \\hspace{0.1cm} ( \\hspace{0.1cm} NA \\hspace{0.1cm} , \\hspace{0.1cm} y_j \\hspace{0.1cm} ) \\hspace{0.15cm} : \\hspace{0.15cm} \\hspace{0.13cm} j=1,...,n_2 \\hspace{0.15cm} , \\hspace{0.15cm} \\nexists \\hspace{0.1cm} i = 1,...,n_1 \\hspace{0.15cm}, \\hspace{0.15cm} x_i \\in x(y_j) \\\\ \\end{pmatrix} \\\\\\] where: \\(c \\hspace{0.1cm} ( \\hspace{0.1cm} x_i \\hspace{0.1cm} , \\hspace{0.1cm} y_j \\hspace{0.1cm} ) \\hspace{0.1cm}\\) is the row resulting from concatenating \\(\\hspace{0.1cm}x_i \\hspace{0.1cm}\\) with \\(\\hspace{0.1cm}y_j \\hspace{0.1cm}\\) Note that in \\(\\hspace{0.1cm}c \\hspace{0.1cm} ( \\hspace{0.1cm} x_i \\hspace{0.1cm} , \\hspace{0.1cm} y_j \\hspace{0.1cm} ) \\hspace{0.1cm}\\) the link column appears two times, so in many software such as Pandas one of them is removed to avoid repetition. The correct way to use merge when the names of link columns are different is the following: # df_merge = pd.merge(df1, df2, left_on=&#39;id1&#39; , right_on=&#39;id2&#39;, how=&#39;inner&#39;) "],["sorting-columns-from-a-data-frame.html", "Chapter 18 Sorting columns from a data-frame", " Chapter 18 Sorting columns from a data-frame House_Price_Data.sort_values(by=&#39;price&#39;, ascending=True) neighborhood_recode latitude longitude price no_of_bedrooms no_of_bathrooms quality_recode maid_room_recode unfurnished_recode balcony_recode … private_garden_recode private_gym_recode private_jacuzzi_recode private_pool_recode security_recode shared_gym_recode shared_pool_recode shared_spa_recode view_of_water_recode size_in_m_2 1592 31.0 25.173301 55.402315 220000 0 1 1.0 0.0 1.0 1.0 … 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 44.965052 1610 23.0 25.036803 55.200909 230000 0 1 2.0 0.0 0.0 1.0 … 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 1.0 35.303140 1609 23.0 25.036803 55.200909 230000 0 1 2.0 0.0 1.0 1.0 … 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 1.0 33.630886 749 25.0 25.115934 55.390236 245000 0 1 1.0 0.0 0.0 0.0 … 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 28.428318 1499 25.0 25.115934 55.390236 250000 0 1 1.0 0.0 1.0 0.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 32.794759 … … … … … … … … … … … … … … … … … … … … … … 427 9.0 25.188299 55.288975 30950000 4 4 2.0 0.0 1.0 0.0 … 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 0.0 735.977566 1885 46.0 25.103972 55.149621 31440000 4 6 0.0 1.0 0.0 1.0 … 0.0 0.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 607.771426 576 46.0 25.103550 55.168509 34314000 4 5 2.0 0.0 1.0 1.0 … 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 889.639128 1869 46.0 25.103972 55.149621 34340000 4 6 0.0 1.0 0.0 1.0 … 1.0 0.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 810.299966 989 46.0 25.103550 55.168509 35000000 4 5 1.0 0.0 1.0 1.0 … 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 682.465438 1905 rows × 29 columns House_Price_Data.sort_values(by=&#39;price&#39;, ascending=False) neighborhood_recode latitude longitude price no_of_bedrooms no_of_bathrooms quality_recode maid_room_recode unfurnished_recode balcony_recode … private_garden_recode private_gym_recode private_jacuzzi_recode private_pool_recode security_recode shared_gym_recode shared_pool_recode shared_spa_recode view_of_water_recode size_in_m_2 989 46.0 25.103550 55.168509 35000000 4 5 1.0 0.0 1.0 1.0 … 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 682.465438 1869 46.0 25.103972 55.149621 34340000 4 6 0.0 1.0 0.0 1.0 … 1.0 0.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 810.299966 576 46.0 25.103550 55.168509 34314000 4 5 2.0 0.0 1.0 1.0 … 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 889.639128 1885 46.0 25.103972 55.149621 31440000 4 6 0.0 1.0 0.0 1.0 … 0.0 0.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 607.771426 427 9.0 25.188299 55.288975 30950000 4 4 2.0 0.0 1.0 0.0 … 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 0.0 735.977566 … … … … … … … … … … … … … … … … … … … … … … 1499 25.0 25.115934 55.390236 250000 0 1 1.0 0.0 1.0 0.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 32.794759 749 25.0 25.115934 55.390236 245000 0 1 1.0 0.0 0.0 0.0 … 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 28.428318 1609 23.0 25.036803 55.200909 230000 0 1 2.0 0.0 1.0 1.0 … 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 1.0 33.630886 1610 23.0 25.036803 55.200909 230000 0 1 2.0 0.0 0.0 1.0 … 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 1.0 35.303140 1592 31.0 25.173301 55.402315 220000 0 1 1.0 0.0 1.0 1.0 … 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 44.965052 1905 rows × 29 columns Mathematically sort operation could be formalized as follows: \\[ df.sort\\_values \\hspace{0.1cm} ( \\hspace{0.1cm} by=name(X_3) \\hspace{0.1cm} , \\hspace{0.1cm} ascending \\hspace{0.1cm} ) \\hspace{0.15cm} = \\hspace{0.15cm} \\begin{pmatrix} x_{i_11} &amp; x_{i_11} &amp; ... &amp; x_{i_1 3} &amp; ... &amp; x_{i_1 p}\\\\ x_{i_21} &amp; x_{i_21} &amp; ... &amp; x_{i_2 3} &amp; ... &amp; x_{i_2 p}\\\\ ... &amp; ... &amp; ... &amp; ... &amp; ... &amp; ...\\\\ x_{i_n1} &amp; x_{i_n 1} &amp; ... &amp; x_{i_n 3} &amp; ...&amp; x_{i_n p} \\end{pmatrix} \\\\ \\] where: if \\(\\hspace{0.1cm}ascending = True\\) \\[x_{i_1 3} \\hspace{0.1cm} &lt; \\hspace{0.1cm} x_{i_2 3} \\hspace{0.1cm} &lt; \\hspace{0.1cm} \\dots \\hspace{0.1cm} &lt; \\hspace{0.1cm} x_{i_n 3} \\\\\\] if \\(\\hspace{0.1cm} ascending = False\\) \\[x_{i_1 3} \\hspace{0.1cm} &gt; \\hspace{0.1cm} x_{i_2 3} \\hspace{0.1cm} &gt; \\dots &gt; \\hspace{0.1cm} x_{i_n 3}\\] "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
