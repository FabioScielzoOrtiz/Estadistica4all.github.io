[["index.html", "Introduction to Pandas Chapter 1 Introduction", " Introduction to Pandas Fabio Scielzo Ortiz 2023-03-13 Chapter 1 Introduction More articles: \\(\\hspace{0.1cm}\\) Estadistica4all Author: \\(\\hspace{0.1cm}\\) Fabio Scielzo Ortiz If you use this article, please cite it: \\(\\hspace{0.5cm}\\) Scielzo Ortiz, F. (2023). Introduction to Pandas. Estadistica4all. It is recommended to open the article on a computer or tablet. This is a hands-on introduction to Pandas, probably the most important Python library for handling data frames. "],["create-a-new-table-data-frame.html", "Chapter 2 Create a new table (data-frame)", " Chapter 2 Create a new table (data-frame) First of all, obviously, we need to import the Pandas library. import pandas as pd We can create a new table (data-frame) using Pandas as follows: AlumnoID = pd.Series([&#39;A1&#39;, &#39;A2&#39;, &#39;A3&#39;, &#39;A4&#39;, &#39;A5&#39;, &#39;A6&#39;, &#39;A7&#39;, &#39;A8&#39;, &#39;A9&#39;, &#39;A10&#39;,&#39;A11&#39;,&#39;A12&#39;, &#39;A13&#39;]) Nombre = pd.Series([&#39;Orlando&#39;, &#39;Keith&#39;, &#39;Donna&#39;, &#39;Janet&#39;, &#39;Fabio&#39;, &#39;Juan&#39;, &#39;Lucia&#39;, &#39;Pedro&#39;, &#39;Sergio&#39;, &#39;Grecia&#39;, &#39;Ismael&#39;, &#39;Luis&#39;, &#39;Pedro&#39;]) Pais = pd.Series([&#39;Australia&#39;, &#39;India&#39;, &#39;Germany&#39;, &#39;United States&#39;, &#39;España&#39;, &#39;España&#39;, &#39;España&#39;, &#39;Italia&#39;, &#39;United States&#39;, &#39;Peru&#39;,&#39;España&#39;,&#39;España&#39;,&#39;Argentina&#39;]) Ciudad = pd.Series([&#39;&#39;,&#39;&#39;,&#39;Berlin&#39;,&#39;California&#39;,&#39;Madrid&#39;, &#39;Sevilla&#39;, &#39;&#39;, &#39;Roma&#39;, &#39;New York&#39;, &#39;Lima&#39;, &#39;Madrid&#39;, &#39;Murcia&#39;, &#39;Buenos Aires&#39;]) Email = pd.Series([&#39;&#39;,&#39;keith0@adventure-works.com&#39;,&#39;donna0@adventure-works.com&#39;,&#39;janet1@adventure-works.com&#39;,&#39;fabio10@gmail.com&#39;, &#39;&#39;, &#39;LuciaPerez@hotmail.com&#39;, &#39;Pedro99@gmail.com&#39;, &#39;sergio_as@gmail.com&#39;, &#39;Grecia89@gmail.com&#39;, &#39;Isma98@gmail.com&#39;, &#39;Luismiguel123@gmail.com&#39;, &#39;Pedro120@gmail.com&#39;]) Telefono = pd.Series([&#39;917755028&#39;, &#39;&#39;, &#39;915547890&#39;, &#39;&#39;, &#39;&#39;, &#39;915869028&#39;, &#39;&#39;, &#39;910007890&#39;, &#39;&#39;, &#39;&#39;, &#39;912234543&#39;, &#39;&#39;, &#39;&#39;]) Alumnos = pd.DataFrame({&#39;AlumnoID&#39;: AlumnoID , &#39;Nombre&#39;: Nombre, &#39;Pais&#39;:Pais , &#39;Ciudad&#39;:Ciudad, &#39;Email&#39;:Email, &#39;Telefono&#39;:Telefono}) Alumnos AlumnoID Nombre Pais Ciudad Email Telefono 0 A1 Orlando Australia 917755028 1 A2 Keith India keith0@adventure-works.com 2 A3 Donna Germany Berlin donna0@adventure-works.com 915547890 3 A4 Janet United States California janet1@adventure-works.com 4 A5 Fabio España Madrid fabio10@gmail.com 5 A6 Juan España Sevilla 915869028 6 A7 Lucia España LuciaPerez@hotmail.com 7 A8 Pedro Italia Roma Pedro99@gmail.com 910007890 8 A9 Sergio United States New York sergio_as@gmail.com 9 A10 Grecia Peru Lima Grecia89@gmail.com 10 A11 Ismael España Madrid Isma98@gmail.com 912234543 11 A12 Luis España Murcia Luismiguel123@gmail.com 12 A13 Pedro Argentina Buenos Aires Pedro120@gmail.com Now we are going to create two additional tables: ProfesorID = pd.Series([&#39;P1&#39;, &#39;P2&#39;, &#39;P3&#39;, &#39;P4&#39;, &#39;P5&#39;, &#39;P6&#39;, &#39;P7&#39;]) Nombre = pd.Series([&#39;Juan&#39;, &#39;Sonia&#39;, &#39;Lucia&#39;, &#39;Marcos&#39;, &#39;Carlos&#39;, &#39;Daniel&#39;, &#39;Garazi&#39;]) Estudios = pd.Series([&#39;Matemáticas&#39;, &#39;Física&#39;, &#39;Lengua&#39;, &#39;Biología&#39;, &#39;Educación Física&#39;, &#39;Geografía&#39;, &#39;Inglés&#39;]) Email = pd.Series([&#39;JuanPerez@colegio.es&#39;,&#39;SoniDiaz@colegio.es&#39;,&#39;LuciaPerez@colegio.es&#39;,&#39;MarcosSanz@colegio.es&#39;,&#39;CarlosFernandez@colegio.es&#39;, &#39;DanielOrtiz@colegio.es&#39;, &#39;GaraziGarcia@colegio.es&#39;]) Profesores = pd.DataFrame({&#39;ProfesorID&#39;: ProfesorID, &#39;Nombre&#39;: Nombre, &#39;Estudios&#39;:Estudios , &#39;Email&#39;:Email}) Profesores ProfesorID Nombre Estudios Email 0 P1 Juan Matemáticas JuanPerez@colegio.es 1 P2 Sonia Física SoniDiaz@colegio.es 2 P3 Lucia Lengua LuciaPerez@colegio.es 3 P4 Marcos Biología MarcosSanz@colegio.es 4 P5 Carlos Educación Física CarlosFernandez@colegio.es 5 P6 Daniel Geografía DanielOrtiz@colegio.es 6 P7 Garazi Inglés GaraziGarcia@colegio.es ExamenId = pd.Series([&#39;E1&#39;, &#39;E2&#39;, &#39;E3&#39;, &#39;E4&#39;, &#39;E5&#39;]) Nota = pd.Series([6.7, 8, 4.25, 6.5, 7]) Asignatura = pd.Series([&#39;Matemáticas&#39;, &#39;Física&#39;, &#39;Matemáticas&#39;, &#39;Inglés&#39;, &#39;Lengua&#39;]) AlumnoID = pd.Series([&#39;A2&#39;,&#39;A4&#39;,&#39;A1&#39;,&#39;A7&#39;, &#39;A9&#39;]) ProfesorID = pd.Series([&#39;P1&#39;, &#39;P2&#39;, &#39;P1&#39;, &#39;P7&#39;, &#39;P3&#39;]) Examenes = pd.DataFrame({&#39;ExamenId&#39;: ExamenId, &#39;Nota&#39;: Nota, &#39;Asignatura&#39;:Asignatura , &#39;AlumnoID&#39;:AlumnoID, &#39;ProfesorID&#39;:ProfesorID}) Examenes ExamenId Nota Asignatura AlumnoID ProfesorID 0 E1 6.7 Matemáticas A2 P1 1 E2 8.0 Física A4 P2 2 E3 4.25 Matemáticas A1 P1 3 E4 6.5 Inglés A7 P7 4 E5 7.0 Lengua A9 P3 "],["import-a-csv-as-a-table.html", "Chapter 3 Import a CSV as a table", " Chapter 3 Import a CSV as a table The most common way to work is not to manually create a data frame, as we saw in the previous section. Instead, we often import CSV as data frames. House_Price_Data = pd.read_csv(&#39;House_Price_Regression.csv&#39;) House_Price_Data neighborhood_recode latitude longitude price no_of_bedrooms no_of_bathrooms quality_recode maid_room_recode unfurnished_recode balcony_recode … private_garden_recode private_gym_recode private_jacuzzi_recode private_pool_recode security_recode shared_gym_recode shared_pool_recode shared_spa_recode view_of_water_recode size_in_m_2 0 46.0 25.113208 55.138932 2700000 1 2 2.0 0.0 0.0 1.0 … 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0 100.242337 1 46.0 25.106809 55.151201 2850000 2 2 2.0 0.0 0.0 1.0 … 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 1.0 146.972546 2 36.0 25.063302 55.137728 1150000 3 5 2.0 1.0 1.0 1.0 … 0.0 0.0 1.0 0.0 1.0 1.0 1.0 0.0 1.0 181.253753 3 11.0 25.227295 55.341761 2850000 2 3 1.0 0.0 1.0 1.0 … 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 187.664060 4 46.0 25.114275 55.139764 1729200 0 1 2.0 0.0 0.0 0.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 47.101821 … … … … … … … … … … … … … … … … … … … … … … 1900 42.0 25.176892 55.310712 1500000 2 2 3.0 0.0 1.0 1.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 100.985561 1901 42.0 25.166145 55.276684 1230000 1 2 2.0 0.0 0.0 1.0 … 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 1.0 70.606280 1902 16.0 25.206500 55.345056 2900000 3 5 2.0 1.0 1.0 1.0 … 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 179.302790 1903 37.0 25.073858 55.229844 675000 1 2 2.0 0.0 1.0 1.0 … 1.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 1.0 68.748220 1904 36.0 25.079130 55.154713 760887 1 2 0.0 0.0 0.0 1.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 74.322400 1905 rows × 29 columns "],["export-a-csv.html", "Chapter 4 Export a CSV", " Chapter 4 Export a CSV We can also export a data-frame as CSV as follows: # data_frame.to_csv(&#39;filename.csv&#39;, index=False) "],["number-of-rows-and-columns.html", "Chapter 5 Number of rows and columns", " Chapter 5 Number of rows and columns We can get the number of rows and columns of a data-frame: House_Price_Data.shape (1905, 29) The number of rows: House_Price_Data.shape[0] 1905 Another way to get the number of rows: len(House_Price_Data) 1905 The number of columns: House_Price_Data.shape[1] 29 "],["head-y-tail.html", "Chapter 6 Head y Tail", " Chapter 6 Head y Tail We can also view the first rows of a data-frame using head() method: House_Price_Data.head() neighborhood_recode latitude longitude price no_of_bedrooms no_of_bathrooms quality_recode maid_room_recode unfurnished_recode balcony_recode … private_garden_recode private_gym_recode private_jacuzzi_recode private_pool_recode security_recode shared_gym_recode shared_pool_recode shared_spa_recode view_of_water_recode size_in_m_2 0 46.0 25.113208 55.138932 2700000 1 2 2.0 0.0 0.0 1.0 … 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0 100.242337 1 46.0 25.106809 55.151201 2850000 2 2 2.0 0.0 0.0 1.0 … 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 1.0 146.972546 2 36.0 25.063302 55.137728 1150000 3 5 2.0 1.0 1.0 1.0 … 0.0 0.0 1.0 0.0 1.0 1.0 1.0 0.0 1.0 181.253753 3 11.0 25.227295 55.341761 2850000 2 3 1.0 0.0 1.0 1.0 … 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 187.664060 4 46.0 25.114275 55.139764 1729200 0 1 2.0 0.0 0.0 0.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 47.101821 5 rows × 29 columns House_Price_Data.head(10) neighborhood_recode latitude longitude price no_of_bedrooms no_of_bathrooms quality_recode maid_room_recode unfurnished_recode balcony_recode … private_garden_recode private_gym_recode private_jacuzzi_recode private_pool_recode security_recode shared_gym_recode shared_pool_recode shared_spa_recode view_of_water_recode size_in_m_2 0 46.0 25.113208 55.138932 2700000 1 2 2.0 0.0 0.0 1.0 … 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0 100.242337 1 46.0 25.106809 55.151201 2850000 2 2 2.0 0.0 0.0 1.0 … 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 1.0 146.972546 2 36.0 25.063302 55.137728 1150000 3 5 2.0 1.0 1.0 1.0 … 0.0 0.0 1.0 0.0 1.0 1.0 1.0 0.0 1.0 181.253753 3 11.0 25.227295 55.341761 2850000 2 3 1.0 0.0 1.0 1.0 … 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 187.664060 4 46.0 25.114275 55.139764 1729200 0 1 2.0 0.0 0.0 0.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 47.101821 5 46.0 25.114275 55.139764 3119900 1 2 2.0 0.0 0.0 0.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 94.296545 6 46.0 25.114275 55.139764 8503600 2 3 0.0 1.0 0.0 0.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 191.565986 7 46.0 25.114275 55.139764 3119900 1 2 2.0 0.0 0.0 0.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 94.296545 8 46.0 25.106668 55.149275 2100000 3 3 1.0 0.0 0.0 0.0 … 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 203.085958 9 15.0 25.194935 55.282665 2690000 2 3 2.0 0.0 0.0 1.0 … 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 1.0 141.305463 10 rows × 29 columns We can also view the last rows of a data-frame using tail() method: House_Price_Data.tail() neighborhood_recode latitude longitude price no_of_bedrooms no_of_bathrooms quality_recode maid_room_recode unfurnished_recode balcony_recode … private_garden_recode private_gym_recode private_jacuzzi_recode private_pool_recode security_recode shared_gym_recode shared_pool_recode shared_spa_recode view_of_water_recode size_in_m_2 1900 42.0 25.176892 55.310712 1500000 2 2 3.0 0.0 1.0 1.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 100.985561 1901 42.0 25.166145 55.276684 1230000 1 2 2.0 0.0 0.0 1.0 … 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 1.0 70.606280 1902 16.0 25.206500 55.345056 2900000 3 5 2.0 1.0 1.0 1.0 … 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 179.302790 1903 37.0 25.073858 55.229844 675000 1 2 2.0 0.0 1.0 1.0 … 1.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 1.0 68.748220 1904 36.0 25.079130 55.154713 760887 1 2 0.0 0.0 0.0 1.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 74.322400 5 rows × 29 columns House_Price_Data.tail(7) neighborhood_recode latitude longitude price no_of_bedrooms no_of_bathrooms quality_recode maid_room_recode unfurnished_recode balcony_recode … private_garden_recode private_gym_recode private_jacuzzi_recode private_pool_recode security_recode shared_gym_recode shared_pool_recode shared_spa_recode view_of_water_recode size_in_m_2 1898 46.0 25.104330 55.148769 2700000 1 2 2.0 0.0 1.0 1.0 … 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 1.0 99.963628 1899 27.0 25.037477 55.221942 550000 1 2 2.0 0.0 1.0 1.0 … 0.0 0.0 0.0 1.0 0.0 1.0 1.0 0.0 0.0 78.688841 1900 42.0 25.176892 55.310712 1500000 2 2 3.0 0.0 1.0 1.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 100.985561 1901 42.0 25.166145 55.276684 1230000 1 2 2.0 0.0 0.0 1.0 … 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 1.0 70.606280 1902 16.0 25.206500 55.345056 2900000 3 5 2.0 1.0 1.0 1.0 … 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 179.302790 1903 37.0 25.073858 55.229844 675000 1 2 2.0 0.0 1.0 1.0 … 1.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 1.0 68.748220 1904 36.0 25.079130 55.154713 760887 1 2 0.0 0.0 0.0 1.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 74.322400 7 rows × 29 columns "],["column-names.html", "Chapter 7 Column Names", " Chapter 7 Column Names We can get the column names of a data-frame: House_Price_Data.columns Index([&#39;neighborhood_recode&#39;, &#39;latitude&#39;, &#39;longitude&#39;, &#39;price&#39;, &#39;no_of_bedrooms&#39;, &#39;no_of_bathrooms&#39;, &#39;quality_recode&#39;, &#39;maid_room_recode&#39;, &#39;unfurnished_recode&#39;, &#39;balcony_recode&#39;, &#39;barbecue_area_recode&#39;, &#39;central_ac_recode&#39;, &#39;childrens_play_area_recode&#39;, &#39;childrens_pool_recode&#39;, &#39;concierge_recode&#39;, &#39;covered_parking_recode&#39;, &#39;kitchen_appliances_recode&#39;, &#39;maid_service_recode&#39;, &#39;pets_allowed_recode&#39;, &#39;private_garden_recode&#39;, &#39;private_gym_recode&#39;, &#39;private_jacuzzi_recode&#39;, &#39;private_pool_recode&#39;, &#39;security_recode&#39;, &#39;shared_gym_recode&#39;, &#39;shared_pool_recode&#39;, &#39;shared_spa_recode&#39;, &#39;view_of_water_recode&#39;, &#39;size_in_m_2&#39;], dtype=&#39;object&#39;) "],["selecting-columns-from-a-data-frame.html", "Chapter 8 Selecting columns from a data-frame 8.1 loc method 8.2 iloc method", " Chapter 8 Selecting columns from a data-frame 8.1 loc method With loc method we can select rows from a data-frame using the column names: House_Price_Data.loc[ : , [&#39;latitude&#39;, &#39;price&#39;, &#39;no_of_bathrooms&#39;, &#39;quality_recode&#39;, &#39;balcony_recode&#39;]] latitude price no_of_bathrooms quality_recode balcony_recode 0 25.1132 2700000 2 2 1 1 25.1068 2850000 2 2 1 2 25.0633 1150000 5 2 1 3 25.2273 2850000 3 1 1 4 25.1143 1729200 1 2 0 … … … … … … 1900 25.1769 1500000 2 3 1 1901 25.1661 1230000 2 2 1 1902 25.2065 2900000 5 2 1 1903 25.0739 675000 2 2 1 1904 25.0791 760887 2 0 1 8.2 iloc method With iloc method we can select columns from a data-frame using the index of the columns: House_Price_Data.iloc[ : , 0:6] neighborhood_recode latitude longitude price no_of_bedrooms no_of_bathrooms 0 46.0 25.113208 55.138932 2700000 1 2 1 46.0 25.106809 55.151201 2850000 2 2 2 36.0 25.063302 55.137728 1150000 3 5 3 11.0 25.227295 55.341761 2850000 2 3 4 46.0 25.114275 55.139764 1729200 0 1 … … … … … … … 1900 42.0 25.176892 55.310712 1500000 2 2 1901 42.0 25.166145 55.276684 1230000 1 2 1902 16.0 25.206500 55.345056 2900000 3 5 1903 37.0 25.073858 55.229844 675000 1 2 1904 36.0 25.079130 55.154713 760887 1 2 1905 rows × 6 columns House_Price_Data.iloc[ : , [0,3,5]] neighborhood_recode price no_of_bathrooms 0 46 2700000 2 1 46 2850000 2 2 36 1150000 5 3 11 2850000 3 4 46 1729200 1 .. … … … 1900 42 1500000 2 1901 42 1230000 2 1902 16 2900000 5 1903 37 675000 2 1904 36 760887 2 "],["filter-rows-of-a-data-frame.html", "Chapter 9 Filter rows of a data-frame 9.1 loc method 9.2 iloc method", " Chapter 9 Filter rows of a data-frame 9.1 loc method With loc method we can filter rows that meet a condition related to their values for some columns: House_Price_Data.loc[ House_Price_Data.price &lt; 500000 , : ] neighborhood_recode latitude longitude price no_of_bedrooms no_of_bathrooms quality_recode maid_room_recode unfurnished_recode balcony_recode … private_garden_recode private_gym_recode private_jacuzzi_recode private_pool_recode security_recode shared_gym_recode shared_pool_recode shared_spa_recode view_of_water_recode size_in_m_2 49 12.0 25.016736 55.251010 365000 0 1 2.0 0.0 1.0 1.0 … 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 0.0 41.899253 55 36.0 25.065736 55.137452 375000 0 1 2.0 0.0 1.0 1.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 1.0 41.806350 146 27.0 25.044572 55.218948 390000 1 2 2.0 0.0 0.0 1.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 78.874647 160 27.0 25.042264 55.217360 410000 1 2 2.0 0.0 1.0 1.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 90.023007 194 38.0 25.043352 55.193510 310000 0 1 1.0 0.0 1.0 1.0 … 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 39.483775 … … … … … … … … … … … … … … … … … … … … … … 1848 24.0 25.091311 55.378277 270000 0 1 1.0 0.0 1.0 1.0 … 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 0.0 42.735380 1849 36.0 25.071246 55.140806 499000 1 1 2.0 0.0 1.0 1.0 … 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 0.0 62.430816 1857 36.0 25.078148 55.148277 400888 0 1 2.0 0.0 0.0 1.0 … 0.0 0.0 1.0 0.0 0.0 1.0 1.0 0.0 0.0 37.439909 1874 50.0 25.003730 55.297034 488888 1 2 2.0 0.0 1.0 1.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 64.846294 1897 4.0 25.153080 55.254242 360000 0 1 2.0 0.0 0.0 1.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 55.741800 114 rows × 29 columns House_Price_Data.loc[ House_Price_Data.price &lt;= 1000000 , : ] neighborhood_recode latitude longitude price no_of_bedrooms no_of_bathrooms quality_recode maid_room_recode unfurnished_recode balcony_recode … private_garden_recode private_gym_recode private_jacuzzi_recode private_pool_recode security_recode shared_gym_recode shared_pool_recode shared_spa_recode view_of_water_recode size_in_m_2 19 9.0 25.180301 55.263892 950000 1 2 2.0 0.0 1.0 1.0 … 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 1.0 83.055282 34 6.0 25.060310 55.241403 750000 1 1 0.0 0.0 1.0 1.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 73.950788 35 6.0 25.060310 55.241403 991000 2 2 0.0 0.0 1.0 1.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 107.953286 49 12.0 25.016736 55.251010 365000 0 1 2.0 0.0 1.0 1.0 … 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 0.0 41.899253 55 36.0 25.065736 55.137452 375000 0 1 2.0 0.0 1.0 1.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 1.0 41.806350 … … … … … … … … … … … … … … … … … … … … … … 1894 15.0 25.191107 55.269910 980888 1 1 2.0 0.0 1.0 1.0 … 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 0.0 101.078464 1897 4.0 25.153080 55.254242 360000 0 1 2.0 0.0 0.0 1.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 55.741800 1899 27.0 25.037477 55.221942 550000 1 2 2.0 0.0 1.0 1.0 … 0.0 0.0 0.0 1.0 0.0 1.0 1.0 0.0 0.0 78.688841 1903 37.0 25.073858 55.229844 675000 1 2 2.0 0.0 1.0 1.0 … 1.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 1.0 68.748220 1904 36.0 25.079130 55.154713 760887 1 2 0.0 0.0 0.0 1.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 74.322400 591 rows × 29 columns House_Price_Data.loc[ House_Price_Data.price &gt; 1000000 , : ] neighborhood_recode latitude longitude price no_of_bedrooms no_of_bathrooms quality_recode maid_room_recode unfurnished_recode balcony_recode … private_garden_recode private_gym_recode private_jacuzzi_recode private_pool_recode security_recode shared_gym_recode shared_pool_recode shared_spa_recode view_of_water_recode size_in_m_2 0 46.0 25.113208 55.138932 2700000 1 2 2.0 0.0 0.0 1.0 … 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0 100.242337 1 46.0 25.106809 55.151201 2850000 2 2 2.0 0.0 0.0 1.0 … 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 1.0 146.972546 2 36.0 25.063302 55.137728 1150000 3 5 2.0 1.0 1.0 1.0 … 0.0 0.0 1.0 0.0 1.0 1.0 1.0 0.0 1.0 181.253753 3 11.0 25.227295 55.341761 2850000 2 3 1.0 0.0 1.0 1.0 … 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 187.664060 4 46.0 25.114275 55.139764 1729200 0 1 2.0 0.0 0.0 0.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 47.101821 … … … … … … … … … … … … … … … … … … … … … … 1896 15.0 25.196489 55.272126 18040888 4 4 2.0 1.0 1.0 1.0 … 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 0.0 488.019459 1898 46.0 25.104330 55.148769 2700000 1 2 2.0 0.0 1.0 1.0 … 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 1.0 99.963628 1900 42.0 25.176892 55.310712 1500000 2 2 3.0 0.0 1.0 1.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 100.985561 1901 42.0 25.166145 55.276684 1230000 1 2 2.0 0.0 0.0 1.0 … 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 1.0 70.606280 1902 16.0 25.206500 55.345056 2900000 3 5 2.0 1.0 1.0 1.0 … 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 179.302790 1314 rows × 29 columns House_Price_Data.loc[ House_Price_Data.no_of_bedrooms == 2 , : ] neighborhood_recode latitude longitude price no_of_bedrooms no_of_bathrooms quality_recode maid_room_recode unfurnished_recode balcony_recode … private_garden_recode private_gym_recode private_jacuzzi_recode private_pool_recode security_recode shared_gym_recode shared_pool_recode shared_spa_recode view_of_water_recode size_in_m_2 1 46.0 25.106809 55.151201 2850000 2 2 2.0 0.0 0.0 1.0 … 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 1.0 146.972546 3 11.0 25.227295 55.341761 2850000 2 3 1.0 0.0 1.0 1.0 … 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 187.664060 6 46.0 25.114275 55.139764 8503600 2 3 0.0 1.0 0.0 0.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 191.565986 9 15.0 25.194935 55.282665 2690000 2 3 2.0 0.0 0.0 1.0 … 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 1.0 141.305463 11 22.0 25.075017 55.137997 2094999 2 3 1.0 0.0 1.0 1.0 … 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 0.0 98.291374 … … … … … … … … … … … … … … … … … … … … … … 1881 49.0 25.088903 55.171065 1850000 2 2 2.0 0.0 1.0 1.0 … 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 0.0 130.064200 1882 22.0 25.080542 55.140343 2090000 2 2 2.0 0.0 1.0 1.0 … 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 1.0 98.570083 1884 34.0 25.072569 55.126527 3300000 2 3 1.0 0.0 1.0 0.0 … 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 109.625540 1895 22.0 25.081243 55.145120 1350000 2 4 1.0 0.0 0.0 0.0 … 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 146.600934 1900 42.0 25.176892 55.310712 1500000 2 2 3.0 0.0 1.0 1.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 100.985561 729 rows × 29 columns House_Price_Data.loc[ House_Price_Data.no_of_bedrooms != 2 , : ] neighborhood_recode latitude longitude price no_of_bedrooms no_of_bathrooms quality_recode maid_room_recode unfurnished_recode balcony_recode … private_garden_recode private_gym_recode private_jacuzzi_recode private_pool_recode security_recode shared_gym_recode shared_pool_recode shared_spa_recode view_of_water_recode size_in_m_2 0 46.0 25.113208 55.138932 2700000 1 2 2.0 0.0 0.0 1.0 … 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0 100.242337 2 36.0 25.063302 55.137728 1150000 3 5 2.0 1.0 1.0 1.0 … 0.0 0.0 1.0 0.0 1.0 1.0 1.0 0.0 1.0 181.253753 4 46.0 25.114275 55.139764 1729200 0 1 2.0 0.0 0.0 0.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 47.101821 5 46.0 25.114275 55.139764 3119900 1 2 2.0 0.0 0.0 0.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 94.296545 7 46.0 25.114275 55.139764 3119900 1 2 2.0 0.0 0.0 0.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 94.296545 … … … … … … … … … … … … … … … … … … … … … … 1899 27.0 25.037477 55.221942 550000 1 2 2.0 0.0 1.0 1.0 … 0.0 0.0 0.0 1.0 0.0 1.0 1.0 0.0 0.0 78.688841 1901 42.0 25.166145 55.276684 1230000 1 2 2.0 0.0 0.0 1.0 … 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 1.0 70.606280 1902 16.0 25.206500 55.345056 2900000 3 5 2.0 1.0 1.0 1.0 … 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 179.302790 1903 37.0 25.073858 55.229844 675000 1 2 2.0 0.0 1.0 1.0 … 1.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 1.0 68.748220 1904 36.0 25.079130 55.154713 760887 1 2 0.0 0.0 0.0 1.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 74.322400 1176 rows × 29 columns House_Price_Data.loc[ House_Price_Data[&#39;no_of_bedrooms&#39;] != 2 , : ] neighborhood_recode latitude longitude price no_of_bedrooms no_of_bathrooms quality_recode maid_room_recode unfurnished_recode balcony_recode … private_garden_recode private_gym_recode private_jacuzzi_recode private_pool_recode security_recode shared_gym_recode shared_pool_recode shared_spa_recode view_of_water_recode size_in_m_2 0 46.0 25.113208 55.138932 2700000 1 2 2.0 0.0 0.0 1.0 … 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0 100.242337 2 36.0 25.063302 55.137728 1150000 3 5 2.0 1.0 1.0 1.0 … 0.0 0.0 1.0 0.0 1.0 1.0 1.0 0.0 1.0 181.253753 4 46.0 25.114275 55.139764 1729200 0 1 2.0 0.0 0.0 0.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 47.101821 5 46.0 25.114275 55.139764 3119900 1 2 2.0 0.0 0.0 0.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 94.296545 7 46.0 25.114275 55.139764 3119900 1 2 2.0 0.0 0.0 0.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 94.296545 … … … … … … … … … … … … … … … … … … … … … … 1899 27.0 25.037477 55.221942 550000 1 2 2.0 0.0 1.0 1.0 … 0.0 0.0 0.0 1.0 0.0 1.0 1.0 0.0 0.0 78.688841 1901 42.0 25.166145 55.276684 1230000 1 2 2.0 0.0 0.0 1.0 … 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 1.0 70.606280 1902 16.0 25.206500 55.345056 2900000 3 5 2.0 1.0 1.0 1.0 … 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 179.302790 1903 37.0 25.073858 55.229844 675000 1 2 2.0 0.0 1.0 1.0 … 1.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 1.0 68.748220 1904 36.0 25.079130 55.154713 760887 1 2 0.0 0.0 0.0 1.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 74.322400 1176 rows × 29 columns We can use isin() method to filter rows that have a value for some column that belongs to a specific set of values. House_Price_Data.loc[ House_Price_Data[&#39;no_of_bedrooms&#39;].isin([2,4]) , : ] neighborhood_recode latitude longitude price no_of_bedrooms no_of_bathrooms quality_recode maid_room_recode unfurnished_recode balcony_recode … private_garden_recode private_gym_recode private_jacuzzi_recode private_pool_recode security_recode shared_gym_recode shared_pool_recode shared_spa_recode view_of_water_recode size_in_m_2 1 46.0 25.106809 55.151201 2850000 2 2 2.0 0.0 0.0 1.0 … 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 1.0 146.972546 3 11.0 25.227295 55.341761 2850000 2 3 1.0 0.0 1.0 1.0 … 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 187.664060 6 46.0 25.114275 55.139764 8503600 2 3 0.0 1.0 0.0 0.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 191.565986 9 15.0 25.194935 55.282665 2690000 2 3 2.0 0.0 0.0 1.0 … 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 1.0 141.305463 11 22.0 25.075017 55.137997 2094999 2 3 1.0 0.0 1.0 1.0 … 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 0.0 98.291374 … … … … … … … … … … … … … … … … … … … … … … 1885 46.0 25.103972 55.149621 31440000 4 6 0.0 1.0 0.0 1.0 … 0.0 0.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 607.771426 1891 11.0 25.226946 55.343628 7000000 4 6 1.0 0.0 0.0 0.0 … 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 377.929404 1895 22.0 25.081243 55.145120 1350000 2 4 1.0 0.0 0.0 0.0 … 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 146.600934 1896 15.0 25.196489 55.272126 18040888 4 4 2.0 1.0 1.0 1.0 … 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 0.0 488.019459 1900 42.0 25.176892 55.310712 1500000 2 2 3.0 0.0 1.0 1.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 100.985561 799 rows × 29 columns We can also use isin() method to filter out rows that have a value for a certain column that doesn’t belong to a specific set of values. House_Price_Data.loc[ House_Price_Data[&#39;no_of_bedrooms&#39;].isin([2,4]) == False , : ] neighborhood_recode latitude longitude price no_of_bedrooms no_of_bathrooms quality_recode maid_room_recode unfurnished_recode balcony_recode … private_garden_recode private_gym_recode private_jacuzzi_recode private_pool_recode security_recode shared_gym_recode shared_pool_recode shared_spa_recode view_of_water_recode size_in_m_2 0 46.0 25.113208 55.138932 2700000 1 2 2.0 0.0 0.0 1.0 … 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0 100.242337 2 36.0 25.063302 55.137728 1150000 3 5 2.0 1.0 1.0 1.0 … 0.0 0.0 1.0 0.0 1.0 1.0 1.0 0.0 1.0 181.253753 4 46.0 25.114275 55.139764 1729200 0 1 2.0 0.0 0.0 0.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 47.101821 5 46.0 25.114275 55.139764 3119900 1 2 2.0 0.0 0.0 0.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 94.296545 7 46.0 25.114275 55.139764 3119900 1 2 2.0 0.0 0.0 0.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 94.296545 … … … … … … … … … … … … … … … … … … … … … … 1899 27.0 25.037477 55.221942 550000 1 2 2.0 0.0 1.0 1.0 … 0.0 0.0 0.0 1.0 0.0 1.0 1.0 0.0 0.0 78.688841 1901 42.0 25.166145 55.276684 1230000 1 2 2.0 0.0 0.0 1.0 … 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 1.0 70.606280 1902 16.0 25.206500 55.345056 2900000 3 5 2.0 1.0 1.0 1.0 … 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 179.302790 1903 37.0 25.073858 55.229844 675000 1 2 2.0 0.0 1.0 1.0 … 1.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 1.0 68.748220 1904 36.0 25.079130 55.154713 760887 1 2 0.0 0.0 0.0 1.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 74.322400 1106 rows × 29 columns House_Price_Data.loc[ ( (House_Price_Data.price &gt; 1000000) &amp; (House_Price_Data.no_of_bedrooms &gt; 2 ) ) | House_Price_Data.quality_recode == 0 , : ] neighborhood_recode latitude longitude price no_of_bedrooms no_of_bathrooms quality_recode maid_room_recode unfurnished_recode balcony_recode … private_garden_recode private_gym_recode private_jacuzzi_recode private_pool_recode security_recode shared_gym_recode shared_pool_recode shared_spa_recode view_of_water_recode size_in_m_2 6 46.0 25.114275 55.139764 8503600 2 3 0.0 1.0 0.0 0.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 191.565986 34 6.0 25.060310 55.241403 750000 1 1 0.0 0.0 1.0 1.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 73.950788 35 6.0 25.060310 55.241403 991000 2 2 0.0 0.0 1.0 1.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 107.953286 80 37.0 25.066791 55.203684 714000 1 1 0.0 0.0 1.0 1.0 … 1.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 68.004996 90 15.0 25.197316 55.274196 2100000 1 1 0.0 0.0 0.0 0.0 … 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 1.0 105.444905 … … … … … … … … … … … … … … … … … … … … … … 1829 37.0 25.066252 55.207929 370000 0 1 0.0 0.0 1.0 1.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 34.559916 1838 36.0 25.079130 55.154713 400888 0 1 0.0 0.0 0.0 1.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 38.554745 1839 36.0 25.079130 55.154713 400888 0 1 0.0 0.0 0.0 1.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 38.554745 1841 34.0 25.076319 55.133627 1500000 1 2 0.0 0.0 0.0 1.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 1.0 98.291374 1904 36.0 25.079130 55.154713 760887 1 2 0.0 0.0 0.0 1.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 74.322400 95 rows × 29 columns We can also filter rows and select columns at the same time using the loc method: House_Price_Data.loc[ House_Price_Data.price &gt; 1000000 , [&#39;price&#39;, &#39;no_of_bedrooms&#39;, &#39;quality_recode&#39;] ] price no_of_bedrooms quality_recode 0 2700000 1 2 1 2850000 2 2 2 1150000 3 2 3 2850000 2 1 4 1729200 0 2 … … … … 1896 18040888 4 2 1898 2700000 1 2 1900 1500000 2 3 1901 1230000 1 2 1902 2900000 3 2 9.2 iloc method With iloc method we can filter rows using the index of those rows: House_Price_Data.iloc[15:120 , :] neighborhood_recode latitude longitude price no_of_bedrooms no_of_bathrooms quality_recode maid_room_recode unfurnished_recode balcony_recode … private_garden_recode private_gym_recode private_jacuzzi_recode private_pool_recode security_recode shared_gym_recode shared_pool_recode shared_spa_recode view_of_water_recode size_in_m_2 15 46.0 25.132021 55.151405 2349990 1 1 2.0 0.0 0.0 1.0 … 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 1.0 103.029427 16 46.0 25.132021 55.151405 3499000 2 2 2.0 0.0 1.0 1.0 … 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 1.0 151.710599 17 15.0 25.198316 55.270758 2700000 2 3 2.0 0.0 1.0 1.0 … 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 125.233244 18 15.0 25.197020 55.271023 1490000 2 2 2.0 0.0 0.0 1.0 … 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 0.0 108.417801 19 9.0 25.180301 55.263892 950000 1 2 2.0 0.0 1.0 1.0 … 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 1.0 83.055282 … … … … … … … … … … … … … … … … … … … … … … 115 15.0 25.196398 55.271002 2100000 2 3 2.0 0.0 1.0 1.0 … 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 0.0 125.790662 116 15.0 25.191753 55.272818 1400000 1 2 1.0 0.0 1.0 1.0 … 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 79.896580 117 45.0 25.189554 55.273783 2300000 2 3 1.0 0.0 1.0 0.0 … 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 124.304214 118 9.0 25.185823 55.291922 2300000 2 3 2.0 0.0 0.0 1.0 … 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 0.0 133.966126 119 49.0 25.090953 55.169542 1335000 2 2 1.0 0.0 0.0 0.0 … 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 124.118408 105 rows × 29 columns House_Price_Data.iloc[[6,10,15] , :] neighborhood_recode latitude longitude price no_of_bedrooms no_of_bathrooms quality_recode maid_room_recode unfurnished_recode balcony_recode … private_garden_recode private_gym_recode private_jacuzzi_recode private_pool_recode security_recode shared_gym_recode shared_pool_recode shared_spa_recode view_of_water_recode size_in_m_2 6 46.0 25.114275 55.139764 8503600 2 3 0.0 1.0 0.0 0.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 191.565986 10 15.0 25.198796 55.271342 3550000 3 4 1.0 0.0 1.0 1.0 … 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 1.0 178.187954 15 46.0 25.132021 55.151405 2349990 1 1 2.0 0.0 0.0 1.0 … 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 1.0 103.029427 3 rows × 29 columns We can filter rows and select columns at the same time using the iloc method as follows: House_Price_Data.iloc[3:15 , 2:5] longitude price no_of_bedrooms 3 55.341761 2850000 2 4 55.139764 1729200 0 5 55.139764 3119900 1 6 55.139764 8503600 2 7 55.139764 3119900 1 8 55.149275 2100000 3 9 55.282665 2690000 2 10 55.271342 3550000 3 11 55.137997 2094999 2 12 55.137997 1049999 1 13 55.151574 1849000 1 14 55.152216 2089999 1 House_Price_Data.iloc[[3,5,6] , [2,8]] longitude unfurnished_recode 3 55.3418 1 5 55.1398 0 6 55.1398 0 "],["traspose-a-data-frame.html", "Chapter 10 Traspose a data-frame", " Chapter 10 Traspose a data-frame We can traspose a data-frame using T method: House_Price_Data.T 0 1 2 3 4 5 6 7 8 9 … 1895 1896 1897 1898 1899 1900 1901 1902 1903 1904 neighborhood_recode 4.600000e+01 4.600000e+01 3.600000e+01 1.100000e+01 4.600000e+01 4.600000e+01 4.600000e+01 4.600000e+01 4.600000e+01 1.500000e+01 … 2.200000e+01 1.500000e+01 4.000000 4.600000e+01 27.000000 4.200000e+01 4.200000e+01 1.600000e+01 37.000000 36.000000 latitude 2.511321e+01 2.510681e+01 2.506330e+01 2.522730e+01 2.511427e+01 2.511427e+01 2.511427e+01 2.511427e+01 2.510667e+01 2.519494e+01 … 2.508124e+01 2.519649e+01 25.153080 2.510433e+01 25.037477 2.517689e+01 2.516615e+01 2.520650e+01 25.073858 25.079130 longitude 5.513893e+01 5.515120e+01 5.513773e+01 5.534176e+01 5.513976e+01 5.513976e+01 5.513976e+01 5.513976e+01 5.514928e+01 5.528267e+01 … 5.514512e+01 5.527213e+01 55.254242 5.514877e+01 55.221942 5.531071e+01 5.527668e+01 5.534506e+01 55.229844 55.154713 price 2.700000e+06 2.850000e+06 1.150000e+06 2.850000e+06 1.729200e+06 3.119900e+06 8.503600e+06 3.119900e+06 2.100000e+06 2.690000e+06 … 1.350000e+06 1.804089e+07 360000.000000 2.700000e+06 550000.000000 1.500000e+06 1.230000e+06 2.900000e+06 675000.000000 760887.000000 no_of_bedrooms 1.000000e+00 2.000000e+00 3.000000e+00 2.000000e+00 0.000000e+00 1.000000e+00 2.000000e+00 1.000000e+00 3.000000e+00 2.000000e+00 … 2.000000e+00 4.000000e+00 0.000000 1.000000e+00 1.000000 2.000000e+00 1.000000e+00 3.000000e+00 1.000000 1.000000 no_of_bathrooms 2.000000e+00 2.000000e+00 5.000000e+00 3.000000e+00 1.000000e+00 2.000000e+00 3.000000e+00 2.000000e+00 3.000000e+00 3.000000e+00 … 4.000000e+00 4.000000e+00 1.000000 2.000000e+00 2.000000 2.000000e+00 2.000000e+00 5.000000e+00 2.000000 2.000000 quality_recode 2.000000e+00 2.000000e+00 2.000000e+00 1.000000e+00 2.000000e+00 2.000000e+00 0.000000e+00 2.000000e+00 1.000000e+00 2.000000e+00 … 1.000000e+00 2.000000e+00 2.000000 2.000000e+00 2.000000 3.000000e+00 2.000000e+00 2.000000e+00 2.000000 0.000000 maid_room_recode 0.000000e+00 0.000000e+00 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 … 0.000000e+00 1.000000e+00 0.000000 0.000000e+00 0.000000 0.000000e+00 0.000000e+00 1.000000e+00 0.000000 0.000000 unfurnished_recode 0.000000e+00 0.000000e+00 1.000000e+00 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 … 0.000000e+00 1.000000e+00 0.000000 1.000000e+00 1.000000 1.000000e+00 0.000000e+00 1.000000e+00 1.000000 0.000000 balcony_recode 1.000000e+00 1.000000e+00 1.000000e+00 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 1.000000e+00 … 0.000000e+00 1.000000e+00 1.000000 1.000000e+00 1.000000 1.000000e+00 1.000000e+00 1.000000e+00 1.000000 1.000000 barbecue_area_recode 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 … 0.000000e+00 0.000000e+00 0.000000 0.000000e+00 0.000000 1.000000e+00 0.000000e+00 0.000000e+00 0.000000 1.000000 central_ac_recode 1.000000e+00 1.000000e+00 0.000000e+00 0.000000e+00 1.000000e+00 1.000000e+00 1.000000e+00 1.000000e+00 0.000000e+00 1.000000e+00 … 0.000000e+00 1.000000e+00 1.000000 0.000000e+00 1.000000 1.000000e+00 1.000000e+00 1.000000e+00 1.000000 1.000000 childrens_play_area_recode 1.000000e+00 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 … 0.000000e+00 1.000000e+00 0.000000 0.000000e+00 0.000000 1.000000e+00 1.000000e+00 1.000000e+00 1.000000 1.000000 childrens_pool_recode 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 … 0.000000e+00 0.000000e+00 0.000000 0.000000e+00 0.000000 1.000000e+00 0.000000e+00 0.000000e+00 0.000000 1.000000 concierge_recode 1.000000e+00 0.000000e+00 0.000000e+00 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 … 0.000000e+00 0.000000e+00 0.000000 0.000000e+00 1.000000 1.000000e+00 1.000000e+00 0.000000e+00 0.000000 1.000000 covered_parking_recode 0.000000e+00 0.000000e+00 1.000000e+00 1.000000e+00 1.000000e+00 1.000000e+00 1.000000e+00 1.000000e+00 0.000000e+00 1.000000e+00 … 0.000000e+00 0.000000e+00 1.000000 1.000000e+00 1.000000 1.000000e+00 0.000000e+00 0.000000e+00 1.000000 1.000000 kitchen_appliances_recode 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 1.000000e+00 1.000000e+00 1.000000e+00 1.000000e+00 0.000000e+00 1.000000e+00 … 0.000000e+00 0.000000e+00 0.000000 1.000000e+00 0.000000 1.000000e+00 1.000000e+00 0.000000e+00 1.000000 1.000000 maid_service_recode 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 … 0.000000e+00 0.000000e+00 0.000000 0.000000e+00 0.000000 1.000000e+00 0.000000e+00 0.000000e+00 0.000000 0.000000 pets_allowed_recode 1.000000e+00 0.000000e+00 0.000000e+00 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 … 0.000000e+00 0.000000e+00 1.000000 0.000000e+00 1.000000 1.000000e+00 0.000000e+00 1.000000e+00 0.000000 0.000000 private_garden_recode 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 … 0.000000e+00 0.000000e+00 0.000000 0.000000e+00 0.000000 0.000000e+00 0.000000e+00 0.000000e+00 1.000000 0.000000 private_gym_recode 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 … 0.000000e+00 0.000000e+00 0.000000 0.000000e+00 0.000000 0.000000e+00 0.000000e+00 0.000000e+00 0.000000 0.000000 private_jacuzzi_recode 0.000000e+00 0.000000e+00 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 … 0.000000e+00 0.000000e+00 0.000000 0.000000e+00 0.000000 0.000000e+00 0.000000e+00 0.000000e+00 0.000000 0.000000 private_pool_recode 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 … 0.000000e+00 0.000000e+00 0.000000 0.000000e+00 1.000000 0.000000e+00 0.000000e+00 0.000000e+00 0.000000 0.000000 security_recode 0.000000e+00 0.000000e+00 1.000000e+00 0.000000e+00 1.000000e+00 1.000000e+00 1.000000e+00 1.000000e+00 0.000000e+00 0.000000e+00 … 0.000000e+00 0.000000e+00 1.000000 0.000000e+00 0.000000 1.000000e+00 0.000000e+00 0.000000e+00 1.000000 1.000000 shared_gym_recode 1.000000e+00 1.000000e+00 1.000000e+00 0.000000e+00 1.000000e+00 1.000000e+00 1.000000e+00 1.000000e+00 0.000000e+00 1.000000e+00 … 0.000000e+00 1.000000e+00 1.000000 1.000000e+00 1.000000 1.000000e+00 1.000000e+00 0.000000e+00 1.000000 1.000000 shared_pool_recode 0.000000e+00 1.000000e+00 1.000000e+00 0.000000e+00 1.000000e+00 1.000000e+00 1.000000e+00 1.000000e+00 0.000000e+00 1.000000e+00 … 0.000000e+00 1.000000e+00 1.000000 1.000000e+00 1.000000 1.000000e+00 1.000000e+00 1.000000e+00 1.000000 1.000000 shared_spa_recode 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 1.000000e+00 1.000000e+00 1.000000e+00 1.000000e+00 0.000000e+00 0.000000e+00 … 0.000000e+00 0.000000e+00 0.000000 0.000000e+00 0.000000 1.000000e+00 0.000000e+00 0.000000e+00 0.000000 1.000000 view_of_water_recode 1.000000e+00 1.000000e+00 1.000000e+00 0.000000e+00 1.000000e+00 1.000000e+00 1.000000e+00 1.000000e+00 0.000000e+00 1.000000e+00 … 0.000000e+00 0.000000e+00 0.000000 1.000000e+00 0.000000 1.000000e+00 1.000000e+00 0.000000e+00 1.000000 1.000000 size_in_m_2 1.002423e+02 1.469725e+02 1.812538e+02 1.876641e+02 4.710182e+01 9.429654e+01 1.915660e+02 9.429654e+01 2.030860e+02 1.413055e+02 … 1.466009e+02 4.880195e+02 55.741800 9.996363e+01 78.688841 1.009856e+02 7.060628e+01 1.793028e+02 68.748220 74.322400 29 rows × 1905 columns "],["data-frame-to-numpy.html", "Chapter 11 Data-frame to numpy", " Chapter 11 Data-frame to numpy We can convert a pandas data-frame to a numpy array using to_numpy() method: House_Price_Data.to_numpy() array([[ 46. , 25.113208, 55.138932, ..., 0. , 1. , 100.242337], [ 46. , 25.106809, 55.151201, ..., 0. , 1. , 146.972546], [ 36. , 25.063302, 55.137728, ..., 0. , 1. , 181.253753], ..., [ 16. , 25.2065 , 55.345056, ..., 0. , 0. , 179.30279 ], [ 37. , 25.073858, 55.229844, ..., 0. , 1. , 68.74822 ], [ 36. , 25.07913 , 55.154713, ..., 1. , 1. , 74.3224 ]]) "],["delete-columns-from-a-data-frame.html", "Chapter 12 Delete columns from a data-frame", " Chapter 12 Delete columns from a data-frame House_Price_Data.drop([&#39;price&#39;], axis=1) neighborhood_recode latitude longitude no_of_bedrooms no_of_bathrooms quality_recode maid_room_recode unfurnished_recode balcony_recode barbecue_area_recode … private_garden_recode private_gym_recode private_jacuzzi_recode private_pool_recode security_recode shared_gym_recode shared_pool_recode shared_spa_recode view_of_water_recode size_in_m_2 0 46.0 25.113208 55.138932 1 2 2.0 0.0 0.0 1.0 1.0 … 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0 100.242337 1 46.0 25.106809 55.151201 2 2 2.0 0.0 0.0 1.0 0.0 … 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 1.0 146.972546 2 36.0 25.063302 55.137728 3 5 2.0 1.0 1.0 1.0 0.0 … 0.0 0.0 1.0 0.0 1.0 1.0 1.0 0.0 1.0 181.253753 3 11.0 25.227295 55.341761 2 3 1.0 0.0 1.0 1.0 0.0 … 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 187.664060 4 46.0 25.114275 55.139764 0 1 2.0 0.0 0.0 0.0 0.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 47.101821 … … … … … … … … … … … … … … … … … … … … … … 1900 42.0 25.176892 55.310712 2 2 3.0 0.0 1.0 1.0 1.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 100.985561 1901 42.0 25.166145 55.276684 1 2 2.0 0.0 0.0 1.0 0.0 … 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 1.0 70.606280 1902 16.0 25.206500 55.345056 3 5 2.0 1.0 1.0 1.0 0.0 … 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 179.302790 1903 37.0 25.073858 55.229844 1 2 2.0 0.0 1.0 1.0 0.0 … 1.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 1.0 68.748220 1904 36.0 25.079130 55.154713 1 2 0.0 0.0 0.0 1.0 1.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 74.322400 1905 rows × 28 columns House_Price_Data.drop([&#39;price&#39;, &#39;longitude&#39;], axis=1) neighborhood_recode latitude no_of_bedrooms no_of_bathrooms quality_recode maid_room_recode unfurnished_recode balcony_recode barbecue_area_recode central_ac_recode … private_garden_recode private_gym_recode private_jacuzzi_recode private_pool_recode security_recode shared_gym_recode shared_pool_recode shared_spa_recode view_of_water_recode size_in_m_2 0 46.0 25.113208 1 2 2.0 0.0 0.0 1.0 1.0 1.0 … 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0 100.242337 1 46.0 25.106809 2 2 2.0 0.0 0.0 1.0 0.0 1.0 … 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 1.0 146.972546 2 36.0 25.063302 3 5 2.0 1.0 1.0 1.0 0.0 0.0 … 0.0 0.0 1.0 0.0 1.0 1.0 1.0 0.0 1.0 181.253753 3 11.0 25.227295 2 3 1.0 0.0 1.0 1.0 0.0 0.0 … 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 187.664060 4 46.0 25.114275 0 1 2.0 0.0 0.0 0.0 0.0 1.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 47.101821 … … … … … … … … … … … … … … … … … … … … … … 1900 42.0 25.176892 2 2 3.0 0.0 1.0 1.0 1.0 1.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 100.985561 1901 42.0 25.166145 1 2 2.0 0.0 0.0 1.0 0.0 1.0 … 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 1.0 70.606280 1902 16.0 25.206500 3 5 2.0 1.0 1.0 1.0 0.0 1.0 … 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 179.302790 1903 37.0 25.073858 1 2 2.0 0.0 1.0 1.0 0.0 1.0 … 1.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 1.0 68.748220 1904 36.0 25.079130 1 2 0.0 0.0 0.0 1.0 1.0 1.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 74.322400 1905 rows × 27 columns "],["delete-rows-from-a-data-frame.html", "Chapter 13 Delete rows from a data-frame", " Chapter 13 Delete rows from a data-frame House_Price_Data.drop(3, axis=0) neighborhood_recode latitude longitude price no_of_bedrooms no_of_bathrooms quality_recode maid_room_recode unfurnished_recode balcony_recode … private_garden_recode private_gym_recode private_jacuzzi_recode private_pool_recode security_recode shared_gym_recode shared_pool_recode shared_spa_recode view_of_water_recode size_in_m_2 0 46.0 25.113208 55.138932 2700000 1 2 2.0 0.0 0.0 1.0 … 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0 100.242337 1 46.0 25.106809 55.151201 2850000 2 2 2.0 0.0 0.0 1.0 … 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 1.0 146.972546 2 36.0 25.063302 55.137728 1150000 3 5 2.0 1.0 1.0 1.0 … 0.0 0.0 1.0 0.0 1.0 1.0 1.0 0.0 1.0 181.253753 4 46.0 25.114275 55.139764 1729200 0 1 2.0 0.0 0.0 0.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 47.101821 5 46.0 25.114275 55.139764 3119900 1 2 2.0 0.0 0.0 0.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 94.296545 … … … … … … … … … … … … … … … … … … … … … … 1900 42.0 25.176892 55.310712 1500000 2 2 3.0 0.0 1.0 1.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 100.985561 1901 42.0 25.166145 55.276684 1230000 1 2 2.0 0.0 0.0 1.0 … 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 1.0 70.606280 1902 16.0 25.206500 55.345056 2900000 3 5 2.0 1.0 1.0 1.0 … 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 179.302790 1903 37.0 25.073858 55.229844 675000 1 2 2.0 0.0 1.0 1.0 … 1.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 1.0 68.748220 1904 36.0 25.079130 55.154713 760887 1 2 0.0 0.0 0.0 1.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 74.322400 1904 rows × 29 columns House_Price_Data.drop([2,3,1900], axis=0) neighborhood_recode latitude longitude price no_of_bedrooms no_of_bathrooms quality_recode maid_room_recode unfurnished_recode balcony_recode … private_garden_recode private_gym_recode private_jacuzzi_recode private_pool_recode security_recode shared_gym_recode shared_pool_recode shared_spa_recode view_of_water_recode size_in_m_2 0 46.0 25.113208 55.138932 2700000 1 2 2.0 0.0 0.0 1.0 … 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0 100.242337 1 46.0 25.106809 55.151201 2850000 2 2 2.0 0.0 0.0 1.0 … 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 1.0 146.972546 4 46.0 25.114275 55.139764 1729200 0 1 2.0 0.0 0.0 0.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 47.101821 5 46.0 25.114275 55.139764 3119900 1 2 2.0 0.0 0.0 0.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 94.296545 6 46.0 25.114275 55.139764 8503600 2 3 0.0 1.0 0.0 0.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 191.565986 … … … … … … … … … … … … … … … … … … … … … … 1899 27.0 25.037477 55.221942 550000 1 2 2.0 0.0 1.0 1.0 … 0.0 0.0 0.0 1.0 0.0 1.0 1.0 0.0 0.0 78.688841 1901 42.0 25.166145 55.276684 1230000 1 2 2.0 0.0 0.0 1.0 … 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 1.0 70.606280 1902 16.0 25.206500 55.345056 2900000 3 5 2.0 1.0 1.0 1.0 … 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 179.302790 1903 37.0 25.073858 55.229844 675000 1 2 2.0 0.0 1.0 1.0 … 1.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 1.0 68.748220 1904 36.0 25.079130 55.154713 760887 1 2 0.0 0.0 0.0 1.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 74.322400 1902 rows × 29 columns "],["rename-columns-from-a-data-frame.html", "Chapter 14 Rename columns from a data-frame", " Chapter 14 Rename columns from a data-frame We can rename columns from a data-frame by several ways. For one thing, we can create a new data frame the same as the original, but with different names for some of its columns: House_Price_Data.rename(columns={&#39;neighborhood_recode&#39; : &#39;neighborhood&#39;}) neighborhood latitude longitude price no_of_bedrooms no_of_bathrooms quality_recode maid_room_recode unfurnished_recode balcony_recode … private_garden_recode private_gym_recode private_jacuzzi_recode private_pool_recode security_recode shared_gym_recode shared_pool_recode shared_spa_recode view_of_water_recode size_in_m_2 0 46.0 25.113208 55.138932 2700000 1 2 2.0 0.0 0.0 1.0 … 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0 100.242337 1 46.0 25.106809 55.151201 2850000 2 2 2.0 0.0 0.0 1.0 … 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 1.0 146.972546 2 36.0 25.063302 55.137728 1150000 3 5 2.0 1.0 1.0 1.0 … 0.0 0.0 1.0 0.0 1.0 1.0 1.0 0.0 1.0 181.253753 3 11.0 25.227295 55.341761 2850000 2 3 1.0 0.0 1.0 1.0 … 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 187.664060 4 46.0 25.114275 55.139764 1729200 0 1 2.0 0.0 0.0 0.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 47.101821 … … … … … … … … … … … … … … … … … … … … … … 1900 42.0 25.176892 55.310712 1500000 2 2 3.0 0.0 1.0 1.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 100.985561 1901 42.0 25.166145 55.276684 1230000 1 2 2.0 0.0 0.0 1.0 … 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 1.0 70.606280 1902 16.0 25.206500 55.345056 2900000 3 5 2.0 1.0 1.0 1.0 … 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 179.302790 1903 37.0 25.073858 55.229844 675000 1 2 2.0 0.0 1.0 1.0 … 1.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 1.0 68.748220 1904 36.0 25.079130 55.154713 760887 1 2 0.0 0.0 0.0 1.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 74.322400 1905 rows × 29 columns On the other hand, we can rename specific columns of a data-frame without the need to create a new additional data-frame setting the inplace parameter to True: House_Price_Data.rename(columns={&#39;neighborhood_recode&#39; : &#39;neighborhood&#39;}, inplace=True) "],["group-by.html", "Chapter 15 Group by", " Chapter 15 Group by We can group the rows of the data frame by the values in one column and then compute within each group a statistic from some of the other columns: House_Price_Data.groupby(&#39;quality_recode&#39;).sum() neighborhood_recode latitude longitude price no_of_bedrooms no_of_bathrooms maid_room_recode unfurnished_recode balcony_recode barbecue_area_recode … private_garden_recode private_gym_recode private_jacuzzi_recode private_pool_recode security_recode shared_gym_recode shared_pool_recode shared_spa_recode view_of_water_recode size_in_m_2 quality_recode 0.0 3733.0 3364.807548 7397.947955 360303131 259 356 48.0 80.0 127.0 50.0 … 9.0 5.0 20.0 14.0 116.0 131.0 129.0 51.0 88.0 19662.548338 1.0 14463.0 13665.847174 30036.819722 1054059587 964 1351 10.0 223.0 140.0 4.0 … 2.0 1.0 5.0 5.0 15.0 87.0 151.0 2.0 36.0 70533.072436 2.0 30586.0 28786.683374 63272.825114 2484669505 2063 2876 163.0 887.0 1023.0 134.0 … 20.0 8.0 71.0 62.0 460.0 959.0 1043.0 62.0 452.0 152492.563551 3.0 2896.0 2029.667054 4471.911678 74473686 130 204 54.0 32.0 81.0 81.0 … 1.0 1.0 1.0 1.0 80.0 81.0 81.0 79.0 78.0 8101.699018 4 rows × 28 columns House_Price_Data.groupby(&#39;quality_recode&#39;)[&#39;price&#39;].sum() quality_recode 0.0 360303131 1.0 1054059587 2.0 2484669505 3.0 74473686 Name: price, dtype: int64 House_Price_Data.groupby(&#39;quality_recode&#39;)[&#39;price&#39;].mean() quality_recode 0.0 2.688829e+06 1.0 1.937610e+06 2.0 2.168123e+06 3.0 9.194282e+05 Name: price, dtype: float64 House_Price_Data.groupby(&#39;quality_recode&#39;)[&#39;price&#39;].median() quality_recode 0.0 1400103.0 1.0 1465444.0 2.0 1470388.5 3.0 759502.0 Name: price, dtype: float64 House_Price_Data.groupby(&#39;quality_recode&#39;)[&#39;price&#39;].std() quality_recode 0.0 4.852033e+06 1.0 2.307412e+06 2.0 2.947205e+06 3.0 3.950463e+05 Name: price, dtype: float64 House_Price_Data.groupby([&#39;quality_recode&#39;, &#39;private_garden_recode&#39;])[&#39;price&#39;].mean() quality_recode private_garden_recode 0.0 0.0 2.530969e+06 1.0 4.881333e+06 1.0 0.0 1.932034e+06 1.0 3.448444e+06 2.0 0.0 2.162129e+06 1.0 2.505600e+06 3.0 0.0 9.213461e+05 1.0 7.660000e+05 Name: price, dtype: float64 import numpy as np House_Price_Data.groupby(&#39;quality_recode&#39;)[&#39;price&#39;].agg([np.min, np.max, np.median, np.sum, np.std]) quality_recode amin amax median sum std 0.0 360000 34340000 1400103 360303131 4.852033e+06 1.0 220000 35000000 1465444 1054059587 2.307412e+06 2.0 230000 34314000 1470388.5 2484669505 2.947205e+06 3.0 440500 2551888 759502 74473686 3.950463e+05 "],["concat-data-frames.html", "Chapter 16 Concat data-frames 16.1 Concat by columns 16.2 Concat by rows", " Chapter 16 Concat data-frames We can concat data-frames using concat() method. First, we are going to remember the Alumnos, Profesoresand Examenes data-frames, because we are going to use them in this section: Alumnos AlumnoID Nombre Pais Ciudad Email Telefono 0 A1 Orlando Australia 917755028 1 A2 Keith India keith0@adventure-works.com 2 A3 Donna Germany Berlin donna0@adventure-works.com 915547890 3 A4 Janet United States California janet1@adventure-works.com 4 A5 Fabio España Madrid fabio10@gmail.com 5 A6 Juan España Sevilla 915869028 6 A7 Lucia España LuciaPerez@hotmail.com 7 A8 Pedro Italia Roma Pedro99@gmail.com 910007890 8 A9 Sergio United States New York sergio_as@gmail.com 9 A10 Grecia Peru Lima Grecia89@gmail.com 10 A11 Ismael España Madrid Isma98@gmail.com 912234543 11 A12 Luis España Murcia Luismiguel123@gmail.com 12 A13 Pedro Argentina Buenos Aires Pedro120@gmail.com Profesores ProfesorID Nombre Estudios Email 0 P1 Juan Matemáticas JuanPerez@colegio.es 1 P2 Sonia Física SoniDiaz@colegio.es 2 P3 Lucia Lengua LuciaPerez@colegio.es 3 P4 Marcos Biología MarcosSanz@colegio.es 4 P5 Carlos Educación Física CarlosFernandez@colegio.es 5 P6 Daniel Geografía DanielOrtiz@colegio.es 6 P7 Garazi Inglés GaraziGarcia@colegio.es Examenes ExamenId Nota Asignatura AlumnoID ProfesorID 0 E1 6.70 Matemáticas A2 P1 1 E2 8.00 Física A4 P2 2 E3 4.25 Matemáticas A1 P1 3 E4 6.50 Inglés A7 P7 4 E5 7.00 Lengua A9 P3 from pandas import concat There are several ways to apply the concat method to a pair of data frames, each one giving different results. Let’s see some of them. 16.1 Concat by columns concat([Profesores,Alumnos], axis=1) ProfesorID Nombre Estudios Email AlumnoID Nombre Pais Ciudad Email Telefono 0 P1 Juan Matemáticas JuanPerez@colegio.es A1 Orlando Australia 917755028 1 P2 Sonia Física SoniDiaz@colegio.es A2 Keith India keith0@adventure-works.com 2 P3 Lucia Lengua LuciaPerez@colegio.es A3 Donna Germany Berlin donna0@adventure-works.com 915547890 3 P4 Marcos Biología MarcosSanz@colegio.es A4 Janet United States California janet1@adventure-works.com 4 P5 Carlos Educación Física CarlosFernandez@colegio.es A5 Fabio España Madrid fabio10@gmail.com 5 P6 Daniel Geografía DanielOrtiz@colegio.es A6 Juan España Sevilla 915869028 6 P7 Garazi Inglés GaraziGarcia@colegio.es A7 Lucia España LuciaPerez@hotmail.com 7 NaN NaN NaN NaN A8 Pedro Italia Roma Pedro99@gmail.com 910007890 8 NaN NaN NaN NaN A9 Sergio United States New York sergio_as@gmail.com 9 NaN NaN NaN NaN A10 Grecia Peru Lima Grecia89@gmail.com 10 NaN NaN NaN NaN A11 Ismael España Madrid Isma98@gmail.com 912234543 11 NaN NaN NaN NaN A12 Luis España Murcia Luismiguel123@gmail.com 12 NaN NaN NaN NaN A13 Pedro Argentina Buenos Aires Pedro120@gmail.com 16.2 Concat by rows concat([Profesores,Alumnos], axis=0) ProfesorID Nombre Estudios Email AlumnoID Pais Ciudad Telefono 0 P1 Juan Matemáticas JuanPerez@colegio.es NaN NaN NaN NaN 1 P2 Sonia Física SoniDiaz@colegio.es NaN NaN NaN NaN 2 P3 Lucia Lengua LuciaPerez@colegio.es NaN NaN NaN NaN 3 P4 Marcos Biología MarcosSanz@colegio.es NaN NaN NaN NaN 4 P5 Carlos Educación Física CarlosFernandez@colegio.es NaN NaN NaN NaN 5 P6 Daniel Geografía DanielOrtiz@colegio.es NaN NaN NaN NaN 6 P7 Garazi Inglés GaraziGarcia@colegio.es NaN NaN NaN NaN 0 NaN Orlando NaN A1 Australia 917755028 1 NaN Keith NaN keith0@adventure-works.com A2 India 2 NaN Donna NaN donna0@adventure-works.com A3 Germany Berlin 915547890 3 NaN Janet NaN janet1@adventure-works.com A4 United States California 4 NaN Fabio NaN fabio10@gmail.com A5 España Madrid 5 NaN Juan NaN A6 España Sevilla 915869028 6 NaN Lucia NaN LuciaPerez@hotmail.com A7 España 7 NaN Pedro NaN Pedro99@gmail.com A8 Italia Roma 910007890 8 NaN Sergio NaN sergio_as@gmail.com A9 United States New York 9 NaN Grecia NaN Grecia89@gmail.com A10 Peru Lima 10 NaN Ismael NaN Isma98@gmail.com A11 España Madrid 912234543 11 NaN Luis NaN Luismiguel123@gmail.com A12 España Murcia 12 NaN Pedro NaN Pedro120@gmail.com A13 Argentina Buenos Aires We create two new data-frames that will have the same column names, to show how concat( , index=0) works in this case: X1 = pd.Series([ 2 , 4 , 3, 35, 23 ]) X2 = pd.Series([10, 12, 3, 3, -13]) X3 = pd.Series([22, 33, 1, 5, -3]) X4 = pd.Series([52, 2, 23, 6, -5]) X5 = pd.Series([ 22 , 34 , 13, 35, 23 ]) X6 = pd.Series([10, 12, 32, 30, -13]) X7 = pd.Series([22, 33, 1, 56, -13]) X8 = pd.Series([5, 12, 2, 66, -5]) df1 = pd.DataFrame( {&quot;X1&quot;: X1 , &quot;X2&quot;: X2 , &quot;X3&quot;: X3 , &quot;X4&quot;: X4} ) df2 = pd.DataFrame( {&quot;X1&quot;: X5 , &quot;X2&quot;: X6 , &quot;X3&quot;: X7 , &quot;X4&quot;: X8} ) df1 X1 X2 X3 X4 0 2 10 22 52 1 4 12 33 2 2 3 3 1 23 3 35 3 5 6 4 23 -13 -3 -5 df2 X1 X2 X3 X4 0 22 10 22 5 1 34 12 33 12 2 13 32 1 2 3 35 30 56 66 4 23 -13 -13 -5 concat([df1,df2] , axis=0) X1 X2 X3 X4 0 2 10 22 52 1 4 12 33 2 2 3 3 1 23 3 35 3 5 6 4 23 -13 -3 -5 0 22 10 22 5 1 34 12 33 12 2 13 32 1 2 3 35 30 56 66 4 23 -13 -13 -5 concat([df1,df2] , axis=1) X1 X2 X3 X4 X1 X2 X3 X4 0 2 10 22 52 22 10 22 5 1 4 12 33 2 34 12 33 12 2 3 3 1 23 13 32 1 2 3 35 3 5 6 35 30 56 66 4 23 -13 -3 -5 23 -13 -13 -5 "],["join-data-frames-using-merge.html", "Chapter 17 Join data-frames using merge 17.1 Inner Join 17.2 Outer Join 17.3 Left Join 17.4 Right Join", " Chapter 17 Join data-frames using merge 17.1 Inner Join The inner join operation applied to two data frames \\(\\hspace{0.01cm}DF_1\\hspace{0.01cm}\\) and \\(\\hspace{0.01cm}DF_2\\hspace{0.01cm}\\) produces another data frame consisting of the union of the rows of \\(DF_1\\) and \\(DF_2\\) that share the same value in the link column (share linking value). pd.merge(Examenes, Alumnos, on=&#39;AlumnoID&#39;, how=&#39;inner&#39;) # equivalent to inner join ExamenId Nota Asignatura AlumnoID ProfesorID Nombre Pais Ciudad Email Telefono 0 E1 6.70 Matemáticas A2 P1 Keith India keith0@adventure-works.com 1 E2 8.00 Física A4 P2 Janet United States California janet1@adventure-works.com 2 E3 4.25 Matemáticas A1 P1 Orlando Australia 917755028 3 E4 6.50 Inglés A7 P7 Lucia España LuciaPerez@hotmail.com 4 E5 7.00 Lengua A9 P3 Sergio United States New York sergio_as@gmail.com pd.merge(Examenes, Profesores, on=&#39;ProfesorID&#39;, how=&#39;inner&#39;) # equivalent to inner join ExamenId Nota Asignatura AlumnoID ProfesorID Nombre Estudios Email 0 E1 6.70 Matemáticas A2 P1 Juan Matemáticas JuanPerez@colegio.es 1 E3 4.25 Matemáticas A1 P1 Juan Matemáticas JuanPerez@colegio.es 2 E2 8.00 Física A4 P2 Sonia Física SoniDiaz@colegio.es 3 E4 6.50 Inglés A7 P7 Garazi Inglés GaraziGarcia@colegio.es 4 E5 7.00 Lengua A9 P3 Lucia Lengua LuciaPerez@colegio.es Observation: The correct way to use merge when the names of link columns are different is: # df_merge = pd.merge(df1, df2, left_on=&#39;id1&#39; , right_on=&#39;id2&#39;, how=&#39;inner&#39;) 17.2 Outer Join The outer join operation applied to two data frames \\(\\hspace{0.01cm}DF_1\\hspace{0.01cm}\\) and \\(\\hspace{0.01cm}DF_2\\hspace{0.01cm}\\) produces the same data frame of inner join, but adding the rows from \\(DF_1\\) that don’t share linking value with any row from \\(DF_2\\), and the rows from \\(DF_2\\) that don’t share linking value with any row form \\(DF_1\\). pd.merge(Examenes, Alumnos, on=&#39;AlumnoID&#39;, how=&#39;outer&#39;) # equivalent to outer join ExamenId Nota Asignatura AlumnoID ProfesorID Nombre Pais Ciudad Email Telefono 0 E1 6.70 Matemáticas A2 P1 Keith India keith0@adventure-works.com 1 E2 8.00 Física A4 P2 Janet United States California janet1@adventure-works.com 2 E3 4.25 Matemáticas A1 P1 Orlando Australia 917755028 3 E4 6.50 Inglés A7 P7 Lucia España LuciaPerez@hotmail.com 4 E5 7.00 Lengua A9 P3 Sergio United States New York sergio_as@gmail.com 5 NaN NaN NaN A3 NaN Donna Germany Berlin donna0@adventure-works.com 915547890 6 NaN NaN NaN A5 NaN Fabio España Madrid fabio10@gmail.com 7 NaN NaN NaN A6 NaN Juan España Sevilla 915869028 8 NaN NaN NaN A8 NaN Pedro Italia Roma Pedro99@gmail.com 910007890 9 NaN NaN NaN A10 NaN Grecia Peru Lima Grecia89@gmail.com 10 NaN NaN NaN A11 NaN Ismael España Madrid Isma98@gmail.com 912234543 11 NaN NaN NaN A12 NaN Luis España Murcia Luismiguel123@gmail.com 12 NaN NaN NaN A13 NaN Pedro Argentina Buenos Aires Pedro120@gmail.com pd.merge(Examenes, Profesores, on=&#39;ProfesorID&#39;, how=&#39;outer&#39;) # equivalent to outer join ExamenId Nota Asignatura AlumnoID ProfesorID Nombre Estudios Email 0 E1 6.70 Matemáticas A2 P1 Juan Matemáticas JuanPerez@colegio.es 1 E3 4.25 Matemáticas A1 P1 Juan Matemáticas JuanPerez@colegio.es 2 E2 8.00 Física A4 P2 Sonia Física SoniDiaz@colegio.es 3 E4 6.50 Inglés A7 P7 Garazi Inglés GaraziGarcia@colegio.es 4 E5 7.00 Lengua A9 P3 Lucia Lengua LuciaPerez@colegio.es 5 NaN NaN NaN NaN P4 Marcos Biología MarcosSanz@colegio.es 6 NaN NaN NaN NaN P5 Carlos Educación Física CarlosFernandez@colegio.es 7 NaN NaN NaN NaN P6 Daniel Geografía DanielOrtiz@colegio.es 17.3 Left Join The left join operation applied to two data frames \\(\\hspace{0.01cm}DF_1\\hspace{0.01cm}\\) and \\(\\hspace{0.01cm}DF_2\\hspace{0.01cm}\\) produces another data frame consisting of the rows of \\(DF_1\\) and \\(DF_2\\) that share link value, and the rest rows of \\(DF_1\\). pd.merge(Examenes, Alumnos, on=&#39;AlumnoID&#39;, how=&#39;left&#39;) # equivalent to left join ExamenId Nota Asignatura AlumnoID ProfesorID Nombre Pais Ciudad Email Telefono 0 E1 6.70 Matemáticas A2 P1 Keith India keith0@adventure-works.com 1 E2 8.00 Física A4 P2 Janet United States California janet1@adventure-works.com 2 E3 4.25 Matemáticas A1 P1 Orlando Australia 917755028 3 E4 6.50 Inglés A7 P7 Lucia España LuciaPerez@hotmail.com 4 E5 7.00 Lengua A9 P3 Sergio United States New York sergio_as@gmail.com pd.merge(Alumnos, Examenes, on=&#39;AlumnoID&#39;, how=&#39;left&#39;) # equivalent to left join AlumnoID Nombre Pais Ciudad Email Telefono ExamenId Nota Asignatura ProfesorID 0 A1 Orlando Australia 917755028 E3 4.25 Matemáticas P1 1 A2 Keith India keith0@adventure-works.com E1 6.70 Matemáticas P1 2 A3 Donna Germany Berlin donna0@adventure-works.com 915547890 NaN NaN NaN NaN 3 A4 Janet United States California janet1@adventure-works.com E2 8.00 Física P2 4 A5 Fabio España Madrid fabio10@gmail.com NaN NaN NaN NaN 5 A6 Juan España Sevilla 915869028 NaN NaN NaN NaN 6 A7 Lucia España LuciaPerez@hotmail.com E4 6.50 Inglés P7 7 A8 Pedro Italia Roma Pedro99@gmail.com 910007890 NaN NaN NaN NaN 8 A9 Sergio United States New York sergio_as@gmail.com E5 7.00 Lengua P3 9 A10 Grecia Peru Lima Grecia89@gmail.com NaN NaN NaN NaN 10 A11 Ismael España Madrid Isma98@gmail.com 912234543 NaN NaN NaN NaN 11 A12 Luis España Murcia Luismiguel123@gmail.com NaN NaN NaN NaN 12 A13 Pedro Argentina Buenos Aires Pedro120@gmail.com NaN NaN NaN NaN 17.4 Right Join The right join operation applied to two data frames \\(\\hspace{0.01cm}DF_1\\hspace{0.01cm}\\) and \\(\\hspace{0.01cm}DF_2\\hspace{0.01cm}\\) produces another data frame consisting of the rows of \\(DF_1\\) and \\(DF_2\\) that share link value, and the rest rows of \\(DF_2\\). pd.merge(Examenes, Alumnos, on=&#39;AlumnoID&#39;, how=&#39;right&#39;) # equivalent to right join ExamenId Nota Asignatura AlumnoID ProfesorID Nombre Pais Ciudad Email Telefono 0 E3 4.25 Matemáticas A1 P1 Orlando Australia 917755028 1 E1 6.70 Matemáticas A2 P1 Keith India keith0@adventure-works.com 2 NaN NaN NaN A3 NaN Donna Germany Berlin donna0@adventure-works.com 915547890 3 E2 8.00 Física A4 P2 Janet United States California janet1@adventure-works.com 4 NaN NaN NaN A5 NaN Fabio España Madrid fabio10@gmail.com 5 NaN NaN NaN A6 NaN Juan España Sevilla 915869028 6 E4 6.50 Inglés A7 P7 Lucia España LuciaPerez@hotmail.com 7 NaN NaN NaN A8 NaN Pedro Italia Roma Pedro99@gmail.com 910007890 8 E5 7.00 Lengua A9 P3 Sergio United States New York sergio_as@gmail.com 9 NaN NaN NaN A10 NaN Grecia Peru Lima Grecia89@gmail.com 10 NaN NaN NaN A11 NaN Ismael España Madrid Isma98@gmail.com 912234543 11 NaN NaN NaN A12 NaN Luis España Murcia Luismiguel123@gmail.com 12 NaN NaN NaN A13 NaN Pedro Argentina Buenos Aires Pedro120@gmail.com "],["sorting-columns-from-a-data-frame.html", "Chapter 18 Sorting columns from a data-frame", " Chapter 18 Sorting columns from a data-frame House_Price_Data.sort_values(by=&#39;price&#39;, ascending=True) neighborhood_recode latitude longitude price no_of_bedrooms no_of_bathrooms quality_recode maid_room_recode unfurnished_recode balcony_recode … private_garden_recode private_gym_recode private_jacuzzi_recode private_pool_recode security_recode shared_gym_recode shared_pool_recode shared_spa_recode view_of_water_recode size_in_m_2 1592 31.0 25.173301 55.402315 220000 0 1 1.0 0.0 1.0 1.0 … 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 44.965052 1610 23.0 25.036803 55.200909 230000 0 1 2.0 0.0 0.0 1.0 … 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 1.0 35.303140 1609 23.0 25.036803 55.200909 230000 0 1 2.0 0.0 1.0 1.0 … 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 1.0 33.630886 749 25.0 25.115934 55.390236 245000 0 1 1.0 0.0 0.0 0.0 … 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 28.428318 1499 25.0 25.115934 55.390236 250000 0 1 1.0 0.0 1.0 0.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 32.794759 … … … … … … … … … … … … … … … … … … … … … … 427 9.0 25.188299 55.288975 30950000 4 4 2.0 0.0 1.0 0.0 … 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 0.0 735.977566 1885 46.0 25.103972 55.149621 31440000 4 6 0.0 1.0 0.0 1.0 … 0.0 0.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 607.771426 576 46.0 25.103550 55.168509 34314000 4 5 2.0 0.0 1.0 1.0 … 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 889.639128 1869 46.0 25.103972 55.149621 34340000 4 6 0.0 1.0 0.0 1.0 … 1.0 0.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 810.299966 989 46.0 25.103550 55.168509 35000000 4 5 1.0 0.0 1.0 1.0 … 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 682.465438 1905 rows × 29 columns House_Price_Data.sort_values(by=&#39;price&#39;, ascending=False) neighborhood_recode latitude longitude price no_of_bedrooms no_of_bathrooms quality_recode maid_room_recode unfurnished_recode balcony_recode … private_garden_recode private_gym_recode private_jacuzzi_recode private_pool_recode security_recode shared_gym_recode shared_pool_recode shared_spa_recode view_of_water_recode size_in_m_2 989 46.0 25.103550 55.168509 35000000 4 5 1.0 0.0 1.0 1.0 … 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 682.465438 1869 46.0 25.103972 55.149621 34340000 4 6 0.0 1.0 0.0 1.0 … 1.0 0.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 810.299966 576 46.0 25.103550 55.168509 34314000 4 5 2.0 0.0 1.0 1.0 … 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 889.639128 1885 46.0 25.103972 55.149621 31440000 4 6 0.0 1.0 0.0 1.0 … 0.0 0.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 607.771426 427 9.0 25.188299 55.288975 30950000 4 4 2.0 0.0 1.0 0.0 … 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 0.0 735.977566 … … … … … … … … … … … … … … … … … … … … … … 1499 25.0 25.115934 55.390236 250000 0 1 1.0 0.0 1.0 0.0 … 0.0 0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 32.794759 749 25.0 25.115934 55.390236 245000 0 1 1.0 0.0 0.0 0.0 … 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 28.428318 1609 23.0 25.036803 55.200909 230000 0 1 2.0 0.0 1.0 1.0 … 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 1.0 33.630886 1610 23.0 25.036803 55.200909 230000 0 1 2.0 0.0 0.0 1.0 … 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 1.0 35.303140 1592 31.0 25.173301 55.402315 220000 0 1 1.0 0.0 1.0 1.0 … 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 44.965052 1905 rows × 29 columns "],["bibliography.html", "Chapter 19 Bibliography", " Chapter 19 Bibliography Pandas. 2023. “Pandas: Python Data Analysis Library.” https://pandas.pydata.org/. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
