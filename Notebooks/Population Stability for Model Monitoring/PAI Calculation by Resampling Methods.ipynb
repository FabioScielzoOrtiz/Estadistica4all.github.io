{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing PAI with resampling methods:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In Linear Regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Old Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "\n",
    "# Quantitative Response\n",
    "\n",
    "Y_old = np.random.normal(loc=50, scale=10, size=500)\n",
    "\n",
    "# Quantitative variables \n",
    "\n",
    "X1_old = np.random.normal(loc=30, scale=25, size=500)\n",
    " \n",
    "# Binary variables \n",
    "\n",
    "X2_old = np.random.uniform(low=0.0, high=1.0, size=500).round()\n",
    " \n",
    "# Multiclass categorical variables\n",
    "\n",
    "X3_old = np.random.uniform(low=0, high=4, size=500).round()   # categories: 0,1,2,3,4\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New Data (with a big change in X1 distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(666)\n",
    "\n",
    "# Quantitative Response\n",
    "\n",
    "Y_new = np.random.normal(loc=50, scale=10, size=500)\n",
    "\n",
    "# Quantitative variables \n",
    "\n",
    "X1_new = np.random.normal(loc=15, scale=60, size=500)\n",
    " \n",
    "# Binary variables \n",
    "\n",
    "X2_new = np.random.uniform(low=0.0, high=1.0, size=500).round()\n",
    " \n",
    "# Multiclass categorical variables\n",
    "\n",
    "X3_new = np.random.uniform(low=0, high=4, size=500).round()   # categories: 0,1,2,3,4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Old = pd.DataFrame( {\"Y\":Y_old , \"X1\": X1_old , \"X2\": X2_old , \"X3\": X3_old} ) \n",
    "\n",
    "df_New = pd.DataFrame( {\"Y\":Y_new , \"X1\": X1_new , \"X2\": X2_new , \"X3\": X3_new} ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotnine import ggplot, aes, geom_line, geom_point, geom_histogram, geom_bar, geom_boxplot, scale_y_continuous, scale_x_continuous, labs, after_stat,  geom_vline, scale_color_manual, theme_gray, theme_xkcd, scale_color_identity, geom_hline, facet_wrap, scale_fill_discrete, scale_fill_manual,  scale_fill_hue, guides, guide_legend, ggtitle\n",
    "from mizani.formatters import percent_format "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39.143694</td>\n",
       "      <td>48.800842</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Old Data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>59.973454</td>\n",
       "      <td>31.741019</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Old Data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52.829785</td>\n",
       "      <td>23.363859</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Old Data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34.937053</td>\n",
       "      <td>53.239612</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Old Data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44.213997</td>\n",
       "      <td>61.520532</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Old Data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>56.756956</td>\n",
       "      <td>12.495333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>New Dta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>36.846327</td>\n",
       "      <td>75.862895</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>New Dta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>36.528625</td>\n",
       "      <td>-21.430239</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>New Dta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>62.143112</td>\n",
       "      <td>-56.088634</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>New Dta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>53.433602</td>\n",
       "      <td>10.075296</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>New Dta</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Y         X1   X2   X3     group\n",
       "0    39.143694  48.800842  1.0  1.0  Old Data\n",
       "1    59.973454  31.741019  0.0  3.0  Old Data\n",
       "2    52.829785  23.363859  0.0  4.0  Old Data\n",
       "3    34.937053  53.239612  1.0  1.0  Old Data\n",
       "4    44.213997  61.520532  1.0  3.0  Old Data\n",
       "..         ...        ...  ...  ...       ...\n",
       "495  56.756956  12.495333  0.0  3.0   New Dta\n",
       "496  36.846327  75.862895  1.0  1.0   New Dta\n",
       "497  36.528625 -21.430239  0.0  0.0   New Dta\n",
       "498  62.143112 -56.088634  0.0  2.0   New Dta\n",
       "499  53.433602  10.075296  0.0  3.0   New Dta\n",
       "\n",
       "[1000 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import array as arr\n",
    "\n",
    "df_Old_New = pd.concat([df_Old , df_New])\n",
    "\n",
    "repeat_Old = ['Old Data']*len(df_Old)\n",
    "\n",
    "repeat_New = ['New Dta']*len(df_New)\n",
    "\n",
    "df_repeat_New = pd.DataFrame( {\"group\": repeat_New} ) \n",
    "\n",
    "df_repeat_Old = pd.DataFrame( {\"group\": repeat_Old} ) \n",
    "\n",
    "groups = pd.concat([df_repeat_Old , df_repeat_New])\n",
    "\n",
    "df_Old_New_groups = pd.concat([df_Old_New , groups], axis=1 ) \n",
    "\n",
    "df_Old_New_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<ggplot: (180082525893)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "ggplot( df_Old_New_groups )\n",
    "+  aes(x='X1' , y =  after_stat('width*density'))\n",
    "+ geom_histogram(fill=\"plum\", color=\"black\", bins = 25)\n",
    "+  labs(x = \"X1\", y = \"Relative Frequency\")\n",
    "+ scale_x_continuous( breaks = range(int(df_Old_New_groups['X1'].min()) , int(df_Old_New_groups['X1'].max()) , 50) ) \n",
    "+ scale_y_continuous( breaks = np.arange(0, 0.5, 0.02) )\n",
    "+ facet_wrap('group')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to consider the following definition of PAI (instead of use the variance, we will use the standard deviation. if we would consider the PAI definition with the variance, the process to compute it would have been very similar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where:\n",
    "\n",
    "The numerator is computing using the model trained with the Old Data (for the response and the predictors) but predicting the response variable using the New Data for the predictors.\n",
    "\n",
    "The denominator is computing using the model trained Old Data (for the response and the predictors) and also predicting the response variable using the Old Data for the predictors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \n",
    "\n",
    "PAI = \\dfrac{\\dfrac{1}{N} \\sum_{i \\in NewData} \\widehat{Var}(\\hat{y}_i)}{\\dfrac{1}{n} \\sum_{i \\in OldData} \\widehat{Var}(\\hat{y}_i)}  \n",
    "\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, PAI is the quotient between the mean variance of the response predictions, using the model trained with the Old data but using the New data for the predictors to get the response predictions and the mean variance of the response predictions, using the model trained with the Old data and also using the Old data for the predictors to get the response predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def varcharProcessing(X, varchar_process = \"dummy_dropfirst\"):\n",
    "    \n",
    "    dtypes = X.dtypes\n",
    "\n",
    "    if varchar_process == \"drop\":   \n",
    "        X = X.drop(columns = dtypes[dtypes == np.object].index.tolist())\n",
    "\n",
    "    elif varchar_process == \"dummy\":\n",
    "        X = pd.get_dummies(X,drop_first=False)\n",
    "\n",
    "    elif varchar_process == \"dummy_dropfirst\":\n",
    "        X = pd.get_dummies(X,drop_first=True)\n",
    "\n",
    "    else: \n",
    "        X = pd.get_dummies(X,drop_first=True)\n",
    "    \n",
    "    X[\"intercept\"] = 1\n",
    "    cols = X.columns.tolist()\n",
    "    cols = cols[-1:] + cols[:-1]\n",
    "    X = X[cols]\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Old['X2'] = df_Old['X2'].astype('category')\n",
    "df_Old['X3'] = df_Old['X3'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "B=100\n",
    "\n",
    "y_predictions_Old_Data = np.zeros((B , len(df_Old)))\n",
    "\n",
    "for i in range(0, B):\n",
    "\n",
    "    df_Old_BOOT_SAMPLE = df_Old.sample( n=len(df_Old) , random_state=i , replace=True )    # i-th boot sample\n",
    "\n",
    "    X_old_Boot_Sample = df_Old_BOOT_SAMPLE[['X1', 'X2', 'X3']]\n",
    "\n",
    "    y_old_Boot_Sample = df_Old_BOOT_SAMPLE['Y']\n",
    "\n",
    "    X_old_Boot_Sample = varcharProcessing(X_old_Boot_Sample, varchar_process = \"dummy_dropfirst\")\n",
    "\n",
    "    # We train the model with i-th boot sample of the Old Data:\n",
    "\n",
    "    Model_train_Old_data = LinearRegression().fit(X_old, y_old)\n",
    "\n",
    "    # y predictions using Model_train_Old_data with the original Old Data for the predictors \n",
    "\n",
    "    X_old = df_Old[['X1', 'X2', 'X3']] \n",
    "    \n",
    "    # La idea es que con cda iteracion el modelo cambia (los parametros) ya que ha sido entrenado con diferentes data set (las muestras bootstrap)\n",
    "    # Pero las predicciones se hacen usando siempre el mismo data set (Old Data), para asi asegurar que \\hat{y}_i es siempre la prediccion de la respuesta\n",
    "    # para el i-esimo individuo (cambiarÃ¡ porque al re-entrenar el modelo con las distintas muestras boot cambian los parametros de este, pero no cambia\n",
    "    # el vector x_i de valores de los predictores del individuo i, con los que tambien se genera la prediccion)\n",
    "    # Por tanto si hubiese mucha variavilidad entre los valores obtenidos de \\hat{y}_i = \\hat{\\beta} x_i esto se deberia no a cambios en x_i (puesto que \n",
    "    # en este programa no cambia), si no a cambios en \\hat{\\beta} debidos a las diferentes muestras boot usadas para entrenar el modelo.\n",
    "    # Si en lugar del modelo de regresion lineal multiple usasemos otro de la misma indole (basicamente un modelo que pueda ser entrenado con unos datos\n",
    "    # y pueda realizar predicciones sobre una respuesta usando otros datos), la idea seria la misma. \n",
    "    \n",
    "\n",
    "    y_predictions_Old_Data[i, :] = Model_train_Old_data.predict(X_old)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The $(k , r)$ element of the $nxB$ matrix `y_predictions_Old_Data` is $\\widehat{y_k}$ (the $Y$ estimation for the $k$-th individual of the sample) when the model is trained with the $r$-th boot sample of  `Old_Data_Set` \n",
    "\n",
    "Where: \n",
    "\n",
    "$n =$ len(Old\\_Data\\_Set)\n",
    "\n",
    "$B=$ nÂº of boot samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[49.95603811, 46.17414532, 50.75655999, ..., 50.08960508,\n",
       "        47.83454445, 49.71383292],\n",
       "       [49.59227112, 48.59741738, 48.38773108, ..., 49.51214128,\n",
       "        49.35931264, 49.0558362 ],\n",
       "       [52.74603235, 50.39946487, 49.44548196, ..., 50.757313  ,\n",
       "        50.85265078, 49.1753534 ],\n",
       "       ...,\n",
       "       [49.04014548, 49.32931668, 50.07903142, ..., 51.22241711,\n",
       "        51.33767296, 49.02068145],\n",
       "       [51.03904278, 47.92718562, 48.44246138, ..., 48.33406358,\n",
       "        49.22132319, 48.48471234],\n",
       "       [49.57212401, 50.58200126, 47.89645783, ..., 49.66999826,\n",
       "        49.34546852, 48.03111945]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predictions_Old_Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compute the standard deviation of each column of the matrix , and we get an estimation of $Var(\\hat{y_i})$ for $i=1,...,n$:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, the i-th value of the following vector is $$\\widehat{Var}(\\hat{y_i})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.3736694 , 1.83531851, 1.49999452, 2.02032802, 2.03471412,\n",
       "       2.59662433, 2.32653866, 2.10161238, 2.51028022, 2.48036944,\n",
       "       1.62799249, 1.81614304, 2.08080234, 2.46520527, 1.90376617,\n",
       "       1.39392336, 2.15432888, 2.81813501, 1.87711112, 1.85249005,\n",
       "       1.52218726, 2.01087683, 2.40951067, 2.01183162, 1.66672321,\n",
       "       1.94795425, 1.9963901 , 2.14494738, 2.13831145, 2.2681182 ,\n",
       "       1.93516707, 2.03019929, 1.86845261, 1.88852273, 1.72905494,\n",
       "       2.29470579, 2.23117035, 2.21600616, 2.52484136, 2.00556638,\n",
       "       2.22137462, 1.90636041, 1.95191852, 2.20370171, 1.99852729,\n",
       "       2.45884646, 1.65150188, 1.86239492, 2.05955444, 2.08133178,\n",
       "       2.09107018, 2.09175392, 2.06124553, 2.37485167, 1.88766883,\n",
       "       2.49074997, 2.03945508, 2.0099999 , 2.41058172, 2.5622215 ,\n",
       "       2.13638402, 1.41088064, 1.94105678, 2.08061339, 2.22737029,\n",
       "       1.7952498 , 2.36554675, 1.88416718, 2.11025968, 2.34593621,\n",
       "       2.43984327, 2.30048053, 1.673033  , 2.0588727 , 1.88850036,\n",
       "       1.84127261, 1.79411597, 2.04758911, 1.44696274, 2.19625116,\n",
       "       2.15356721, 2.43663391, 1.84033922, 2.06567795, 1.90737313,\n",
       "       2.16427552, 2.0374608 , 2.13522344, 2.32175074, 1.57980151,\n",
       "       1.72416516, 2.01295333, 2.30454453, 2.15839882, 2.03820604,\n",
       "       2.28739972, 1.59712926, 2.37949883, 2.34071099, 1.86147695,\n",
       "       2.12172721, 2.14539257, 1.94091567, 1.78402293, 2.46771354,\n",
       "       1.99270509, 1.53240014, 2.33558246, 2.07521755, 2.55004932,\n",
       "       1.65392279, 2.12119825, 2.28159141, 1.65037548, 2.31523818,\n",
       "       2.13680489, 1.87511976, 1.75703361, 2.0454583 , 1.53014661,\n",
       "       2.13877468, 2.54344998, 1.58554634, 2.33854072, 1.67445219,\n",
       "       2.02464584, 2.3964662 , 2.05904698, 2.08089888, 2.44399203,\n",
       "       2.61004032, 1.50477361, 2.53486839, 2.53077422, 2.13594314,\n",
       "       2.23053751, 1.92258065, 1.65479316, 2.43723677, 1.76171786,\n",
       "       1.87181612, 2.85410433, 1.80040757, 1.9774813 , 2.50829495,\n",
       "       1.82073469, 1.35377844, 1.64070325, 1.9955039 , 2.14942544,\n",
       "       1.9044506 , 2.33536142, 1.99318704, 2.0761117 , 1.76030416,\n",
       "       2.22150564, 1.70504076, 2.62562896, 1.50452379, 1.75079702,\n",
       "       2.19909294, 2.03393218, 2.23558377, 2.44166098, 2.21683168,\n",
       "       2.11363514, 2.25179509, 2.10235741, 1.82524657, 2.14479637,\n",
       "       2.06238252, 1.99094124, 2.27144346, 1.93958067, 2.04749002,\n",
       "       1.92035156, 2.04206279, 2.41948644, 1.92003609, 2.12542531,\n",
       "       2.04362215, 2.13274738, 1.94066355, 2.28056378, 2.20246062,\n",
       "       2.09574509, 2.14728063, 1.79952586, 1.90968647, 2.30099991,\n",
       "       2.08461461, 2.06745162, 1.70799634, 1.58290215, 2.16830128,\n",
       "       2.71768198, 1.88706053, 1.97205293, 1.54657729, 1.99446846,\n",
       "       2.26345717, 1.82202836, 1.89404385, 1.87438696, 2.09730691,\n",
       "       2.34628035, 2.47698091, 2.0823044 , 2.27619031, 2.36119729,\n",
       "       2.13013124, 1.81366296, 1.57515908, 2.38465154, 1.99567066,\n",
       "       1.89722962, 1.99436165, 1.98936705, 1.75289221, 1.69596951,\n",
       "       1.92087342, 1.44895286, 2.29045143, 1.4558231 , 2.22876575,\n",
       "       2.2043377 , 1.91871643, 1.84483136, 2.54140936, 1.70117437,\n",
       "       2.05965361, 1.51705794, 1.81781142, 2.0291577 , 1.80783854,\n",
       "       2.0138298 , 1.980037  , 1.85588429, 1.93060558, 1.34773886,\n",
       "       1.91447034, 1.75978513, 1.82873048, 2.08978356, 1.26643026,\n",
       "       2.48213802, 1.7683624 , 2.40895928, 2.62557341, 1.81964648,\n",
       "       1.84348552, 2.43502039, 1.997738  , 1.98100989, 1.91718359,\n",
       "       1.79334553, 1.93679284, 1.80742317, 1.74573569, 1.99522728,\n",
       "       1.9001478 , 2.27293834, 1.98647476, 1.8150405 , 1.90720433,\n",
       "       2.94119796, 2.17876897, 1.78138715, 1.67709711, 2.02725868,\n",
       "       2.44678822, 2.03694414, 2.45989757, 1.74778493, 2.2518794 ,\n",
       "       1.4898767 , 2.01469702, 2.38008713, 2.07756995, 2.26563375,\n",
       "       2.12764036, 1.8845882 , 1.97192778, 2.30337725, 2.10122967,\n",
       "       2.03942583, 2.14544503, 1.73591251, 2.20886238, 1.9728476 ,\n",
       "       1.7450414 , 1.56217245, 2.14676333, 1.79893176, 2.19542478,\n",
       "       2.6825844 , 1.79935841, 2.17114618, 1.46349292, 1.65724671,\n",
       "       2.16626081, 2.09234108, 1.93827301, 1.96406104, 2.37485225,\n",
       "       1.9537505 , 2.00596074, 2.16019626, 2.38724097, 2.22956641,\n",
       "       2.26797791, 2.50453138, 1.91770088, 1.78979546, 1.50465685,\n",
       "       1.87395415, 1.97592566, 2.48935403, 2.26473888, 1.63286279,\n",
       "       2.21744957, 2.13937929, 2.06175399, 2.01967067, 2.06383905,\n",
       "       2.25066181, 2.14990025, 2.19456881, 2.46169743, 2.41642957,\n",
       "       2.20500691, 2.32417108, 2.23428504, 1.95356526, 1.70782296,\n",
       "       2.67923403, 2.14299365, 2.00925918, 1.73751139, 2.13069998,\n",
       "       2.64781339, 2.06361869, 1.72032094, 1.74286309, 1.69799942,\n",
       "       1.95868322, 2.53519862, 2.13479637, 1.95793641, 2.12800488,\n",
       "       2.01263571, 2.10727252, 1.91302864, 1.83486435, 2.16943251,\n",
       "       2.14040675, 2.3763879 , 2.48511886, 1.89110727, 2.40598257,\n",
       "       1.91144116, 2.47957096, 1.7461907 , 1.8994968 , 2.03663375,\n",
       "       2.06548666, 2.39147523, 2.13028001, 1.9895038 , 2.11336714,\n",
       "       2.06628776, 1.67736474, 1.6982976 , 2.23559273, 1.45225013,\n",
       "       2.05293631, 2.09933561, 2.00132161, 2.02721961, 1.98032174,\n",
       "       1.7617149 , 2.26029724, 2.00410287, 1.99882748, 1.82394422,\n",
       "       1.87950783, 2.55704616, 2.07020351, 1.76886125, 1.74954093,\n",
       "       2.69517098, 2.03615693, 2.60928485, 2.28406125, 2.17860311,\n",
       "       2.11681652, 1.90374738, 1.90010615, 2.28947187, 1.67149551,\n",
       "       1.86005984, 1.69373367, 2.15954387, 1.66653857, 2.0549499 ,\n",
       "       2.0648361 , 2.6528081 , 1.62746167, 2.04650615, 1.76701236,\n",
       "       1.95427137, 1.83815072, 1.29638993, 1.67176704, 2.18433503,\n",
       "       3.07357893, 2.02822515, 2.10611903, 2.28984108, 1.97791392,\n",
       "       1.87486014, 1.69433803, 2.56305081, 2.08959835, 1.87512355,\n",
       "       1.93869501, 2.15874497, 2.09769598, 1.80132271, 2.51913779,\n",
       "       1.92941412, 1.73694928, 2.0107068 , 2.29794933, 1.93119752,\n",
       "       1.45788239, 2.20500358, 1.89032568, 2.29115143, 2.23884199,\n",
       "       1.74264001, 2.73923327, 2.68588831, 1.74000188, 1.78868645,\n",
       "       2.37355951, 2.20379106, 2.02378358, 2.40677578, 1.98724561,\n",
       "       2.236324  , 2.34800342, 1.89604148, 1.97626666, 2.30193197,\n",
       "       2.36817312, 2.19185091, 2.10060257, 2.19113991, 1.93710022,\n",
       "       2.01165533, 1.94384554, 2.80405332, 2.24648819, 2.01963755,\n",
       "       1.88669824, 1.92848419, 2.22336388, 2.01584707, 1.92979416,\n",
       "       1.52671847, 2.59624977, 1.98359465, 1.94686938, 1.74162761,\n",
       "       2.44356091, 2.19694542, 1.94772047, 2.2195643 , 2.04941136,\n",
       "       2.17055792, 1.99614261, 1.94694232, 2.23885179, 2.14774963,\n",
       "       2.06236136, 1.78791691, 1.59434478, 2.37666278, 2.64634448,\n",
       "       2.05839346, 2.10317574, 1.97646033, 2.19247227, 1.92437924,\n",
       "       2.06393185, 2.07380102, 2.57959118, 1.93219581, 2.48894233])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # compute the variance by cols in an array\n",
    " \n",
    "y_predictions_Old_Data.var(axis=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_predictions_Old_Data.var(axis=0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we compute the mean of the previous vector:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\dfrac{1}{n} \\cdot \\sum_{i=1,...,n} \\widehat{Var}(\\hat{y_i})$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0548992883622264"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predictions_Old_Data.var(axis=0).mean()  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAI_denominator = y_predictions_Old_Data.var(axis=0).mean()  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We repeat the previous process but now we get the response predictions for de predictors of the New_Data_Set (this is so important, taking into a count the PAI definitions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_New['X2'] = df_New['X2'].astype('category')\n",
    "df_New['X3'] = df_New['X3'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "B=100\n",
    "\n",
    "y_predictions_New_Data = np.zeros((B , len(df_New)))\n",
    "\n",
    "for i in range(0, B):\n",
    "\n",
    "    # i-th boot sample of the Old Data\n",
    "\n",
    "    df_Old_BOOT_SAMPLE = df_Old.sample( n=len(df_Old) , random_state=i , replace=True ) \n",
    " \n",
    "\n",
    "    \n",
    "    X_old = df_Old_BOOT_SAMPLE[['X1', 'X2', 'X3']]  \n",
    "\n",
    "    y_old =  df_Old_BOOT_SAMPLE['Y']\n",
    "\n",
    "    X_old = varcharProcessing(X_old, varchar_process = \"dummy_dropfirst\")\n",
    "\n",
    "    \n",
    "\n",
    "    X_new = df_New[['X1', 'X2', 'X3']]\n",
    "\n",
    "    y_new = df_New['Y']\n",
    "\n",
    "    X_new = varcharProcessing(X_new, varchar_process = \"dummy_dropfirst\") \n",
    "\n",
    "\n",
    "    Model_Old_Boot_Sample = LinearRegression().fit(X_old, y_old)\n",
    "\n",
    "    \n",
    "    # y predictions for the New Data using the model trained with the Old Data Boot Sample\n",
    "    # For this step with sk-learn is necessary X_new (test_set) columns have the same name as X_old (train set) columns\n",
    "\n",
    "    y_predictions_New_Data[i, :] = Model_Old_Boot_Sample.predict(X_new)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAI_numerator = y_predictions_New_Data.var(axis=0).mean()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.406479599837219"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PAI_numerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0548992883622264"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PAI_denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.171093694696447"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PAI = PAI_numerator / PAI_denominator\n",
    "PAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember:\n",
    "\n",
    "$$ \n",
    "\n",
    "PAI =  \\dfrac{\\text{mean variance of the response predictions, using the model trained with the Old data but using the New data for the predictors to get the response predictions }}{\\text{mean variance of the response predictions, using the model trained with the Old data and also using the Old data for the predictors to get the response predictions} }  \n",
    "\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, in mean, the variance of the response predictions using the New Data Set is 1.17 times greater than the variance of the response predictions using the Old Data Set.\n",
    "\n",
    "Following the interpretation \"values less than 1.1 indicate no significant deterioration; values from 1.1 to 1.5 indicate a deterioration requiring further investigation, values exceeding 1.5 indicate the predictive\n",
    "accuracy of the model has deteriorated significantly\" exposed in the paper `The Population Accuracy Index: A New Measure of\n",
    "Population Stability for Model Monitoring` , so, the PAI value that we have got indicates a deterioration of  the model predictive\n",
    "accuracy , so could be recommendable to train again the model using the New Data Set instead the Old."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c63d8c7d738c2960218a10995aedf0a7f67a49a231e71037adf0440953cdb45b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
