{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN for supervised classification   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have $\\hspace{0.1cm} p \\hspace{0.1cm}$ variables $\\hspace{0.1cm} X=(X_1,...,X_p) \\hspace{0.1cm}$ measurements on a $n$ size sample.\n",
    "\n",
    "We also have a categorical response variable $\\hspace{0.1cm} Y \\hspace{0.1cm}$ with $\\hspace{0.1cm} g \\hspace{0.1cm}$  categories that indicates  the group to which each element of the sample belongs  $ ( \\hspace{0.05cm} Range(Y)=\\lbrace c_1 ,..., c_g \\rbrace \\hspace{0.05cm})$\n",
    "\n",
    "The groups generated by $\\hspace{0.1cm} Y \\hspace{0.1cm}$ are denoted as $\\hspace{0.1cm} \\Omega_1 ,..., \\Omega_g \\hspace{0.15cm}$   $\\hspace{0.15cm}( \\hspace{0.1cm} y_i = c_r \\hspace{0.15cm} \\Leftrightarrow \\hspace{0.15cm}$  $ i \\in \\Omega_r \\hspace{0.1cm})$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The supervised classification problem consists in, for a new observation $\\hspace{0.1cm} x_{new} = (x_{new,1},x_{new,2},...,x_{new,p}) \\hspace{0.1cm}$ of the variables $X_1,...,X_p  \\hspace{0.1cm}$, predict it's $\\hspace{0.1cm} Y \\hspace{0.1cm}$ value $\\hspace{0.1cm} (y_{new})\\hspace{0.1cm}$  using the information of $\\hspace{0.1cm} X_1,...,X_p \\hspace{0.1cm}$ and $ \\hspace{0.1cm} Y$\n",
    "\n",
    "So , the problem is to classify a new element/individual in one of the $\\hspace{0.1cm} g \\hspace{0.1cm}$ groups generated by $\\hspace{0.1cm} Y \\hspace{0.1cm}$ using the information available of $\\hspace{0.1cm} X_1,...,X_p \\hspace{0.1cm}$ and $Y$, and also $\\hspace{0.1cm} x_{new} = (x_{new,1},x_{new,2},...,x_{new,p})$\n",
    "\n",
    "Note that if we haven't information about $\\hspace{0.1cm} Y \\hspace{0.1cm}$ this would be an unsupervised classification problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The KNN (K-nearest neighbors) algorithm for classification have the following steps:\n",
    "\n",
    " $1. \\hspace{0.15cm}$ Define a distance measure between the observation of the original sample respect to the variables $X_1,...,X_p$ $\\hspace{0.15cm} \\Rightarrow \\hspace{0.15cm}$ $\\delta$\n",
    "\n",
    "\n",
    "\n",
    " $2. \\hspace{0.15cm}$ Compute the distances between $x_{new}$ and the initial observations $\\hspace{0.1cm} \\lbrace x_1,...,x_n \\rbrace$ $\\hspace{0.15cm} \\Rightarrow \\hspace{0.15cm}$ $\\lbrace \\hspace{0.1 cm}  \\delta(x_{new}, x_i) \\hspace{0.1 cm} / \\hspace{0.1 cm}  i=1,...,n \\hspace{0.1 cm}  \\rbrace$\n",
    "\n",
    "  \n",
    " $3. \\hspace{0.15cm}$ Select the  $k$ nearest observation to $x_{new}$ based on $\\hspace{0.05cm} \\delta \\hspace{0.12cm}$ $(k$ nearest neighbors of $x_{new})$ $\\hspace{0.15cm} \\Rightarrow \\hspace{0.15cm}$   The set of these observation will be denote by $KNN$ \n",
    "\n",
    " $4. \\hspace{0.15cm}$ Compute the proportion of these observation (neighbors) that belongs to each group $\\hspace{0.15cm} \\Rightarrow \\hspace{0.15cm}$  \n",
    " \n",
    " $\\hspace{0.65cm} \\Rightarrow \\hspace{0.15cm}$ The proportion of $KNN$ that belongs to the group $\\hspace{0.15cm} \\Omega_r$ $\\hspace{0.1cm}(Y=c_r)\\hspace{0.1cm}$ will be denote by $\\hspace{0.1 cm} f^{knn}_{r}  $\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "   $$ \\hspace{0.1 cm} f^{knn}_{r} \\hspace{0.15cm}=\\hspace{0.15cm} \\dfrac{ \\# \\hspace{0.1cm}\\lbrace\\hspace{0.1cm} i \\in KNN \\hspace{0.1cm}/\\hspace{0.1cm} i \\in \\Omega_r \\hspace{0.1cm}\\rbrace  }{k} $$\n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$5. \\hspace{0.15cm}$ Classify $\\hspace{0.1cm} x_{new} \\hspace{0.1cm}$ in that group such has a bigger neighbors proportion $\\hspace{0.18cm} \\Rightarrow \\hspace{0.2cm}$ $\\text{If}   \\hspace{0.15cm} \\underbrace{ f^{knn}_{s} \\geqslant f^{knn}_{r} \\hspace{0.15cm},\\hspace{0.15cm} \\forall r = 1,...,g  }_{\\Omega_s \\hspace{0.1cm}\\text{is the most frequent group in}\\hspace{0.1cm} KNN } $    $\\hspace{0.1cm} \\hspace{0.15cm}  \\Rightarrow \\hspace{0.15cm} x_{new} \\hspace{0.1cm}$ is classify in $\\hspace{0.1cm} \\Omega_s$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why KNN is a supervised classification method and not an unsupervised ?\n",
    "\n",
    "Because in this problem we have a vector of observations of the response variable $Y$\n",
    "\n",
    "The fact that we haven't $\\hspace{0.1 cm} y_{new} \\hspace{0.1 cm}$ doesn't transform it in a unsupervised problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Toy example:\n",
    "\n",
    "Sample: $n=3$\n",
    "\n",
    "Predictors:\n",
    "\n",
    "$X1 = (10 , 2 , 4)$\n",
    "$X2 = (20 , 25, 40)$\n",
    "\n",
    "Observations:\n",
    "\n",
    "$x_1 =(10,20)$\n",
    "$x_2=(2,25)$\n",
    "$x_3=(4,40)$\n",
    "\n",
    "Response: (2 categories (0,1), then 2 groups $\\Omega_0 , \\Omega_1$)\n",
    "\n",
    "$Y =( 1 , 1 , 0 )$\n",
    "\n",
    "Distance $\\hspace{0.15cm} \\Rightarrow \\hspace{0.15cm}$  $ \\delta_{Euclidean}$\n",
    "\n",
    "New observation:\n",
    "\n",
    "$x_{new}=(6, 20)$\n",
    "\n",
    "Computing the distances:\n",
    "\n",
    "$\\delta(x_{new}, x_1)_{Euclidean} = (10-6)^2 + (20-20)^2 = 16$\n",
    "$\\delta(x_{new}, x_2)_{Euclidean} = (2-6)^2 + (25-20)^2 = 16 + 25 = 41$\n",
    "$\\delta(x_{new}, x_3)_{Euclidean} = (4-6)^2 + (40-20)^2 = 4 + 400 = 404$\n",
    "\n",
    "Selecting k=2 nearest neighbor to $x_{new}$: $x_1$ and $x_2$\n",
    "\n",
    "Computing the proportions $f^{knn}$ : $f^{knn}_0 =  0/2 = 0$ , $f^{knn}_1 =  2/2 = 1$\n",
    "\n",
    "So, the algorithm classify $x_{new}$ in the group $\\Omega_1$ , so the algorithm predict that $\\hat{y}_{new} = 1$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimal k (ver Aurea)\n",
    "\n",
    "The typical approach to select the value of $k$ is to set $k=\\sqrt{n}$\n",
    "\n",
    "A more complex approach is the following:\n",
    "\n",
    "\n",
    "Tenemos x_i=(x_{i1},...,x_{ip}) y tambien y_i para i =1,...,n\n",
    "\n",
    "Suponer que x_i es una observacion no clasificada (auqnue realmente conocemos y_i) \n",
    "\n",
    "Fijar un valor de k\n",
    "\n",
    "Clasificar x_i usando KNN\n",
    "\n",
    "Determinar si la clasificacion ha sido correcta o incorrecta (lo podemos hacer gracias a que tenemos el dato y_i)\n",
    "\n",
    "Repetir el proceso para el resto de i=1,....,n \n",
    "\n",
    "Calcular la proporcion de clasificaciones correctas (proporcion de aciertos)  , esta sera la metrica de error del KNN para el hiperparametro k\n",
    "\n",
    "Repetir el proceso para el resto de k=2,3,...\n",
    "\n",
    "Seleccionar el valor de k que maximiza la proporcion de aciertos (minimiza la proporcion de errores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN for classification in Python with `Sklearn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gender_classification = pd.read_csv('gender_classification.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>long_hair</th>\n",
       "      <th>forehead_width_cm</th>\n",
       "      <th>forehead_height_cm</th>\n",
       "      <th>nose_wide</th>\n",
       "      <th>nose_long</th>\n",
       "      <th>lips_thin</th>\n",
       "      <th>distance_nose_to_lip_long</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>11.8</td>\n",
       "      <td>6.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>5.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>11.8</td>\n",
       "      <td>6.3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>14.4</td>\n",
       "      <td>6.1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13.5</td>\n",
       "      <td>5.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   long_hair  forehead_width_cm  forehead_height_cm  nose_wide  nose_long  \\\n",
       "0          1               11.8                 6.1          1          0   \n",
       "1          0               14.0                 5.4          0          0   \n",
       "2          0               11.8                 6.3          1          1   \n",
       "3          0               14.4                 6.1          0          1   \n",
       "4          1               13.5                 5.9          0          0   \n",
       "\n",
       "   lips_thin  distance_nose_to_lip_long  gender  \n",
       "0          1                          1    Male  \n",
       "1          1                          0  Female  \n",
       "2          1                          1    Male  \n",
       "3          1                          1    Male  \n",
       "4          0                          0  Female  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Gender_classification.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Gender_classification.iloc[ : , 0:7]\n",
    "\n",
    "Y = Gender_classification.iloc[ : , 7]\n",
    "\n",
    "x_new = [1,\t10, 5, 1, 0, 1,\t1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = sklearn.neighbors.KNeighborsClassifier(n_neighbors=10 ,  weights='uniform', p=2, metric='minkowski')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n_neighbors = Number of neighbors to use (k)\n",
    "\n",
    "weights:\n",
    "\n",
    "   ‘uniform’ : uniform weights. All points in each neighborhood are weighted equally.\n",
    "\n",
    "   ‘distance’ : weight points by the inverse of their distance. in this case, closer neighbors of a query point will have a greater influence than neighbors which are further away.\n",
    "\n",
    "   [callable] : a user-defined function which accepts an array of distances, and returns an array of the same shape containing the weights.\n",
    "\n",
    "metric:\n",
    "\n",
    "  Metric to use for distance computation. Default is “minkowski”, which results in the standard Euclidean distance when p = 2. See the documentation of scipy.spatial.distance and the metrics listed in distance_metrics for valid metric values. Metrics available ‘cityblock’ , 'cosine', ‘euclidean’, 'haversine', 'l1', 'l2', 'manhattan', 'nan_euclidean'.\n",
    "\n",
    "\n",
    "\n",
    "  If metric is “precomputed”, X is assumed to be a distance matrix and must be square during fit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Male']\n",
      "[[0.2 0.8]]\n"
     ]
    }
   ],
   "source": [
    "knn.fit(X, Y)\n",
    "\n",
    "print( knn.predict( [x_new] ) )\n",
    " \n",
    "print( knn.predict_proba([x_new]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With other distances:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = sklearn.neighbors.KNeighborsClassifier(n_neighbors=10 ,  weights='uniform',  metric='cityblock')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Male']\n",
      "[[0.1 0.9]]\n"
     ]
    }
   ],
   "source": [
    "knn.fit(X, Y)\n",
    "\n",
    "print( knn.predict( [x_new] ) )\n",
    " \n",
    "print( knn.predict_proba([x_new]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = sklearn.neighbors.KNeighborsClassifier(n_neighbors=10 ,  weights='uniform', metric='cosine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Male']\n",
      "[[0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "knn.fit(X, Y)\n",
    "\n",
    "print( knn.predict( [x_new] ) ) \n",
    "\n",
    "print( knn.predict_proba([x_new]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = sklearn.neighbors.KNeighborsClassifier(n_neighbors=10 ,  weights='uniform', metric='nan_euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Male']\n",
      "[[0.2 0.8]]\n"
     ]
    }
   ],
   "source": [
    "knn.fit(X, Y)\n",
    "\n",
    "print( knn.predict( [x_new] ) ) \n",
    "\n",
    "print( knn.predict_proba([x_new]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = sklearn.neighbors.KNeighborsClassifier(n_neighbors=10 ,  weights='uniform', metric='manhattan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Male']\n",
      "[[0.1 0.9]]\n"
     ]
    }
   ],
   "source": [
    "knn.fit(X, Y)\n",
    "\n",
    "print( knn.predict( [x_new] ) ) \n",
    "\n",
    "print( knn.predict_proba([x_new]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN for classification in Python with own algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our algorithm for not depend on sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN_classification( X , Y , x_new, k, distance = \"Minkowski\" , q = 0, p1=0, p2=0, p3=0 ):\n",
    "\n",
    "####################################################################################################################################################################################################################################################\n",
    "\n",
    "    # Y tiene que ser una variable categorica con categorias estandar (0,1,2,...)\n",
    "\n",
    "    # Ejemplo de Y :  Y = Gender_classification.iloc[0:20 , 7]\n",
    "\n",
    "    # Ejemplo de como codificar Y en categorias estandar (si ya esta en el formato estandar indicado no hace falta):\n",
    "      \n",
    "      # for i in range(0, len(Y)):\n",
    "          # if Y[i]=='Male':\n",
    "          #   Y[i] = 0\n",
    "          # elif Y[i]=='Female':\n",
    "          #   Y[i]=1\n",
    "\n",
    "    # X tiene que ser un panda data frame con los predictotres (X1,...,Xp). Ejemplo X = Gender_classification.iloc[0:20 , 0:7]\n",
    "\n",
    "    # x_new tiene que ser una panda series. Ejemplo x_new = pd.Series({'long_hair': 1, 'forehead_width_cm': 4, 'forehead_height_cm': 6, 'nose_wide': 1 , 'nose_long': 1 , 'nose_long': 1 , 'lips_thin':1, 'distance_nose_to_lip_long': 1 })\n",
    "\n",
    "####################################################################################################################################################################################################################################################\n",
    "\n",
    "    X = pd.concat([X, x_new.to_frame().T], ignore_index=True)\n",
    "\n",
    "    distances = []\n",
    "\n",
    "    groups_knn = []\n",
    "\n",
    "\n",
    "####################################################################################################################################################################################################################################################\n",
    "    \n",
    "    if distance == \"Euclidean\":\n",
    "\n",
    "        def Dist_Euclidea_Python(i, j, Quantitative_Data_set): \n",
    "\n",
    "            Dist_Euclidea = ( ( Quantitative_Data_set.iloc[i-1, ] - Quantitative_Data_set.iloc[j-1, ] )**2 ).sum()\n",
    "\n",
    "            Dist_Euclidea = np.sqrt(Dist_Euclidea)\n",
    "\n",
    "            return Dist_Euclidea\n",
    "\n",
    "    ###################################################################\n",
    "\n",
    "        for i in range(1, len(X)):\n",
    "\n",
    "            distances.append( Dist_Euclidea_Python( len(X), i , X) )\n",
    "\n",
    "    ###################################################################\n",
    "\n",
    "    if distance == \"Minkowski\":\n",
    "\n",
    "        def Dist_Minkowski_Python(i,j, q , Quantitative_Data_set):\n",
    "\n",
    "            Dist_Minkowski = ( ( ( ( Quantitative_Data_set.iloc[i-1, ] - Quantitative_Data_set.iloc[j-1, ] ).abs() )**q ).sum() )**(1/q)\n",
    "\n",
    "            return Dist_Minkowski\n",
    "\n",
    "    ###################################################################\n",
    "\n",
    "        for i in range(1, len(X)):\n",
    "\n",
    "            distances.append( Dist_Minkowski_Python( len(X), i , q , X) )\n",
    "\n",
    "        \n",
    "\n",
    "    ###################################################################\n",
    "\n",
    "    if distance == \"Canberra\":\n",
    "\n",
    "        def Dist_Canberra_Python(i,j, Quantitative_Data_set):\n",
    "\n",
    "            Dist_Canberra =  ( ( Quantitative_Data_set.iloc[i-1, ] - Quantitative_Data_set.iloc[j-1, ] ).abs()  / ( (Quantitative_Data_set.iloc[i-1, ]).abs() + (Quantitative_Data_set.iloc[j-1, ]).abs() ) ).sum()\n",
    "\n",
    "            return Dist_Canberra\n",
    "\n",
    "    ###################################################################\n",
    "    \n",
    "        for i in range(1, len(X)):\n",
    "\n",
    "            distances.append( Dist_Canberra_Python( len(X), i , X) )\n",
    "\n",
    "    ###################################################################\n",
    "   \n",
    "    if distance == \"Pearson\":\n",
    "\n",
    "        def Dist_Pearson_Python(i, j, Quantitative_Data_set):\n",
    "\n",
    "            Dist_Pearson = ( ( Quantitative_Data_set.iloc[i-1, ] - Quantitative_Data_set.iloc[j-1, ] )**2 / Quantitative_Data_set.var() ).sum()\n",
    "\n",
    "            Dist_Pearson = np.sqrt(Dist_Pearson)\n",
    "\n",
    "            return Dist_Pearson\n",
    "\n",
    "    ###################################################################\n",
    "\n",
    "        for i in range(1, len(X)):\n",
    "\n",
    "            distances.append( Dist_Pearson_Python( len(X), i , X) )\n",
    "\n",
    "    ###################################################################\n",
    "    \n",
    "    if distance == \"Mahalanobis\":\n",
    "\n",
    "        def Dist_Mahalanobis_Python(i, j, Quantitative_Data_set):\n",
    "\n",
    "            x = (Quantitative_Data_set.to_numpy()[i-1, ] - Quantitative_Data_set.to_numpy()[j-1, ])\n",
    "\n",
    "            x = np.array([x]) # necessary step to transpose a 1D array\n",
    "\n",
    "            S_inv = np.linalg.inv( Quantitative_Data_set.cov() ) # inverse of covariance matrix\n",
    "\n",
    "            Dist_Maha = np.sqrt( x @ S_inv @ x.T )  # x @ S_inv @ x.T = np.matmul( np.matmul(x , S_inv) , x.T )\n",
    "\n",
    "            Dist_Maha = float(Dist_Maha)\n",
    "\n",
    "            return Dist_Maha\n",
    "\n",
    "        \n",
    "    ###################################################################\n",
    "\n",
    "        for i in range(1, len(X)):\n",
    "\n",
    "            distances.append( Dist_Mahalanobis_Python( len(X), i , X) )\n",
    "\n",
    "       \n",
    "\n",
    "    ###################################################################\n",
    "    \n",
    "    if distance == \"Sokal\":\n",
    "\n",
    "        a = X @ X.T\n",
    "        n = X.shape[0]\n",
    "        p = X.shape[1]\n",
    "        ones_matrix = np.ones((n, p))\n",
    "        b = (ones_matrix - X) @ X.T\n",
    "        c = b.T\n",
    "        d = (ones_matrix - X) @ (ones_matrix - X).T\n",
    "\n",
    "        def Sokal_Similarity_Py(i, j):\n",
    "\n",
    "            Sokal_Similarity = (a.iloc[i-1,j-1] + d.iloc[i-1,j-1])/p\n",
    "\n",
    "            return Sokal_Similarity\n",
    "\n",
    "\n",
    "        def Dist_Sokal_Python(i, j, Binary_Data_set):\n",
    "\n",
    "            dist_Sokal = np.sqrt( 2 - 2*Sokal_Similarity_Py(i,j, Binary_Data_set) )\n",
    "\n",
    "            return dist_Sokal\n",
    "\n",
    "    ###################################################################\n",
    "\n",
    "        for i in range(1, len(X)):\n",
    "\n",
    "            distances.append( Dist_Sokal_Python( len(X), i , X) )\n",
    "\n",
    "    ###################################################################\n",
    "   \n",
    "    if distance == \"Jaccard\":\n",
    "\n",
    "        def Jaccard_Similarity_Py(i, j, Binary_Data_Matrix):\n",
    "\n",
    "            X = Binary_Data_Py\n",
    "            a = X @ X.T\n",
    "            n = X.shape[0]\n",
    "            p = X.shape[1]\n",
    "            ones_matrix = np.ones((n, p)) \n",
    "            b = (ones_matrix - X) @ X.T\n",
    "            c = b.T\n",
    "            d = (ones_matrix - X) @ (ones_matrix - X).T\n",
    "\n",
    "            Jaccard_Similarity = a.iloc[i-1,j-1] / (a.iloc[i-1,j-1] + b.iloc[i-1,j-1] + c.iloc[i-1,j-1])\n",
    "            \n",
    "            return Jaccard_Similarity\n",
    "\n",
    "\n",
    "        def Dist_Jaccard_Python(i, j, Binary_Data_set):\n",
    "\n",
    "            dist_Jaccard = np.sqrt( Jaccard_Similarity_Py(i,i, Binary_Data_set) + Jaccard_Similarity_Py(i,i, Binary_Data_set) - 2*Jaccard_Similarity_Py(i,j, Binary_Data_set) )\n",
    "\n",
    "            return dist_Jaccard\n",
    "\n",
    "    ###################################################################\n",
    "\n",
    "        for i in range(1, len(X)):\n",
    "\n",
    "            distances.append( Dist_Jaccard_Python( len(X), i , X) )\n",
    "\n",
    "    ###################################################################\n",
    "    \n",
    "    if distance == \"Matches\":\n",
    "\n",
    "        def alpha_py(i,j, Multiple_Categorical_Data):\n",
    "\n",
    "            X = Multiple_Categorical_Data\n",
    "            alpha = np.repeat(0, X.shape[1])\n",
    "\n",
    "            for k in range(0, X.shape[1]) :\n",
    "\n",
    "                if X.iloc[i-1, k] == X.iloc[j-1, k] :\n",
    "\n",
    "                    alpha[k] = 1\n",
    "\n",
    "                else :\n",
    "\n",
    "                    alpha[k] = 0\n",
    "\n",
    "            alpha = alpha.sum()\n",
    "\n",
    "            return(alpha)\n",
    "\n",
    "\n",
    "        def matches_similarity_py(i, j, Multiple_Categorical_Data):\n",
    "\n",
    "            p = Multiple_Categorical_Data.shape[1]\n",
    "\n",
    "            matches_similarity = alpha_py(i,j, Multiple_Categorical_Data) / p\n",
    "\n",
    "            return(matches_similarity)\n",
    "\n",
    "\n",
    "        def Dist_Matches_Py(i,j, Multiple_Categorical_Data):\n",
    "\n",
    "            Dist_Matches = np.sqrt( matches_similarity_py(i, i, Multiple_Categorical_Data) +  matches_similarity_py(j, j, Multiple_Categorical_Data) - 2*matches_similarity_py(i, j, Multiple_Categorical_Data) )\n",
    "\n",
    "            return( Dist_Matches )\n",
    "\n",
    "    ###################################################################\n",
    "\n",
    "        for i in range(1, len(X)):\n",
    "\n",
    "            distances.append( Dist_Matches_Py( len(X), i , X) )\n",
    "\n",
    "    ###################################################################\n",
    "   \n",
    "    if distance == \"Gower\":\n",
    "\n",
    "        def Gower_Similarity_Python(i,j, Mixed_Data_Set, p1, p2, p3):\n",
    "\n",
    "            X = Mixed_Data_Set\n",
    "\n",
    "            # The variable must to be order in the following way: \n",
    "            # the p1 first are quantitative, the following p2 are binary categorical, and the following p3 are multiclass categorical.\n",
    "\n",
    "        #################################################################################\n",
    "      \n",
    "            def G(k, X):\n",
    "\n",
    "                range = X.iloc[:,k].max() - X.iloc[:,k].min()\n",
    "                \n",
    "                return(range)\n",
    "\n",
    "            G_vector = np.repeat(0, p1)\n",
    "\n",
    "            for r in range(0, p1):\n",
    "\n",
    "                G_vector[r] = G(r, X)\n",
    "            \n",
    "        ########################################################################################\n",
    "    \n",
    "            ones = np.repeat(1, p1)\n",
    "\n",
    "            Quantitative_Data = X.iloc[: , 0:p1]\n",
    "            Binary_Data = X.iloc[: , (p1):(p1+p2)]\n",
    "            Multiple_Categorical_Data = X.iloc[: , (p1+p2):(p1+p2+p3) ]\n",
    "\n",
    "            a = Binary_Data @ Binary_Data.T\n",
    "\n",
    "            ones_matrix = np.ones(( Binary_Data.shape[0] , Binary_Data.shape[1])) \n",
    "   \n",
    "            d = (ones_matrix - Binary_Data) @ (ones_matrix - Binary_Data).T\n",
    "\n",
    "        #################################################################################\n",
    "\n",
    "            numerator_part_1 = ( ones - ( (Quantitative_Data.iloc[i,:] - Quantitative_Data.iloc[j,:]).abs() / G_vector ) ).sum() \n",
    "\n",
    "            numerator_part_2 = a.iloc[i,j] + alpha_py(i,j, Multiple_Categorical_Data)\n",
    "\n",
    "            numerator = numerator_part_1 + numerator_part_2\n",
    "\n",
    "            denominator = p1 + (p2 - d.iloc[i,j]) + p3\n",
    "\n",
    "            Similarity_Gower = numerator / denominator  \n",
    "\n",
    "            return(Similarity_Gower)\n",
    "\n",
    "        #################################################################################\n",
    "        \n",
    "        def Dist_Gower_Py(i, j, Mixed_Data , p1, p2, p3):\n",
    "\n",
    "            Dist_Gower = np.sqrt( 1 - Gower_Similarity_Python(i, j, Mixed_Data , p1, p2, p3) )\n",
    "\n",
    "            return(Dist_Gower)    \n",
    "\n",
    "    ###################################################################\n",
    "\n",
    "        for i in range(1, len(X)):\n",
    "\n",
    "            distances.append( Dist_Gower_Py( len(X), i , X, p1, p2, p3) )\n",
    "\n",
    "    ###################################################################\n",
    "    \n",
    "    distances = pd.DataFrame({'distances': distances})\n",
    "\n",
    "    distances = distances.sort_values(by=[\"distances\"]).reset_index(drop=False)\n",
    "        \n",
    "    knn = distances.iloc[0:k , :]\n",
    "\n",
    "    for i in knn.iloc[:,0]:\n",
    "\n",
    "        groups_knn.append(Y[i])\n",
    "\n",
    "    unique, counts = np.unique(groups_knn , return_counts=True)\n",
    "\n",
    "    unique_Y , counts_Y = np.unique(Y , return_counts=True)\n",
    "\n",
    "    if len(unique) == len(unique_Y) :\n",
    "\n",
    "        proportions_groups_knn = pd.DataFrame({'proportions_groups': counts/k, 'groups': unique_Y })\n",
    "    \n",
    "    elif len(unique) < len(unique_Y) :\n",
    "\n",
    "        proportions_groups_knn = pd.DataFrame({'proportions_groups': counts/k, 'groups': unique })\n",
    "\n",
    "\n",
    "\n",
    "    prediction_group = proportions_groups_knn.sort_values(by=[\"proportions_groups\"], ascending=False).iloc[0,:]['groups']\n",
    "\n",
    "    message = print( \"x_new is classify in the group\", prediction_group , \". So KNN algorithm predict y_new =\",  prediction_group )                                      \n",
    "                                       \n",
    "\n",
    "    return proportions_groups_knn , message  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gender_classification = pd.read_csv('gender_classification.csv')\n",
    "\n",
    "X = Gender_classification.iloc[: , 0:7]\n",
    "\n",
    "Y = Gender_classification.iloc[: , 7]\n",
    "\n",
    "x_new = pd.Series({'long_hair': 1, 'forehead_width_cm': 4, 'forehead_height_cm': 6, 'nose_wide': 1 , 'nose_long': 1 , 'nose_long': 1 , 'lips_thin':1, 'distance_nose_to_lip_long': 1 })\n",
    "\n",
    "for i in range(0, len(Y)):\n",
    "\n",
    "    if Y[i]=='Male':\n",
    "\n",
    "        Y[i] = 0\n",
    "\n",
    "    elif Y[i]=='Female':\n",
    "\n",
    "        Y[i]=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_new is classify in the group 0 . So KNN algorithm predict y_new = 0\n"
     ]
    }
   ],
   "source": [
    "proportions_groups_knn , message = KNN_classification( X , Y , x_new, 10 , distance = \"Euclidean\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>proportions_groups</th>\n",
       "      <th>groups</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   proportions_groups groups\n",
       "0                 0.9      0\n",
       "1                 0.1      1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proportions_groups_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_new is classify in the group 0 . So KNN algorithm predict y_new = 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(   proportions_groups groups\n",
       " 0                 0.9      0\n",
       " 1                 0.1      1,\n",
       " None)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNN_classification( X , Y , x_new, 10 , distance = \"Minkowski\" , q = 2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_new is classify in the group 0.0 . So KNN algorithm predict y_new = 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(   proportions_groups  groups\n",
       " 0                 1.0       0,\n",
       " None)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNN_classification( X , Y , x_new, 10 , distance = \"Minkowski\" , q = 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_new is classify in the group 1.0 . So KNN algorithm predict y_new = 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(   proportions_groups  groups\n",
       " 0                 1.0       1,\n",
       " None)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNN_classification( X , Y , x_new, 10 , distance = \"Minkowski\" , q = 3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_new is classify in the group 0.0 . So KNN algorithm predict y_new = 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(   proportions_groups  groups\n",
       " 0                 1.0       0,\n",
       " None)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNN_classification( X , Y , x_new, 10 , distance = \"Canberra\"  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_new is classify in the group 0.0 . So KNN algorithm predict y_new = 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(   proportions_groups  groups\n",
       " 0                 1.0       0,\n",
       " None)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNN_classification( X , Y , x_new, 10 , distance = \"Mahalanobis\"  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_new is classify in the group 0.0 . So KNN algorithm predict y_new = 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(   proportions_groups  groups\n",
       " 0                 1.0       0,\n",
       " None)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNN_classification( X , Y , x_new, 10 , distance = \"Pearson\"  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso no puede implementarse la distancia de Gower porque X no es una matriz de datos mixta (solo tiene cuanqitativas y binarias, faltan las multiclase).\n",
    "Tampoco pueden usarse las distancias de Sokal y Jaccard porque X no es una matriz de datos binarios, ni tampoco el coeficiente de matches (coincidencias) porque X no es una matriz de datos categoricos multiclase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN for regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have $\\hspace{0.1cm} p \\hspace{0.1cm}$ variables $\\hspace{0.1cm} X=(X_1,...,X_p) \\hspace{0.1cm}$ measurements on a $n$ size sample.\n",
    "\n",
    "We also have a quantitative response variable $\\hspace{0.1cm} Y $ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The regression problem consists in, for a new observation $\\hspace{0.1cm} x_{new} = (x_{new,1},x_{new,2},...,x_{new,p}) \\hspace{0.1cm}$ of the variables $X_1,...,X_p  \\hspace{0.1cm}$, predict it's $\\hspace{0.1cm} Y \\hspace{0.05cm}$ value $\\hspace{0.1cm} (y_{new})\\hspace{0.1cm}$  using the information of $\\hspace{0.1cm} X_1,...,X_p \\hspace{0.1cm}$ and $ \\hspace{0.1cm} Y$\n",
    "\n",
    "So , the problem is to get $\\hspace{0.1cm} \\hat{y}_{new} \\hspace{0.1cm}$  using the information available of $\\hspace{0.1cm} X_1,...,X_p \\hspace{0.1cm}$ , $Y$ and  $\\hspace{0.1cm} x_{new} = (x_{new,1},x_{new,2},...,x_{new,p})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The KNN (K-nearest neighbors) algorithm for regression have the following steps:\n",
    "\n",
    " $1. \\hspace{0.15cm}$ Define a distance measure between the observation of the original sample respect to the variables $X_1,...,X_p$ $\\hspace{0.15cm} \\Rightarrow \\hspace{0.15cm}$ $\\delta$\n",
    "\n",
    "\n",
    "\n",
    " $2. \\hspace{0.15cm}$ Compute the distances between $x_{new}$ and the initial observations $\\hspace{0.1cm} \\lbrace x_1,...,x_n \\rbrace$ $\\hspace{0.15cm} \\Rightarrow \\hspace{0.15cm}$ $\\lbrace \\hspace{0.1 cm}  \\delta(x_{new}, x_i) \\hspace{0.1 cm} / \\hspace{0.1 cm}  i=1,...,n \\hspace{0.1 cm}  \\rbrace$\n",
    "\n",
    "  \n",
    " $3. \\hspace{0.15cm}$ Select the  $k$ nearest observation to $x_{new}$ based on $\\hspace{0.05cm} \\delta \\hspace{0.12cm}$ $(k$ nearest neighbors of $x_{new})$ $\\hspace{0.15cm} \\Rightarrow \\hspace{0.15cm}$   The set of these observation will be denote by $KNN$ \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$5. \\hspace{0.15cm}$ The method predict $\\hspace{0.1cm} y_{new} \\hspace{0.1cm}$  as follows:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "   \n",
    " \\widehat{y}_{new} =  \\dfrac{1}{KNN }\\cdot \\sum_{i \\in KNN}  y_i\n",
    "  \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN for regression in Python with `Sklearn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN for regression in Python with own algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN_regression( X , Y , x_new, k, distance = \"Minkowski\" , q = 0, p1=0, p2=0, p3=0 ):\n",
    "\n",
    "####################################################################################################################################################################################################################################################\n",
    "\n",
    "    # Y tiene que ser una variable cuantitativa\n",
    "\n",
    "    # Ejemplo de Y :  \n",
    "\n",
    " \n",
    "    # X tiene que ser un panda data frame con los predictotres (X1,...,Xp). Ejemplo de X :\n",
    "\n",
    "    # x_new tiene que ser una panda series. Ejemplo   \n",
    "\n",
    "####################################################################################################################################################################################################################################################\n",
    "\n",
    "    X = pd.concat([X, x_new.to_frame().T], ignore_index=True)\n",
    "\n",
    "    distances = []\n",
    "\n",
    "    Y_values_knn = []\n",
    "\n",
    "\n",
    "####################################################################################################################################################################################################################################################\n",
    "    \n",
    "    if distance == \"Euclidean\":\n",
    "\n",
    "        def Dist_Euclidea_Python(i, j, Quantitative_Data_set): \n",
    "\n",
    "            Dist_Euclidea = ( ( Quantitative_Data_set.iloc[i-1, ] - Quantitative_Data_set.iloc[j-1, ] )**2 ).sum()\n",
    "\n",
    "            Dist_Euclidea = np.sqrt(Dist_Euclidea)\n",
    "\n",
    "            return Dist_Euclidea\n",
    "\n",
    "    ###################################################################\n",
    "\n",
    "        for i in range(1, len(X)):\n",
    "\n",
    "            distances.append( Dist_Euclidea_Python( len(X), i , X) )\n",
    "\n",
    "    ###################################################################\n",
    "\n",
    "    if distance == \"Minkowski\":\n",
    "\n",
    "        def Dist_Minkowski_Python(i,j, q , Quantitative_Data_set):\n",
    "\n",
    "            Dist_Minkowski = ( ( ( ( Quantitative_Data_set.iloc[i-1, ] - Quantitative_Data_set.iloc[j-1, ] ).abs() )**q ).sum() )**(1/q)\n",
    "\n",
    "            return Dist_Minkowski\n",
    "\n",
    "    ###################################################################\n",
    "\n",
    "        for i in range(1, len(X)):\n",
    "\n",
    "            distances.append( Dist_Minkowski_Python( len(X), i , q , X) )\n",
    "\n",
    "        \n",
    "\n",
    "    ###################################################################\n",
    "\n",
    "    if distance == \"Canberra\":\n",
    "\n",
    "        def Dist_Canberra_Python(i,j, Quantitative_Data_set):\n",
    "\n",
    "            numerator =  ( Quantitative_Data_set.iloc[i-1, ] - Quantitative_Data_set.iloc[j-1, ] ).abs()  \n",
    "\n",
    "            denominator =  ( (Quantitative_Data_set.iloc[i-1, ]).abs() + (Quantitative_Data_set.iloc[j-1, ]).abs() )\n",
    "       \n",
    "            numerator=np.array([numerator], dtype=float)\n",
    "\n",
    "            denominator=np.array([denominator], dtype=float)\n",
    "\n",
    "            Dist_Canberra = ( np.divide( numerator , denominator , out=np.zeros_like(numerator), where=denominator!=0) ).sum()\n",
    "\n",
    "            return Dist_Canberra\n",
    "\n",
    "    ###################################################################\n",
    "    \n",
    "        for i in range(1, len(X)):\n",
    "\n",
    "            distances.append( Dist_Canberra_Python( len(X), i , X) )\n",
    "\n",
    "    ###################################################################\n",
    "   \n",
    "    if distance == \"Pearson\":\n",
    "\n",
    "        def Dist_Pearson_Python(i, j, Quantitative_Data_set):\n",
    "\n",
    "            Dist_Pearson = ( ( Quantitative_Data_set.iloc[i-1, ] - Quantitative_Data_set.iloc[j-1, ] )**2 / Quantitative_Data_set.var() ).sum()\n",
    "\n",
    "            Dist_Pearson = np.sqrt(Dist_Pearson)\n",
    "\n",
    "            return Dist_Pearson\n",
    "\n",
    "    ###################################################################\n",
    "\n",
    "        for i in range(1, len(X)):\n",
    "\n",
    "            distances.append( Dist_Pearson_Python( len(X), i , X) )\n",
    "\n",
    "    ###################################################################\n",
    "    \n",
    "    if distance == \"Mahalanobis\":\n",
    "\n",
    "        def Dist_Mahalanobis_Python(i, j, Quantitative_Data_set):\n",
    "\n",
    "            x = (Quantitative_Data_set.to_numpy()[i-1, ] - Quantitative_Data_set.to_numpy()[j-1, ])\n",
    "\n",
    "            x = np.array([x]) # necessary step to transpose a 1D array\n",
    "\n",
    "            S_inv = np.linalg.inv( Quantitative_Data_set.cov() ) # inverse of covariance matrix\n",
    "\n",
    "            Dist_Maha = np.sqrt( x @ S_inv @ x.T )  # x @ S_inv @ x.T = np.matmul( np.matmul(x , S_inv) , x.T )\n",
    "\n",
    "            Dist_Maha = float(Dist_Maha)\n",
    "\n",
    "            return Dist_Maha\n",
    "\n",
    "        \n",
    "    ###################################################################\n",
    "\n",
    "        for i in range(1, len(X)):\n",
    "\n",
    "            distances.append( Dist_Mahalanobis_Python( len(X), i , X) )\n",
    "\n",
    "       \n",
    "    ###################################################################\n",
    "    \n",
    "    if distance == \"Sokal\":\n",
    "\n",
    "        a = X @ X.T\n",
    "        n = X.shape[0]\n",
    "        p = X.shape[1]\n",
    "        ones_matrix = np.ones((n, p))\n",
    "        b = (ones_matrix - X) @ X.T\n",
    "        c = b.T\n",
    "        d = (ones_matrix - X) @ (ones_matrix - X).T\n",
    "\n",
    "        def Sokal_Similarity_Py(i, j):\n",
    "\n",
    "            Sokal_Similarity = (a.iloc[i-1,j-1] + d.iloc[i-1,j-1])/p\n",
    "\n",
    "            return Sokal_Similarity\n",
    "\n",
    "\n",
    "        def Dist_Sokal_Python(i, j, Binary_Data_set):\n",
    "\n",
    "            dist_Sokal = np.sqrt( 2 - 2*Sokal_Similarity_Py(i,j, Binary_Data_set) )\n",
    "\n",
    "            return dist_Sokal\n",
    "\n",
    "    ###################################################################\n",
    "\n",
    "        for i in range(1, len(X)):\n",
    "\n",
    "            distances.append( Dist_Sokal_Python( len(X), i , X) )\n",
    "\n",
    "    ###################################################################\n",
    "   \n",
    "    if distance == \"Jaccard\":\n",
    "\n",
    "        def Jaccard_Similarity_Py(i, j, Binary_Data_Matrix):\n",
    "\n",
    "            X = Binary_Data_Py\n",
    "            a = X @ X.T\n",
    "            n = X.shape[0]\n",
    "            p = X.shape[1]\n",
    "            ones_matrix = np.ones((n, p)) \n",
    "            b = (ones_matrix - X) @ X.T\n",
    "            c = b.T\n",
    "            d = (ones_matrix - X) @ (ones_matrix - X).T\n",
    "\n",
    "            Jaccard_Similarity = a.iloc[i-1,j-1] / (a.iloc[i-1,j-1] + b.iloc[i-1,j-1] + c.iloc[i-1,j-1])\n",
    "            \n",
    "            return Jaccard_Similarity\n",
    "\n",
    "\n",
    "        def Dist_Jaccard_Python(i, j, Binary_Data_set):\n",
    "\n",
    "            dist_Jaccard = np.sqrt( Jaccard_Similarity_Py(i,i, Binary_Data_set) + Jaccard_Similarity_Py(i,i, Binary_Data_set) - 2*Jaccard_Similarity_Py(i,j, Binary_Data_set) )\n",
    "\n",
    "            return dist_Jaccard\n",
    "\n",
    "    ###################################################################\n",
    "\n",
    "        for i in range(1, len(X)):\n",
    "\n",
    "            distances.append( Dist_Jaccard_Python( len(X), i , X) )\n",
    "\n",
    "    ###################################################################\n",
    "    \n",
    "    if distance == \"Matches\":\n",
    "\n",
    "        def alpha_py(i,j, Multiple_Categorical_Data):\n",
    "\n",
    "            X = Multiple_Categorical_Data\n",
    "            alpha = np.repeat(0, X.shape[1])\n",
    "\n",
    "            for k in range(0, X.shape[1]) :\n",
    "\n",
    "                if X.iloc[i-1, k] == X.iloc[j-1, k] :\n",
    "\n",
    "                    alpha[k] = 1\n",
    "\n",
    "                else :\n",
    "\n",
    "                    alpha[k] = 0\n",
    "\n",
    "            alpha = alpha.sum()\n",
    "\n",
    "            return(alpha)\n",
    "\n",
    "\n",
    "        def matches_similarity_py(i, j, Multiple_Categorical_Data):\n",
    "\n",
    "            p = Multiple_Categorical_Data.shape[1]\n",
    "\n",
    "            matches_similarity = alpha_py(i,j, Multiple_Categorical_Data) / p\n",
    "\n",
    "            return(matches_similarity)\n",
    "\n",
    "\n",
    "        def Dist_Matches_Py(i,j, Multiple_Categorical_Data):\n",
    "\n",
    "            Dist_Matches = np.sqrt( matches_similarity_py(i, i, Multiple_Categorical_Data) +  matches_similarity_py(j, j, Multiple_Categorical_Data) - 2*matches_similarity_py(i, j, Multiple_Categorical_Data) )\n",
    "\n",
    "            return( Dist_Matches )\n",
    "\n",
    "    ###################################################################\n",
    "\n",
    "        for i in range(1, len(X)):\n",
    "\n",
    "            distances.append( Dist_Matches_Py( len(X), i , X) )\n",
    "\n",
    "    ###################################################################\n",
    "   \n",
    "    if distance == \"Gower\":\n",
    "\n",
    "        def Gower_Similarity_Python(i,j, Mixed_Data_Set, p1, p2, p3):\n",
    "\n",
    "            X = Mixed_Data_Set\n",
    "\n",
    "            # The variable must to be order in the following way: \n",
    "            # the p1 first are quantitative, the following p2 are binary categorical, and the following p3 are multiclass categorical.\n",
    "\n",
    "        #################################################################################\n",
    "      \n",
    "            def G(k, X):\n",
    "\n",
    "                range = X.iloc[:,k].max() - X.iloc[:,k].min()\n",
    "                \n",
    "                return(range)\n",
    "\n",
    "            G_vector = np.repeat(0, p1)\n",
    "\n",
    "            for r in range(0, p1):\n",
    "\n",
    "                G_vector[r] = G(r, X)\n",
    "            \n",
    "        ########################################################################################\n",
    "    \n",
    "            ones = np.repeat(1, p1)\n",
    "\n",
    "            Quantitative_Data = X.iloc[: , 0:p1]\n",
    "            Binary_Data = X.iloc[: , (p1):(p1+p2)]\n",
    "            Multiple_Categorical_Data = X.iloc[: , (p1+p2):(p1+p2+p3) ]\n",
    "\n",
    "            a = Binary_Data @ Binary_Data.T\n",
    "\n",
    "            ones_matrix = np.ones(( Binary_Data.shape[0] , Binary_Data.shape[1])) \n",
    "   \n",
    "            d = (ones_matrix - Binary_Data) @ (ones_matrix - Binary_Data).T\n",
    "\n",
    "        #################################################################################\n",
    "\n",
    "            numerator_part_1 = ( ones - ( (Quantitative_Data.iloc[i,:] - Quantitative_Data.iloc[j,:]).abs() / G_vector ) ).sum() \n",
    "\n",
    "            numerator_part_2 = a.iloc[i,j] + alpha_py(i,j, Multiple_Categorical_Data)\n",
    "\n",
    "            numerator = numerator_part_1 + numerator_part_2\n",
    "\n",
    "            denominator = p1 + (p2 - d.iloc[i,j]) + p3\n",
    "\n",
    "            Similarity_Gower = numerator / denominator  \n",
    "\n",
    "            return(Similarity_Gower)\n",
    "\n",
    "        #################################################################################\n",
    "        \n",
    "        def Dist_Gower_Py(i, j, Mixed_Data , p1, p2, p3):\n",
    "\n",
    "            Dist_Gower = np.sqrt( 1 - Gower_Similarity_Python(i, j, Mixed_Data , p1, p2, p3) )\n",
    "\n",
    "            return(Dist_Gower)    \n",
    "\n",
    "    ###################################################################\n",
    "\n",
    "        for i in range(1, len(X)):\n",
    "\n",
    "            distances.append( Dist_Gower_Py( len(X), i , X, p1, p2, p3) )\n",
    "\n",
    "    ######################################################################################################################################\n",
    "    \n",
    "    distances = pd.DataFrame({'distances': distances})\n",
    "\n",
    "    distances = distances.sort_values(by=[\"distances\"]).reset_index(drop=False)\n",
    "        \n",
    "    knn = distances.iloc[0:k , :]\n",
    "\n",
    "    for i in knn.iloc[:,0]:\n",
    "\n",
    "        Y_values_knn.append(Y.iloc[i , :])\n",
    "\n",
    "    \n",
    "    from itertools import chain\n",
    "\n",
    "    Y_values_knn = list(chain(*Y_values_knn))\n",
    "\n",
    "\n",
    "    prediction = sum(Y_values_knn)/k\n",
    "\n",
    "    message = print( \"KNN algorithm predict y_new =\",  prediction )                                      \n",
    "                                       \n",
    "\n",
    "    return prediction , message  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the KNN_regression function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gender_classification = pd.read_csv('gender_classification.csv')\n",
    "\n",
    "for i in range(0, len(Gender_classification)):\n",
    "\n",
    "    if Gender_classification['gender'][i] == 'Male':\n",
    "\n",
    "        Gender_classification['gender'][i] = 0\n",
    "\n",
    "    elif Gender_classification['gender'][i] == 'Female':\n",
    "\n",
    "        Gender_classification['gender'][i] = 1\n",
    "\n",
    "X = Gender_classification.loc[ : , ['long_hair', 'forehead_height_cm', 'nose_wide', 'nose_long', 'lips_thin', 'distance_nose_to_lip_long', 'gender']]\n",
    "\n",
    "Y = Gender_classification.loc[: , ['forehead_width_cm']]  # forehead_width_cm will be our response in this case, because is quantitative (and  we are now in a regression problem)\n",
    "\n",
    "x_new = pd.Series({'long_hair': 1, 'forehead_height_cm': 6, 'nose_wide': 1 , 'nose_long': 1 , 'nose_long': 1 , 'lips_thin':1, 'distance_nose_to_lip_long': 1 , 'gender': 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN algorithm predict y_new = 13.11\n"
     ]
    }
   ],
   "source": [
    "prediction , message = KNN_regression( X , Y , x_new, k=10, distance = \"Minkowski\" , q = 2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.11"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN algorithm predict y_new = 12.95\n"
     ]
    }
   ],
   "source": [
    "prediction , message = KNN_regression( X , Y , x_new, k=10, distance = \"Minkowski\" , q = 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "single positional indexer is out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Usuario\\Documents\\fabio\\Fabio\\Estadistica4all.github.io\\Notebooks\\KNN\\KNN.ipynb Celda 84\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Usuario/Documents/fabio/Fabio/Estadistica4all.github.io/Notebooks/KNN/KNN.ipynb#Y236sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m prediction , message \u001b[39m=\u001b[39m KNN_regression( X , Y , x_new, k\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, distance \u001b[39m=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mCanberra\u001b[39;49m\u001b[39m\"\u001b[39;49m )\n",
      "\u001b[1;32mc:\\Users\\Usuario\\Documents\\fabio\\Fabio\\Estadistica4all.github.io\\Notebooks\\KNN\\KNN.ipynb Celda 84\u001b[0m in \u001b[0;36mKNN_regression\u001b[1;34m(X, Y, x_new, k, distance, q, p1, p2, p3)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Usuario/Documents/fabio/Fabio/Estadistica4all.github.io/Notebooks/KNN/KNN.ipynb#Y236sZmlsZQ%3D%3D?line=307'>308</a>\u001b[0m knn \u001b[39m=\u001b[39m distances\u001b[39m.\u001b[39miloc[\u001b[39m0\u001b[39m:k , :]\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Usuario/Documents/fabio/Fabio/Estadistica4all.github.io/Notebooks/KNN/KNN.ipynb#Y236sZmlsZQ%3D%3D?line=309'>310</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m knn\u001b[39m.\u001b[39miloc[:,\u001b[39m0\u001b[39m]:\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/Usuario/Documents/fabio/Fabio/Estadistica4all.github.io/Notebooks/KNN/KNN.ipynb#Y236sZmlsZQ%3D%3D?line=311'>312</a>\u001b[0m     Y_values_knn\u001b[39m.\u001b[39mappend(Y\u001b[39m.\u001b[39;49miloc[i , :])\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Usuario/Documents/fabio/Fabio/Estadistica4all.github.io/Notebooks/KNN/KNN.ipynb#Y236sZmlsZQ%3D%3D?line=314'>315</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mitertools\u001b[39;00m \u001b[39mimport\u001b[39;00m chain\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Usuario/Documents/fabio/Fabio/Estadistica4all.github.io/Notebooks/KNN/KNN.ipynb#Y236sZmlsZQ%3D%3D?line=316'>317</a>\u001b[0m Y_values_knn \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(chain(\u001b[39m*\u001b[39mY_values_knn))\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexing.py:961\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    959\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_scalar_access(key):\n\u001b[0;32m    960\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_get_value(\u001b[39m*\u001b[39mkey, takeable\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_takeable)\n\u001b[1;32m--> 961\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_tuple(key)\n\u001b[0;32m    962\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    963\u001b[0m     \u001b[39m# we by definition only have the 0th axis\u001b[39;00m\n\u001b[0;32m    964\u001b[0m     axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39mor\u001b[39;00m \u001b[39m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexing.py:1458\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_tuple\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m   1456\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_getitem_tuple\u001b[39m(\u001b[39mself\u001b[39m, tup: \u001b[39mtuple\u001b[39m):\n\u001b[1;32m-> 1458\u001b[0m     tup \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_tuple_indexer(tup)\n\u001b[0;32m   1459\u001b[0m     \u001b[39mwith\u001b[39;00m suppress(IndexingError):\n\u001b[0;32m   1460\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_lowerdim(tup)\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexing.py:769\u001b[0m, in \u001b[0;36m_LocationIndexer._validate_tuple_indexer\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    767\u001b[0m \u001b[39mfor\u001b[39;00m i, k \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(key):\n\u001b[0;32m    768\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 769\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_key(k, i)\n\u001b[0;32m    770\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m    771\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    772\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mLocation based indexing can only have \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    773\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_valid_types\u001b[39m}\u001b[39;00m\u001b[39m] types\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    774\u001b[0m         ) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexing.py:1361\u001b[0m, in \u001b[0;36m_iLocIndexer._validate_key\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1359\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m   1360\u001b[0m \u001b[39melif\u001b[39;00m is_integer(key):\n\u001b[1;32m-> 1361\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_integer(key, axis)\n\u001b[0;32m   1362\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m   1363\u001b[0m     \u001b[39m# a tuple should already have been caught by this point\u001b[39;00m\n\u001b[0;32m   1364\u001b[0m     \u001b[39m# so don't treat a tuple as a valid indexer\u001b[39;00m\n\u001b[0;32m   1365\u001b[0m     \u001b[39mraise\u001b[39;00m IndexingError(\u001b[39m\"\u001b[39m\u001b[39mToo many indexers\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexing.py:1452\u001b[0m, in \u001b[0;36m_iLocIndexer._validate_integer\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1450\u001b[0m len_axis \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_get_axis(axis))\n\u001b[0;32m   1451\u001b[0m \u001b[39mif\u001b[39;00m key \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m len_axis \u001b[39mor\u001b[39;00m key \u001b[39m<\u001b[39m \u001b[39m-\u001b[39mlen_axis:\n\u001b[1;32m-> 1452\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIndexError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39msingle positional indexer is out-of-bounds\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mIndexError\u001b[0m: single positional indexer is out-of-bounds"
     ]
    }
   ],
   "source": [
    "prediction , message = KNN_regression( X , Y , x_new, k=10, distance = \"Canberra\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([X, x_new.to_frame().T], ignore_index=True)\n",
    "\n",
    "distances = []\n",
    "Y_values_knn = []\n",
    "\n",
    "        def Dist_Canberra_Python(i,j, Quantitative_Data_set):\n",
    "\n",
    "            numerator =  ( Quantitative_Data_set.iloc[i-1, ] - Quantitative_Data_set.iloc[j-1, ] ).abs()  \n",
    "\n",
    "            denominator =  ( (Quantitative_Data_set.iloc[i-1, ]).abs() + (Quantitative_Data_set.iloc[j-1, ]).abs() )\n",
    "       \n",
    "            numerator=np.array([numerator], dtype=float)\n",
    "\n",
    "            denominator=np.array([denominator], dtype=float)\n",
    "\n",
    "            Dist_Canberra = ( np.divide( numerator , denominator , out=np.zeros_like(numerator), where=denominator!=0) ).sum()\n",
    "\n",
    "            return Dist_Canberra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5002"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>long_hair</th>\n",
       "      <th>forehead_height_cm</th>\n",
       "      <th>nose_wide</th>\n",
       "      <th>nose_long</th>\n",
       "      <th>lips_thin</th>\n",
       "      <th>distance_nose_to_lip_long</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>6.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>5.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>6.3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>1</td>\n",
       "      <td>5.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>1</td>\n",
       "      <td>5.7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>1</td>\n",
       "      <td>6.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5000</th>\n",
       "      <td>1</td>\n",
       "      <td>5.4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5001</th>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5002 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      long_hair  forehead_height_cm  nose_wide  nose_long  lips_thin  \\\n",
       "0             1                 6.1          1          0          1   \n",
       "1             0                 5.4          0          0          1   \n",
       "2             0                 6.3          1          1          1   \n",
       "3             0                 6.1          0          1          1   \n",
       "4             1                 5.9          0          0          0   \n",
       "...         ...                 ...        ...        ...        ...   \n",
       "4997          1                 5.4          0          0          0   \n",
       "4998          1                 5.7          0          0          0   \n",
       "4999          1                 6.2          0          0          0   \n",
       "5000          1                 5.4          1          1          1   \n",
       "5001          1                 6.0          1          1          1   \n",
       "\n",
       "      distance_nose_to_lip_long gender  \n",
       "0                             1      0  \n",
       "1                             0      1  \n",
       "2                             1      0  \n",
       "3                             1      0  \n",
       "4                             0      1  \n",
       "...                         ...    ...  \n",
       "4997                          0      1  \n",
       "4998                          0      1  \n",
       "4999                          0      1  \n",
       "5000                          1      0  \n",
       "5001                          1      0  \n",
       "\n",
       "[5002 rows x 7 columns]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_1 = X.iloc[5001, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "long_hair                      1\n",
       "forehead_height_cm           6.0\n",
       "nose_wide                      1\n",
       "nose_long                      1\n",
       "lips_thin                      1\n",
       "distance_nose_to_lip_long      1\n",
       "gender                         0\n",
       "Name: 5001, dtype: object"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_2 = X.iloc[5001, ] + X.iloc[0, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 6., 1., 1., 1., 1., 0.]])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([array_1], dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_1=np.array([array_1], dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_2=np.array([array_2], dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_1=array_1 + 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2. , 12.1,  2. ,  1. ,  2. ,  2. ,  0. ]])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.        , 0.74380165, 2.        , 4.        , 2.        ,\n",
       "        2.        , 0.        ]])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " np.divide(  array_1, array_2 , out=np.zeros_like(array_1 ), where=array_2!=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "long_hair                       2\n",
       "forehead_height_cm           12.1\n",
       "nose_wide                       2\n",
       "nose_long                       1\n",
       "lips_thin                       2\n",
       "distance_nose_to_lip_long       2\n",
       "gender                          0\n",
       "dtype: object"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X.iloc[5001, ]).abs() + (X.iloc[0, ]).abs() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Usuario\\Documents\\fabio\\Fabio\\Estadistica4all.github.io\\Notebooks\\KNN\\KNN.ipynb Celda 88\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Usuario/Documents/fabio/Fabio/Estadistica4all.github.io/Notebooks/KNN/KNN.ipynb#Y246sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m Dist_Canberra_Python( \u001b[39m5002\u001b[39;49m, \u001b[39m1\u001b[39;49m , X)\n",
      "\u001b[1;32mc:\\Users\\Usuario\\Documents\\fabio\\Fabio\\Estadistica4all.github.io\\Notebooks\\KNN\\KNN.ipynb Celda 88\u001b[0m in \u001b[0;36mDist_Canberra_Python\u001b[1;34m(i, j, Quantitative_Data_set)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Usuario/Documents/fabio/Fabio/Estadistica4all.github.io/Notebooks/KNN/KNN.ipynb#Y246sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mDist_Canberra_Python\u001b[39m(i,j, Quantitative_Data_set):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Usuario/Documents/fabio/Fabio/Estadistica4all.github.io/Notebooks/KNN/KNN.ipynb#Y246sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m             Dist_Canberra \u001b[39m=\u001b[39m  ( ( Quantitative_Data_set\u001b[39m.\u001b[39;49miloc[i\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, ] \u001b[39m-\u001b[39;49m Quantitative_Data_set\u001b[39m.\u001b[39;49miloc[j\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, ] )\u001b[39m.\u001b[39;49mabs()  \u001b[39m/\u001b[39;49m ( (Quantitative_Data_set\u001b[39m.\u001b[39;49miloc[i\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, ])\u001b[39m.\u001b[39;49mabs() \u001b[39m+\u001b[39;49m (Quantitative_Data_set\u001b[39m.\u001b[39;49miloc[j\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, ])\u001b[39m.\u001b[39;49mabs() ) )\u001b[39m.\u001b[39msum()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Usuario/Documents/fabio/Fabio/Estadistica4all.github.io/Notebooks/KNN/KNN.ipynb#Y246sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m             \u001b[39mreturn\u001b[39;00m Dist_Canberra\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\ops\\common.py:70\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     66\u001b[0m             \u001b[39mreturn\u001b[39;00m \u001b[39mNotImplemented\u001b[39m\n\u001b[0;32m     68\u001b[0m other \u001b[39m=\u001b[39m item_from_zerodim(other)\n\u001b[1;32m---> 70\u001b[0m \u001b[39mreturn\u001b[39;00m method(\u001b[39mself\u001b[39;49m, other)\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\arraylike.py:124\u001b[0m, in \u001b[0;36mOpsMixin.__truediv__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[39m@unpack_zerodim_and_defer\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m__truediv__\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    123\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__truediv__\u001b[39m(\u001b[39mself\u001b[39m, other):\n\u001b[1;32m--> 124\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_arith_method(other, operator\u001b[39m.\u001b[39;49mtruediv)\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\series.py:5639\u001b[0m, in \u001b[0;36mSeries._arith_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   5637\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_arith_method\u001b[39m(\u001b[39mself\u001b[39m, other, op):\n\u001b[0;32m   5638\u001b[0m     \u001b[39mself\u001b[39m, other \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39malign_method_SERIES(\u001b[39mself\u001b[39m, other)\n\u001b[1;32m-> 5639\u001b[0m     \u001b[39mreturn\u001b[39;00m base\u001b[39m.\u001b[39;49mIndexOpsMixin\u001b[39m.\u001b[39;49m_arith_method(\u001b[39mself\u001b[39;49m, other, op)\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\base.py:1295\u001b[0m, in \u001b[0;36mIndexOpsMixin._arith_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   1292\u001b[0m rvalues \u001b[39m=\u001b[39m ensure_wrapped_if_datetimelike(rvalues)\n\u001b[0;32m   1294\u001b[0m \u001b[39mwith\u001b[39;00m np\u001b[39m.\u001b[39merrstate(\u001b[39mall\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m-> 1295\u001b[0m     result \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39;49marithmetic_op(lvalues, rvalues, op)\n\u001b[0;32m   1297\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_construct_result(result, name\u001b[39m=\u001b[39mres_name)\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py:222\u001b[0m, in \u001b[0;36marithmetic_op\u001b[1;34m(left, right, op)\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    218\u001b[0m     \u001b[39m# TODO we should handle EAs consistently and move this check before the if/else\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     \u001b[39m# (https://github.com/pandas-dev/pandas/issues/41165)\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     _bool_arith_check(op, left, right)\n\u001b[1;32m--> 222\u001b[0m     res_values \u001b[39m=\u001b[39m _na_arithmetic_op(left, right, op)\n\u001b[0;32m    224\u001b[0m \u001b[39mreturn\u001b[39;00m res_values\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py:163\u001b[0m, in \u001b[0;36m_na_arithmetic_op\u001b[1;34m(left, right, op, is_cmp)\u001b[0m\n\u001b[0;32m    160\u001b[0m     func \u001b[39m=\u001b[39m partial(expressions\u001b[39m.\u001b[39mevaluate, op)\n\u001b[0;32m    162\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 163\u001b[0m     result \u001b[39m=\u001b[39m func(left, right)\n\u001b[0;32m    164\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m    165\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_cmp \u001b[39mand\u001b[39;00m (is_object_dtype(left\u001b[39m.\u001b[39mdtype) \u001b[39mor\u001b[39;00m is_object_dtype(right)):\n\u001b[0;32m    166\u001b[0m         \u001b[39m# For object dtype, fallback to a masked operation (only operating\u001b[39;00m\n\u001b[0;32m    167\u001b[0m         \u001b[39m#  on the non-missing values)\u001b[39;00m\n\u001b[0;32m    168\u001b[0m         \u001b[39m# Don't do this for comparisons, as that will handle complex numbers\u001b[39;00m\n\u001b[0;32m    169\u001b[0m         \u001b[39m#  incorrectly, see GH#32047\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:239\u001b[0m, in \u001b[0;36mevaluate\u001b[1;34m(op, a, b, use_numexpr)\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[39mif\u001b[39;00m op_str \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    237\u001b[0m     \u001b[39mif\u001b[39;00m use_numexpr:\n\u001b[0;32m    238\u001b[0m         \u001b[39m# error: \"None\" not callable\u001b[39;00m\n\u001b[1;32m--> 239\u001b[0m         \u001b[39mreturn\u001b[39;00m _evaluate(op, op_str, a, b)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m    240\u001b[0m \u001b[39mreturn\u001b[39;00m _evaluate_standard(op, op_str, a, b)\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:69\u001b[0m, in \u001b[0;36m_evaluate_standard\u001b[1;34m(op, op_str, a, b)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[39mif\u001b[39;00m _TEST_MODE:\n\u001b[0;32m     68\u001b[0m     _store_test_result(\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m---> 69\u001b[0m \u001b[39mreturn\u001b[39;00m op(a, b)\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "Dist_Canberra_Python( 5002, 1 , X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Usuario\\Documents\\fabio\\Fabio\\Estadistica4all.github.io\\Notebooks\\KNN\\KNN.ipynb Celda 86\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Usuario/Documents/fabio/Fabio/Estadistica4all.github.io/Notebooks/KNN/KNN.ipynb#Y245sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39mlen\u001b[39m(X)):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Usuario/Documents/fabio/Fabio/Estadistica4all.github.io/Notebooks/KNN/KNN.ipynb#Y245sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     distances\u001b[39m.\u001b[39mappend( Dist_Canberra_Python( \u001b[39mlen\u001b[39;49m(X), i , X) )\n",
      "\u001b[1;32mc:\\Users\\Usuario\\Documents\\fabio\\Fabio\\Estadistica4all.github.io\\Notebooks\\KNN\\KNN.ipynb Celda 86\u001b[0m in \u001b[0;36mDist_Canberra_Python\u001b[1;34m(i, j, Quantitative_Data_set)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Usuario/Documents/fabio/Fabio/Estadistica4all.github.io/Notebooks/KNN/KNN.ipynb#Y245sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mDist_Canberra_Python\u001b[39m(i,j, Quantitative_Data_set):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Usuario/Documents/fabio/Fabio/Estadistica4all.github.io/Notebooks/KNN/KNN.ipynb#Y245sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m             Dist_Canberra \u001b[39m=\u001b[39m  ( ( Quantitative_Data_set\u001b[39m.\u001b[39;49miloc[i\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, ] \u001b[39m-\u001b[39;49m Quantitative_Data_set\u001b[39m.\u001b[39;49miloc[j\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, ] )\u001b[39m.\u001b[39;49mabs()  \u001b[39m/\u001b[39;49m ( (Quantitative_Data_set\u001b[39m.\u001b[39;49miloc[i\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, ])\u001b[39m.\u001b[39;49mabs() \u001b[39m+\u001b[39;49m (Quantitative_Data_set\u001b[39m.\u001b[39;49miloc[j\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, ])\u001b[39m.\u001b[39;49mabs() ) )\u001b[39m.\u001b[39msum()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Usuario/Documents/fabio/Fabio/Estadistica4all.github.io/Notebooks/KNN/KNN.ipynb#Y245sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m             \u001b[39mreturn\u001b[39;00m Dist_Canberra\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\ops\\common.py:70\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     66\u001b[0m             \u001b[39mreturn\u001b[39;00m \u001b[39mNotImplemented\u001b[39m\n\u001b[0;32m     68\u001b[0m other \u001b[39m=\u001b[39m item_from_zerodim(other)\n\u001b[1;32m---> 70\u001b[0m \u001b[39mreturn\u001b[39;00m method(\u001b[39mself\u001b[39;49m, other)\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\arraylike.py:124\u001b[0m, in \u001b[0;36mOpsMixin.__truediv__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[39m@unpack_zerodim_and_defer\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m__truediv__\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    123\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__truediv__\u001b[39m(\u001b[39mself\u001b[39m, other):\n\u001b[1;32m--> 124\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_arith_method(other, operator\u001b[39m.\u001b[39;49mtruediv)\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\series.py:5639\u001b[0m, in \u001b[0;36mSeries._arith_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   5637\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_arith_method\u001b[39m(\u001b[39mself\u001b[39m, other, op):\n\u001b[0;32m   5638\u001b[0m     \u001b[39mself\u001b[39m, other \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39malign_method_SERIES(\u001b[39mself\u001b[39m, other)\n\u001b[1;32m-> 5639\u001b[0m     \u001b[39mreturn\u001b[39;00m base\u001b[39m.\u001b[39;49mIndexOpsMixin\u001b[39m.\u001b[39;49m_arith_method(\u001b[39mself\u001b[39;49m, other, op)\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\base.py:1295\u001b[0m, in \u001b[0;36mIndexOpsMixin._arith_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   1292\u001b[0m rvalues \u001b[39m=\u001b[39m ensure_wrapped_if_datetimelike(rvalues)\n\u001b[0;32m   1294\u001b[0m \u001b[39mwith\u001b[39;00m np\u001b[39m.\u001b[39merrstate(\u001b[39mall\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m-> 1295\u001b[0m     result \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39;49marithmetic_op(lvalues, rvalues, op)\n\u001b[0;32m   1297\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_construct_result(result, name\u001b[39m=\u001b[39mres_name)\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py:222\u001b[0m, in \u001b[0;36marithmetic_op\u001b[1;34m(left, right, op)\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    218\u001b[0m     \u001b[39m# TODO we should handle EAs consistently and move this check before the if/else\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     \u001b[39m# (https://github.com/pandas-dev/pandas/issues/41165)\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     _bool_arith_check(op, left, right)\n\u001b[1;32m--> 222\u001b[0m     res_values \u001b[39m=\u001b[39m _na_arithmetic_op(left, right, op)\n\u001b[0;32m    224\u001b[0m \u001b[39mreturn\u001b[39;00m res_values\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py:163\u001b[0m, in \u001b[0;36m_na_arithmetic_op\u001b[1;34m(left, right, op, is_cmp)\u001b[0m\n\u001b[0;32m    160\u001b[0m     func \u001b[39m=\u001b[39m partial(expressions\u001b[39m.\u001b[39mevaluate, op)\n\u001b[0;32m    162\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 163\u001b[0m     result \u001b[39m=\u001b[39m func(left, right)\n\u001b[0;32m    164\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m    165\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_cmp \u001b[39mand\u001b[39;00m (is_object_dtype(left\u001b[39m.\u001b[39mdtype) \u001b[39mor\u001b[39;00m is_object_dtype(right)):\n\u001b[0;32m    166\u001b[0m         \u001b[39m# For object dtype, fallback to a masked operation (only operating\u001b[39;00m\n\u001b[0;32m    167\u001b[0m         \u001b[39m#  on the non-missing values)\u001b[39;00m\n\u001b[0;32m    168\u001b[0m         \u001b[39m# Don't do this for comparisons, as that will handle complex numbers\u001b[39;00m\n\u001b[0;32m    169\u001b[0m         \u001b[39m#  incorrectly, see GH#32047\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:239\u001b[0m, in \u001b[0;36mevaluate\u001b[1;34m(op, a, b, use_numexpr)\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[39mif\u001b[39;00m op_str \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    237\u001b[0m     \u001b[39mif\u001b[39;00m use_numexpr:\n\u001b[0;32m    238\u001b[0m         \u001b[39m# error: \"None\" not callable\u001b[39;00m\n\u001b[1;32m--> 239\u001b[0m         \u001b[39mreturn\u001b[39;00m _evaluate(op, op_str, a, b)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m    240\u001b[0m \u001b[39mreturn\u001b[39;00m _evaluate_standard(op, op_str, a, b)\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:69\u001b[0m, in \u001b[0;36m_evaluate_standard\u001b[1;34m(op, op_str, a, b)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[39mif\u001b[39;00m _TEST_MODE:\n\u001b[0;32m     68\u001b[0m     _store_test_result(\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m---> 69\u001b[0m \u001b[39mreturn\u001b[39;00m op(a, b)\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "for i in range(1, len(X)):\n",
    "\n",
    "    distances.append( Dist_Canberra_Python( len(X), i , X) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 6 is different from 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Usuario\\Documents\\fabio\\Fabio\\Estadistica4all.github.io\\Notebooks\\KNN\\KNN.ipynb Celda 85\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Usuario/Documents/fabio/Fabio/Estadistica4all.github.io/Notebooks/KNN/KNN.ipynb#Y240sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m prediction , message \u001b[39m=\u001b[39m KNN_regression( X , Y , x_new, k\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, distance \u001b[39m=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mMahalanobis\u001b[39;49m\u001b[39m\"\u001b[39;49m  )\n",
      "\u001b[1;32mc:\\Users\\Usuario\\Documents\\fabio\\Fabio\\Estadistica4all.github.io\\Notebooks\\KNN\\KNN.ipynb Celda 85\u001b[0m in \u001b[0;36mKNN_regression\u001b[1;34m(X, Y, x_new, k, distance, q, p1, p2, p3)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Usuario/Documents/fabio/Fabio/Estadistica4all.github.io/Notebooks/KNN/KNN.ipynb#Y240sZmlsZQ%3D%3D?line=111'>112</a>\u001b[0m \u001b[39m###################################################################\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Usuario/Documents/fabio/Fabio/Estadistica4all.github.io/Notebooks/KNN/KNN.ipynb#Y240sZmlsZQ%3D%3D?line=113'>114</a>\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39mlen\u001b[39m(X)):\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/Usuario/Documents/fabio/Fabio/Estadistica4all.github.io/Notebooks/KNN/KNN.ipynb#Y240sZmlsZQ%3D%3D?line=115'>116</a>\u001b[0m         distances\u001b[39m.\u001b[39mappend( Dist_Mahalanobis_Python( \u001b[39mlen\u001b[39;49m(X), i , X) )\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Usuario/Documents/fabio/Fabio/Estadistica4all.github.io/Notebooks/KNN/KNN.ipynb#Y240sZmlsZQ%3D%3D?line=118'>119</a>\u001b[0m \u001b[39m###################################################################\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Usuario/Documents/fabio/Fabio/Estadistica4all.github.io/Notebooks/KNN/KNN.ipynb#Y240sZmlsZQ%3D%3D?line=120'>121</a>\u001b[0m \u001b[39mif\u001b[39;00m distance \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mSokal\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "\u001b[1;32mc:\\Users\\Usuario\\Documents\\fabio\\Fabio\\Estadistica4all.github.io\\Notebooks\\KNN\\KNN.ipynb Celda 85\u001b[0m in \u001b[0;36mKNN_regression.<locals>.Dist_Mahalanobis_Python\u001b[1;34m(i, j, Quantitative_Data_set)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Usuario/Documents/fabio/Fabio/Estadistica4all.github.io/Notebooks/KNN/KNN.ipynb#Y240sZmlsZQ%3D%3D?line=100'>101</a>\u001b[0m x \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([x]) \u001b[39m# necessary step to transpose a 1D array\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Usuario/Documents/fabio/Fabio/Estadistica4all.github.io/Notebooks/KNN/KNN.ipynb#Y240sZmlsZQ%3D%3D?line=102'>103</a>\u001b[0m S_inv \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mlinalg\u001b[39m.\u001b[39minv( Quantitative_Data_set\u001b[39m.\u001b[39mcov() ) \u001b[39m# inverse of covariance matrix\u001b[39;00m\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/Usuario/Documents/fabio/Fabio/Estadistica4all.github.io/Notebooks/KNN/KNN.ipynb#Y240sZmlsZQ%3D%3D?line=104'>105</a>\u001b[0m Dist_Maha \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msqrt( x \u001b[39m@\u001b[39;49m S_inv \u001b[39m@\u001b[39m x\u001b[39m.\u001b[39mT )  \u001b[39m# x @ S_inv @ x.T = np.matmul( np.matmul(x , S_inv) , x.T )\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Usuario/Documents/fabio/Fabio/Estadistica4all.github.io/Notebooks/KNN/KNN.ipynb#Y240sZmlsZQ%3D%3D?line=106'>107</a>\u001b[0m Dist_Maha \u001b[39m=\u001b[39m \u001b[39mfloat\u001b[39m(Dist_Maha)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Usuario/Documents/fabio/Fabio/Estadistica4all.github.io/Notebooks/KNN/KNN.ipynb#Y240sZmlsZQ%3D%3D?line=108'>109</a>\u001b[0m \u001b[39mreturn\u001b[39;00m Dist_Maha\n",
      "\u001b[1;31mValueError\u001b[0m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 6 is different from 7)"
     ]
    }
   ],
   "source": [
    "prediction , message = KNN_regression( X , Y , x_new, k=10, distance = \"Mahalanobis\"  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN algorithm predict y_new = 13.11\n"
     ]
    }
   ],
   "source": [
    "prediction , message = KNN_regression( X , Y , x_new, k=10, distance = \"Euclidean\"  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN algorithm predict y_new = 13.820000000000002\n"
     ]
    }
   ],
   "source": [
    "prediction , message = KNN_regression( X , Y , x_new, k=10, distance = \"Pearson\"  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliography\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c63d8c7d738c2960218a10995aedf0a7f67a49a231e71037adf0440953cdb45b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
