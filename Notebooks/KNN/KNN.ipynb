{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN for supervised classification   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have $\\hspace{0.1cm} p \\hspace{0.1cm}$ variables $\\hspace{0.1cm} X=(X_1,...,X_p) \\hspace{0.1cm}$ measurements on a $n$ size sample\n",
    "\n",
    "\n",
    "Also we have a categorical variable $\\hspace{0.1cm} Y \\hspace{0.1cm}$ with $\\hspace{0.1cm} g \\hspace{0.1cm}$  categories that indicates  the group to which each element of the sample belongs  $ ( \\hspace{0.05cm} Range(Y)=\\lbrace c_1 ,..., c_g \\rbrace \\hspace{0.05cm})$\n",
    "\n",
    "The groups generated by $\\hspace{0.1cm} Y \\hspace{0.1cm}$ are denoted as $\\hspace{0.1cm} \\Omega_1 ,..., \\Omega_g$\n",
    "\n",
    "If $\\hspace{0.15cm} y_i = c_r \\hspace{0.15cm} \\Rightarrow \\hspace{0.15cm}$ the individual $\\hspace{0.05cm} i \\hspace{0.05cm}$ (associated to $x_i$ observation) belongs to the group $\\hspace{0.1cm} \\Omega_r$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The supervised classification problem consists in, for a new observation $\\hspace{0.1cm} x_{new} = (x_{new,1},x_{new,2},...,x_{new,p}) \\hspace{0.1cm}$, predict its $\\hspace{0.1cm} Y \\hspace{0.1cm}$ value $\\hspace{0.1cm} (y_{new})\\hspace{0.1cm}$  using $\\hspace{0.1cm} X_1,...,X_p \\hspace{0.1cm}$\n",
    "\n",
    "So , the problem is to classify a new element/individual in one of the $\\hspace{0.1cm} g \\hspace{0.1cm}$ groups generated by $\\hspace{0.1cm} Y \\hspace{0.1cm}$ using the information available of $\\hspace{0.1cm} X_1,...,X_p \\hspace{0.1cm}$ and its observation of that variables $\\hspace{0.1cm} x_{new} = (x_{new,1},x_{new,2},...,x_{new,p})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The KNN (K-nearest neighbors) algorithm have the following steps:\n",
    "\n",
    "1. Define a distance measure between the observation of the original sample respect to the variables $X_1,...,X_p$ $\\hspace{0.15cm} \\Rightarrow \\hspace{0.15cm}$ $\\delta$\n",
    "\n",
    "\n",
    "\n",
    "2. Compute the distances between $x_{new}$ and the initial observations $\\lbrace x_1,...,x_n \\rbrace$ $\\hspace{0.15cm} \\Rightarrow \\hspace{0.15cm}$ $\\lbrace \\delta(x_{new}, x_i) / i=1,...,n \\rbrace$\n",
    "\n",
    "  \n",
    "3. Select the  $k$ nearest observation to $x_{new}$ based on $\\hspace{0.05cm} \\delta \\hspace{0.1cm}$ ($k$ nearest neighbors of $x_{new}$) $\\hspace{0.15cm} \\Rightarrow \\hspace{0.15cm}$   The set of these observation will be denote by $KNN$ \n",
    "\n",
    "4. Compute the proportion of these observation (neighbors) that belongs to each group $\\hspace{0.15cm} \\Rightarrow \\hspace{0.15cm}$  The proportion of $KNN$ that belongs to the group $\\hspace{0.15cm} \\Omega_j$ $\\hspace{0.1cm}(Y=c_j)\\hspace{0.1cm}$ will be denote by $\\hspace{0.1 cm} f^{knn}_{j} = \\dfrac{\\text{nÂº of KNN in group} \\hspace{0.1 cm} \\Omega_j \\hspace{0.1 cm} ( \\text{with} \\hspace{0.1 cm} Y=c_j)}{k} $\n",
    "   \n",
    "5. Classify $x_new$ in that group such has a bigger neighbors proportion $\\hspace{0.15cm} \\Rightarrow \\hspace{0.15cm}$ If $f^{knn}_{s} > f^{knn}_{r} \\hspace{0.1cm}$   $\\hspace{0.1cm} \\forall r = 1,...,g \\hspace{0.1cm}  \\Rightarrow \\hspace{0.1cm} x_{new} \\hspace{0.1cm}$ is classify in $\\hspace{0.1cm} \\Omega_s$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Toy example:\n",
    "\n",
    "Sample: $n=3$\n",
    "\n",
    "Predictors:\n",
    "\n",
    "$X1 = (10 , 2 , 4)$\n",
    "$X2 = (20 , 25, 40)$\n",
    "\n",
    "Observations:\n",
    "\n",
    "$x_1 =(10,20)$\n",
    "$x_2=(2,25)$\n",
    "$x_3=(4,40)$\n",
    "\n",
    "Response: (2 categories (0,1), then 2 groups $\\Omega_0 , \\Omega_1$)\n",
    "\n",
    "$Y =( 1 , 1 , 0 )$\n",
    "\n",
    "Distance $\\hspace{0.15cm} \\Rightarrow \\hspace{0.15cm}$  $ \\delta_{Euclidean}$\n",
    "\n",
    "New observation:\n",
    "\n",
    "$x_{new}=(6, 20)$\n",
    "\n",
    "Computing the distances:\n",
    "\n",
    "$\\delta(x_{new}, x_1)_{Euclidean} = (10-6)^2 + (20-20)^2 = 16$\n",
    "$\\delta(x_{new}, x_2)_{Euclidean} = (2-6)^2 + (25-20)^2 = 16 + 25 = 41$\n",
    "$\\delta(x_{new}, x_3)_{Euclidean} = (4-6)^2 + (40-20)^2 = 4 + 400 = 404$\n",
    "\n",
    "Selecting k=2 nearest neighbor to $x_{new}$: $x_1$ and $x_2$\n",
    "\n",
    "Computing the proportions $f^{knn}$ : $f^{knn}_0 =  0/2 = 0$ , $f^{knn}_1 =  2/2 = 1$\n",
    "\n",
    "So, the algorithm classify $x_new$ in the group $\\Omega_1$ , so the algorithm predict that $y_{new} = 1$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why this is a supervised classification method and not an unsupervised"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimal k (ver Aurea)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN para regresion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c63d8c7d738c2960218a10995aedf0a7f67a49a231e71037adf0440953cdb45b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
