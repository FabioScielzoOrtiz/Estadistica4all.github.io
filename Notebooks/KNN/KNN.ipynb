{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN in `Python`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [KNN for supervised classification   ](#1)\n",
    "* * [Toy example](#2)\n",
    "* * [ KNN for supervised classification in `Python` with `Sklearn`](#3)\n",
    "* * [ KNN for classification in `Python` with own algorithm](#4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [KNN for regression](#5)\n",
    "* * [KNN for regression in `Python` with `Sklearn`](#6)\n",
    "* * [KNN for regression in Python with own algorithm](#7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Selecting an optimal k with cross-validation](#8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN for supervised classification <a class=\"anchor\" id=\"1\"></a>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We have $\\hspace{0.1cm} p \\hspace{0.1cm}$ variables $\\hspace{0.1cm} X=(X_1,...,X_p) \\hspace{0.1cm}$ measurements on a $n$ size sample.\n",
    "\n",
    "- We also have a **categorical** response variable $\\hspace{0.1cm} Y \\hspace{0.1cm}$ with $\\hspace{0.1cm} g \\hspace{0.1cm}$  categories that indicates  the group to which each element of the sample belongs  $ ( \\hspace{0.05cm} Range(Y)=\\lbrace c_1 ,..., c_g \\rbrace \\hspace{0.05cm})$\n",
    "\n",
    "- The groups generated by $\\hspace{0.1cm} Y \\hspace{0.1cm}$ are denoted as $\\hspace{0.1cm} \\Omega_1 ,..., \\Omega_g \\hspace{0.15cm}$   $\\hspace{0.15cm}( \\hspace{0.1cm} y_i = c_r \\hspace{0.15cm} \\Leftrightarrow \\hspace{0.15cm}$  $ i \\in \\Omega_r \\hspace{0.1cm})$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The supervised classification problem consists in, for a new observation  of the variables $X_1,...,X_p  \\hspace{0.1cm}$, $\\hspace{0.1cm} x_{new} = (x_{new,1}\\hspace{0.1cm},\\hspace{0.1cm}x_{new,2}\\hspace{0.1cm},\\dots,\\hspace{0.1cm}x_{new,p}) \\hspace{0.1cm}$, predict it's $\\hspace{0.1cm} Y \\hspace{0.1cm}$ value $\\hspace{0.1cm} (y_{new})\\hspace{0.1cm}$  using the available information of $\\hspace{0.1cm} X_1,...,X_p \\hspace{0.1cm}$ and $ \\hspace{0.1cm} Y$\n",
    "\n",
    "So , the problem is to classify a new element/individual in one of the $\\hspace{0.1cm} g \\hspace{0.1cm}$ groups generated by $\\hspace{0.1cm} Y \\hspace{0.1cm}$ using the information available of $\\hspace{0.1cm} X_1,...,X_p \\hspace{0.1cm}$ and $Y$, and also  $\\hspace{0.1cm} x_{new} = (x_{new,1}\\hspace{0.1cm},\\hspace{0.1cm}x_{new,2}\\hspace{0.1cm},\\dots,\\hspace{0.1cm}x_{new,p}) \\hspace{0.1cm}$\n",
    "\n",
    "Note that if we haven't information about $\\hspace{0.1cm} Y \\hspace{0.1cm}$ this would be an unsupervised classification problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The KNN (K-nearest neighbors) algorithm for supervised classification have the following steps:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " $1. \\hspace{0.15cm}$ Define a **distance** measure between the observations of the original sample respect to the variables $X_1,...,X_p$ $\\hspace{0.15cm} \\Rightarrow \\hspace{0.15cm}$ $\\delta$\n",
    "\n",
    "\n",
    "\n",
    " $2. \\hspace{0.15cm}$ Compute the distances between $\\hspace{0.1 cm}x_{new}\\hspace{0.1 cm}$ and the initial observations $\\hspace{0.1cm} \\lbrace x_1,...,x_n \\rbrace$ $\\hspace{0.15cm} \\Rightarrow \\hspace{0.15cm}$ $\\lbrace \\hspace{0.1 cm}  \\delta(x_{new}\\hspace{0.03 cm},\\hspace{0.03 cm} x_i) \\hspace{0.1 cm} / \\hspace{0.1 cm}  i=1,...,n \\hspace{0.1 cm}  \\rbrace$\n",
    "\n",
    "  \n",
    " $3. \\hspace{0.15cm}$ Select the  $\\hspace{0.03 cm} k \\hspace{0.03 cm}$ nearest observation to $\\hspace{0.06 cm} x_{new}\\hspace{0.06 cm}$ based on $\\hspace{0.05cm} \\delta \\hspace{0.12cm}$ $(k$ nearest neighbors of $x_{new})$ $\\hspace{0.15cm} \\Rightarrow \\hspace{0.15cm}$   The set of these observation will be denote by $KNN$ \n",
    "\n",
    " $4. \\hspace{0.15cm}$ Compute the proportion of these observation (neighbors) that belongs to each group $\\hspace{0.15cm} \\Rightarrow \\hspace{0.15cm}$  \n",
    " \n",
    " $\\hspace{0.65cm} \\Rightarrow \\hspace{0.15cm}$ The proportion of $KNN$ that belongs to the group $\\hspace{0.15cm} \\Omega_r$ $\\hspace{0.1cm}(Y=c_r)\\hspace{0.1cm}$ will be denote by $\\hspace{0.1 cm} f^{knn}_{r}  $\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "   $$ \\hspace{0.1 cm} f^{knn}_{r} \\hspace{0.15cm}=\\hspace{0.15cm} \\dfrac{ \\# \\hspace{0.1cm}\\lbrace\\hspace{0.1cm} i \\in KNN \\hspace{0.1cm}/\\hspace{0.1cm} i \\in \\Omega_r \\hspace{0.1cm}\\rbrace  }{\\# \\hspace{0.1cm} KNN = k} $$\n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$5. \\hspace{0.15cm}$ Classify $\\hspace{0.1cm} x_{new} \\hspace{0.1cm}$ in that group such has a bigger nearest neighbors proportion $\\hspace{0.18cm} \\Rightarrow \\hspace{0.2cm}$ $\\text{If}   \\hspace{0.15cm} \\underbrace{ f^{knn}_{s} \\geqslant f^{knn}_{r} \\hspace{0.15cm},\\hspace{0.15cm} \\forall r = 1,...,g  }_{\\Omega_s \\hspace{0.1cm}\\text{is the most frequent group in}\\hspace{0.1cm} KNN } $    $\\hspace{0.1cm} \\hspace{0.15cm}  \\Rightarrow \\hspace{0.15cm} x_{new} \\hspace{0.1cm}$ is classify in $\\hspace{0.1cm} \\Omega_s$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why KNN is a supervised classification method and not an unsupervised ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Because in this problem we have a vector of observations of the response variable $Y$\n",
    "\n",
    "The fact that we haven't $\\hspace{0.1 cm} y_{new} \\hspace{0.1 cm}$ doesn't transform it in a unsupervised problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Toy example <a class=\"anchor\" id=\"2\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Sample: $n=3$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Predictors:\n",
    "\n",
    "$X1 = (10 , 2 , 4)$\n",
    "\n",
    "$X2 = (20 , 25, 40)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Observations:\n",
    "\n",
    "$x_1 =(10,20)$\n",
    "\n",
    "$x_2=(2,25)$\n",
    "\n",
    "$x_3=(4,40)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Response: $\\hspace{0.1cm}(2$ categories $(0,1)$, then $2$ groups $\\hspace{0.1cm}\\Omega_0 , \\Omega_1)$\n",
    "\n",
    "$Y =( 1 , 1 , 0 )$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Distance $\\hspace{0.15cm} \\Rightarrow \\hspace{0.15cm}$  $ \\delta_{Euclidean}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- New observation:  \n",
    "\n",
    "$x_{new}=(6, 20)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Computing the distances:\n",
    "\n",
    "$\\delta(x_{new}, x_1)_{Euclidean} = (10-6)^2 + (20-20)^2 = 16$\n",
    "\n",
    "$\\delta(x_{new}, x_2)_{Euclidean} = (2-6)^2 + (25-20)^2 = 16 + 25 = 41$\n",
    "\n",
    "$\\delta(x_{new}, x_3)_{Euclidean} = (4-6)^2 + (40-20)^2 = 4 + 400 = 404$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Selecting $\\hspace{0.05cm} k=2 \\hspace{0.05cm}$ nearest neighbor to $\\hspace{0.05cm}x_{new}$ $\\hspace{0.2cm}\\Rightarrow\\hspace{0.215cm}$ $ KNN \\hspace{0.01cm}=\\hspace{0.01cm} \\lbrace\\hspace{0.1cm} x_1 , x_2 \\hspace{0.1cm}\\rbrace \\hspace{0.01cm}=\\hspace{0.01cm} \\lbrace \\hspace{0.1cm} individual 1 , individual 2  \\hspace{0.1cm}\\rbrace $\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Computing the proportions $f^{knn}$ : \n",
    "\n",
    "Note that $\\hspace{0.1cm} y_1 = 1 \\hspace{0.1cm}$ and $ \\hspace{0.1cm} y_2 = 1\\hspace{0.2cm} \\Rightarrow \\hspace{0.2cm} f^{knn}_0 =  0/2 = 0\\hspace{0.1cm} $ and $\\hspace{0.1cm} f^{knn}_1 =  2/2 = 1$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- So, the algorithm classify $x_{new}$ in the group $\\Omega_1$ , so the algorithm predict that $\\hat{y}_{new} = 1$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN for supervised classification in `Python` with `sklearn`<a class=\"anchor\" id=\"3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gender_classification = pd.read_csv('gender_classification.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>long_hair</th>\n",
       "      <th>forehead_width_cm</th>\n",
       "      <th>forehead_height_cm</th>\n",
       "      <th>nose_wide</th>\n",
       "      <th>nose_long</th>\n",
       "      <th>lips_thin</th>\n",
       "      <th>distance_nose_to_lip_long</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>11.8</td>\n",
       "      <td>6.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>5.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>11.8</td>\n",
       "      <td>6.3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>14.4</td>\n",
       "      <td>6.1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13.5</td>\n",
       "      <td>5.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   long_hair  forehead_width_cm  forehead_height_cm  nose_wide  nose_long  \\\n",
       "0          1               11.8                 6.1          1          0   \n",
       "1          0               14.0                 5.4          0          0   \n",
       "2          0               11.8                 6.3          1          1   \n",
       "3          0               14.4                 6.1          0          1   \n",
       "4          1               13.5                 5.9          0          0   \n",
       "\n",
       "   lips_thin  distance_nose_to_lip_long  gender  \n",
       "0          1                          1    Male  \n",
       "1          1                          0  Female  \n",
       "2          1                          1    Male  \n",
       "3          1                          1    Male  \n",
       "4          0                          0  Female  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Gender_classification.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Gender_classification.iloc[ : , 0:7]\n",
    "\n",
    "Y = Gender_classification.iloc[ : , 7]\n",
    "\n",
    "x_new = [1,\t10, 5, 1, 0, 1,\t1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = sklearn.neighbors.KNeighborsClassifier(n_neighbors=10 ,  weights='uniform', p=2, metric='minkowski')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's advisable  to see the sklearn documentation first: https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=10)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Male']\n"
     ]
    }
   ],
   "source": [
    "print( knn.predict( [x_new] ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.2 0.8]]\n"
     ]
    }
   ],
   "source": [
    "print( knn.predict_proba([x_new]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With other distances:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = sklearn.neighbors.KNeighborsClassifier(n_neighbors=10 ,  weights='uniform',  metric='cityblock')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Male']\n",
      "[[0.1 0.9]]\n"
     ]
    }
   ],
   "source": [
    "knn.fit(X, Y)\n",
    "\n",
    "print( knn.predict( [x_new] ) )\n",
    " \n",
    "print( knn.predict_proba([x_new]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = sklearn.neighbors.KNeighborsClassifier(n_neighbors=10 ,  weights='uniform', metric='cosine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Male']\n",
      "[[0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "knn.fit(X, Y)\n",
    "\n",
    "print( knn.predict( [x_new] ) ) \n",
    "\n",
    "print( knn.predict_proba([x_new]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = sklearn.neighbors.KNeighborsClassifier(n_neighbors=10 ,  weights='uniform', metric='nan_euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Male']\n",
      "[[0.2 0.8]]\n"
     ]
    }
   ],
   "source": [
    "knn.fit(X, Y)\n",
    "\n",
    "print( knn.predict( [x_new] ) ) \n",
    "\n",
    "print( knn.predict_proba([x_new]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = sklearn.neighbors.KNeighborsClassifier(n_neighbors=10 ,  weights='uniform', metric='manhattan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Male']\n",
      "[[0.1 0.9]]\n"
     ]
    }
   ],
   "source": [
    "knn.fit(X, Y)\n",
    "\n",
    "print( knn.predict( [x_new] ) ) \n",
    "\n",
    "print( knn.predict_proba([x_new]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN for classification in `Python` with own algorithm <a class=\"anchor\" id=\"4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to develop our own algorithm so as not to depend on sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN_classification( X , Y , x_new, k, distance = \"Minkowski\" , q=0, p1=0, p2=0, p3=0 ):\n",
    "\n",
    "####################################################################################################################################################################################################################################################\n",
    "\n",
    "    # Y tiene que ser una variable categorica con categorias estandar (0,1,2,...)\n",
    "\n",
    "    # Ejemplo de Y :  Y = Gender_classification.iloc[0:20 , 7]\n",
    "\n",
    "    # Ejemplo de como codificar Y en categorias estandar (si ya esta en el formato estandar indicado no hace falta):\n",
    "      \n",
    "      # for i in range(0, len(Y)):\n",
    "          # if Y[i]=='Male':\n",
    "          #   Y[i] = 0\n",
    "          # elif Y[i]=='Female':\n",
    "          #   Y[i]=1\n",
    "\n",
    "    # X tiene que ser un panda data frame con los predictotres (X1,...,Xp). Ejemplo X = Gender_classification.iloc[0:20 , 0:7]\n",
    "\n",
    "    # x_new tiene que ser una panda series. Ejemplo x_new = pd.Series({'long_hair': 1, 'forehead_width_cm': 4, 'forehead_height_cm': 6, 'nose_wide': 1 , 'nose_long': 1 , 'nose_long': 1 , 'lips_thin':1, 'distance_nose_to_lip_long': 1 })\n",
    "\n",
    "####################################################################################################################################################################################################################################################\n",
    "\n",
    "    X = pd.concat([X, x_new.to_frame().T], ignore_index=True)\n",
    "\n",
    "    distances = []\n",
    "\n",
    "    groups_knn = []\n",
    "\n",
    "\n",
    "####################################################################################################################################################################################################################################################\n",
    "    \n",
    "    if distance == \"Euclidean\":\n",
    "\n",
    "        def Dist_Euclidea_Python(i, j, Quantitative_Data_set): \n",
    "\n",
    "            Dist_Euclidea = ( ( Quantitative_Data_set.iloc[i-1, ] - Quantitative_Data_set.iloc[j-1, ] )**2 ).sum()\n",
    "\n",
    "            Dist_Euclidea = np.sqrt(Dist_Euclidea)\n",
    "\n",
    "            return Dist_Euclidea\n",
    "\n",
    "    ###################################################################\n",
    "\n",
    "        for i in range(1, len(X)):\n",
    "\n",
    "            distances.append( Dist_Euclidea_Python( len(X), i , X) )\n",
    "\n",
    "    ###################################################################\n",
    "\n",
    "    if distance == \"Minkowski\":\n",
    "\n",
    "        def Dist_Minkowski_Python(i,j, q , Quantitative_Data_set):\n",
    "\n",
    "            Dist_Minkowski = ( ( ( ( Quantitative_Data_set.iloc[i-1, ] - Quantitative_Data_set.iloc[j-1, ] ).abs() )**q ).sum() )**(1/q)\n",
    "\n",
    "            return Dist_Minkowski\n",
    "\n",
    "    ###################################################################\n",
    "\n",
    "        for i in range(1, len(X)):\n",
    "\n",
    "            distances.append( Dist_Minkowski_Python( len(X), i , q , X) )\n",
    "\n",
    "        \n",
    "\n",
    "    ###################################################################\n",
    "\n",
    "    if distance == \"Canberra\":\n",
    "\n",
    "        def Dist_Canberra_Python(i,j, Quantitative_Data_set):\n",
    "\n",
    "            numerator =  ( Quantitative_Data_set.iloc[i-1, ] - Quantitative_Data_set.iloc[j-1, ] ).abs()  \n",
    "\n",
    "            denominator =  ( (Quantitative_Data_set.iloc[i-1, ]).abs() + (Quantitative_Data_set.iloc[j-1, ]).abs() )\n",
    "       \n",
    "            numerator=np.array([numerator], dtype=float)\n",
    "\n",
    "            denominator=np.array([denominator], dtype=float)\n",
    "\n",
    "            Dist_Canberra = ( np.divide( numerator , denominator , out=np.zeros_like(numerator), where=denominator!=0) ).sum()\n",
    "\n",
    "            return Dist_Canberra\n",
    "\n",
    "    ###################################################################\n",
    "    \n",
    "        for i in range(1, len(X)):\n",
    "\n",
    "            distances.append( Dist_Canberra_Python( len(X), i , X) )\n",
    "\n",
    "    ###################################################################\n",
    "   \n",
    "    if distance == \"Pearson\":\n",
    "\n",
    "        def Dist_Pearson_Python(i, j, Quantitative_Data_set):\n",
    "\n",
    "            Dist_Pearson = ( ( Quantitative_Data_set.iloc[i-1, ] - Quantitative_Data_set.iloc[j-1, ] )**2 / Quantitative_Data_set.var() ).sum()\n",
    "\n",
    "            Dist_Pearson = np.sqrt(Dist_Pearson)\n",
    "\n",
    "            return Dist_Pearson\n",
    "\n",
    "    ###################################################################\n",
    "\n",
    "        for i in range(1, len(X)):\n",
    "\n",
    "            distances.append( Dist_Pearson_Python( len(X), i , X) )\n",
    "\n",
    "    ###################################################################\n",
    "    \n",
    "    if distance == \"Mahalanobis\":\n",
    "\n",
    "        def Dist_Mahalanobis_Python(i, j, Quantitative_Data_set):\n",
    "\n",
    "            # All the columns of Quantitative_Data_set must be type = 'float' or 'int' (specially not 'object'), in other case we will find \n",
    "            # dimensional problems when Python compute   x @ S_inv @ x.T\n",
    "\n",
    "            x = (Quantitative_Data_set.to_numpy()[i-1, ] - Quantitative_Data_set.to_numpy()[j-1, ])\n",
    "\n",
    "            x = np.array([x]) # necessary step to transpose a 1D array\n",
    "\n",
    "            S_inv = np.linalg.inv( Quantitative_Data_set.cov() ) # inverse of covariance matrix\n",
    "\n",
    "            Dist_Maha = np.sqrt( x @ S_inv @ x.T )  # x @ S_inv @ x.T = np.matmul( np.matmul(x , S_inv) , x.T )\n",
    "\n",
    "            Dist_Maha = float(Dist_Maha)\n",
    "\n",
    "            return Dist_Maha\n",
    "\n",
    "        \n",
    "    ###################################################################\n",
    "\n",
    "        for i in range(1, len(X)):\n",
    "\n",
    "            distances.append( Dist_Mahalanobis_Python( len(X), i , X) )\n",
    "\n",
    "       \n",
    "\n",
    "    ###################################################################\n",
    "    \n",
    "    if distance == \"Sokal\":\n",
    "\n",
    "        a = X @ X.T\n",
    "        n = X.shape[0]\n",
    "        p = X.shape[1]\n",
    "        ones_matrix = np.ones((n, p))\n",
    "        b = (ones_matrix - X) @ X.T\n",
    "        c = b.T\n",
    "        d = (ones_matrix - X) @ (ones_matrix - X).T\n",
    "\n",
    "        def Sokal_Similarity_Py(i, j):\n",
    "\n",
    "            Sokal_Similarity = (a.iloc[i-1,j-1] + d.iloc[i-1,j-1])/p\n",
    "\n",
    "            return Sokal_Similarity\n",
    "\n",
    "\n",
    "        def Dist_Sokal_Python(i, j, Binary_Data_set):\n",
    "\n",
    "            dist_Sokal = np.sqrt( 2 - 2*Sokal_Similarity_Py(i,j, Binary_Data_set) )\n",
    "\n",
    "            return dist_Sokal\n",
    "\n",
    "    ###################################################################\n",
    "\n",
    "        for i in range(1, len(X)):\n",
    "\n",
    "            distances.append( Dist_Sokal_Python( len(X), i , X) )\n",
    "\n",
    "    ###################################################################\n",
    "   \n",
    "    if distance == \"Jaccard\":\n",
    "\n",
    "        def Jaccard_Similarity_Py(i, j, Binary_Data_Matrix):\n",
    "\n",
    "            X = Binary_Data_Py\n",
    "            a = X @ X.T\n",
    "            n = X.shape[0]\n",
    "            p = X.shape[1]\n",
    "            ones_matrix = np.ones((n, p)) \n",
    "            b = (ones_matrix - X) @ X.T\n",
    "            c = b.T\n",
    "            d = (ones_matrix - X) @ (ones_matrix - X).T\n",
    "\n",
    "            Jaccard_Similarity = a.iloc[i-1,j-1] / (a.iloc[i-1,j-1] + b.iloc[i-1,j-1] + c.iloc[i-1,j-1])\n",
    "            \n",
    "            return Jaccard_Similarity\n",
    "\n",
    "\n",
    "        def Dist_Jaccard_Python(i, j, Binary_Data_set):\n",
    "\n",
    "            dist_Jaccard = np.sqrt( Jaccard_Similarity_Py(i,i, Binary_Data_set) + Jaccard_Similarity_Py(i,i, Binary_Data_set) - 2*Jaccard_Similarity_Py(i,j, Binary_Data_set) )\n",
    "\n",
    "            return dist_Jaccard\n",
    "\n",
    "    ###################################################################\n",
    "\n",
    "        for i in range(1, len(X)):\n",
    "\n",
    "            distances.append( Dist_Jaccard_Python( len(X), i , X) )\n",
    "\n",
    "    ###################################################################\n",
    "    \n",
    "    if distance == \"Matches\":\n",
    "\n",
    "        def alpha_py(i,j, Multiple_Categorical_Data):\n",
    "\n",
    "            X = Multiple_Categorical_Data\n",
    "            alpha = np.repeat(0, X.shape[1])\n",
    "\n",
    "            for k in range(0, X.shape[1]) :\n",
    "\n",
    "                if X.iloc[i-1, k] == X.iloc[j-1, k] :\n",
    "\n",
    "                    alpha[k] = 1\n",
    "\n",
    "                else :\n",
    "\n",
    "                    alpha[k] = 0\n",
    "\n",
    "            alpha = alpha.sum()\n",
    "\n",
    "            return(alpha)\n",
    "\n",
    "\n",
    "        def matches_similarity_py(i, j, Multiple_Categorical_Data):\n",
    "\n",
    "            p = Multiple_Categorical_Data.shape[1]\n",
    "\n",
    "            matches_similarity = alpha_py(i,j, Multiple_Categorical_Data) / p\n",
    "\n",
    "            return(matches_similarity)\n",
    "\n",
    "\n",
    "        def Dist_Matches_Py(i,j, Multiple_Categorical_Data):\n",
    "\n",
    "            Dist_Matches = np.sqrt( matches_similarity_py(i, i, Multiple_Categorical_Data) +  matches_similarity_py(j, j, Multiple_Categorical_Data) - 2*matches_similarity_py(i, j, Multiple_Categorical_Data) )\n",
    "\n",
    "            return( Dist_Matches )\n",
    "\n",
    "    ###################################################################\n",
    "\n",
    "        for i in range(1, len(X)):\n",
    "\n",
    "            distances.append( Dist_Matches_Py( len(X), i , X) )\n",
    "\n",
    "    ###################################################################\n",
    "   \n",
    "    if distance == \"Gower\":\n",
    "\n",
    "            \n",
    "        def a(Binary_Data) :\n",
    "\n",
    "            X = Binary_Data\n",
    "\n",
    "            a = X @ X.T\n",
    "\n",
    "            return(a)\n",
    "\n",
    "##########################################################################################\n",
    "\n",
    "        def d(Binary_Data):\n",
    "\n",
    "            X = Binary_Data\n",
    "\n",
    "            ones_matrix = np.ones(( X.shape[0] , X.shape[1])) \n",
    "\n",
    "            d = (ones_matrix - X) @ (ones_matrix - X).T\n",
    "\n",
    "            return(d)\n",
    "\n",
    "##########################################################################################\n",
    "\n",
    "        def alpha_py(i,j, Multiple_Categorical_Data):\n",
    "\n",
    "                X = Multiple_Categorical_Data\n",
    "\n",
    "                alpha = np.repeat(0, X.shape[1])\n",
    "\n",
    "                for k in range(0, X.shape[1]) :\n",
    "\n",
    "                    if X.iloc[i-1, k] == X.iloc[j-1, k] :\n",
    "\n",
    "                        alpha[k] = 1\n",
    "\n",
    "                    else :\n",
    "\n",
    "                        alpha[k] = 0\n",
    "\n",
    "\n",
    "                alpha = alpha.sum()\n",
    "\n",
    "                return(alpha)\n",
    "\n",
    "   ##########################################################################################\n",
    "\n",
    "\n",
    "        def Gower_Similarity_Python(i,j, Mixed_Data_Set, p1, p2, p3):\n",
    "\n",
    "            X = Mixed_Data_Set\n",
    "\n",
    "   # The data matrix X have to be order in the following way:\n",
    "   # The p1 first are quantitative, the following p2 are binary categorical, and the following p3 are multiple categorical.\n",
    "\n",
    "   #####################################################################################\n",
    "        \n",
    "            def G(k, X):\n",
    "\n",
    "                range = X.iloc[:,k].max() - X.iloc[:,k].min() \n",
    "\n",
    "                return(range)\n",
    "\n",
    "            G_vector = np.repeat(0, p1)\n",
    "\n",
    "            for r in range(0, p1):\n",
    "\n",
    "                G_vector[r] = G(r, X)\n",
    "                \n",
    "      \n",
    "    ##########################################################################################\n",
    "    \n",
    "            ones = np.repeat(1, p1)\n",
    "\n",
    "            Quantitative_Data = X.iloc[: , 0:p1]\n",
    "\n",
    "            Binary_Data = X.iloc[: , (p1):(p1+p2)]\n",
    "            \n",
    "            Multiple_Categorical_Data = X.iloc[: , (p1+p2):(p1+p2+p3) ]\n",
    "\n",
    "    ##########################################################################################\n",
    "\n",
    "            numerator_part_1 = ( ones - ( (Quantitative_Data.iloc[i-1,:] - Quantitative_Data.iloc[j-1,:]).abs() / G_vector ) ).sum() \n",
    "\n",
    "            numerator_part_2 = a(Binary_Data).iloc[i-1,j-1] + alpha_py(i,j, Multiple_Categorical_Data)\n",
    "\n",
    "            numerator = numerator_part_1 + numerator_part_2\n",
    " \n",
    "            denominator = p1 + (p2 - d(Binary_Data).iloc[i-1,j-1]) + p3\n",
    "\n",
    "            Similarity_Gower = numerator / denominator  \n",
    "\n",
    "            return(Similarity_Gower)\n",
    "\n",
    "##########################################################################################\n",
    "\n",
    "        def Dist_Gower_Py(i, j, Mixed_Data , p1, p2, p3):\n",
    "\n",
    "            Dist_Gower = np.sqrt( 1 - Gower_Similarity_Python(i, j, Mixed_Data , p1, p2, p3) )\n",
    "\n",
    "            return(Dist_Gower)    \n",
    "\n",
    "    ###################################################################\n",
    "\n",
    "        for i in range(1, len(X)):\n",
    "\n",
    "            distances.append( Dist_Gower_Py( len(X), i , X, p1, p2, p3) )    \n",
    "\n",
    "######################################################################################################################################\n",
    "    \n",
    "    \n",
    "    if distance == \"Gower-BM\":\n",
    "\n",
    "        def a(Binary_Data) :\n",
    "\n",
    "            X = Binary_Data\n",
    "\n",
    "            a = X @ X.T\n",
    "\n",
    "            return(a)\n",
    "\n",
    "##########################################################################################\n",
    "\n",
    "        def d(Binary_Data):\n",
    "\n",
    "            X = Binary_Data\n",
    "\n",
    "            ones_matrix = np.ones(( X.shape[0] , X.shape[1])) \n",
    "\n",
    "            d = (ones_matrix - X) @ (ones_matrix - X).T\n",
    "\n",
    "            return(d)\n",
    "\n",
    "##########################################################################################\n",
    "\n",
    "        def alpha_py(i,j, Multiple_Categorical_Data):\n",
    "\n",
    "                X = Multiple_Categorical_Data\n",
    "\n",
    "                alpha = np.repeat(0, X.shape[1])\n",
    "\n",
    "                for k in range(0, X.shape[1]) :\n",
    "\n",
    "                    if X.iloc[i-1, k] == X.iloc[j-1, k] :\n",
    "\n",
    "                        alpha[k] = 1\n",
    "\n",
    "                    else :\n",
    "\n",
    "                        alpha[k] = 0\n",
    "\n",
    "\n",
    "                alpha = alpha.sum()\n",
    "\n",
    "                return(alpha)\n",
    "\n",
    "##########################################################################################\n",
    "\n",
    "        def GowerBM_Similarity_Python(i,j, BM_Data_Set, p2, p3):\n",
    "\n",
    "            X = BM_Data_Set\n",
    "\n",
    "   # The data matrix X have to be order in the following way:\n",
    "   # The p2 first are binary categorical, and the following p3 are multiple categorical.\n",
    "\n",
    "##########################################################################################\n",
    "       \n",
    "            Binary_Data = X.iloc[: , 0:p2]\n",
    "\n",
    "            Multiple_Categorical_Data = X.iloc[: , (p2):(p2+p3)]\n",
    " \n",
    "##########################################################################################\n",
    "\n",
    " \n",
    "            numerator_part_2 = a(Binary_Data).iloc[i-1,j-1] + alpha_py(i,j, Multiple_Categorical_Data)\n",
    "\n",
    "            numerator = numerator_part_2\n",
    "\n",
    "            denominator = (p2 - d(Binary_Data).iloc[i-1,j-1]) + p3\n",
    "\n",
    "            Similarity_Gower = numerator / denominator  \n",
    "\n",
    "            return(Similarity_Gower)    \n",
    "\n",
    "##########################################################################################\n",
    "\n",
    "        def Dist_GowerBM_Py(i, j, BM_Data ,  p2, p3):\n",
    "\n",
    "            Dist_Gower = np.sqrt( 1 - GowerBM_Similarity_Python(i, j, BM_Data , p2, p3) )\n",
    "\n",
    "            return(Dist_Gower)\n",
    "\n",
    "    ###################################################################\n",
    "\n",
    "        for i in range(1, len(X)):\n",
    "\n",
    "            distances.append( Dist_GowerBM_Py( len(X), i , X, p2, p3) )\n",
    "\n",
    "######################################################################################################################################\n",
    "\n",
    "\n",
    "    if distance == \"Gower-BQ\":\n",
    "\n",
    "        def a(Binary_Data) :\n",
    "\n",
    "            X = Binary_Data\n",
    "\n",
    "            a = X @ X.T\n",
    "\n",
    "            return(a)\n",
    "\n",
    "##########################################################################################\n",
    "\n",
    "        def d(Binary_Data):\n",
    "\n",
    "            X = Binary_Data\n",
    "\n",
    "            ones_matrix = np.ones(( X.shape[0] , X.shape[1])) \n",
    "\n",
    "            d = (ones_matrix - X) @ (ones_matrix - X).T\n",
    "\n",
    "            return(d)\n",
    "\n",
    "##########################################################################################\n",
    "\n",
    "        def GowerBQ_Similarity_Python(i,j, BQ_Data_Set, p1, p2):\n",
    "\n",
    "            X = BQ_Data_Set\n",
    "\n",
    "   # The data matrix X have to be order in the following way:\n",
    "   # The p1 first are quantitative, the following p2 are binary categorical \n",
    "\n",
    "##########################################################################################\n",
    "            def G(k, X):\n",
    "\n",
    "                range = X.iloc[:,k].max() - X.iloc[:,k].min() \n",
    "\n",
    "                return(range)\n",
    "\n",
    "            G_vector = np.repeat(0, p1)\n",
    "\n",
    "            for r in range(0, p1): \n",
    "\n",
    "                G_vector[r] = G(r, X)\n",
    "##########################################################################################\n",
    "    \n",
    "            ones = np.repeat(1, p1)\n",
    "\n",
    "            Quantitative_Data = X.iloc[: , 0:p1]\n",
    "\n",
    "            Binary_Data = X.iloc[: , (p1):(p1+p2)]\n",
    "         \n",
    " \n",
    "##########################################################################################\n",
    "\n",
    "            numerator_part_1 = ( ones - ( (Quantitative_Data.iloc[i-1,:] - Quantitative_Data.iloc[j-1,:]).abs() / G_vector ) ).sum() \n",
    "\n",
    "            numerator_part_2 = a(Binary_Data).iloc[i-1,j-1] \n",
    "     \n",
    "            numerator = numerator_part_1 + numerator_part_2\n",
    "\n",
    "            denominator = p1 + (p2 - d(Binary_Data).iloc[i-1,j-1])  \n",
    "\n",
    "            Similarity_Gower = numerator / denominator  \n",
    "\n",
    "            return(Similarity_Gower)\n",
    "\n",
    "##########################################################################################\n",
    "\n",
    "\n",
    "        def Dist_GowerBQ_Py(i, j, BQ_Data ,  p1, p2):\n",
    "\n",
    "            Dist_Gower = np.sqrt( 1 - GowerBQ_Similarity_Python(i, j, BQ_Data , p1, p2) )\n",
    "\n",
    "            return(Dist_Gower)\n",
    "\n",
    "##########################################################################################\n",
    "\n",
    "        for i in range(1, len(X)):\n",
    "\n",
    "            distances.append( Dist_GowerBQ_Py( len(X), i , X, p1, p2) )\n",
    "\n",
    "##########################################################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "######################################################################################################################################\n",
    "\n",
    "######################################################################################################################################\n",
    "    \n",
    "    distances = pd.DataFrame({'distances': distances})\n",
    "\n",
    "    distances = distances.sort_values(by=[\"distances\"]).reset_index(drop=False)\n",
    "        \n",
    "    knn = distances.iloc[0:k , :]\n",
    "\n",
    "    for i in knn.iloc[:,0]:\n",
    "\n",
    "        groups_knn.append(Y[i])\n",
    "\n",
    "    unique, counts = np.unique(groups_knn , return_counts=True)\n",
    "\n",
    "    unique_Y , counts_Y = np.unique(Y , return_counts=True)\n",
    "\n",
    "    if len(unique) == len(unique_Y) :\n",
    "\n",
    "        proportions_groups_knn = pd.DataFrame({'proportions_groups': counts/k, 'groups': unique_Y })\n",
    "    \n",
    "    elif len(unique) < len(unique_Y) :\n",
    "\n",
    "        proportions_groups_knn = pd.DataFrame({'proportions_groups': counts/k, 'groups': unique })\n",
    "\n",
    "\n",
    "\n",
    "    prediction_group = proportions_groups_knn.sort_values(by=[\"proportions_groups\"], ascending=False).iloc[0,:]['groups']\n",
    "\n",
    "    message = print( \"x_new is classify in the group\", prediction_group , \". So KNN algorithm predict y_new =\",  prediction_group )                                      \n",
    "                                       \n",
    "\n",
    "    return proportions_groups_knn , message  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing our `KNN_classification` function in a binary classification problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gender_classification = pd.read_csv('gender_classification.csv')\n",
    "\n",
    "X = Gender_classification.iloc[: , 0:7]\n",
    "\n",
    "Y = Gender_classification.iloc[: , 7]\n",
    "\n",
    "x_new = pd.Series({'long_hair': 1, 'forehead_width_cm': 4, 'forehead_height_cm': 6, 'nose_wide': 1 , 'nose_long': 1 , 'nose_long': 1 , 'lips_thin':1, 'distance_nose_to_lip_long': 1 })\n",
    "\n",
    "\n",
    "# Recoding Y using the standard format:\n",
    "\n",
    "for i in range(0, len(Y)):\n",
    "\n",
    "    if Y[i]=='Male':\n",
    "\n",
    "        Y[i] = 0\n",
    "\n",
    "    elif Y[i]=='Female':\n",
    "\n",
    "        Y[i]=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_new is classify in the group 0 . So KNN algorithm predict y_new = 0\n"
     ]
    }
   ],
   "source": [
    "proportions_groups_knn , message = KNN_classification( X , Y , x_new, 10 , distance = \"Euclidean\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>proportions_groups</th>\n",
       "      <th>groups</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   proportions_groups groups\n",
       "0                 0.9      0\n",
       "1                 0.1      1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proportions_groups_knn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using another distance function and $k$ :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_new is classify in the group 0 . So KNN algorithm predict y_new = 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(   proportions_groups groups\n",
       " 0                 0.8      0\n",
       " 1                 0.2      1,\n",
       " None)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNN_classification( X , Y , x_new, 5 , distance = \"Minkowski\" , q = 2 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_new is classify in the group 0.0 . So KNN algorithm predict y_new = 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(   proportions_groups  groups\n",
       " 0                 1.0       0,\n",
       " None)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNN_classification( X , Y , x_new, 2 , distance = \"Minkowski\" , q = 1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_new is classify in the group 1.0 . So KNN algorithm predict y_new = 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(   proportions_groups  groups\n",
       " 0                 1.0       1,\n",
       " None)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNN_classification( X , Y , x_new, 10 , distance = \"Minkowski\" , q = 3 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_new is classify in the group 0.0 . So KNN algorithm predict y_new = 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(   proportions_groups  groups\n",
       " 0                 1.0       0,\n",
       " None)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNN_classification( X , Y , x_new, 3 , distance = \"Canberra\"  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_new is classify in the group 0.0 . So KNN algorithm predict y_new = 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(   proportions_groups  groups\n",
       " 0                 1.0       0,\n",
       " None)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNN_classification( X , Y , x_new, 15 , distance = \"Mahalanobis\"  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_new is classify in the group 0.0 . So KNN algorithm predict y_new = 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(   proportions_groups  groups\n",
       " 0                 1.0       0,\n",
       " None)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNN_classification( X , Y , x_new, 6 , distance = \"Pearson\"  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN_classification( X , Y , x_new, 10 , distance = \"Gower\"  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the Gower distance cannot be implemented because X is not a mixed data matrix (it only has quantitative and binary, the multiclasses are missing).\n",
    "Neither can the Sokal and Jaccard distances be used because X is not a binary data matrix, nor can the matches coefficient be used because X is not a multiclass categorical data matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since in this case $X$ is a matrix of **Binary-Quantitative data**, the most suitable distance allowed by our `KNN_regression` function is the **Gower-BQ distance**.\n",
    "\n",
    "To use our Gower distance we must order the columns of $X$ appropriately. The first $p1$ will be the quantitative variables, and the next $p2$ the binary ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Gender_classification.loc[: , ['forehead_width_cm', 'forehead_height_cm',   # Quantitative (2)\n",
    "\n",
    "                   'long_hair', 'nose_wide', 'nose_long', 'lips_thin', 'distance_nose_to_lip_long'     # Binary (5)\n",
    "                 \n",
    "                            ]]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN_classification( X , Y  , x_new, 5 , distance = \"Gower-BQ\" , p1=2, p2=5 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: with 3000 observations it takes 3 minutes, but with 5001 (all) it takes almost 14 minutes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing our `KNN_classification` function in a multi-class classification problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "Wine_Classification = pd.read_csv('WineQT.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "      <th>Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  Id  \n",
       "0      9.4        5   0  \n",
       "1      9.8        5   1  \n",
       "2      9.8        5   2  \n",
       "3      9.8        6   3  \n",
       "4      9.4        5   4  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Wine_Classification.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Wine_Classification.iloc[: , 0:11]\n",
    "\n",
    "Y = Wine_Classification.iloc[: , 11]\n",
    "\n",
    "x_new = pd.Series({'fixed acidity': 7, 'volatile acidity': 0.8, 'citric acid': 0.04, 'residual sugar': 2.1 , 'chlorides': 0.070 , 'free sulfur dioxide': 12 , 'total sulfur dioxide':37 , 'density': 0.998 , 'pH':3.45, 'sulphates':0.60, 'alcohol':9.6 })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  \n",
       "0      9.4  \n",
       "1      9.8  \n",
       "2      9.8  \n",
       "3      9.8  \n",
       "4      9.4  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5\n",
       "1    5\n",
       "2    5\n",
       "3    6\n",
       "4    5\n",
       "Name: quality, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case response variable $Y$ has $10$ categories, so we are in a multi-class classification problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_new is classify in the group 6.0 . So KNN algorithm predict y_new = 6.0\n"
     ]
    }
   ],
   "source": [
    "proportions_groups_knn , message = KNN_classification( X , Y , x_new, 10 , distance = \"Euclidean\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>proportions_groups</th>\n",
       "      <th>groups</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.7</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   proportions_groups  groups\n",
       "0                 0.3       5\n",
       "1                 0.7       6"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proportions_groups_knn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We tried with another $k$ and distance :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_new is classify in the group 5.0 . So KNN algorithm predict y_new = 5.0\n"
     ]
    }
   ],
   "source": [
    "proportions_groups_knn , message = KNN_classification( X , Y , x_new, 5 , distance = \"Minkowski\" , q = 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>proportions_groups</th>\n",
       "      <th>groups</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   proportions_groups  groups\n",
       "0                 0.6       5\n",
       "1                 0.4       6"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proportions_groups_knn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_new is classify in the group 5.0 . So KNN algorithm predict y_new = 5.0\n"
     ]
    }
   ],
   "source": [
    "proportions_groups_knn , message = KNN_classification( X , Y , x_new, 5 , distance = \"Mahalanobis\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>proportions_groups</th>\n",
       "      <th>groups</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   proportions_groups  groups\n",
       "0                 0.6       5\n",
       "1                 0.4       6"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proportions_groups_knn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing with sklearn function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = sklearn.neighbors.KNeighborsClassifier(n_neighbors=10 ,  weights='uniform',  metric='euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6]\n",
      "[[0.  0.  0.3 0.7 0.  0. ]]\n"
     ]
    }
   ],
   "source": [
    "knn.fit(X, Y)\n",
    "\n",
    "print( knn.predict( [x_new] ) )\n",
    "\n",
    "print( knn.predict_proba([x_new]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = sklearn.neighbors.KNeighborsClassifier(n_neighbors=5 ,  weights='uniform',   p=1, metric='minkowski')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5]\n",
      "[[0.  0.  0.6 0.4 0.  0. ]]\n"
     ]
    }
   ],
   "source": [
    "knn.fit(X, Y)\n",
    "\n",
    "print( knn.predict( [x_new] ) )\n",
    "\n",
    "print( knn.predict_proba([x_new]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN for regression <a class=\"anchor\" id=\"5\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We have $\\hspace{0.1cm} p \\hspace{0.1cm}$ variables $\\hspace{0.1cm} X=(X_1,...,X_p) \\hspace{0.1cm}$ measurements on a $n$ size sample.\n",
    "\n",
    "- We also have a **quantitative** response variable $\\hspace{0.1cm} Y $ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The regression problem consists in, for a new observation $\\hspace{0.1cm} x_{new} = (x_{new,1},x_{new,2},...,x_{new,p}) \\hspace{0.1cm}$ of the variables $X_1,...,X_p  \\hspace{0.1cm}$, predict it's $\\hspace{0.1cm} Y \\hspace{0.05cm}$ value $\\hspace{0.1cm} (y_{new})\\hspace{0.1cm}$  using the information of $\\hspace{0.1cm} X_1,...,X_p \\hspace{0.1cm}$ and $ \\hspace{0.1cm} Y$\n",
    "\n",
    "So , the problem is to get $\\hspace{0.1cm} \\hat{y}_{new} \\hspace{0.1cm}$  using the information available of $\\hspace{0.1cm} X_1,...,X_p \\hspace{0.1cm}$ , $Y$ and  $\\hspace{0.1cm} x_{new} = (x_{new,1},x_{new,2},...,x_{new,p})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The KNN (K-nearest neighbors) algorithm for regression have the following steps:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " $1. \\hspace{0.15cm}$ Define a distance measure between the observation of the original sample respect to the variables $X_1,...,X_p$ $\\hspace{0.15cm} \\Rightarrow \\hspace{0.15cm}$ $\\delta$\n",
    "\n",
    "\n",
    "\n",
    " $2. \\hspace{0.15cm}$ Compute the distances between $x_{new}$ and the initial observations $\\hspace{0.1cm} \\lbrace x_1,...,x_n \\rbrace$ $\\hspace{0.15cm} \\Rightarrow \\hspace{0.15cm}$ $\\lbrace \\hspace{0.1 cm}  \\delta(x_{new}, x_i) \\hspace{0.1 cm} / \\hspace{0.1 cm}  i=1,...,n \\hspace{0.1 cm}  \\rbrace$\n",
    "\n",
    "  \n",
    " $3. \\hspace{0.15cm}$ Select the  $k$ nearest observation to $x_{new}$ based on $\\hspace{0.05cm} \\delta \\hspace{0.12cm}$ $(k$ nearest neighbors of $x_{new})$ $\\hspace{0.15cm} \\Rightarrow \\hspace{0.15cm}$   The set of these observation will be denote by $KNN$ \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$5. \\hspace{0.15cm}$ The method predict $\\hspace{0.1cm} y_{new} \\hspace{0.1cm}$  as follows:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "   \n",
    " \\widehat{y}_{new} =  \\dfrac{1}{KNN }\\cdot \\sum_{i \\in KNN}  y_i\n",
    "  \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN for regression in Python with `Sklearn` <a class=\"anchor\" id=\"6\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN for regression in Python with own algorithm <a class=\"anchor\" id=\"7\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN_regression( X , Y , x_new, k, distance = \"Minkowski\" , q = 0, p1=0, p2=0, p3=0 ):\n",
    "\n",
    "####################################################################################################################################################################################################################################################\n",
    "\n",
    "    # Y tiene que ser una variable cuantitativa\n",
    "\n",
    "    # Ejemplo de Y :  \n",
    "\n",
    " \n",
    "    # X tiene que ser un panda data frame con los predictotres (X1,...,Xp). Ejemplo de X :\n",
    "\n",
    "    # x_new tiene que ser una panda series. Ejemplo   \n",
    "\n",
    "####################################################################################################################################################################################################################################################\n",
    "\n",
    "    X = pd.concat([X, x_new.to_frame().T], ignore_index=True)\n",
    "\n",
    "    distances = []\n",
    "\n",
    "    Y_values_knn = []\n",
    "\n",
    "\n",
    "####################################################################################################################################################################################################################################################\n",
    "    \n",
    "    if distance == \"Euclidean\":\n",
    "\n",
    "        def Dist_Euclidea_Python(i, j, Quantitative_Data_set): \n",
    "\n",
    "            Dist_Euclidea = ( ( Quantitative_Data_set.iloc[i-1, ] - Quantitative_Data_set.iloc[j-1, ] )**2 ).sum()\n",
    "\n",
    "            Dist_Euclidea = np.sqrt(Dist_Euclidea)\n",
    "\n",
    "            return Dist_Euclidea\n",
    "\n",
    "    ###################################################################\n",
    "\n",
    "        for i in range(1, len(X)):\n",
    "\n",
    "            distances.append( Dist_Euclidea_Python( len(X), i , X) )\n",
    "\n",
    "    ###################################################################\n",
    "\n",
    "    if distance == \"Minkowski\":\n",
    "\n",
    "        def Dist_Minkowski_Python(i,j, q , Quantitative_Data_set):\n",
    "\n",
    "            Dist_Minkowski = ( ( ( ( Quantitative_Data_set.iloc[i-1, ] - Quantitative_Data_set.iloc[j-1, ] ).abs() )**q ).sum() )**(1/q)\n",
    "\n",
    "            return Dist_Minkowski\n",
    "\n",
    "    ###################################################################\n",
    "\n",
    "        for i in range(1, len(X)):\n",
    "\n",
    "            distances.append( Dist_Minkowski_Python( len(X), i , q , X) )\n",
    "\n",
    "        \n",
    "\n",
    "    ###################################################################\n",
    "\n",
    "    if distance == \"Canberra\":\n",
    "\n",
    "        def Dist_Canberra_Python(i,j, Quantitative_Data_set):\n",
    "\n",
    "            numerator =  ( Quantitative_Data_set.iloc[i-1, ] - Quantitative_Data_set.iloc[j-1, ] ).abs()  \n",
    "\n",
    "            denominator =  ( (Quantitative_Data_set.iloc[i-1, ]).abs() + (Quantitative_Data_set.iloc[j-1, ]).abs() )\n",
    "       \n",
    "            numerator=np.array([numerator], dtype=float)\n",
    "\n",
    "            denominator=np.array([denominator], dtype=float)\n",
    "\n",
    "            Dist_Canberra = ( np.divide( numerator , denominator , out=np.zeros_like(numerator), where=denominator!=0) ).sum()\n",
    "\n",
    "            return Dist_Canberra\n",
    "\n",
    "    ###################################################################\n",
    "    \n",
    "        for i in range(1, len(X)):\n",
    "\n",
    "            distances.append( Dist_Canberra_Python( len(X), i , X) )\n",
    "\n",
    "    ###################################################################\n",
    "   \n",
    "    if distance == \"Pearson\":\n",
    "\n",
    "        def Dist_Pearson_Python(i, j, Quantitative_Data_set):\n",
    "\n",
    "            Dist_Pearson = ( ( Quantitative_Data_set.iloc[i-1, ] - Quantitative_Data_set.iloc[j-1, ] )**2 / Quantitative_Data_set.var() ).sum()\n",
    "\n",
    "            Dist_Pearson = np.sqrt(Dist_Pearson)\n",
    "\n",
    "            return Dist_Pearson\n",
    "\n",
    "    ###################################################################\n",
    "\n",
    "        for i in range(1, len(X)):\n",
    "\n",
    "            distances.append( Dist_Pearson_Python( len(X), i , X) )\n",
    "\n",
    "    ###################################################################\n",
    "    \n",
    "    if distance == \"Mahalanobis\":\n",
    "\n",
    "        def Dist_Mahalanobis_Python(i, j, Quantitative_Data_set):\n",
    "\n",
    "            # All the columns of Quantitative_Data_set must be type = 'float' or 'int' (specially not 'object'), in other case we will find \n",
    "            # dimensional problems when Python compute   x @ S_inv @ x.T\n",
    "\n",
    "            x = (Quantitative_Data_set.to_numpy()[i-1, ] - Quantitative_Data_set.to_numpy()[j-1, ])\n",
    "\n",
    "            x = np.array([x]) # necessary step to transpose a 1D array\n",
    "\n",
    "            S_inv = np.linalg.inv( Quantitative_Data_set.cov() ) # inverse of covariance matrix\n",
    "\n",
    "            Dist_Maha = np.sqrt( x @ S_inv @ x.T )  # x @ S_inv @ x.T = np.matmul( np.matmul(x , S_inv) , x.T )\n",
    "\n",
    "            Dist_Maha = float(Dist_Maha)\n",
    "\n",
    "            return Dist_Maha\n",
    "\n",
    "        \n",
    "    ###################################################################\n",
    "\n",
    "        for i in range(1, len(X)):\n",
    "\n",
    "            distances.append( Dist_Mahalanobis_Python( len(X), i , X) )\n",
    "\n",
    "       \n",
    "\n",
    "    ###################################################################\n",
    "    \n",
    "    if distance == \"Sokal\":\n",
    "\n",
    "        a = X @ X.T\n",
    "        n = X.shape[0]\n",
    "        p = X.shape[1]\n",
    "        ones_matrix = np.ones((n, p))\n",
    "        b = (ones_matrix - X) @ X.T\n",
    "        c = b.T\n",
    "        d = (ones_matrix - X) @ (ones_matrix - X).T\n",
    "\n",
    "        def Sokal_Similarity_Py(i, j):\n",
    "\n",
    "            Sokal_Similarity = (a.iloc[i-1,j-1] + d.iloc[i-1,j-1])/p\n",
    "\n",
    "            return Sokal_Similarity\n",
    "\n",
    "\n",
    "        def Dist_Sokal_Python(i, j, Binary_Data_set):\n",
    "\n",
    "            dist_Sokal = np.sqrt( 2 - 2*Sokal_Similarity_Py(i,j, Binary_Data_set) )\n",
    "\n",
    "            return dist_Sokal\n",
    "\n",
    "    ###################################################################\n",
    "\n",
    "        for i in range(1, len(X)):\n",
    "\n",
    "            distances.append( Dist_Sokal_Python( len(X), i , X) )\n",
    "\n",
    "    ###################################################################\n",
    "   \n",
    "    if distance == \"Jaccard\":\n",
    "\n",
    "        def Jaccard_Similarity_Py(i, j, Binary_Data_Matrix):\n",
    "\n",
    "            X = Binary_Data_Py\n",
    "            a = X @ X.T\n",
    "            n = X.shape[0]\n",
    "            p = X.shape[1]\n",
    "            ones_matrix = np.ones((n, p)) \n",
    "            b = (ones_matrix - X) @ X.T\n",
    "            c = b.T\n",
    "            d = (ones_matrix - X) @ (ones_matrix - X).T\n",
    "\n",
    "            Jaccard_Similarity = a.iloc[i-1,j-1] / (a.iloc[i-1,j-1] + b.iloc[i-1,j-1] + c.iloc[i-1,j-1])\n",
    "            \n",
    "            return Jaccard_Similarity\n",
    "\n",
    "\n",
    "        def Dist_Jaccard_Python(i, j, Binary_Data_set):\n",
    "\n",
    "            dist_Jaccard = np.sqrt( Jaccard_Similarity_Py(i,i, Binary_Data_set) + Jaccard_Similarity_Py(i,i, Binary_Data_set) - 2*Jaccard_Similarity_Py(i,j, Binary_Data_set) )\n",
    "\n",
    "            return dist_Jaccard\n",
    "\n",
    "    ###################################################################\n",
    "\n",
    "        for i in range(1, len(X)):\n",
    "\n",
    "            distances.append( Dist_Jaccard_Python( len(X), i , X) )\n",
    "\n",
    "    ###################################################################\n",
    "    \n",
    "    if distance == \"Matches\":\n",
    "\n",
    "        def alpha_py(i,j, Multiple_Categorical_Data):\n",
    "\n",
    "            X = Multiple_Categorical_Data\n",
    "            alpha = np.repeat(0, X.shape[1])\n",
    "\n",
    "            for k in range(0, X.shape[1]) :\n",
    "\n",
    "                if X.iloc[i-1, k] == X.iloc[j-1, k] :\n",
    "\n",
    "                    alpha[k] = 1\n",
    "\n",
    "                else :\n",
    "\n",
    "                    alpha[k] = 0\n",
    "\n",
    "            alpha = alpha.sum()\n",
    "\n",
    "            return(alpha)\n",
    "\n",
    "\n",
    "        def matches_similarity_py(i, j, Multiple_Categorical_Data):\n",
    "\n",
    "            p = Multiple_Categorical_Data.shape[1]\n",
    "\n",
    "            matches_similarity = alpha_py(i,j, Multiple_Categorical_Data) / p\n",
    "\n",
    "            return(matches_similarity)\n",
    "\n",
    "\n",
    "        def Dist_Matches_Py(i,j, Multiple_Categorical_Data):\n",
    "\n",
    "            Dist_Matches = np.sqrt( matches_similarity_py(i, i, Multiple_Categorical_Data) +  matches_similarity_py(j, j, Multiple_Categorical_Data) - 2*matches_similarity_py(i, j, Multiple_Categorical_Data) )\n",
    "\n",
    "            return( Dist_Matches )\n",
    "\n",
    "    ###################################################################\n",
    "\n",
    "        for i in range(1, len(X)):\n",
    "\n",
    "            distances.append( Dist_Matches_Py( len(X), i , X) )\n",
    "\n",
    " #######################################################################   \n",
    "   \n",
    "    if distance == \"Gower\":\n",
    "\n",
    "        # The data matrix X have to be order in the following way:\n",
    "        # The p1 first are quantitative, the following p2 are binary categorical, and the following p3 are multiple categorical.\n",
    "\n",
    "\n",
    "        def a(Binary_Data) :\n",
    "\n",
    "            X = Binary_Data\n",
    "\n",
    "            a = X @ X.T\n",
    "\n",
    "            return(a)\n",
    "\n",
    "##########################################################################################\n",
    "\n",
    "        def d(Binary_Data):\n",
    "\n",
    "            X = Binary_Data\n",
    "\n",
    "            ones_matrix = np.ones(( X.shape[0] , X.shape[1])) \n",
    "\n",
    "            d = (ones_matrix - X) @ (ones_matrix - X).T\n",
    "\n",
    "            return(d)\n",
    "\n",
    "##########################################################################################\n",
    "\n",
    "        def alpha_py(i,j, Multiple_Categorical_Data):\n",
    "\n",
    "                X = Multiple_Categorical_Data\n",
    "\n",
    "                alpha = np.repeat(0, X.shape[1])\n",
    "\n",
    "                for k in range(0, X.shape[1]) :\n",
    "\n",
    "                    if X.iloc[i-1, k] == X.iloc[j-1, k] :\n",
    "\n",
    "                        alpha[k] = 1\n",
    "\n",
    "                    else :\n",
    "\n",
    "                        alpha[k] = 0\n",
    "\n",
    "\n",
    "                alpha = alpha.sum()\n",
    "\n",
    "                return(alpha)\n",
    "\n",
    "   ##########################################################################################\n",
    "\n",
    "\n",
    "        def Gower_Similarity_Python(i,j, Mixed_Data_Set, p1, p2, p3):\n",
    "\n",
    "            X = Mixed_Data_Set\n",
    "\n",
    "   # The data matrix X have to be order in the following way:\n",
    "   # The p1 first are quantitative, the following p2 are binary categorical, and the following p3 are multiple categorical.\n",
    "\n",
    "   #####################################################################################\n",
    "        \n",
    "            def G(k, X):\n",
    "\n",
    "                range = X.iloc[:,k].max() - X.iloc[:,k].min() \n",
    "\n",
    "                return(range)\n",
    "\n",
    "            G_vector = np.repeat(0, p1)\n",
    "\n",
    "            for r in range(0, p1):\n",
    "\n",
    "                G_vector[r] = G(r, X)\n",
    "                \n",
    "      \n",
    "    ##########################################################################################\n",
    "    \n",
    "            ones = np.repeat(1, p1)\n",
    "\n",
    "            Quantitative_Data = X.iloc[: , 0:p1]\n",
    "\n",
    "            Binary_Data = X.iloc[: , (p1):(p1+p2)]\n",
    "            \n",
    "            Multiple_Categorical_Data = X.iloc[: , (p1+p2):(p1+p2+p3) ]\n",
    "\n",
    "    ##########################################################################################\n",
    "\n",
    "            numerator_part_1 = ( ones - ( (Quantitative_Data.iloc[i-1,:] - Quantitative_Data.iloc[j-1,:]).abs() / G_vector ) ).sum() \n",
    "\n",
    "            numerator_part_2 = a(Binary_Data).iloc[i-1,j-1] + alpha_py(i,j, Multiple_Categorical_Data)\n",
    "\n",
    "            numerator = numerator_part_1 + numerator_part_2\n",
    " \n",
    "            denominator = p1 + (p2 - d(Binary_Data).iloc[i-1,j-1]) + p3\n",
    "\n",
    "            Similarity_Gower = numerator / denominator  \n",
    "\n",
    "            return(Similarity_Gower)\n",
    "\n",
    "##########################################################################################\n",
    "\n",
    "        def Dist_Gower_Py(i, j, Mixed_Data , p1, p2, p3):\n",
    "\n",
    "            Dist_Gower = np.sqrt( 1 - Gower_Similarity_Python(i, j, Mixed_Data , p1, p2, p3) )\n",
    "\n",
    "            return(Dist_Gower)    \n",
    "\n",
    "    ###################################################################\n",
    "\n",
    "        for i in range(1, len(X)):\n",
    "\n",
    "            distances.append( Dist_Gower_Py( len(X), i , X, p1, p2, p3) )\n",
    "\n",
    "######################################################################################################################################\n",
    "    \n",
    "    distances = pd.DataFrame({'distances': distances})\n",
    "\n",
    "    distances = distances.sort_values(by=[\"distances\"]).reset_index(drop=False)\n",
    "        \n",
    "    knn = distances.iloc[0:k , :]\n",
    "\n",
    "    for i in knn.iloc[:,0]:\n",
    "\n",
    "        Y_values_knn.append(Y.iloc[i , :])\n",
    "\n",
    "    \n",
    "    from itertools import chain\n",
    "\n",
    "    Y_values_knn = list(chain(*Y_values_knn)) # To unlist a list\n",
    "\n",
    "\n",
    "    prediction = sum(Y_values_knn)/k\n",
    "\n",
    "    message = print( \"KNN algorithm predict y_new =\",  prediction )                                      \n",
    "                                       \n",
    "\n",
    "    return prediction , message  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing our `KNN_regression` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "House_Price_Regression = pd.read_csv('House_Price_Regression.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neighborhood_recode</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>price</th>\n",
       "      <th>no_of_bedrooms</th>\n",
       "      <th>no_of_bathrooms</th>\n",
       "      <th>quality_recode</th>\n",
       "      <th>maid_room_recode</th>\n",
       "      <th>unfurnished_recode</th>\n",
       "      <th>balcony_recode</th>\n",
       "      <th>...</th>\n",
       "      <th>private_garden_recode</th>\n",
       "      <th>private_gym_recode</th>\n",
       "      <th>private_jacuzzi_recode</th>\n",
       "      <th>private_pool_recode</th>\n",
       "      <th>security_recode</th>\n",
       "      <th>shared_gym_recode</th>\n",
       "      <th>shared_pool_recode</th>\n",
       "      <th>shared_spa_recode</th>\n",
       "      <th>view_of_water_recode</th>\n",
       "      <th>size_in_m_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>46.0</td>\n",
       "      <td>25.113208</td>\n",
       "      <td>55.138932</td>\n",
       "      <td>2700000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.242337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46.0</td>\n",
       "      <td>25.106809</td>\n",
       "      <td>55.151201</td>\n",
       "      <td>2850000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>146.972546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36.0</td>\n",
       "      <td>25.063302</td>\n",
       "      <td>55.137728</td>\n",
       "      <td>1150000</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>181.253753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.0</td>\n",
       "      <td>25.227295</td>\n",
       "      <td>55.341761</td>\n",
       "      <td>2850000</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>187.664060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>46.0</td>\n",
       "      <td>25.114275</td>\n",
       "      <td>55.139764</td>\n",
       "      <td>1729200</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>47.101821</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   neighborhood_recode   latitude  longitude    price  no_of_bedrooms  \\\n",
       "0                 46.0  25.113208  55.138932  2700000               1   \n",
       "1                 46.0  25.106809  55.151201  2850000               2   \n",
       "2                 36.0  25.063302  55.137728  1150000               3   \n",
       "3                 11.0  25.227295  55.341761  2850000               2   \n",
       "4                 46.0  25.114275  55.139764  1729200               0   \n",
       "\n",
       "   no_of_bathrooms  quality_recode  maid_room_recode  unfurnished_recode  \\\n",
       "0                2             2.0               0.0                 0.0   \n",
       "1                2             2.0               0.0                 0.0   \n",
       "2                5             2.0               1.0                 1.0   \n",
       "3                3             1.0               0.0                 1.0   \n",
       "4                1             2.0               0.0                 0.0   \n",
       "\n",
       "   balcony_recode  ...  private_garden_recode  private_gym_recode  \\\n",
       "0             1.0  ...                    0.0                 0.0   \n",
       "1             1.0  ...                    0.0                 0.0   \n",
       "2             1.0  ...                    0.0                 0.0   \n",
       "3             1.0  ...                    0.0                 0.0   \n",
       "4             0.0  ...                    0.0                 0.0   \n",
       "\n",
       "   private_jacuzzi_recode  private_pool_recode  security_recode  \\\n",
       "0                     0.0                  0.0              0.0   \n",
       "1                     0.0                  0.0              0.0   \n",
       "2                     1.0                  0.0              1.0   \n",
       "3                     0.0                  0.0              0.0   \n",
       "4                     0.0                  0.0              1.0   \n",
       "\n",
       "   shared_gym_recode  shared_pool_recode  shared_spa_recode  \\\n",
       "0                1.0                 0.0                0.0   \n",
       "1                1.0                 1.0                0.0   \n",
       "2                1.0                 1.0                0.0   \n",
       "3                0.0                 0.0                0.0   \n",
       "4                1.0                 1.0                1.0   \n",
       "\n",
       "   view_of_water_recode  size_in_m_2  \n",
       "0                   1.0   100.242337  \n",
       "1                   1.0   146.972546  \n",
       "2                   1.0   181.253753  \n",
       "3                   0.0   187.664060  \n",
       "4                   1.0    47.101821  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "House_Price_Regression.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['neighborhood_recode', 'latitude', 'longitude', 'price',\n",
       "       'no_of_bedrooms', 'no_of_bathrooms', 'quality_recode',\n",
       "       'maid_room_recode', 'unfurnished_recode', 'balcony_recode',\n",
       "       'barbecue_area_recode', 'central_ac_recode',\n",
       "       'childrens_play_area_recode', 'childrens_pool_recode',\n",
       "       'concierge_recode', 'covered_parking_recode',\n",
       "       'kitchen_appliances_recode', 'maid_service_recode',\n",
       "       'pets_allowed_recode', 'private_garden_recode', 'private_gym_recode',\n",
       "       'private_jacuzzi_recode', 'private_pool_recode', 'security_recode',\n",
       "       'shared_gym_recode', 'shared_pool_recode', 'shared_spa_recode',\n",
       "       'view_of_water_recode', 'size_in_m_2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "House_Price_Regression.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = House_Price_Regression.loc[ : , ['neighborhood_recode', 'latitude', 'longitude',\n",
    "       'no_of_bedrooms', 'no_of_bathrooms', 'quality_recode',\n",
    "       'maid_room_recode', 'unfurnished_recode', 'balcony_recode',\n",
    "       'barbecue_area_recode', 'central_ac_recode',\n",
    "       'childrens_play_area_recode', 'childrens_pool_recode',\n",
    "       'concierge_recode', 'covered_parking_recode',\n",
    "       'kitchen_appliances_recode', 'maid_service_recode',\n",
    "       'pets_allowed_recode', 'private_garden_recode', 'private_gym_recode',\n",
    "       'private_jacuzzi_recode', 'private_pool_recode', 'security_recode',\n",
    "       'shared_gym_recode', 'shared_pool_recode', 'shared_spa_recode',\n",
    "       'view_of_water_recode', 'size_in_m_2']]\n",
    "\n",
    "\n",
    "Y = House_Price_Regression.loc[: , ['price']]  \n",
    "\n",
    "x_new = pd.Series({ 'neighborhood_recode':46, 'latitude': 25.2 , 'longitude': 55,\n",
    "       'no_of_bedrooms': 3, 'no_of_bathrooms':2, 'quality_recode': 0,\n",
    "       'maid_room_recode': 0, 'unfurnished_recode': 0 , 'balcony_recode': 1,\n",
    "       'barbecue_area_recode': 1, 'central_ac_recode': 1,\n",
    "       'childrens_play_area_recode': 1, 'childrens_pool_recode': 1,\n",
    "       'concierge_recode': 1, 'covered_parking_recode': 1,\n",
    "       'kitchen_appliances_recode':0, 'maid_service_recode':1,\n",
    "       'pets_allowed_recode':0, 'private_garden_recode':1, 'private_gym_recode':0,\n",
    "       'private_jacuzzi_recode':1, 'private_pool_recode':1, 'security_recode':1,\n",
    "       'shared_gym_recode':0, 'shared_pool_recode':0, 'shared_spa_recode':0,\n",
    "       'view_of_water_recode':1, 'size_in_m_2': 140.5 })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN algorithm predict y_new = 1978499.9\n"
     ]
    }
   ],
   "source": [
    "prediction , message = KNN_regression( X , Y , x_new, k=10, distance = \"Minkowski\" , q = 2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1978499.9"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN algorithm predict y_new = 2163500.0\n"
     ]
    }
   ],
   "source": [
    "prediction , message = KNN_regression( X , Y , x_new, k=10, distance = \"Minkowski\" , q = 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN algorithm predict y_new = 1745188.6\n"
     ]
    }
   ],
   "source": [
    "prediction , message = KNN_regression( X , Y , x_new, k=10, distance = \"Pearson\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since in this case $X$ is a matrix of **mixed data**, the most suitable distance allowed by our `KNN_regression` function is the **Gower distance**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use our Gower distance we must order the columns of $X$ appropriately. The first $p1$ will be the quantitative variables, the next $p2$ the binary ones and the last $p3$ the multi class ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = House_Price_Regression.loc[ : , ['size_in_m_2',  'latitude', 'longitude', 'no_of_bedrooms', 'no_of_bathrooms',           # Quantitatives (5)\n",
    "                                    \n",
    "                                       'maid_room_recode', 'unfurnished_recode', 'balcony_recode', 'barbecue_area_recode', 'central_ac_recode',\n",
    "                                       'childrens_play_area_recode', 'childrens_pool_recode', 'concierge_recode', 'covered_parking_recode',\n",
    "                                       'kitchen_appliances_recode', 'maid_service_recode', 'pets_allowed_recode', 'private_garden_recode',         # Binary (21)\n",
    "                                       'private_gym_recode', 'private_jacuzzi_recode', 'private_pool_recode', 'security_recode',\n",
    "                                       'shared_gym_recode', 'shared_pool_recode', 'shared_spa_recode', 'view_of_water_recode' ,\n",
    "                                       \n",
    "                                       'neighborhood_recode', 'quality_recode'         # Multi-class (2)\n",
    "                                       \n",
    "                                       ]]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Usuario\\Documents\\fabio\\Fabio\\Estadistica4all.github.io\\Notebooks\\KNN\\KNN.ipynb Celda 174\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Usuario/Documents/fabio/Fabio/Estadistica4all.github.io/Notebooks/KNN/KNN.ipynb#Y336sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m prediction , message \u001b[39m=\u001b[39m KNN_regression( X , Y , x_new, k\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, distance \u001b[39m=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mGower\u001b[39;49m\u001b[39m\"\u001b[39;49m,  p1\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m, p2\u001b[39m=\u001b[39;49m\u001b[39m21\u001b[39;49m, p3\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m  )\n",
      "\u001b[1;32mc:\\Users\\Usuario\\Documents\\fabio\\Fabio\\Estadistica4all.github.io\\Notebooks\\KNN\\KNN.ipynb Celda 174\u001b[0m in \u001b[0;36mKNN_regression\u001b[1;34m(X, Y, x_new, k, distance, q, p1, p2, p3)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Usuario/Documents/fabio/Fabio/Estadistica4all.github.io/Notebooks/KNN/KNN.ipynb#Y336sZmlsZQ%3D%3D?line=346'>347</a>\u001b[0m     \u001b[39m###################################################################\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Usuario/Documents/fabio/Fabio/Estadistica4all.github.io/Notebooks/KNN/KNN.ipynb#Y336sZmlsZQ%3D%3D?line=348'>349</a>\u001b[0m         \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39mlen\u001b[39m(X)):\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/Usuario/Documents/fabio/Fabio/Estadistica4all.github.io/Notebooks/KNN/KNN.ipynb#Y336sZmlsZQ%3D%3D?line=350'>351</a>\u001b[0m             distances\u001b[39m.\u001b[39mappend( Dist_Gower_Py( \u001b[39mlen\u001b[39;49m(X), i , X, p1, p2, p3) )\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Usuario/Documents/fabio/Fabio/Estadistica4all.github.io/Notebooks/KNN/KNN.ipynb#Y336sZmlsZQ%3D%3D?line=352'>353</a>\u001b[0m \u001b[39m######################################################################################################################################\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Usuario/Documents/fabio/Fabio/Estadistica4all.github.io/Notebooks/KNN/KNN.ipynb#Y336sZmlsZQ%3D%3D?line=354'>355</a>\u001b[0m     distances \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame({\u001b[39m'\u001b[39m\u001b[39mdistances\u001b[39m\u001b[39m'\u001b[39m: distances})\n",
      "\u001b[1;32mc:\\Users\\Usuario\\Documents\\fabio\\Fabio\\Estadistica4all.github.io\\Notebooks\\KNN\\KNN.ipynb Celda 174\u001b[0m in \u001b[0;36mKNN_regression.<locals>.Dist_Gower_Py\u001b[1;34m(i, j, Mixed_Data, p1, p2, p3)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Usuario/Documents/fabio/Fabio/Estadistica4all.github.io/Notebooks/KNN/KNN.ipynb#Y336sZmlsZQ%3D%3D?line=340'>341</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mDist_Gower_Py\u001b[39m(i, j, Mixed_Data , p1, p2, p3):\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/Usuario/Documents/fabio/Fabio/Estadistica4all.github.io/Notebooks/KNN/KNN.ipynb#Y336sZmlsZQ%3D%3D?line=342'>343</a>\u001b[0m     Dist_Gower \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msqrt( \u001b[39m1\u001b[39m \u001b[39m-\u001b[39m Gower_Similarity_Python(i, j, Mixed_Data , p1, p2, p3) )\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Usuario/Documents/fabio/Fabio/Estadistica4all.github.io/Notebooks/KNN/KNN.ipynb#Y336sZmlsZQ%3D%3D?line=344'>345</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m(Dist_Gower)\n",
      "\u001b[1;32mc:\\Users\\Usuario\\Documents\\fabio\\Fabio\\Estadistica4all.github.io\\Notebooks\\KNN\\KNN.ipynb Celda 174\u001b[0m in \u001b[0;36mKNN_regression.<locals>.Gower_Similarity_Python\u001b[1;34m(i, j, Mixed_Data_Set, p1, p2, p3)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Usuario/Documents/fabio/Fabio/Estadistica4all.github.io/Notebooks/KNN/KNN.ipynb#Y336sZmlsZQ%3D%3D?line=328'>329</a>\u001b[0m numerator_part_2 \u001b[39m=\u001b[39m a(Binary_Data)\u001b[39m.\u001b[39miloc[i\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,j\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m+\u001b[39m alpha_py(i,j, Multiple_Categorical_Data)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Usuario/Documents/fabio/Fabio/Estadistica4all.github.io/Notebooks/KNN/KNN.ipynb#Y336sZmlsZQ%3D%3D?line=330'>331</a>\u001b[0m numerator \u001b[39m=\u001b[39m numerator_part_1 \u001b[39m+\u001b[39m numerator_part_2\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/Usuario/Documents/fabio/Fabio/Estadistica4all.github.io/Notebooks/KNN/KNN.ipynb#Y336sZmlsZQ%3D%3D?line=332'>333</a>\u001b[0m denominator \u001b[39m=\u001b[39m p1 \u001b[39m+\u001b[39m (p2 \u001b[39m-\u001b[39m d(Binary_Data)\u001b[39m.\u001b[39miloc[i\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,j\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]) \u001b[39m+\u001b[39m p3\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Usuario/Documents/fabio/Fabio/Estadistica4all.github.io/Notebooks/KNN/KNN.ipynb#Y336sZmlsZQ%3D%3D?line=334'>335</a>\u001b[0m Similarity_Gower \u001b[39m=\u001b[39m numerator \u001b[39m/\u001b[39m denominator  \n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Usuario/Documents/fabio/Fabio/Estadistica4all.github.io/Notebooks/KNN/KNN.ipynb#Y336sZmlsZQ%3D%3D?line=336'>337</a>\u001b[0m \u001b[39mreturn\u001b[39;00m(Similarity_Gower)\n",
      "\u001b[1;32mc:\\Users\\Usuario\\Documents\\fabio\\Fabio\\Estadistica4all.github.io\\Notebooks\\KNN\\KNN.ipynb Celda 174\u001b[0m in \u001b[0;36mKNN_regression.<locals>.d\u001b[1;34m(Binary_Data)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Usuario/Documents/fabio/Fabio/Estadistica4all.github.io/Notebooks/KNN/KNN.ipynb#Y336sZmlsZQ%3D%3D?line=258'>259</a>\u001b[0m X \u001b[39m=\u001b[39m Binary_Data\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Usuario/Documents/fabio/Fabio/Estadistica4all.github.io/Notebooks/KNN/KNN.ipynb#Y336sZmlsZQ%3D%3D?line=260'>261</a>\u001b[0m ones_matrix \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mones(( X\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] , X\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m])) \n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/Usuario/Documents/fabio/Fabio/Estadistica4all.github.io/Notebooks/KNN/KNN.ipynb#Y336sZmlsZQ%3D%3D?line=262'>263</a>\u001b[0m d \u001b[39m=\u001b[39m (ones_matrix \u001b[39m-\u001b[39;49m X) \u001b[39m@\u001b[39;49m (ones_matrix \u001b[39m-\u001b[39;49m X)\u001b[39m.\u001b[39;49mT\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Usuario/Documents/fabio/Fabio/Estadistica4all.github.io/Notebooks/KNN/KNN.ipynb#Y336sZmlsZQ%3D%3D?line=264'>265</a>\u001b[0m \u001b[39mreturn\u001b[39;00m(d)\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:1553\u001b[0m, in \u001b[0;36mDataFrame.__matmul__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m   1547\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__matmul__\u001b[39m(\n\u001b[0;32m   1548\u001b[0m     \u001b[39mself\u001b[39m, other: AnyArrayLike \u001b[39m|\u001b[39m DataFrame \u001b[39m|\u001b[39m Series\n\u001b[0;32m   1549\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[0;32m   1550\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1551\u001b[0m \u001b[39m    Matrix multiplication using binary `@` operator in Python>=3.5.\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1553\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdot(other)\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:1524\u001b[0m, in \u001b[0;36mDataFrame.dot\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m   1518\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1519\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mDot product shape mismatch, \u001b[39m\u001b[39m{\u001b[39;00mlvals\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m vs \u001b[39m\u001b[39m{\u001b[39;00mrvals\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1520\u001b[0m         )\n\u001b[0;32m   1522\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(other, DataFrame):\n\u001b[0;32m   1523\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_constructor(\n\u001b[1;32m-> 1524\u001b[0m         np\u001b[39m.\u001b[39;49mdot(lvals, rvals), index\u001b[39m=\u001b[39mleft\u001b[39m.\u001b[39mindex, columns\u001b[39m=\u001b[39mother\u001b[39m.\u001b[39mcolumns\n\u001b[0;32m   1525\u001b[0m     )\n\u001b[0;32m   1526\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(other, Series):\n\u001b[0;32m   1527\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_constructor_sliced(np\u001b[39m.\u001b[39mdot(lvals, rvals), index\u001b[39m=\u001b[39mleft\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "prediction , message = KNN_regression( X , Y , x_new, k=10, distance = \"Gower\",  p1=5, p2=21, p3=2  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting an optimal k with cross-validation <a class=\"anchor\" id=\"8\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliography\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\n",
    "\n",
    "apuntes aurea\n",
    "\n",
    "apuntes nogales\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c63d8c7d738c2960218a10995aedf0a7f67a49a231e71037adf0440953cdb45b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
