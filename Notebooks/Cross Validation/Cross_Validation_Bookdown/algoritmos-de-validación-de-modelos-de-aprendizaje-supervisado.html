<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 5 Algoritmos de validación de modelos de aprendizaje supervisado | Algoritmos de validación de modelos de aprendizaje supervisado</title>
  <meta name="description" content="Esta es una introducción a los algoritmos de validación de modelos de aprendizaje supervisado." />
  <meta name="generator" content="bookdown 0.32 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 5 Algoritmos de validación de modelos de aprendizaje supervisado | Algoritmos de validación de modelos de aprendizaje supervisado" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="Esta es una introducción a los algoritmos de validación de modelos de aprendizaje supervisado." />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 5 Algoritmos de validación de modelos de aprendizaje supervisado | Algoritmos de validación de modelos de aprendizaje supervisado" />
  
  <meta name="twitter:description" content="Esta es una introducción a los algoritmos de validación de modelos de aprendizaje supervisado." />
  

<meta name="author" content="Fabio Scielzo Ortiz" />


<meta name="date" content="2023-03-07" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="métricas-para-evaluar-modelos-de-clasificación-supervisada.html"/>
<link rel="next" href="selección-de-modelos-basada-en-validación-cruzada.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Algoritmos de validación de modelos de aprendizaje supervisado </a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introducción</a></li>
<li class="chapter" data-level="2" data-path="muestras-y-predicciones-de-de-train-y-test.html"><a href="muestras-y-predicciones-de-de-train-y-test.html"><i class="fa fa-check"></i><b>2</b> Muestras y predicciones de de train y test</a>
<ul>
<li class="chapter" data-level="2.1" data-path="muestras-y-predicciones-de-de-train-y-test.html"><a href="muestras-y-predicciones-de-de-train-y-test.html#train-set"><i class="fa fa-check"></i><b>2.1</b> Train-set</a></li>
<li class="chapter" data-level="2.2" data-path="muestras-y-predicciones-de-de-train-y-test.html"><a href="muestras-y-predicciones-de-de-train-y-test.html#predicciones-de-train"><i class="fa fa-check"></i><b>2.2</b> Predicciones de train</a></li>
<li class="chapter" data-level="2.3" data-path="muestras-y-predicciones-de-de-train-y-test.html"><a href="muestras-y-predicciones-de-de-train-y-test.html#test-set"><i class="fa fa-check"></i><b>2.3</b> Test-set</a></li>
<li class="chapter" data-level="2.4" data-path="muestras-y-predicciones-de-de-train-y-test.html"><a href="muestras-y-predicciones-de-de-train-y-test.html#predicciones-de-test"><i class="fa fa-check"></i><b>2.4</b> Predicciones de test</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="métricas-para-evaluar-modelos-de-regresión.html"><a href="métricas-para-evaluar-modelos-de-regresión.html"><i class="fa fa-check"></i><b>3</b> Métricas para evaluar modelos de regresión</a>
<ul>
<li class="chapter" data-level="3.1" data-path="métricas-para-evaluar-modelos-de-regresión.html"><a href="métricas-para-evaluar-modelos-de-regresión.html#error-cuadrático-medio-ecm"><i class="fa fa-check"></i><b>3.1</b> Error cuadrático medio (ECM)</a></li>
<li class="chapter" data-level="3.2" data-path="métricas-para-evaluar-modelos-de-regresión.html"><a href="métricas-para-evaluar-modelos-de-regresión.html#raiz-del-error-cuadrático-medio-recm"><i class="fa fa-check"></i><b>3.2</b> Raiz del error cuadrático medio (RECM)</a></li>
<li class="chapter" data-level="3.3" data-path="métricas-para-evaluar-modelos-de-regresión.html"><a href="métricas-para-evaluar-modelos-de-regresión.html#error-cuadratico-relativo-ecr"><i class="fa fa-check"></i><b>3.3</b> Error cuadratico relativo (ECR)</a></li>
<li class="chapter" data-level="3.4" data-path="métricas-para-evaluar-modelos-de-regresión.html"><a href="métricas-para-evaluar-modelos-de-regresión.html#coeficiente-de-determinación"><i class="fa fa-check"></i><b>3.4</b> Coeficiente de determinación</a></li>
<li class="chapter" data-level="3.5" data-path="métricas-para-evaluar-modelos-de-regresión.html"><a href="métricas-para-evaluar-modelos-de-regresión.html#error-absoluto-medio-eam"><i class="fa fa-check"></i><b>3.5</b> Error absoluto medio (EAM)</a></li>
<li class="chapter" data-level="3.6" data-path="métricas-para-evaluar-modelos-de-regresión.html"><a href="métricas-para-evaluar-modelos-de-regresión.html#error-absoluto-relativo-ear"><i class="fa fa-check"></i><b>3.6</b> Error absoluto relativo (EAR)</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="métricas-para-evaluar-modelos-de-clasificación-supervisada.html"><a href="métricas-para-evaluar-modelos-de-clasificación-supervisada.html"><i class="fa fa-check"></i><b>4</b> Métricas para evaluar modelos de clasificación supervisada</a>
<ul>
<li class="chapter" data-level="4.1" data-path="métricas-para-evaluar-modelos-de-clasificación-supervisada.html"><a href="métricas-para-evaluar-modelos-de-clasificación-supervisada.html#tasa-de-acierto-en-la-clasificación-tac"><i class="fa fa-check"></i><b>4.1</b> Tasa de acierto en la clasificación (TAC)</a></li>
<li class="chapter" data-level="4.2" data-path="métricas-para-evaluar-modelos-de-clasificación-supervisada.html"><a href="métricas-para-evaluar-modelos-de-clasificación-supervisada.html#tasa-de-error-en-la-clasificación-tec"><i class="fa fa-check"></i><b>4.2</b> Tasa de error en la clasificación (TEC)</a></li>
<li class="chapter" data-level="4.3" data-path="métricas-para-evaluar-modelos-de-clasificación-supervisada.html"><a href="métricas-para-evaluar-modelos-de-clasificación-supervisada.html#kappa"><i class="fa fa-check"></i><b>4.3</b> Kappa</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="métricas-para-evaluar-modelos-de-clasificación-supervisada.html"><a href="métricas-para-evaluar-modelos-de-clasificación-supervisada.html#modelo-de-clasificación-aleatoria-uniforme"><i class="fa fa-check"></i><b>4.3.1</b> Modelo de clasificación aleatoria uniforme</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="algoritmos-de-validación-de-modelos-de-aprendizaje-supervisado.html"><a href="algoritmos-de-validación-de-modelos-de-aprendizaje-supervisado.html"><i class="fa fa-check"></i><b>5</b> Algoritmos de validación de modelos de aprendizaje supervisado</a>
<ul>
<li class="chapter" data-level="5.1" data-path="algoritmos-de-validación-de-modelos-de-aprendizaje-supervisado.html"><a href="algoritmos-de-validación-de-modelos-de-aprendizaje-supervisado.html#validación-simple-no-aleatoria"><i class="fa fa-check"></i><b>5.1</b> Validación simple no aleatoria</a></li>
<li class="chapter" data-level="5.2" data-path="algoritmos-de-validación-de-modelos-de-aprendizaje-supervisado.html"><a href="algoritmos-de-validación-de-modelos-de-aprendizaje-supervisado.html#validación-simple-aleatoria"><i class="fa fa-check"></i><b>5.2</b> Validación simple aleatoria</a></li>
<li class="chapter" data-level="5.3" data-path="algoritmos-de-validación-de-modelos-de-aprendizaje-supervisado.html"><a href="algoritmos-de-validación-de-modelos-de-aprendizaje-supervisado.html#validación-simple-aleatoria-repetida"><i class="fa fa-check"></i><b>5.3</b> Validación simple aleatoria repetida</a></li>
<li class="chapter" data-level="5.4" data-path="algoritmos-de-validación-de-modelos-de-aprendizaje-supervisado.html"><a href="algoritmos-de-validación-de-modelos-de-aprendizaje-supervisado.html#leave-one-out"><i class="fa fa-check"></i><b>5.4</b> Leave-one-out</a></li>
<li class="chapter" data-level="5.5" data-path="algoritmos-de-validación-de-modelos-de-aprendizaje-supervisado.html"><a href="algoritmos-de-validación-de-modelos-de-aprendizaje-supervisado.html#k-fold"><i class="fa fa-check"></i><b>5.5</b> k-fold</a></li>
<li class="chapter" data-level="5.6" data-path="algoritmos-de-validación-de-modelos-de-aprendizaje-supervisado.html"><a href="algoritmos-de-validación-de-modelos-de-aprendizaje-supervisado.html#repeted-k-fold"><i class="fa fa-check"></i><b>5.6</b> Repeted k-fold</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="selección-de-modelos-basada-en-validación-cruzada.html"><a href="selección-de-modelos-basada-en-validación-cruzada.html"><i class="fa fa-check"></i><b>6</b> Selección de modelos basada en validación cruzada</a></li>
<li class="chapter" data-level="7" data-path="algoritmos-de-validación-cruzada-programados-en-python.html"><a href="algoritmos-de-validación-cruzada-programados-en-python.html"><i class="fa fa-check"></i><b>7</b> Algoritmos de validación cruzada programados en <code>Python</code></a>
<ul>
<li class="chapter" data-level="7.1" data-path="algoritmos-de-validación-cruzada-programados-en-python.html"><a href="algoritmos-de-validación-cruzada-programados-en-python.html#validación-simple-no-aleatoria-1"><i class="fa fa-check"></i><b>7.1</b> Validación simple no aleatoria</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="algoritmos-de-validación-cruzada-programados-en-python.html"><a href="algoritmos-de-validación-cruzada-programados-en-python.html#ejemplo-de-aplicación-a-knn-para-regresión"><i class="fa fa-check"></i><b>7.1.1</b> Ejemplo de aplicación a KNN para regresión</a></li>
<li class="chapter" data-level="7.1.2" data-path="algoritmos-de-validación-cruzada-programados-en-python.html"><a href="algoritmos-de-validación-cruzada-programados-en-python.html#ejemplo-de-aplicación-a-knn-para-clasificación"><i class="fa fa-check"></i><b>7.1.2</b> Ejemplo de aplicación a KNN para clasificación</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="algoritmos-de-validación-cruzada-programados-en-python.html"><a href="algoritmos-de-validación-cruzada-programados-en-python.html#validación-simple-aleatoria-1"><i class="fa fa-check"></i><b>7.2</b> Validación simple aleatoria</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="algoritmos-de-validación-cruzada-programados-en-python.html"><a href="algoritmos-de-validación-cruzada-programados-en-python.html#ejemplo-de-aplicación-a-knn-para-regresión-1"><i class="fa fa-check"></i><b>7.2.1</b> Ejemplo de aplicación a KNN para regresión</a></li>
<li class="chapter" data-level="7.2.2" data-path="algoritmos-de-validación-cruzada-programados-en-python.html"><a href="algoritmos-de-validación-cruzada-programados-en-python.html#ejemplo-de-aplicación-a-knn-para-clasifación"><i class="fa fa-check"></i><b>7.2.2</b> Ejemplo de aplicación a KNN para clasifación</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="algoritmos-de-validación-cruzada-programados-en-python.html"><a href="algoritmos-de-validación-cruzada-programados-en-python.html#validación-simple-aleatoria-repetida-1"><i class="fa fa-check"></i><b>7.3</b> Validación simple aleatoria repetida</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="algoritmos-de-validación-cruzada-programados-en-python.html"><a href="algoritmos-de-validación-cruzada-programados-en-python.html#ejemplo-de-aplicación-a-knn-para-regresión-2"><i class="fa fa-check"></i><b>7.3.1</b> Ejemplo de aplicación a KNN para regresión</a></li>
<li class="chapter" data-level="7.3.2" data-path="algoritmos-de-validación-cruzada-programados-en-python.html"><a href="algoritmos-de-validación-cruzada-programados-en-python.html#ejemplo-de-aplicación-a-knn-para-clasificación-1"><i class="fa fa-check"></i><b>7.3.2</b> Ejemplo de aplicación a KNN para clasificación</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="algoritmos-de-validación-cruzada-programados-en-python.html"><a href="algoritmos-de-validación-cruzada-programados-en-python.html#leave-one-out-1"><i class="fa fa-check"></i><b>7.4</b> Leave one out</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="algoritmos-de-validación-cruzada-programados-en-python.html"><a href="algoritmos-de-validación-cruzada-programados-en-python.html#ejemplo-de-aplicación-a-kkn-para-regresión"><i class="fa fa-check"></i><b>7.4.1</b> Ejemplo de aplicación a KKN para regresión</a></li>
<li class="chapter" data-level="7.4.2" data-path="algoritmos-de-validación-cruzada-programados-en-python.html"><a href="algoritmos-de-validación-cruzada-programados-en-python.html#ejemplo-de-aplicación-a-kkn-para-clasificación"><i class="fa fa-check"></i><b>7.4.2</b> Ejemplo de aplicación a KKN para clasificación</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="algoritmos-de-validación-cruzada-programados-en-python.html"><a href="algoritmos-de-validación-cruzada-programados-en-python.html#k-fold-1"><i class="fa fa-check"></i><b>7.5</b> k-fold</a>
<ul>
<li class="chapter" data-level="7.5.1" data-path="algoritmos-de-validación-cruzada-programados-en-python.html"><a href="algoritmos-de-validación-cruzada-programados-en-python.html#ejemplo-de-aplicación-a-kkn-para-regresión-1"><i class="fa fa-check"></i><b>7.5.1</b> Ejemplo de aplicación a KKN para regresión</a></li>
<li class="chapter" data-level="7.5.2" data-path="algoritmos-de-validación-cruzada-programados-en-python.html"><a href="algoritmos-de-validación-cruzada-programados-en-python.html#ejemplo-de-aplicación-a-kkn-para-clasificación-1"><i class="fa fa-check"></i><b>7.5.2</b> Ejemplo de aplicación a KKN para clasificación</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="algoritmos-de-validación-cruzada-programados-en-python.html"><a href="algoritmos-de-validación-cruzada-programados-en-python.html#repeated-k-folds"><i class="fa fa-check"></i><b>7.6</b> Repeated k-folds</a>
<ul>
<li class="chapter" data-level="7.6.1" data-path="algoritmos-de-validación-cruzada-programados-en-python.html"><a href="algoritmos-de-validación-cruzada-programados-en-python.html#ejemplo-de-aplicación-a-kkn-para-regresión-2"><i class="fa fa-check"></i><b>7.6.1</b> Ejemplo de aplicación a KKN para regresión</a></li>
<li class="chapter" data-level="7.6.2" data-path="algoritmos-de-validación-cruzada-programados-en-python.html"><a href="algoritmos-de-validación-cruzada-programados-en-python.html#ejemplo-de-aplicación-a-kkn-para-clasificación-2"><i class="fa fa-check"></i><b>7.6.2</b> Ejemplo de aplicación a KKN para clasificación</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="algoritmos-de-valicación-cruzada-con-sklearn.html"><a href="algoritmos-de-valicación-cruzada-con-sklearn.html"><i class="fa fa-check"></i><b>8</b> Algoritmos de valicación cruzada con <code>Sklearn</code></a>
<ul>
<li class="chapter" data-level="8.1" data-path="algoritmos-de-valicación-cruzada-con-sklearn.html"><a href="algoritmos-de-valicación-cruzada-con-sklearn.html#k-fold-2"><i class="fa fa-check"></i><b>8.1</b> k-fold</a>
<ul>
<li class="chapter" data-level="8.1.1" data-path="algoritmos-de-valicación-cruzada-con-sklearn.html"><a href="algoritmos-de-valicación-cruzada-con-sklearn.html#aplicación-a-knn-para-regresión"><i class="fa fa-check"></i><b>8.1.1</b> Aplicación a KNN para regresión</a></li>
<li class="chapter" data-level="8.1.2" data-path="algoritmos-de-valicación-cruzada-con-sklearn.html"><a href="algoritmos-de-valicación-cruzada-con-sklearn.html#aplicación-a-knn-para-clasificación"><i class="fa fa-check"></i><b>8.1.2</b> Aplicación a KNN para clasificación</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="algoritmos-de-valicación-cruzada-con-sklearn.html"><a href="algoritmos-de-valicación-cruzada-con-sklearn.html#repeated-k-fold"><i class="fa fa-check"></i><b>8.2</b> Repeated k-fold</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="algoritmos-de-valicación-cruzada-con-sklearn.html"><a href="algoritmos-de-valicación-cruzada-con-sklearn.html#aplicación-a-knn-para-regresión-1"><i class="fa fa-check"></i><b>8.2.1</b> Aplicación a KNN para regresión</a></li>
<li class="chapter" data-level="8.2.2" data-path="algoritmos-de-valicación-cruzada-con-sklearn.html"><a href="algoritmos-de-valicación-cruzada-con-sklearn.html#aplicación-a-knn-para-regresión-2"><i class="fa fa-check"></i><b>8.2.2</b> Aplicación a KNN para regresión</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="comparación-final.html"><a href="comparación-final.html"><i class="fa fa-check"></i><b>9</b> Comparación final</a>
<ul>
<li class="chapter" data-level="9.1" data-path="comparación-final.html"><a href="comparación-final.html#visualización-aplicada-a-knn-para-regresión"><i class="fa fa-check"></i><b>9.1</b> Visualización aplicada a KNN para regresión</a></li>
<li class="chapter" data-level="9.2" data-path="comparación-final.html"><a href="comparación-final.html#visualización-aplicada-a-knn-para-clasificación"><i class="fa fa-check"></i><b>9.2</b> Visualización aplicada a KNN para clasificación</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="bibliografía.html"><a href="bibliografía.html"><i class="fa fa-check"></i><b>10</b> Bibliografía</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Algoritmos de validación de modelos de aprendizaje supervisado</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="algoritmos-de-validación-de-modelos-de-aprendizaje-supervisado" class="section level1 hasAnchor" number="5">
<h1><span class="header-section-number">Chapter 5</span> Algoritmos de validación de modelos de aprendizaje supervisado<a href="algoritmos-de-validación-de-modelos-de-aprendizaje-supervisado.html#algoritmos-de-validación-de-modelos-de-aprendizaje-supervisado" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>Los algoritmos de validación de modelos de aprendizaje supervisado permiten medir la capacidad predictiva de dichos modelos. Estoas algoritmos se suelen basar en:</p>
<ul>
<li><p>División del data-set inicial de la respuesta y los predictores en parte de train y parte de test.</p></li>
<li><p>Entrenamiento del modelo con la parte de train.</p></li>
<li><p>Obtención de predicciones de la respuesta con la parte de test.</p></li>
<li><p>Cálculo de una métrica de evaluación usando las predicciones obtenidas en el paso 4) y las observaciones de test de la respuesta. <span class="math inline">\(\\[0.3cm]\)</span></p></li>
</ul>
<p>Tenemos un modelo de aprendizaje supervisado <span class="math inline">\(\hspace{0.1cm}M\hspace{0.1cm}\)</span> y una muestra de <span class="math inline">\(\hspace{0.1cm}N\hspace{0.1cm}\)</span> observaciones de <span class="math inline">\(\hspace{0.1cm}p\hspace{0.1cm}\)</span> predictores <span class="math inline">\(\hspace{0.1cm}\mathcal{X}_1,...,\mathcal{X}_p\hspace{0.1cm}\)</span> y de la respuesta <span class="math inline">\(\hspace{0.1cm}\mathcal{Y}\)</span>.</p>
<p><span class="math display">\[D\hspace{0.1cm}=\hspace{0.1cm}[X_1,...,X_p,Y]\hspace{0.1cm}=\hspace{0.1cm}\begin{pmatrix}
    x_{11}&amp;x_{12}&amp;...&amp;x_{1p}&amp; y_1\\
    x_{21}&amp;x_{22}&amp;...&amp;x_{2p} &amp; y_2\\
    &amp;...&amp;\\
    x_{N1}&amp;x_{N2}&amp;...&amp;x_{Np}&amp; y_N
    \end{pmatrix}=\begin{pmatrix}
    x_{1}&amp; y_1\\
    x_{2}&amp; y_2\\
    ...&amp;...\\
    x_{N}&amp; y_N
    \end{pmatrix}\]</span></p>
<p><br></p>
<p><br></p>
<div id="validación-simple-no-aleatoria" class="section level2 hasAnchor" number="5.1">
<h2><span class="header-section-number">5.1</span> Validación simple no aleatoria<a href="algoritmos-de-validación-de-modelos-de-aprendizaje-supervisado.html#validación-simple-no-aleatoria" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p><strong>Descripción no formal del algoritmo:</strong></p>
<p>Este algoritmo de validación consiste en dividir el data-set inicial en una parte de train y otra de test de manera no aleatoria.</p>
<p>El <span class="math inline">\(\hspace{0.1cm} k\% \hspace{0.1cm}\)</span> de las primeras filas del data-set serán la parte de train, y el resto la parte de test.</p>
<p>El modelo es entrenado con la muestra train y testado calculando una métrica de evaluación con la muestra test. Este valor de la métrica de evaluación es el que será usado para medir la capacidad predictiva del modelo y compararlo con otros modelos. <span class="math inline">\(\\[0.4cm]\)</span></p>
<p><strong>Decripción formal del algoritmo:</strong></p>
<p>El algoritmo de validación simple no aleatoria tiene los siguientes pasos: <span class="math inline">\(\\[0.3cm]\)</span></p>
<div class="warning" style="background-color:#F7EBE8; color: #030000; border-left: solid #CA0B0B 7px; border-radius: 3px; size:1px ; padding:0.1em;">
<p><span></p>
<p style="margin-left:1em;">
<ul>
<li><p>Se divide <span class="math inline">\(D\)</span> en parte de train y parte de test del siguiente modo:</p>
<p>Sea <span class="math inline">\(\hspace{0.05cm}k\in (0,1)\hspace{0.05cm}\)</span> la proporción de filas de <span class="math inline">\(D\)</span> que formaran parte del muestra de <strong>train</strong> :</p>
<ul>
<li><p>Las primeras <span class="math inline">\(\hspace{0.2cm}\lfloor k \cdot N \rfloor\hspace{0.2cm}\)</span> observaciones (filas) definen el conjunto de train: <span class="math inline">\(\\[0.15cm]\)</span></p>
<p><span class="math display">\[D_{train}= \begin{pmatrix}
  x_{11}&amp;...&amp;x_{1p}&amp; y_1\\
  x_{21}&amp;...&amp;x_{2p} &amp; y_2\\
  ...&amp;...&amp;...&amp;... \\
  x_{\lfloor k  \cdot N \rfloor1}&amp; ...&amp;x_{\lfloor k  \cdot N \rfloor p}&amp; y_{\lfloor k  \cdot N \rfloor}
  \end{pmatrix}\\\]</span></p>
<p>Donde:</p>
<ul>
<li><span class="math inline">\(\# D_{train}\hspace{0.01cm}\)</span> es el número de <strong>filas</strong> de <span class="math inline">\(\hspace{0.01cm}D_{train}\)</span>. <span class="math inline">\(\\[0.25cm]\)</span></li>
</ul></li>
<li><p>Las siguientes <span class="math inline">\(\hspace{0.2cm} N - \lfloor k \cdot N \rfloor\hspace{0.2cm}\)</span> observaciones definen (filas) el conjunto de test: <span class="math inline">\(\\[0.15cm]\)</span></p>
<p><span class="math display">\[D_{test}= \begin{pmatrix}
x_{(\lfloor k  \cdot N \rfloor + 1) \hspace{0.05cm} 1 } &amp;...&amp;x_{(\lfloor k  \cdot N \rfloor + 1) \hspace{0.05cm} p}&amp; y_{\lfloor k  \cdot N \rfloor + 1} \\
x_{(\lfloor k  \cdot N \rfloor + 2) \hspace{0.05cm} 1 }&amp;...&amp;x_{(\lfloor k  \cdot N \rfloor + 2) \hspace{0.05cm} p}&amp; y_{\lfloor k  \cdot N \rfloor + 2}\\  ...&amp;...&amp;...&amp;... \\
    x_{N \hspace{0.05cm} 1 } &amp;...&amp;x_{N p}&amp; y_{N}
\end{pmatrix} \\\]</span></p>
<p>Donde:</p>
<ul>
<li><p><span class="math inline">\(\# D_{test}\hspace{0.1cm}\)</span> es el número de <strong>filas</strong> de <span class="math inline">\(\hspace{0.1cm}D_{test}\)</span> .</p></li>
<li><p><span class="math inline">\(\lfloor \cdot \rfloor\hspace{0.1cm}\)</span> es la funcion suelo, que dado un número como argumento te devuelve el mayor entero menor que dicho número. <span class="math inline">\(\\[0.15cm]\)</span></p></li>
</ul></li>
</ul></li>
<li><p>Se entrena el modelo <span class="math inline">\(\hspace{0.1cm} M\hspace{0.1cm}\)</span> con la <strong>muestra de train</strong> <span class="math inline">\(\hspace{0.1cm} D_{train}\hspace{0.1cm}\)</span> <span class="math inline">\(\hspace{0.25cm}\Rightarrow\hspace{0.25cm}\)</span> <span class="math inline">\(\widehat{M}\)</span> .</p></li>
<li><p>Se calcula una métrica de evaluación sobre el modelo entrenado <span class="math inline">\(\hspace{0.1cm}\widehat{M}\hspace{0.1cm}\)</span> usando la <strong>muestra de test</strong> <span class="math inline">\(\hspace{0.1cm} D_{test}\hspace{0.1cm}\)</span> <span class="math inline">\(\hspace{0.2cm}\Rightarrow\hspace{0.2cm}\)</span> Si por ejemplo se calcula el <span class="math inline">\(\hspace{0.1cm}ECM\hspace{0.1cm}\)</span> , se obtendria el <span class="math inline">\(\hspace{0.1cm}ECM_{test}\)</span> .</p></li>
<li><p>La métrica de evaluación final del modelo es la obtenida en el paso anterior.</p>
<ul>
<li><p>Si la métrica empleada en el paso anterior es el <span class="math inline">\(\hspace{0.1cm}ECM\hspace{0.1cm}\)</span> , entonces la métrica de evaluación calculada con el algoritmo de validación simple no aleatoria es la siguiente:</p>
<p><span class="math display">\[ECM(M)_{test}^* \hspace{0.1cm}=\hspace{0.1cm} ECM(\widehat{M})_{test} \hspace{0.1cm}=\hspace{0.1cm} \dfrac{1}{\# D_{test}} \cdot \sum_{i=1}^{\# D_{test}} \hspace{0.1cm} ( \hspace{0.1cm} y_i^{test} - \hat{y}_i^{test} \hspace{0.1cm})^2\]</span></p>
<p>Donde:</p>
<ul>
<li><span class="math inline">\(\hat{y}_i^{test} \hspace{0.1cm}=\hspace{0.1cm} \widehat{M}(\hspace{0.1cm} x_i^{test} \hspace{0.1cm}|\hspace{0.1cm} D_{train}) \hspace{0.1cm}=\hspace{0.1cm} M(\hspace{0.1cm} x_i^{test} \hspace{0.1cm}|\hspace{0.1cm} X_1^{train},...,X_p^{train},Y^{train})\hspace{0.1cm}=\hspace{0.1cm} \widehat{M}(\hspace{0.1cm} x_i^{test} \hspace{0.1cm})\)</span></li>
</ul></li>
</ul></li>
</ul>
</p>
</p>
<p></span></p>
</div>
<p><br></p>
<p><strong>Problemas</strong></p>
<p>Toda la validación queda condicionada a solo una muestra de train y otra de test. Si alguna de estas muestras tienen defectos, estos se van a trasladar a la validación, que será por tanto defectuosa. Es la primera aproximación naive a los algoritmos de validación.</p>
<p><br></p>
</div>
<div id="validación-simple-aleatoria" class="section level2 hasAnchor" number="5.2">
<h2><span class="header-section-number">5.2</span> Validación simple aleatoria<a href="algoritmos-de-validación-de-modelos-de-aprendizaje-supervisado.html#validación-simple-aleatoria" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p><strong>Decripción no formal del algoritmo:</strong></p>
<p>Este algoritmo de validacion consiste en dividir el data-set inicial en una parte de train y otra de test de manera <strong>aleatoria</strong>.</p>
<p>Se obtiene una muestra aleatoria sin remplazo de un <span class="math inline">\(\hspace{0.1cm} k\% \hspace{0.1cm}\)</span> de las filas del data-set inicial, las cuales serán la parte de train, y el resto la parte de test.</p>
<p>El modelo es entrenado con la muestra train y testado calculando un métrica de evaluación con la muestra de test. Este valor de la métrica de evaluación es el que será usado para medir el poder predictivo del modelo y compararlo con otros modelos.</p>
<p><br></p>
<p><strong>Decripción formal del algoritmo:</strong></p>
<p>El algoritmo de validación simple aleatoria tiene los siguientes pasos:</p>
<div class="warning" style="background-color:#F7EBE8; color: #030000; border-left: solid #CA0B0B 7px; border-radius: 3px; size:1px ; padding:0.1em;">
<p><span></p>
<p style="margin-left:1em;">
<ul>
<li><p>Se divide <span class="math inline">\(\hspace{0.1cm}D\hspace{0.1cm}\)</span> en parte de train y parte de test del siguiente modo:</p>
<p>Sea <span class="math inline">\(\hspace{0.1cm}k\in (0,1)\hspace{0.1cm}\)</span> la proporción de filas de <span class="math inline">\(\hspace{0.1cm}D\hspace{0.1cm}\)</span> que formarán parte de la muestra de <strong>train</strong> (es un hiper-parametro del algoritmo): <span class="math inline">\(\\[0.05cm]\)</span></p>
<ul>
<li>Se genera una muestra aleatoria sin reemplazamiento de tamaño <span class="math inline">\(\lfloor k \cdot N \rfloor\)</span> del vector <span class="math inline">\((\hspace{0.05cm}1,2,...,N\hspace{0.05cm})\)</span> :</li>
</ul>
<p><span class="math display">\[m=(m_1 ,m_2,...,m_{\lfloor k  \cdot N \rfloor}) \\\]</span></p>
<ul>
<li><p>Las observaciones (filas) <span class="math inline">\(\hspace{0.1cm}m=(m_1,m_2 ,...,m_{\lfloor k \cdot N \rfloor})\hspace{0.1cm}\)</span> de <span class="math inline">\(D\)</span> definen la <strong>muestra de train</strong>: <span class="math inline">\(\\[0.15cm]\)</span></p>
<p><span class="math display">\[D_{train}= D[m , :] = \begin{pmatrix}
  x_{m_11}&amp; ...&amp;x_{m_1p}&amp; y_{m_1}\\
  x_{m_21}&amp; ...&amp;x_{m_2p} &amp; y_{m_2}\\
  &amp;...&amp;\\
  x_{m_{\lfloor k  \cdot N \rfloor} 1} &amp;...&amp;x_{m_{\lfloor k  \cdot N \rfloor} p}&amp; y_{m_{\lfloor k  \cdot N \rfloor}}
  \end{pmatrix}  =  \begin{pmatrix}
  x_{1}^{train} &amp; y_{1}^{train}\\
  x_{2}^{train} &amp; y_{2}^{train}\\
  ....&amp;...\\
  x_{\# D_{train}}^{train} &amp; y_{\# D_{train}}^{train}\\
  \end{pmatrix} \\\]</span></p>
<p>Donde:</p>
<ul>
<li><span class="math inline">\(\# D_{train}\hspace{0.1cm}\)</span> es el número de <strong>filas</strong> de <span class="math inline">\(\hspace{0.1cm}D_{train}\)</span> <span class="math inline">\(\\[0.2cm]\)</span></li>
</ul></li>
<li><p>Las observaciones (filas) de <span class="math inline">\(D\)</span> complementarias a <span class="math inline">\(\hspace{0.1cm}m\hspace{0.1cm}\)</span> , es decir, las filas de <span class="math inline">\(D\)</span> que no estan en <span class="math inline">\(D_{train}\)</span>, es decir, las filas de <span class="math inline">\(m^c\)</span>,
definen la <strong>muestra de test</strong>: <span class="math inline">\(\\[0.15cm]\)</span></p>
<p><span class="math display">\[D_{test} = D[m^c , :] =  \begin{pmatrix}
  x_{1}^{test} &amp; y_{1}^{test}\\
  x_{2}^{test} &amp; y_{2}^{test}\\
  ....&amp;...\\
  x_{\# D_{test}}^{test} &amp; y_{\# D_{test}}^{test}\\
  \end{pmatrix} \\\]</span></p>
<p>Donde:</p>
<ul>
<li><p><span class="math inline">\(\# D_{test}\hspace{0.1cm}\)</span> es el número de <strong>filas</strong> de <span class="math inline">\(\hspace{0.1cm}D_{test}\)</span>.</p></li>
<li><p><span class="math inline">\(\lfloor \cdot \rfloor\hspace{0.1cm}\)</span> es la funcion suelo, que dado un número como argumento te devuelve el mayor entero menor que dicho número.</p></li>
<li><p><span class="math inline">\(m^c \hspace{0.1cm}= \hspace{0.1cm}\bigl(\hspace{0.1cm} i =1,...,N \hspace{0.15cm} : \hspace{0.15cm} i\neq m_j \hspace{0.1cm},\hspace{0.1cm} \forall j=1,...,\lfloor k \cdot N \rfloor \hspace{0.1cm} \bigr)\)</span> <span class="math inline">\(\\[0.15cm]\)</span></p></li>
</ul></li>
</ul></li>
<li><p>Se entrena el modelo <span class="math inline">\(\hspace{0.1cm}M\hspace{0.1cm}\)</span> con la <strong>muestra de train</strong> <span class="math inline">\(\hspace{0.1cm}D_{train}\hspace{0.1cm}\)</span> <span class="math inline">\(\hspace{0.1cm}\Rightarrow\hspace{0.2cm}\)</span> <span class="math inline">\(\widehat{M}\)</span>.</p></li>
<li><p>Se calcula una métrica de evaluación sobre el modelo entrenado <span class="math inline">\(\hspace{0.1cm}\widehat{M}\hspace{0.1cm}\)</span> con la <strong>muestra de test</strong> <span class="math inline">\(\hspace{0.1cm}D_{test}\)</span> <span class="math inline">\(\hspace{0.2cm}\Rightarrow\hspace{0.2cm}\)</span>
Si por ejemplo se calcula el <span class="math inline">\(\hspace{0.1cm}ECM\hspace{0.1cm}\)</span> , se obtendria el <span class="math inline">\(\hspace{0.1cm}ECM_{test}(\widehat{M})\)</span>.</p></li>
<li><p>La métrica de evaluación final del modelo es la obtenida en el paso anterior:</p>
<ul>
<li><p>Si la métrica empleada en el paso anterior fue el <span class="math inline">\(\hspace{0.1cm}ECM\hspace{0.1cm}\)</span> , entonces:</p>
<p><span class="math display">\[ECM(M)_{test}^* \hspace{0.1cm}=\hspace{0.1cm} ECM(\widehat{M})_{test} \hspace{0.1cm}=\hspace{0.1cm} \dfrac{1}{\# D_{test}} \cdot \sum_{i=1}^{\# D_{test}} (y_i^{test} - \hat{y}_i^{test})^2\]</span></p>
<p>Donde:</p>
<ul>
<li><span class="math inline">\(\hat{y}_i^{test} \hspace{0.1cm}=\hspace{0.1cm} M(\hspace{0.1cm} x_i^{test} \hspace{0.15cm}|\hspace{0.15cm} D_{train})\hspace{0.1cm}=\hspace{0.1cm} M(\hspace{0.1cm} x_i^{test} \hspace{0.1cm}|\hspace{0.1cm} X_1^{train},...,X_p^{train},Y^{train})\hspace{0.1cm}=\hspace{0.1cm} \widehat{M}(\hspace{0.1cm} x_i^{test} \hspace{0.1cm})\)</span></li>
</ul></li>
</ul></li>
</ul>
</p>
</p>
<p></span></p>
</div>
<p><br></p>
<p><strong>Problemas</strong></p>
<p>Toda la validación queda condicionada a solo una muestra de train y otra de test. Si alguna de estas muestras tienen defectos, estos se van a trasladar a la validación, que será por tanto defectuosa.</p>
<p>Ademas la métrica de evaluacion calculada por validación simple aleatoria tiene generalmente una varianza alta, en comparación con otros métodos de validación. Esto será ilustrado en la práctica.</p>
<p>La varianza de una metrica de evaluación calculada con un algorimo de validación se puede entender como como la varianza de los valores obtenidos de la métrica al ejecutar el algoritmo un número elevado de veces.</p>
<p>Es la segunda aproximación naive a los algoritmos de validación.</p>
<p><br></p>
<p><br></p>
</div>
<div id="validación-simple-aleatoria-repetida" class="section level2 hasAnchor" number="5.3">
<h2><span class="header-section-number">5.3</span> Validación simple aleatoria repetida<a href="algoritmos-de-validación-de-modelos-de-aprendizaje-supervisado.html#validación-simple-aleatoria-repetida" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p><strong>Decripción no formal del algoritmo:</strong></p>
<p>Este algoritmo de validacion consiste en dividir el data-set inicial en una parte de train y otra de test de manera aleatoria.</p>
<p>Se obtiene una muestra aleatoria sin remplazo de un <span class="math inline">\(\hspace{0.05cm}k\%\hspace{0.05cm}\)</span> de las filas del data-set inicial, las cuales serán la parte de train, y el resto la parte de test.</p>
<p>El modelo es enetrenado con la muestra train y testado con la muestra test a través de una métrica de evaluación como las vistas en la sección anterior.</p>
<p>Este proceso se repite un número <span class="math inline">\(\hspace{0.03cm}B\hspace{0.03cm}\)</span> de veces, asi se obtienen <span class="math inline">\(\hspace{0.03cm}B\hspace{0.03cm}\)</span> valores de la métrica de evaluación.</p>
<p>La métrica de evaluacion calculada usando este método de validación es la media de dichos <span class="math inline">\(\hspace{0.03cm}B\hspace{0.03cm}\)</span> valores obtenidos para la métrica de evaluación escogida. Este valor medio final es la que será usado para medir el poder predictivo del modelo y compararlo con otros modelos.</p>
<p><br></p>
<p><strong>Decripción formal del algoritmo:</strong></p>
<p>El algoritmo de validación simple aleatoria tiene los siguientes pasos:</p>
<div class="warning" style="background-color:#F7EBE8; color: #030000; border-left: solid #CA0B0B 7px; border-radius: 3px; size:1px ; padding:0.1em;">
<p><span></p>
<p style="margin-left:1em;">
<ul>
<li><p>Se obtienen <span class="math inline">\(B\)</span> particiones de la muestra de observaciones <span class="math inline">\(D\)</span> en parte de <strong>train</strong> y parte de <strong>test</strong> del siguiente modo:</p>
<p>Sea <span class="math inline">\(\hspace{0.05cm}k\in (0,1)\hspace{0.05cm}\)</span> la proporción de filas de <span class="math inline">\(\hspace{0.05cm}D\hspace{0.05cm}\)</span> que formarán parte de la muestra de <strong>train</strong> :</p>
<ul>
<li><p>Se generan <span class="math inline">\(\hspace{0.01cm}B\hspace{0.01cm}\)</span> muestras aleatoria sin reemplazamiento de tamaño <span class="math inline">\(\hspace{0.01cm}\lfloor k \cdot N \rfloor\hspace{0.01cm}\)</span> del vector <span class="math inline">\(\hspace{0.01cm}(1,2,...,N)\hspace{0.1cm}\)</span> :</p>
<p><span class="math display">\[m_1 \hspace{0.1cm},\hspace{0.1cm} m_2 \hspace{0.1cm},\hspace{0.1cm} ...\hspace{0.1cm},\hspace{0.1cm} m_B \\[0.01cm]\]</span></p>
<p>Donde:</p>
<ul>
<li><p><span class="math inline">\(m_r=(m_{r1} ,...,m_{r\lfloor k \cdot N \rfloor})\hspace{0.15cm} \hspace{0.25cm} , \hspace{0.25cm} \forall \hspace{0.1cm} r\in\lbrace 1,...,B\rbrace\)</span></p></li>
<li><p><span class="math inline">\(\lfloor \cdot \rfloor\hspace{0.1cm}\)</span> es la función suelo, que dado un número como argumento devuelve el mayor entero menor que dicho número. <span class="math inline">\(\\[0.08cm]\)</span></p></li>
</ul></li>
<li><p>Se obtienen las siguientes <span class="math inline">\(\hspace{0.05cm}B\hspace{0.05cm}\)</span> <strong>muestras de train</strong> del data-set original <span class="math inline">\(\hspace{0.05cm}D\hspace{0.1cm}\)</span>: <span class="math inline">\(\\[0.03cm]\)</span></p>
<p><span class="math display">\[D_{train, 1}= D[\hspace{0.1cm}m_1\hspace{0.1cm} ,\hspace{0.1cm} :\hspace{0.1cm}] \hspace{0.15cm},\hspace{0.15cm} D_{train, 2}= D[\hspace{0.1cm}m_2\hspace{0.1cm} ,\hspace{0.1cm} :\hspace{0.1cm}] \hspace{0.15cm}, \dots ,\hspace{0.15cm} D_{train, B}= D[\hspace{0.1cm}m_B\hspace{0.1cm} ,\hspace{0.1cm} :\hspace{0.1cm}] \\\]</span></p>
<p>Donde <span class="math inline">\(D_{train, r}\hspace{0.03cm}\)</span> es la submatriz que resulta de quedarse solo con las filas de <span class="math inline">\(D\)</span> definidas por la muestra <span class="math inline">\(m_r\)</span> de <span class="math inline">\((1,...,N) \hspace{0.1cm}\)</span> :</p>
<p><span class="math display">\[D_{train, r} \hspace{0.1cm}=\hspace{0.1cm} D[\hspace{0.1cm}m_r\hspace{0.1cm} ,\hspace{0.1cm} :\hspace{0.1cm}] \hspace{0.1cm}=\hspace{0.1cm} \begin{pmatrix}
  x_{m_{r1},1}  &amp; ... &amp; x_{m_{r1},p} &amp; y_{m_{r1}} \\
  x_{m_{r2},1} &amp;   ... &amp; x_{m_{r2},p} &amp; y_{m_{r2}} \\
  ....&amp;...\\
  x_{m_{r\lfloor k  \cdot N \rfloor} ,1}   &amp; ... &amp; x_{m_{r\lfloor k  \cdot N \rfloor},p} &amp; y_{m_{r\lfloor k  \cdot N \rfloor}} \end{pmatrix}  \\[1.7cm]\]</span></p></li>
<li><p>Se obtienen las siguientes <span class="math inline">\(\hspace{0.01cm}B\hspace{0.01cm}\)</span> <strong>muestras de test</strong> del data-set original <span class="math inline">\(\hspace{0.01cm}D \hspace{0.02cm}:\)</span></p>
<p><span class="math display">\[D_{test, 1}= D[\hspace{0.1cm}m_1^c\hspace{0.1cm} ,\hspace{0.1cm} :\hspace{0.1cm}] \hspace{0.15cm},\hspace{0.15cm} D_{test, 2}= D[\hspace{0.1cm}m_2^c\hspace{0.1cm} ,\hspace{0.1cm} :\hspace{0.1cm}] \hspace{0.15cm}, ... ,\hspace{0.15cm} D_{test, B}= D[\hspace{0.1cm}m_B^c\hspace{0.1cm} , \hspace{0.1cm}:\hspace{0.1cm}] \\\]</span></p>
<p>Donde: <span class="math inline">\(\hspace{0.1cm}D_{test, r} \hspace{0.1cm}=\hspace{0.1cm} D[\hspace{0.1cm}m_r^c\hspace{0.1cm} ,\hspace{0.1cm} :\hspace{0.1cm}]\hspace{0.1cm}\)</span> es la submatriz que resulta de quedarse solo con las filas de <span class="math inline">\(\hspace{0.01cm}D\hspace{0.01cm}\)</span> que no están en <span class="math inline">\(\hspace{0.01cm}D_{train}\hspace{0.01cm}\)</span>, es decir, las filas de <span class="math inline">\(\hspace{0.01cm}m_r^c\)</span>.</p>
<p>Formalmente: <span class="math inline">\(\hspace{0.15cm} m_r^c \hspace{0.1cm}=\hspace{0.1cm}\left(\hspace{0.1cm} i \in \lbrace 1,...,N \rbrace \hspace{0.15cm} / \hspace{0.15cm} i\hspace{0.1cm}\neq\hspace{0.1cm} m_{rj} \hspace{0.15cm} , \hspace{0.15cm} \forall \hspace{0.1cm} j\in \lbrace 1,...,\lfloor k \cdot N \rfloor \rbrace \hspace{0.1cm} \right) \hspace{0.15cm}\)</span> <span class="math inline">\(\\[0.2cm]\)</span></p></li>
<li><p>En conclusión: <span class="math inline">\(\hspace{0.03cm}\)</span> se obtienen <span class="math inline">\(\hspace{0.01cm}B\hspace{0.01cm}\)</span> particiones de <strong>train</strong> y <strong>test</strong> de <span class="math inline">\(\hspace{0.01cm}D\hspace{0.03cm}\)</span> . <span class="math inline">\(\\[0.5cm]\)</span></p></li>
</ul></li>
<li><p>Para cada <span class="math inline">\(\hspace{0.01cm}r\in \lbrace 1,...,B\rbrace\hspace{0.03cm}\)</span> :</p>
<ul>
<li><p>Se entrena el modelo <span class="math inline">\(\hspace{0.01cm}M\hspace{0.01cm}\)</span> con cada una de las <strong>muestras de train</strong> <span class="math inline">\(\hspace{0.01cm} D_{train,r} \hspace{0.1cm}\)</span> <span class="math inline">\(\hspace{0.2cm}\Rightarrow\hspace{0.2cm}\)</span> <span class="math inline">\(\hspace{0.1cm}\widehat{M}_r\hspace{0.03cm}\)</span>.</p></li>
<li><p>Se calcula una misma métrica de evaluación sobre el modelo entrenado <span class="math inline">\(\hspace{0.1cm}\widehat{M}_r\hspace{0.1cm}\)</span> con la <strong>muestra de test</strong> <span class="math inline">\(\hspace{0.01cm}D_{test,r}\hspace{0.03cm}\)</span>.</p>
<ul>
<li><p>Supongamos que la métrica de evaluación usada es el <span class="math inline">\(\hspace{0.1cm}ECM\hspace{0.1cm}\)</span> , entonces se obtienen <span class="math inline">\(\hspace{0.1cm}B\hspace{0.1cm}\)</span> valores de esta métrica : <span class="math inline">\(\\[0.02cm]\)</span></p>
<p><span class="math display">\[ECM_{test }(\widehat{M}_1) \hspace{0.1cm},\hspace{0.1cm}  ECM_{test }(\widehat{M}_2)\hspace{0.1cm} , ... ,\hspace{0.1cm} ECM_{test}(\widehat{M}_B)\]</span></p>
<p>Donde:</p>
<p><span class="math inline">\(\hspace{0.5cm}\)</span> <span class="math inline">\(ECM_{test , r} \hspace{0.1cm}\)</span> es el <span class="math inline">\(\hspace{0.1cm}ECM\hspace{0.1cm}\)</span> calculado sobre <span class="math inline">\(\hspace{0.1cm}\widehat{M}_r\hspace{0.1cm}\)</span> usando <span class="math inline">\(\hspace{0.1cm}D_{test,r}\hspace{0.02cm}\)</span> :</p>
<p><span class="math display">\[ECM_{test }(\widehat{M}_r) \hspace{0.1cm}=\hspace{0.1cm} \dfrac{1}{\# D_{test,r}} \cdot \sum_{i=1}^{\# D_{test,r}} \hspace{0.1cm} (\hspace{0.1cm} y_i^{\hspace{0.1cm}test,r} - \hat{\hspace{0.1cm}y\hspace{0.1cm}}_i^{\hspace{0.1cm}test,r} \hspace{0.1cm})^2 \\\]</span></p>
<p>Teniendo en cuenta que:</p>
<ul>
<li><span class="math inline">\(\hat{y}_i^{test,r} \hspace{0.1cm}=\hspace{0.1cm} M(\hspace{0.1cm} x_i^{test, r} \hspace{0.1cm}|\hspace{0.1cm} D_{train,r}) \hspace{0.1cm}=\hspace{0.1cm} \widehat{M}_r (\hspace{0.1cm} x_i^{test, r} \hspace{0.1cm} )\)</span> <span class="math inline">\(\\[0.4cm]\)</span></li>
</ul></li>
</ul></li>
</ul></li>
<li><p>Se calcula la métrica final de evaluación del modelo como el promedio de las <span class="math inline">\(B\)</span> métricas calculadas en el apartado anterior.</p>
<ul>
<li>Si la métrica usada en el apartado anterior es el <span class="math inline">\(ECM\)</span>, entonces:</li>
</ul>
<p><span class="math display">\[ECM_{test}^{\hspace{0.08cm}*}( {M}) \hspace{0.07cm} = \hspace{0.07cm} \dfrac{1}{B} \cdot \sum_{r=1}^B ECM_{test}(\widehat{M}_r)\]</span></p></li>
</ul>
</p>
</p>
<p></span></p>
</div>
<p><br></p>
<p><strong>Ventajas</strong></p>
<p>Permite reducir la varianza de la métrica de validación. En la validación simple aleatoria no repetida la métrica de validación obtenida usando validacion simple tiene mayor varianza, en el sentido de que si se implementa el algoritmo un número elevado de veces, la varianza de los valores obtenidos de la métrica es mayor si se aplica el mismo procedimiento con validación simple aleatoria repetida. Esto será ilustrado en la práctica.</p>
<p><br></p>
</div>
<div id="leave-one-out" class="section level2 hasAnchor" number="5.4">
<h2><span class="header-section-number">5.4</span> Leave-one-out<a href="algoritmos-de-validación-de-modelos-de-aprendizaje-supervisado.html#leave-one-out" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p><strong>Descripción no formal del algoritmo:</strong></p>
<p>Este algoritmo de validación consiste en dividir el data-set inicial en una parte de train y otra de test de una forma tal que la primera observación forma parte del conjunto de test y el resto de la de train. Se entrena el modelo con la muestra de train y se calculan las predicciones de la respuesta para las observaciones de test de los predictores.</p>
<p>Con las observaciones de test de la respuesta y las predicciones de esta misma se calcula una métrica de validación.</p>
<p>Se repite el proceso anterior, pero tomando la segunda observación como muestra de test y las restantes como muestra de train. Se vuelve a repetir con la tercera observación, luego con la cuarta, y asi sucesivamente hasta llegar al punto en el que la última observación es la muestra de test.</p>
<p>Tras este proceso se habrán obtenido <span class="math inline">\(N\)</span> valores de la métrica de validación.</p>
<p>El valor final de la métrica por el algoritmo de validación leave-one-out es la media de esos <span class="math inline">\(N\)</span> valores. <span class="math inline">\(\\[0.05cm]\)</span></p>
<p><strong>Decripción formal del algoritmo:</strong></p>
<p>El algoritmo de validación simple no aleatoria tiene los siguientes pasos:</p>
<div class="warning" style="background-color:#F7EBE8; color: #030000; border-left: solid #CA0B0B 7px; border-radius: 3px; size:1px ; padding:0.1em;">
<p><span></p>
<p style="margin-left:1em;">
<ul>
<li><p>Se obtienen <span class="math inline">\(B\)</span> particiones de <span class="math inline">\(D\)</span> en parte de train y parte de test del siguiente modo:</p>
<ul>
<li><p>Se obtienen las siguientes <span class="math inline">\(B\)</span> <strong>muestras test</strong> del data-set original <span class="math inline">\(D\)</span>.</p>
<p><span class="math display">\[D_{test,1}=D[1, :] \hspace{0.1cm} ,\hspace{0.15cm} D_{test,2}=D[2, :]\hspace{0.15cm},...,\hspace{0.15cm} D_{test,B}=D[B, :] \\\]</span></p>
<ul>
<li><p>Donde :</p>
<p><span class="math inline">\(D_{test,r}=D[\hspace{0.1cm}r\hspace{0.1cm}, \hspace{0.1cm}:\hspace{0.1cm}]\hspace{0.1cm}\)</span> es la submatriz que resulta de considerar solo la fila <span class="math inline">\(r\)</span> de <span class="math inline">\(D\)</span> , es decir, es la observación <span class="math inline">\(r\)</span>-esima del data-set inicial <span class="math inline">\(\hspace{0.1cm}D\hspace{0.03cm}\)</span> :</p>
<p><span class="math display">\[D_{test,r} \hspace{0.1cm}=\hspace{0.1cm} D[\hspace{0.1cm}r\hspace{0.1cm},\hspace{0.1cm} :\hspace{0.1cm}] \hspace{0.1cm}=\hspace{0.1cm} (x_{r1} , ..., x_{rp} , y_r)=(x_r \hspace{0.1cm} ,\hspace{0.1cm}  y_r) \\[0.4cm]\]</span></p></li>
</ul></li>
<li><p>Se obtienen las siguientes <span class="math inline">\(B\)</span> <strong>muestras train</strong> del data-set original <span class="math inline">\(D\hspace{0.03cm}\)</span>:</p>
<p><span class="math display">\[D_{train,1}=D[\hspace{0.1cm}-1 \hspace{0.1cm},\hspace{0.1cm} :\hspace{0.1cm}] \hspace{0.2cm},\hspace{0.2cm} D_{train,2}=D[\hspace{0.1cm}-2\hspace{0.1cm}, \hspace{0.1cm}:\hspace{0.1cm}]\hspace{0.2cm},...,\hspace{0.2cm} D_{train,B}=D[\hspace{0.1cm}-B\hspace{0.1cm},\hspace{0.1cm} :\hspace{0.1cm}] \\\]</span></p>
<ul>
<li><p>Donde:</p>
<p><span class="math inline">\(D_{train,r}\hspace{0.1cm}=\hspace{0.1cm}D[\hspace{0.1cm}-r\hspace{0.1cm},\hspace{0.1cm} :\hspace{0.1cm}]\hspace{0.15cm}\)</span> es la submatriz que resulta de eliminar la fila <span class="math inline">\(i\)</span> de <span class="math inline">\(\hspace{0.1cm} D\hspace{0.1cm}\)</span>, es decir: <span class="math inline">\(\\[0.1cm]\)</span></p></li>
</ul></li>
</ul>
<p><span class="math display">\[D_{train,r}\hspace{0.1cm}=\hspace{0.1cm}D[\hspace{0.1cm}-r\hspace{0.1cm},\hspace{0.1cm} :\hspace{0.1cm}] \hspace{0.1cm}= \hspace{0.1cm}\begin{pmatrix}
  x_{11}&amp;...&amp;x_{1p}&amp; y_1\\
  ...&amp;...&amp;...&amp;...\\
  x_{(r-1)1}&amp;x_{(r-1)2}&amp;...&amp;x_{(r-1)p} &amp; y_{(r-1)}\\
  x_{(r+1)1}&amp;...&amp;x_{(r+1)p} &amp; y_{(r+1)}\\    ...&amp;...&amp;...&amp;...\\
  x_{N1}&amp;...&amp;x_{Np}&amp; y_N
  \end{pmatrix} \\\]</span></p></li>
<li><p>Para <span class="math inline">\(\hspace{0.02cm}r\in \lbrace 1,...,B \rbrace \hspace{0.03cm}\)</span> :</p>
<ul>
<li><p>Se entrena el modelo <span class="math inline">\(\hspace{0.1cm}M\hspace{0.1cm}\)</span> con la <strong>muestra de train</strong> <span class="math inline">\(\hspace{0.1cm} D_{train,r}\hspace{0.1cm}\)</span> <span class="math inline">\(\hspace{0.1cm}\Rightarrow\hspace{0.1cm}\)</span> <span class="math inline">\(\hspace{0.1cm}\widehat{M}_r\hspace{0.02cm}\)</span>.</p></li>
<li><p>Se calcula una misma métrica de evaluación sobre el modelo entrenado <span class="math inline">\(\hspace{0.01cm}\widehat{M}_r\hspace{0.01cm}\)</span> con la <strong>muestra de test</strong> <span class="math inline">\(\hspace{0.01cm}D_{test,r}\hspace{0.02cm}\)</span>.</p>
<ul>
<li><p>Supongamos que la métrica de evaluación usada es el <span class="math inline">\(\hspace{0.01cm}ECM\hspace{0.01cm}\)</span> , entonces se obtienen <span class="math inline">\(\hspace{0.1cm}B\hspace{0.1cm}\)</span> valores de esta métrica :</p>
<p><span class="math display">\[ECM(\widehat{M}_1)_{test } \hspace{0.1cm} ,\hspace{0.1cm}   ECM(\widehat{M}_2)_{test } \hspace{0.1cm} , ... ,\hspace{0.1cm}  ECM(\widehat{M}_B)_{test}\\\]</span></p>
<p>Donde:</p>
<p><span class="math inline">\(\hspace{0.5cm} ECM_{test , r}\hspace{0.01cm}\)</span> es el <span class="math inline">\(\hspace{0.01cm}ECM\hspace{0.01cm}\)</span> calculado sobre <span class="math inline">\(\hspace{0.01cm}\widehat{M}_r\hspace{0.01cm}\)</span> usando <span class="math inline">\(\hspace{0.01cm}D_{test,r}\hspace{0.03cm}\)</span>:</p>
<p><span class="math display">\[ECM(\widehat{M}_r)_{test } =  (\hspace{0.1cm} y_r - \hat{y}_r \hspace{0.1cm})^2\]</span></p>
<p>Teniendo en cuenta que:</p>
<ul>
<li><p><span class="math inline">\(\hat{y}_r \hspace{0.1cm}=\hspace{0.1cm} M(\hspace{0.1cm} x_r \hspace{0.1cm}|\hspace{0.1cm} D_{train,r}) \hspace{0.1cm}=\hspace{0.1cm} \widehat{M}_r (\hspace{0.03cm} x_r \hspace{0.03cm} )\)</span></p></li>
<li><p><span class="math inline">\(y_r\hspace{0.1cm}\)</span> es la única observación de la muestra de test <span class="math inline">\(\hspace{0.1cm} r\)</span>-esima de la variable respuesta. <span class="math inline">\(\\[0.6cm]\)</span></p></li>
</ul></li>
</ul></li>
</ul></li>
<li><p>Se calcula la métrica final de evaluación del modelo como el promedio de las <span class="math inline">\(\hspace{0.01cm}B\hspace{0.01cm}\)</span> métricas calculadas en el paso anterior.</p>
<ul>
<li>Si la métrica usada es el <span class="math inline">\(\hspace{0.1cm}ECM\hspace{0.1cm}\)</span>, entonces:</li>
</ul>
<p><span class="math display">\[ECM( M )_{test}^{\hspace{0.08cm}*} \hspace{0.1cm}=\hspace{0.1cm} \dfrac{1}{B} \cdot \sum_{r=1}^B \hspace{0.1cm} ECM(\widehat{M}_r)_{test}\]</span></p></li>
</ul>
</p>
</p>
<p></span></p>
</div>
<p><br></p>
<p><strong>Ventaja</strong></p>
<p>Una vez aplicado el algoritmo todas las observaciones han formado parte de conjunto de train (en alguna iteracion), y lo mismo para el conjunto de test.</p>
<p><br></p>
<p><strong>Problema</strong></p>
<p>Algunos autores (vease la referencia 1) consideran que, al emplearse todas las observaciones como entrenamiento, se puede estar cayendo en overfitting (sobre-ajuste).</p>
<p><br></p>
<p><br></p>
</div>
<div id="k-fold" class="section level2 hasAnchor" number="5.5">
<h2><span class="header-section-number">5.5</span> k-fold<a href="algoritmos-de-validación-de-modelos-de-aprendizaje-supervisado.html#k-fold" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p><strong>Decripción no formal del algoritmo:</strong></p>
<p>Este algoritmo de validación consiste en dividir el data-set inicial en <span class="math inline">\(\hspace{0.01cm} k\hspace{0.01cm}\)</span> partes, y usar de manera secuencial cada una de esas partes como muestra test, y las unión de las partes restantes como muestra train.</p>
<p>Por tanto con este método se usan <span class="math inline">\(\hspace{0.01cm}k\hspace{0.01cm}\)</span> muestras de test y de train.</p>
<p>El modelo es entrenado secuencialmente con cada una de las <span class="math inline">\(\hspace{0.01cm}k\hspace{0.01cm}\)</span> muestras de train disitntas, y se testea con la correspondiente muestra de test (que es el complementario de la de train), usando una métrica de evaluación.</p>
<p>Es decir, tras dividir el data-set inicial en <span class="math inline">\(\hspace{0.01cm}k\hspace{0.01cm}\)</span> partes, la parte 1 se usa como test y el resto como train, se calcula la métrica de evaluación. Luego la parte 2 se usa como test y el resto como train, y se calcula la métrica de evaluación. Asi sucesivamente hasta haber usado las <span class="math inline">\(\hspace{0.1cm}k\hspace{0.1cm}\)</span> partes como muestras de test.</p>
<p>Tras este proceso se habrán obtenido <span class="math inline">\(\hspace{0.1cm}k\hspace{0.1cm}\)</span> valores de dicha métrica de evaluacion.</p>
<p>La métrica de evaluacion calculada usando este método de validación es la media de dichos <span class="math inline">\(\hspace{0.01cm}k\hspace{0.01cm}\)</span> valores obtenidos para la métrica de evaluación escogida. Este valor medio final es la que será usado para medir el poder predictivo del modelo y compararlo con otros modelos.</p>
<p><br></p>
<p><strong>Decripción formal del algoritmo:</strong></p>
<p>El algoritmo de validación k-folds tiene los siguientes pasos:</p>
<div class="warning" style="background-color:#F7EBE8; color: #030000; border-left: solid #CA0B0B 7px; border-radius: 3px; size:1px ; padding:0.1em;">
<p><span></p>
<p style="margin-left:1em;">
<ul>
<li><p>Se divide aleatoriamente el data-set inicial <span class="math inline">\(\hspace{0.01cm}D\hspace{0.01cm}\)</span> en <span class="math inline">\(\hspace{0.01cm}k\hspace{0.01cm}\)</span> partes de manera que cada parte tenga aproximadamente el mismo número de observaciones (sean lo mas balanceadas posibles).</p>
<ul>
<li><p>Existen diferentes métodos para hacer esta división. La problematica de la división es cómo hacer que las partes resultantes estén lo más balanceadas posibles respecto al numero de observaciones que contienen.</p></li>
<li><p>Hemos desarrollado un método basado en cuantiles que permite obtener este balanceo, el cual ha sido implementado en Python con buenos resultados en este aspecto, como se podrá ver posteriormente en la parte de implementación.</p></li>
<li><p>Vamos a explicar la mecánica del método ideado:</p>
<ul>
<li><p>Obtenemos una muestra aleatoria sin remplazamiento <span class="math inline">\(\hspace{0.01cm}m=(m_1,...,m_N)\hspace{0.01cm}\)</span> de tamaño <span class="math inline">\(N\)</span> del vector <span class="math inline">\(\hspace{0.01cm}(1,...,N)\hspace{0.03cm}\)</span>.</p></li>
<li><p>El siguiente paso es dividir la muestra <span class="math inline">\(\hspace{0.01cm}m\hspace{0.01cm}\)</span> en <span class="math inline">\(\hspace{0.01cm}k\hspace{0.01cm}\)</span> partes lo mas balanceadas posibles. No queremos que unas partes tenga muchos elementos, y otras pocos. Queremos que la repartición de los elementos de <span class="math inline">\(\hspace{0.01cm}m\hspace{0.01cm}\)</span> en las <span class="math inline">\(\hspace{0.01cm}k\hspace{0.01cm}\)</span> partes sea lo mas igualitaria posible.</p></li>
<li><p>La idea es que si, por ejemplo <span class="math inline">\(\hspace{0.01cm}k=10\hspace{0.01cm}\)</span>, cada una de las 10 partes en las que dividimos <span class="math inline">\(\hspace{0.01cm}m\hspace{0.01cm}\)</span> tenga un 10% de los elementos totales de <span class="math inline">\(m\)</span>.</p></li>
<li><p>Si <span class="math inline">\(\hspace{0.01cm}k=4\hspace{0.01cm}\)</span> se busca que cada una de las 4 partes en las que dividimos <span class="math inline">\(\hspace{0.1cm}m\hspace{0.1cm}\)</span> tenga el 25% de los elementos de <span class="math inline">\(\hspace{0.01cm}m\)</span>.</p></li>
<li><p>En general, se busca que cada una de las <span class="math inline">\(\hspace{0.01cm} k\hspace{0.01cm}\)</span> partes en las que dividimos <span class="math inline">\(\hspace{0.01cm}m\hspace{0.01cm}\)</span> tengan <span class="math inline">\(\hspace{0.01cm}(1/k)\cdot 100 \%\hspace{0.01cm}\)</span> de elementos de <span class="math inline">\(\hspace{0.01cm}m\hspace{0.01cm}\)</span>, es decir, <span class="math inline">\(\hspace{0.01cm} N/k\hspace{0.01cm}\)</span> elementos de <span class="math inline">\(\hspace{0.01cm}m\hspace{0.01cm}\)</span> , puesto que <span class="math inline">\(m\)</span> tiene <span class="math inline">\(N\)</span> elementos.</p></li>
<li><p>Una forma de hacer esto es usando los cuantiles <span class="math inline">\(\hspace{0.01cm} Q_0 \hspace{0.1cm} , \hspace{0.1cm} Q_{1/k} \hspace{0.1cm} ,\hspace{0.1cm} Q_{2/k} \hspace{0.1cm} ,...,\hspace{0.1cm} Q_{(k-1)/k}\hspace{0.1cm} ,\hspace{0.1cm} Q_1\hspace{0.01cm}\)</span> del vector <span class="math inline">\(\hspace{0.01cm}(1,...,N)\hspace{0.01cm}\)</span> como los limites que definen las partes en las que dividiremos <span class="math inline">\(\hspace{0.01cm} m=(m_1,...,m_N)\hspace{0.01cm}\)</span>.</p></li>
<li><p>Dichos cuantiles permiten separar <span class="math inline">\(\hspace{0.01cm} m \hspace{0.01cm}\)</span> en <span class="math inline">\(\hspace{0.01cm} k \hspace{0.01cm}\)</span> partes de un tamaño aproximadamente igual.</p></li>
<li><p>Si <span class="math inline">\(\hspace{0.01cm} k=10\hspace{0.1cm}\)</span>, entonces esos cuantiles serian <span class="math inline">\(\hspace{0.01cm} Q_0 \hspace{0.1cm},\hspace{0.1cm} Q_{0.1} \hspace{0.1cm},\hspace{0.1cm} Q_{0.2} \hspace{0.1cm}, ...,\hspace{0.1cm} Q_{0.8} \hspace{0.1cm},\hspace{0.1cm} Q_{0.9} \hspace{0.1cm},\hspace{0.1cm} Q_1\hspace{0.01cm}\)</span>.</p></li>
<li><p>Si <span class="math inline">\(\hspace{0.01cm} k=4\hspace{0.1cm}\)</span> , los cuantiles serían <span class="math inline">\(\hspace{0.1cm} Q_0 \hspace{0.1cm},\hspace{0.1cm} Q_{0.25} \hspace{0.1cm},\hspace{0.1cm} Q_{0.5} \hspace{0.1cm},\hspace{0.1cm} Q_{0.75} \hspace{0.1cm},\hspace{0.1cm} Q_1\hspace{0.01cm}\)</span>.</p>
<p>Notese que: <span class="math inline">\(\hspace{0.02cm} Q_0 = Min(1,...,N) = 1\hspace{0.2cm}\)</span> y <span class="math inline">\(\hspace{0.2cm} Q_1=Max(1,...,N)=N \hspace{0.01cm}\)</span>. <span class="math inline">\(\\[0.25cm]\)</span></p></li>
</ul></li>
<li><p>Definimos las <span class="math inline">\(\hspace{0.01cm} k\hspace{0.01cm}\)</span> particiones de <span class="math inline">\(\hspace{0.01cm} m \hspace{0.01cm}\)</span> usando los cuantiles <span class="math inline">\(\hspace{0.01cm} Q_0\hspace{0.01cm},\hspace{0.01cm} Q_{1/k} \hspace{0.01cm},\hspace{0.01cm} Q_{2/k}\hspace{0.01cm},...,\hspace{0.01cm} Q_{(k-1)/k}\hspace{0.01cm},\hspace{0.01cm} Q_1\hspace{0.02cm}\)</span> como sigue:</p>
<p><span class="math inline">\(\hspace{2cm} p_{1,m} \hspace{0.1cm}=\hspace{0.1cm} m\left[\hspace{0.1cm}1:(\lfloor Q_{1/k} \rfloor -1)\hspace{0.1cm}\right]\hspace{0.1cm}=\hspace{0.1cm}(m_1,...,m_{\lfloor Q_{1/k} \rfloor - 1} ) \\\)</span></p>
<p><span class="math inline">\(\hspace{2cm} p_{2,m} \hspace{0.1cm}=\hspace{0.1cm} m\left[\hspace{0.1cm}\lfloor Q_{1/k} \rfloor:(\lfloor Q_{2/k} \rfloor-1)\hspace{0.1cm}\right]\hspace{0.1cm}=\hspace{0.1cm}(m_{\lfloor Q_{1/k} \rfloor},...,m_{\lfloor Q_{2/k} \rfloor - 1})\)</span></p>
<p><span class="math inline">\(\hspace{2cm} \dots \\\)</span></p>
<p><span class="math inline">\(\hspace{2cm} p_{k,m} \hspace{0.1cm}=\hspace{0.1cm} m\left[\hspace{0.1cm}\lfloor Q_{(k-1)/k} \rfloor : N\hspace{0.1cm}\right]\hspace{0.1cm}=\hspace{0.1cm}(m_{\lfloor Q_{(k-1)/k} \rfloor},...,m_{N})\\[0.75cm]\)</span></p></li>
<li><p>Se puede demostrar que <span class="math inline">\(\hspace{0.1cm} p_{1,m}\hspace{0.1cm},...,\hspace{0.1cm} p_{k,m}\hspace{0.1cm}\)</span> tienen un número de elementos aproximadamente igual , por lo que son particiones aproximadamente igualitarias (balanceadas), que era lo que buscabamos.</p></li>
<li><p>La siguiente matriz ilustra por qué este método funciona: <span class="math inline">\(\\[0.02cm]\)</span></p></li>
</ul>
<p><span class="math display">\[\begin{pmatrix}
  1 &amp; m_1\\
  2 &amp; m_2\\
  ... &amp; ... \\
  \lfloor  Q_{1/k} \rfloor - 1  &amp; m_{\lfloor  Q_{1/k} \rfloor - 1} \\
  ----- &amp; ----- \\
  \lfloor  Q_{1/k} \rfloor  &amp; m_{\lfloor  Q_{1/k} \rfloor} \\
  ... &amp; ... \\
  \lfloor  Q_{2/k} \rfloor - 1  &amp; m_{\lfloor  Q_{2/k} \rfloor - 1} \\
  ----- &amp; -----\\
  \lfloor  Q_{2/k} \rfloor  &amp; m_{\lfloor  Q_{2/k} \rfloor} \\
  ... &amp; ... \\
   \lfloor  Q_{3/k} \rfloor - 1  &amp; m_{\lfloor  Q_{3/k} \rfloor - 1} \\
  ----- &amp; -----\\
  ... &amp; ... \\
  ... &amp; ... \\
  ----- &amp; -----\\
  \lfloor  Q_{(k-1)/k} \rfloor  &amp; m_{\lfloor  Q_{(k-1)/k} \rfloor} \\
  ... &amp; ... \\
  N &amp; m_N
  \end{pmatrix}\hspace{0.1cm} = \hspace{0.1cm} \begin{pmatrix}
  ... &amp; ...\\
  ... &amp; ...\\
  \text{Parte 1} \hspace{0.15cm}(p_{1,m})  &amp; \hspace{0.2cm} \approx N/k \hspace{0.15cm} \text{elementos} \\
  ... &amp; ...\\
  ----- &amp; -----\\
  ... &amp; ...\\
  \text{Parte 2}\hspace{0.15cm}(p_{2,m}) &amp; \hspace{0.2cm} \approx N/k \hspace{0.15cm} \text{elementos}  \\
  ... &amp; ...\\
  ----- &amp; -----\\
  ... &amp; ...\\
     \text{Parte 3}\hspace{0.15cm}(p_{3,m}) &amp; \hspace{0.2cm} \approx N/k \hspace{0.15cm} \text{elementos} \\
  ... &amp; ...\\
  ----- &amp; -----\\
  ... &amp; ...\\
  ... &amp; ...\\
  ----- &amp; -----\\
  ... &amp; ...\\
  \text{Parte k}\hspace{0.15cm}(p_{k,m}) &amp; \hspace{0.2cm} \approx N/k \hspace{0.15cm} \text{elementos} \\
  ... &amp; ...\\
  \end{pmatrix}\]</span></p></li>
</ul>
<p><span class="math inline">\(\\[0.35cm]\)</span></p>
<ul>
<li><p>Se obtienen la siguientes <span class="math inline">\(\hspace{0.1cm}k\hspace{0.1cm}\)</span> muestras de test: <span class="math inline">\(\\[0.01cm]\)</span></p>
<p><span class="math inline">\(\hspace{2cm} D_{test, 1} \hspace{0.1cm}=\hspace{0.1cm} D[\hspace{0.1cm} p_{1,m} \hspace{0.1cm} ,\hspace{0.1cm} : \hspace{0.1cm}] \hspace{0.1cm}=\hspace{0.1cm} D[\hspace{0.12cm}m[1:(\lfloor Q_{1/k} \rfloor -1)] \hspace{0.12cm},\hspace{0.12cm} : \hspace{0.12cm}]\)</span></p>
<p><span class="math inline">\(\hspace{2cm}D_{test, 2} \hspace{0.1cm}=\hspace{0.1cm} D[\hspace{0.1cm}p_{2,m} \hspace{0.1cm} ,\hspace{0.1cm} :\hspace{0.1cm}] \hspace{0.1cm}=\hspace{0.1cm} D[\hspace{0.12cm}m[\lfloor Q_{1/k} \rfloor : (\lfloor Q_{2/k} \rfloor - 1 )]\hspace{0.12cm} ,\hspace{0.12cm}:\hspace{0.12cm}]\)</span>$</p>
<p><span class="math inline">\(\hspace{2cm}\dots\)</span></p>
<p><span class="math inline">\(\hspace{2cm}D_{test, k}\hspace{0.1cm} =\hspace{0.1cm} D[\hspace{0.1cm}p_{k,m} \hspace{0.12cm} ,\hspace{0.12cm} :\hspace{0.12cm}] \hspace{0.1cm}=\hspace{0.1cm} D[\hspace{0.12cm}m[\lfloor Q_{(k-1)/k} \rfloor : N]\hspace{0.12cm} ,\hspace{0.12cm} :\hspace{0.12cm}] \\[0.7cm]\)</span></p></li>
<li><p>Se obtiene las siguientes <span class="math inline">\(\hspace{0.01cm}k\hspace{0.01cm}\)</span> muestras de train: <span class="math inline">\(\\[0.01cm]\)</span></p>
<p><span class="math inline">\(\hspace{2cm}D_{train, 1} \hspace{0.1cm}=\hspace{0.1cm} D[\hspace{0.12cm}-\hspace{0.12cm}p_{1,m} \hspace{0.12cm},\hspace{0.12cm} :\hspace{0.12cm}] \hspace{0.1cm}=\hspace{0.1cm} D[\hspace{0.12cm}-\hspace{0.12cm} m[1:(\lfloor Q_{1/k} \rfloor -1)] \hspace{0.12cm},\hspace{0.12cm}:\hspace{0.12cm}]\)</span></p>
<p><span class="math inline">\(\hspace{2cm}D_{train, 2} \hspace{0.1cm}=\hspace{0.1cm} D[\hspace{0.12cm}-\hspace{0.12cm} p_{2,m} \hspace{0.12cm},\hspace{0.12cm} :\hspace{0.12cm}] \hspace{0.1cm}=\hspace{0.1cm} D[\hspace{0.12cm}-\hspace{0.12cm}m[\lfloor Q_{1/k} \rfloor : (\lfloor Q_{2/k} \rfloor - 1 )] \hspace{0.12cm},\hspace{0.12cm}:\hspace{0.12cm}]\)</span></p>
<p><span class="math inline">\(\hspace{2cm} \dots\)</span></p>
<p><span class="math inline">\(\hspace{2cm}D_{train, k} \hspace{0.1cm}=\hspace{0.1cm} D[\hspace{0.12cm}-\hspace{0.12cm} p_{k,m} \hspace{0.12cm},\hspace{0.12cm} : \hspace{0.12cm}] \hspace{0.1cm}=\hspace{0.1cm} D[\hspace{0.12cm}-\hspace{0.12cm} m[\lfloor Q_{(k-1)/k} \rfloor : N] \hspace{0.12cm},\hspace{0.12cm} : \hspace{0.12cm}] \\[0.25cm]\)</span></p></li>
<li><p>Para <span class="math inline">\(\hspace{0.03cm}r \in \lbrace 1,...,k \rbrace\hspace{0.1cm}\)</span> :</p>
<ul>
<li><p>Se entrena el modelo <span class="math inline">\(\hspace{0.01cm}M\hspace{0.01cm}\)</span> con la <strong>muestra de train</strong> <span class="math inline">\(\hspace{0.01cm} D_{train,r}\)</span> <span class="math inline">\(\hspace{0.02cm}\Rightarrow\hspace{0.2cm}\)</span> <span class="math inline">\(\hspace{0.01cm}\widehat{M}_r\hspace{0.02cm}\)</span> .</p></li>
<li><p>Se calcula una misma métrica de evaluación sobre el modelo entrenado <span class="math inline">\(\hspace{0.01cm}\widehat{M}_r\hspace{0.01cm}\)</span> con la <strong>muestra de test</strong> <span class="math inline">\(\hspace{0.01cm}D_{test,r}\hspace{0.02cm}\)</span> .</p>
<ul>
<li><p>Supongamos que la métrica de evaluación usada es el <span class="math inline">\(\hspace{0.1cm}ECM\hspace{0.1cm}\)</span> , entonces se obtienen <span class="math inline">\(\hspace{0.1cm}k\hspace{0.1cm}\)</span> valores de esta métrica :</p>
<p><span class="math display">\[ECM_{test }\left(\widehat{M}_1\right) \hspace{0.1cm},\hspace{0.1cm}  ECM_{test }\left(\widehat{M}_2\right) \hspace{0.1cm}, ... ,\hspace{0.1cm} ECM_{test}\left( \widehat{M}_k \right)\\\]</span></p>
<p>Donde:</p>
<p><span class="math inline">\(\hspace{0.5cm} ECM_{test , r}\hspace{0.1cm}\)</span> es el <span class="math inline">\(\hspace{0.1cm}ECM\hspace{0.1cm}\)</span> calculado sobre <span class="math inline">\(\hspace{0.1cm}\widehat{M}_r\hspace{0.1cm}\)</span> usando <span class="math inline">\(\hspace{0.1cm}D_{test,r}\hspace{0.1cm}\)</span></p>
<p><span class="math display">\[ECM_{test }\left( \hspace{0.05cm} \widehat{M}_r \hspace{0.05cm}\right) \hspace{0.1cm}=\hspace{0.1cm} \dfrac{1}{\# D_{test, r}} \cdot \sum_{i=1}^{\# D_{test, r}} \hspace{0.1cm} \left( \hspace{0.1cm} y_i^{\hspace{0.1cm}test,r} - \hat{\hspace{0.1cm}y\hspace{0.1cm}}_i^{\hspace{0.1cm}test,r} \hspace{0.1cm} \right)^2 \\\]</span></p>
<p>Teniendo en cuenta que :</p>
<ul>
<li><p><span class="math inline">\(\hat{\hspace{0.1cm}y\hspace{0.1cm}}_i^{\hspace{0.1cm}test,r} \hspace{0.1cm}=\hspace{0.1cm} M\left(\hspace{0.1cm} x_i^{test, r} \hspace{0.1cm}|\hspace{0.1cm} D_{train,r} \right) \hspace{0.1cm}=\hspace{0.1cm} \widehat{M}_r \left(\hspace{0.1cm} x_i^{test, r} \hspace{0.1cm} \right)\)</span></p></li>
<li><p><span class="math inline">\(x_i^{\hspace{0.1cm}test,r}\hspace{0.1cm}\)</span> es la observación <span class="math inline">\(\hspace{0.1cm}i\)</span>-esima de la muestra de test <span class="math inline">\(\hspace{0.1cm}r\)</span>-esima de los predictores.</p></li>
<li><p><span class="math inline">\(y_i^{\hspace{0.1cm}test,r}\hspace{0.1cm}\)</span> es la observación <span class="math inline">\(\hspace{0.1cm}i\)</span>-esima de la muestra de test <span class="math inline">\(\hspace{0.1cm}r\)</span>-esima de la variable respuesta. <span class="math inline">\(\\[0.25cm]\)</span></p></li>
</ul></li>
</ul></li>
</ul></li>
<li><p>Se calcula la métrica final de evaluación del modelo como el promedio de las <span class="math inline">\(\hspace{0.01cm}k\hspace{0.01cm}\)</span> métricas calculadas en el paso anterior. Si la métrica usada fuera el ECM, entonces:</p>
<p><span class="math display">\[ECM({M})_{test}^{\hspace{0.08cm}*} \hspace{0.1cm}=\hspace{0.1cm} \dfrac{1}{k} \cdot \sum_{r=1}^k ECM_{test}(\widehat{M}_r)\]</span></p></li>
</ul>
</p>
</p>
<p></span></p>
</div>
<p><br></p>
<p><strong>Ventajas</strong></p>
<p>La metrica de validacion calculada por k-fold tiene menor varianza que con los métodos anteriores, luego es el mas preciso de todos ellos.</p>
<p><br></p>
</div>
<div id="repeted-k-fold" class="section level2 hasAnchor" number="5.6">
<h2><span class="header-section-number">5.6</span> Repeted k-fold<a href="algoritmos-de-validación-de-modelos-de-aprendizaje-supervisado.html#repeted-k-fold" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Este algoritmo consiste en <strong>repetir</strong> el algoritmo <strong>k-fold</strong> un número <span class="math inline">\(\hspace{0.01cm} B \hspace{0.01cm}\)</span> de veces.</p>
<p>No vamos a hacer aquí una descripción tan detallada del algoritmo como las anteriores, puesto que buena parte es repetir <span class="math inline">\(\hspace{0.01cm}B\hspace{0.01cm}\)</span> veces la estructura del k-fold. <span class="math inline">\(\\[0.1cm]\)</span></p>
<p>Sintetizando, los pasos del algoritmo <span class="math inline">\(\hspace{0.01cm}B\)</span>-repeated <span class="math inline">\(\hspace{0.01cm}k\)</span>-fold son los siguientes:</p>
<div class="warning" style="background-color:#F7EBE8; color: #030000; border-left: solid #CA0B0B 7px; border-radius: 3px; size:1px ; padding:0.1em;">
<p><span></p>
<p style="margin-left:1em;">
<ul>
<li><p>Se itera el algoritmo <span class="math inline">\(\hspace{0.01cm}k\)</span>-fold un total de <span class="math inline">\(\hspace{0.01cm}B\hspace{0.01cm}\)</span> veces. Con ello se obtienen <span class="math inline">\(\hspace{0.01cm}k\cdot B\hspace{0.01cm}\)</span> valores de la métrica de validacion, ya que cada iteracion del algoritmo k-fold produce <span class="math inline">\(\hspace{0.01cm}k\hspace{0.01cm}\)</span> valores de la métrica, y el algoritmo se itera <span class="math inline">\(\hspace{0.08cm}B\hspace{0.08cm}\)</span> veces. <span class="math inline">\(\\[0.04cm]\)</span></p>
<ul>
<li><p>Si la métrica usada para evaluar el modelo fuera el <span class="math inline">\(\hspace{0.01cm}ECM\hspace{0.01cm}\)</span> , entocnes se obtendrian los siguientes <span class="math inline">\(\hspace{0.01cm}k\cdot B\hspace{0.01cm}\)</span> valores de esta métrica:</p>
<p><span class="math display">\[ECM_{test }(\hspace{0.1cm}\widehat{M}_1^{\hspace{0.1cm}1}\hspace{0.1cm} ) \hspace{0.05cm}, ... ,\hspace{0.05cm} ECM_{test}\left(\hspace{0.1cm}\widehat{M}_k^{\hspace{0.1cm}1}\hspace{0.1cm}\right) \hspace{0.05cm},...,\hspace{0.05cm}ECM_{test }\left(\hspace{0.1cm}\widehat{M}_1^{\hspace{0.1cm}B}\hspace{0.1cm}\right) \hspace{0.05cm}, ... ,\hspace{0.05cm} ECM_{test}\left(\hspace{0.1cm}\widehat{M}_k^{\hspace{0.1cm}B} \hspace{0.1cm} \hspace{0.1cm}\right) \\\]</span></p>
<p>Donde, para <span class="math inline">\(\hspace{0.1cm}r\in \lbrace 1,...,k \rbrace\hspace{0.15cm}\)</span> y <span class="math inline">\(\hspace{0.15cm} j\in \lbrace 1,...,B \rbrace\)</span> :</p>
<ul>
<li><p><span class="math inline">\(\widehat{M}_r^{\hspace{0.1cm}j}\hspace{0.1cm}\)</span> es el modelo <span class="math inline">\(\hspace{0.1cm}M\hspace{0.1cm}\)</span> entrenado con la <strong>muestra de train</strong> <span class="math inline">\(\hspace{0.1cm}r\)</span>-esima obtenida en la iteración <span class="math inline">\(\hspace{0.1cm}j\)</span>-esima del algoritmo k-fold, es decir, es el modelo entrenado con la muestra de train <span class="math inline">\(\hspace{0.1cm}D_{train, r}^{\hspace{0.1cm}j}\)</span> .</p></li>
<li><p><span class="math inline">\(ECM_{test }\left(\hspace{0.1cm}\widehat{M}_r^{\hspace{0.1cm}j} \hspace{0.1cm}\right)\hspace{0.1cm}\)</span> es el <span class="math inline">\(\hspace{0.1cm}ECM\hspace{0.1cm}\)</span> calculado sobre el modelo <span class="math inline">\(\hspace{0.1cm}\widehat{M}_r^{\hspace{0.1cm}j}\hspace{0.1cm}\)</span> con la <strong>muestra de test</strong> <span class="math inline">\(\hspace{0.1cm}r\)</span>-esima obtenida en la repetición <span class="math inline">\(\hspace{0.1cm}j\)</span>-esima del algoritmo k-fold, es decir, con la muestra de test <span class="math inline">\(\hspace{0.1cm}D_{test, r}^{\hspace{0.1cm}j}\)</span> :</p></li>
</ul>
<p><span class="math display">\[ECM_{test }\left( \hspace{0.1cm} \widehat{M}_r^{\hspace{0.1cm}j} \hspace{0.1cm}\right) = \dfrac{1}{\# D_{test, r}^{\hspace{0.1cm}j}} \cdot \sum_{i=1}^{\# D_{test, r}^{\hspace{0.1cm}j}} \hspace{0.1cm} \left(\hspace{0.1cm} y_i^{\hspace{0.1cm}test,r,j} - \hat{\hspace{0.1cm}y\hspace{0.1cm}}_i^{\hspace{0.1cm}test,r,j} \hspace{0.1cm} \right)^2  \\[1cm]\]</span></p>
<p>Considerando lo siguiente :</p>
<ul>
<li><p><span class="math inline">\(\hat{y}_i^{\hspace{0.1cm}test,r,j} \hspace{0.1cm}=\hspace{0.1cm} M(\hspace{0.1cm} x_i^{\hspace{0.1cm}test, r,j} \hspace{0.12cm}|\hspace{0.12cm} D_{train,r}^{\hspace{0.1cm}j}) \hspace{0.1cm}=\hspace{0.1cm} \widehat{M}_r^{\hspace{0.1cm}j} (\hspace{0.1cm} x_i^{test, r,j} \hspace{0.1cm} )\)</span></p></li>
<li><p><span class="math inline">\(( \hspace{0.1cm} x_i^{\hspace{0.1cm} test, r,j} , y_i^{test, r,j} \hspace{0.1cm})\hspace{0.02cm}\)</span> es la observación (fila) <span class="math inline">\(\hspace{0.01cm}i\)</span>-esima de <span class="math inline">\(\hspace{0.01cm}D_{test,r}^{\hspace{0.1cm} j}\)</span></p></li>
<li><p><span class="math inline">\(x_i^{\hspace{0.1cm}test, r,j}\hspace{0.01cm}\)</span> es la observación <span class="math inline">\(\hspace{0.01cm}i\)</span>-esima de la muestra de test <span class="math inline">\(\hspace{0.01cm}r\)</span>-esima de los predictores obtenida en la repetición <span class="math inline">\(\hspace{0.01cm}j\)</span>-esima del algoritmo <span class="math inline">\(k\)</span>-folds.</p></li>
<li><p><span class="math inline">\(y_i^{\hspace{0.1cm}test, r,j}\hspace{0.1cm}\)</span> es la observacion <span class="math inline">\(\hspace{0.1cm}i\)</span>-esima de la muestra de test <span class="math inline">\(\hspace{0.1cm}r\)</span>-esima de la variable respuesta obtenida en la repetición <span class="math inline">\(\hspace{0.1cm}j\)</span>-esima del algoritmo k-folds.</p></li>
</ul>
<p>Nótese que debido al componente aleatorio presente en el algoritmo k-folds, cada vez que se repita el algoritmo se obtendran muestras de train y test diferentes. <span class="math inline">\(\\[0.5cm]\)</span></p></li>
</ul></li>
<li><p>Se calcula la métrica final de evaluación del modelo como el promedio de las <span class="math inline">\(\hspace{0.01cm}k\cdot B\hspace{0.01cm}\)</span> métricas calculadas en el paso anterior. Es decir, como el promedio de las <span class="math inline">\(\hspace{0.01cm}B\hspace{0.01cm}\)</span> metricas obtenidas al iterar <span class="math inline">\(\hspace{0.01cm}B\hspace{0.01cm}\)</span> veces el algoritmo k-fold.</p>
<ul>
<li><p>Si la métrica considerada es el <span class="math inline">\(\hspace{0.1cm}ECM\hspace{0.1cm}\)</span>, entonces:</p>
<p>En la iteración <span class="math inline">\(\hspace{0.01cm}j\)</span>-esima del algoritmo <span class="math inline">\(\hspace{0.01cm}k\)</span>-fold se obtiene como métrica de validación final:</p>
<p><span class="math display">\[ECM( {M})_{test}^{\hspace{0.08cm}j \hspace{0.05cm} *} \hspace{0.13cm} = \hspace{0.13cm}\dfrac{1}{k} \hspace{0.1cm} \cdot\hspace{0.1cm}   \sum_{r=1}^k \hspace{0.15cm}   ECM_{test}\left(\hspace{0.1cm}\widehat{M}_r^{\hspace{0.1cm}j}\hspace{0.1cm}\right) \\\]</span></p>
<p>Por lo tanto, la métrica de validación final obtenida con el algoritmo <span class="math inline">\(\hspace{0.08cm}B\)</span>-repeated <span class="math inline">\(\hspace{0.08cm}k\)</span>-fold es: <span class="math inline">\(\\[0.15cm]\)</span></p>
<p><span class="math display">\[ECM( {M})_{test}^{\hspace{0.08cm}*} \hspace{0.13cm} = \hspace{0.13cm} \dfrac{1}{ B} \hspace{0.1cm} \cdot\hspace{0.1cm} \sum_{j=1}^B ECM( {M})_{test}^{\hspace{0.08cm}j \hspace{0.05cm} *} \hspace{0.13cm} = \hspace{0.13cm}
  \dfrac{1}{k\cdot B} \hspace{0.1cm} \cdot\hspace{0.1cm} \sum_{j=1}^B \hspace{0.1cm} \sum_{r=1}^k \hspace{0.15cm}   ECM_{test}\left(\hspace{0.1cm}\widehat{M}_r^{\hspace{0.1cm}j}\hspace{0.1cm}\right)\\\]</span></p></li>
</ul></li>
</ul>
</p>
</p>
<p></span></p>
</div>
<p><br></p>
<p><strong>Ventajas</strong></p>
<p>La métrica de validación calculada por repeted k-fold tiene menor varianza que con los métodos anteriores, luego es el mas preciso de todos ellos. Este debería ser el método empleado en la práctica, siempre que se pueda, ya que también es el que mas requerimientos computacionales tiene.</p>
<p><br></p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="métricas-para-evaluar-modelos-de-clasificación-supervisada.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="selección-de-modelos-basada-en-validación-cruzada.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/USERNAME/REPO/edit/BRANCH/index.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["_main.pdf", "_main.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
