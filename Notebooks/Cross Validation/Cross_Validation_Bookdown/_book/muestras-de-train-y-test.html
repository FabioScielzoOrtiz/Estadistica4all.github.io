<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 2 Muestras de train y test | Algoritmos de validación de modelos de aprendizaje supervisado</title>
  <meta name="description" content="Esta es una introducción a los algoritmos de validación de modelos de aprendizaje supervisado." />
  <meta name="generator" content="bookdown 0.32 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 2 Muestras de train y test | Algoritmos de validación de modelos de aprendizaje supervisado" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="Esta es una introducción a los algoritmos de validación de modelos de aprendizaje supervisado." />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 2 Muestras de train y test | Algoritmos de validación de modelos de aprendizaje supervisado" />
  
  <meta name="twitter:description" content="Esta es una introducción a los algoritmos de validación de modelos de aprendizaje supervisado." />
  

<meta name="author" content="Fabio Scielzo Ortiz" />


<meta name="date" content="2023-03-07" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="index.html"/>
<link rel="next" href="métricas-para-evaluar-modelos-de-regresión.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Algoritmos de validación de modelos de aprendizaje supervisado </a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introducción</a></li>
<li class="chapter" data-level="2" data-path="muestras-de-train-y-test.html"><a href="muestras-de-train-y-test.html"><i class="fa fa-check"></i><b>2</b> Muestras de train y test</a>
<ul>
<li class="chapter" data-level="2.1" data-path="muestras-de-train-y-test.html"><a href="muestras-de-train-y-test.html#train-set"><i class="fa fa-check"></i><b>2.1</b> Train-set</a></li>
<li class="chapter" data-level="2.2" data-path="muestras-de-train-y-test.html"><a href="muestras-de-train-y-test.html#predicciones-de-train"><i class="fa fa-check"></i><b>2.2</b> Predicciones de train</a></li>
<li class="chapter" data-level="2.3" data-path="muestras-de-train-y-test.html"><a href="muestras-de-train-y-test.html#test-set"><i class="fa fa-check"></i><b>2.3</b> Test-set</a></li>
<li class="chapter" data-level="2.4" data-path="muestras-de-train-y-test.html"><a href="muestras-de-train-y-test.html#predicciones-de-test"><i class="fa fa-check"></i><b>2.4</b> Predicciones de test <a class="anchor" id="1"></a></a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="métricas-para-evaluar-modelos-de-regresión.html"><a href="métricas-para-evaluar-modelos-de-regresión.html"><i class="fa fa-check"></i><b>3</b> Métricas para evaluar modelos de regresión</a>
<ul>
<li class="chapter" data-level="3.1" data-path="métricas-para-evaluar-modelos-de-regresión.html"><a href="métricas-para-evaluar-modelos-de-regresión.html#error-cuadrático-medio-ecm"><i class="fa fa-check"></i><b>3.1</b> Error cuadrático medio (ECM)</a></li>
<li class="chapter" data-level="3.2" data-path="métricas-para-evaluar-modelos-de-regresión.html"><a href="métricas-para-evaluar-modelos-de-regresión.html#raiz-del-error-cuadrático-medio-recm"><i class="fa fa-check"></i><b>3.2</b> Raiz del error cuadrático medio (RECM)</a></li>
<li class="chapter" data-level="3.3" data-path="métricas-para-evaluar-modelos-de-regresión.html"><a href="métricas-para-evaluar-modelos-de-regresión.html#error-cuadratico-relativo-ecr"><i class="fa fa-check"></i><b>3.3</b> Error cuadratico relativo (ECR)</a></li>
<li class="chapter" data-level="3.4" data-path="métricas-para-evaluar-modelos-de-regresión.html"><a href="métricas-para-evaluar-modelos-de-regresión.html#coeficiente-de-determinación"><i class="fa fa-check"></i><b>3.4</b> Coeficiente de determinación</a></li>
<li class="chapter" data-level="3.5" data-path="métricas-para-evaluar-modelos-de-regresión.html"><a href="métricas-para-evaluar-modelos-de-regresión.html#error-absoluto-medio-eam"><i class="fa fa-check"></i><b>3.5</b> Error absoluto medio (EAM)</a></li>
<li class="chapter" data-level="3.6" data-path="métricas-para-evaluar-modelos-de-regresión.html"><a href="métricas-para-evaluar-modelos-de-regresión.html#error-absoluto-relativo-ear"><i class="fa fa-check"></i><b>3.6</b> Error absoluto relativo (EAR) <a class="anchor" id="1"></a></a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="métricas-para-evaluar-modelos-de-clasificación-supervisada.html"><a href="métricas-para-evaluar-modelos-de-clasificación-supervisada.html"><i class="fa fa-check"></i><b>4</b> Métricas para evaluar modelos de clasificación supervisada</a>
<ul>
<li class="chapter" data-level="4.1" data-path="métricas-para-evaluar-modelos-de-clasificación-supervisada.html"><a href="métricas-para-evaluar-modelos-de-clasificación-supervisada.html#tasa-de-acierto-en-la-clasificación-tac"><i class="fa fa-check"></i><b>4.1</b> Tasa de acierto en la clasificación (TAC)</a></li>
<li class="chapter" data-level="4.2" data-path="métricas-para-evaluar-modelos-de-clasificación-supervisada.html"><a href="métricas-para-evaluar-modelos-de-clasificación-supervisada.html#tasa-de-error-en-la-clasificación-tec"><i class="fa fa-check"></i><b>4.2</b> Tasa de error en la clasificación (TEC)</a></li>
<li class="chapter" data-level="4.3" data-path="métricas-para-evaluar-modelos-de-clasificación-supervisada.html"><a href="métricas-para-evaluar-modelos-de-clasificación-supervisada.html#kappa"><i class="fa fa-check"></i><b>4.3</b> Kappa <a class="anchor" id="1"></a></a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="métricas-para-evaluar-modelos-de-clasificación-supervisada.html"><a href="métricas-para-evaluar-modelos-de-clasificación-supervisada.html#modelo-de-clasificación-aleatoria-uniforme"><i class="fa fa-check"></i><b>4.3.1</b> Modelo de clasificación aleatoria uniforme</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="algoritmos-de-validación-de-modelos-de-aprendizaje-supervisado.html"><a href="algoritmos-de-validación-de-modelos-de-aprendizaje-supervisado.html"><i class="fa fa-check"></i><b>5</b> Algoritmos de validación de modelos de aprendizaje supervisado</a>
<ul>
<li class="chapter" data-level="5.1" data-path="algoritmos-de-validación-de-modelos-de-aprendizaje-supervisado.html"><a href="algoritmos-de-validación-de-modelos-de-aprendizaje-supervisado.html#validación-simple-no-aleatoria"><i class="fa fa-check"></i><b>5.1</b> Validación simple no aleatoria</a></li>
<li class="chapter" data-level="5.2" data-path="algoritmos-de-validación-de-modelos-de-aprendizaje-supervisado.html"><a href="algoritmos-de-validación-de-modelos-de-aprendizaje-supervisado.html#validación-simple-aleatoria"><i class="fa fa-check"></i><b>5.2</b> Validación simple aleatoria</a></li>
<li class="chapter" data-level="5.3" data-path="algoritmos-de-validación-de-modelos-de-aprendizaje-supervisado.html"><a href="algoritmos-de-validación-de-modelos-de-aprendizaje-supervisado.html#validación-simple-aleatoria-repetida"><i class="fa fa-check"></i><b>5.3</b> Validación simple aleatoria repetida</a></li>
<li class="chapter" data-level="5.4" data-path="algoritmos-de-validación-de-modelos-de-aprendizaje-supervisado.html"><a href="algoritmos-de-validación-de-modelos-de-aprendizaje-supervisado.html#leave-one-out"><i class="fa fa-check"></i><b>5.4</b> Leave-one-out</a></li>
<li class="chapter" data-level="5.5" data-path="algoritmos-de-validación-de-modelos-de-aprendizaje-supervisado.html"><a href="algoritmos-de-validación-de-modelos-de-aprendizaje-supervisado.html#k-fold"><i class="fa fa-check"></i><b>5.5</b> k-fold</a></li>
<li class="chapter" data-level="5.6" data-path="algoritmos-de-validación-de-modelos-de-aprendizaje-supervisado.html"><a href="algoritmos-de-validación-de-modelos-de-aprendizaje-supervisado.html#repeted-k-fold"><i class="fa fa-check"></i><b>5.6</b> Repeted k-fold <a class="anchor" id="1"></a></a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="selección-de-modelos-basada-en-validación-cruzada.html"><a href="selección-de-modelos-basada-en-validación-cruzada.html"><i class="fa fa-check"></i><b>6</b> Selección de modelos basada en validación cruzada <a class="anchor" id="1"></a></a></li>
<li class="chapter" data-level="7" data-path="algoritmos-de-validación-cruzada-programados-en-python.html"><a href="algoritmos-de-validación-cruzada-programados-en-python.html"><i class="fa fa-check"></i><b>7</b> Algoritmos de validación cruzada programados en <code>Python</code></a>
<ul>
<li class="chapter" data-level="7.1" data-path="algoritmos-de-validación-cruzada-programados-en-python.html"><a href="algoritmos-de-validación-cruzada-programados-en-python.html#validación-simple-no-aleatoria-1"><i class="fa fa-check"></i><b>7.1</b> Validación simple no aleatoria</a></li>
<li class="chapter" data-level="7.2" data-path="algoritmos-de-validación-cruzada-programados-en-python.html"><a href="algoritmos-de-validación-cruzada-programados-en-python.html#validación-simple-aleatoria-1"><i class="fa fa-check"></i><b>7.2</b> Validación simple aleatoria</a></li>
<li class="chapter" data-level="7.3" data-path="algoritmos-de-validación-cruzada-programados-en-python.html"><a href="algoritmos-de-validación-cruzada-programados-en-python.html#validación-simple-aleatoria-repetida-1"><i class="fa fa-check"></i><b>7.3</b> Validación simple aleatoria repetida</a></li>
<li class="chapter" data-level="7.4" data-path="algoritmos-de-validación-cruzada-programados-en-python.html"><a href="algoritmos-de-validación-cruzada-programados-en-python.html#leave-one-out-1"><i class="fa fa-check"></i><b>7.4</b> Leave one out</a></li>
<li class="chapter" data-level="7.5" data-path="algoritmos-de-validación-cruzada-programados-en-python.html"><a href="algoritmos-de-validación-cruzada-programados-en-python.html#k-fold-1"><i class="fa fa-check"></i><b>7.5</b> k-fold</a></li>
<li class="chapter" data-level="7.6" data-path="algoritmos-de-validación-cruzada-programados-en-python.html"><a href="algoritmos-de-validación-cruzada-programados-en-python.html#repeated-k-folds"><i class="fa fa-check"></i><b>7.6</b> Repeated k-folds <a class="anchor" id="1"></a></a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="algoritmos-de-valicación-cruzada-con-sklearn.html"><a href="algoritmos-de-valicación-cruzada-con-sklearn.html"><i class="fa fa-check"></i><b>8</b> Algoritmos de valicación cruzada con <code>Sklearn</code></a>
<ul>
<li class="chapter" data-level="8.1" data-path="algoritmos-de-valicación-cruzada-con-sklearn.html"><a href="algoritmos-de-valicación-cruzada-con-sklearn.html#k-fold-2"><i class="fa fa-check"></i><b>8.1</b> k-fold</a></li>
<li class="chapter" data-level="8.2" data-path="algoritmos-de-valicación-cruzada-con-sklearn.html"><a href="algoritmos-de-valicación-cruzada-con-sklearn.html#repeated-k-fold"><i class="fa fa-check"></i><b>8.2</b> Repeated k-fold <a class="anchor" id="1"></a></a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="comparación-final.html"><a href="comparación-final.html"><i class="fa fa-check"></i><b>9</b> Comparación final <a class="anchor" id="1"></a></a></li>
<li class="chapter" data-level="10" data-path="bibliografía.html"><a href="bibliografía.html"><i class="fa fa-check"></i><b>10</b> Bibliografía <a class="anchor" id="1"></a></a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Algoritmos de validación de modelos de aprendizaje supervisado</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="muestras-de-train-y-test" class="section level1 hasAnchor" number="2">
<h1><span class="header-section-number">Chapter 2</span> Muestras de train y test<a href="muestras-de-train-y-test.html#muestras-de-train-y-test" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div class="warning" style="background-color:#F7EBE8; color: #030000; border-left: solid #CA0B0B 7px; border-radius: 3px; size:1px ; padding:0.1em;">
<p><span></p>
<p style="margin-left:1em;">
<ul>
<li><p>Tenemos una muestra de <span class="math inline">\(N\)</span> observaciones de <span class="math inline">\(p\)</span> predictores <span class="math inline">\(\mathcal{X}_1,...,\mathcal{X}_p\)</span> y de una variable respuesta <span class="math inline">\(\mathcal{Y}\)</span> :</p>
<p><span class="math display">\[D=[\hspace{0.1cm} X_1,...,X_p,Y \hspace{0.1cm}]=\begin{pmatrix}
  x_{11}&amp;x_{12}&amp;...&amp;x_{1p}&amp; y_1\\
  x_{21}&amp;x_{22}&amp;...&amp;x_{2p} &amp; y_2\\
  ...&amp;...&amp;...&amp;...\\
  x_{N1}&amp;x_{N2}&amp;...&amp;x_{Np}&amp; y_N
  \end{pmatrix} = \begin{pmatrix}
  x_{1}&amp; y_1\\
  x_{2}&amp; y_2\\
  ...&amp;...\\
  x_{N}&amp; y_N
  \end{pmatrix} \\\]</span></p></li>
</ul>
</p>
</p>
<p></span></p>
</div>
<p><br></p>
<p>Sin entrar aquí en particularidades, para evaluar un modelo de aprendizaje supervisado <span class="math inline">\(M\)</span> este tiene que ser entrenado con un subconjunto de <span class="math inline">\(n\)</span> filas de <span class="math inline">\(D\)</span> , llamado <strong>muestra de entrenamiento</strong> o de <strong>train</strong> <span class="math inline">\(D_{train}\)</span>, y testado con el subconjunto de las <span class="math inline">\(h\)</span> filas restantes de <span class="math inline">\(D\)</span>, llamado <strong>muestra de test</strong> <span class="math inline">\(D_{test}\)</span> , de modo que <span class="math inline">\(n+h=N\)</span></p>
<p>Los métodos de validación típicos usan de algún modo <span class="math inline">\(D_{train}\)</span> y <span class="math inline">\(D_{test}\)</span> , junto con una <strong>métrica de evaluación</strong>, es por ello que vamos a definir estos elementos con mas precisión a continuación.</p>
<p><br></p>
<div id="train-set" class="section level2 hasAnchor" number="2.1">
<h2><span class="header-section-number">2.1</span> Train-set<a href="muestras-de-train-y-test.html#train-set" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Los elementos antes mencionados se definen formalmente como sigue:</p>
<div class="warning" style="background-color:#F7EBE8; color: #030000; border-left: solid #CA0B0B 7px; border-radius: 3px; size:1px ; padding:0.1em;">
<p><span></p>
<p style="margin-left:1em;">
<ul>
<li><strong>Muestra train</strong> de <span class="math inline">\(n\)</span> observaciones del predictor <span class="math inline">\(\mathcal{X}_j\)</span> :</li>
</ul>
<p><span class="math display">\[X_j^{train} \hspace{0.1cm}=\hspace{0.1cm} (\hspace{0.1cm} x_{1j}^{train},...,x_{nj}^{train}\hspace{0.1cm} )^t \hspace{0.3cm} , \hspace{0.3cm} j\in \lbrace 1,...,p \rbrace \\[0.4cm]\]</span></p>
<ul>
<li><strong>Muestra train</strong> de <span class="math inline">\(n\)</span> observaciones de la respuesta <span class="math inline">\(\mathcal{Y}\)</span> :</li>
</ul>
<p><span class="math display">\[Y^{train} \hspace{0.1cm}=\hspace{0.1cm} \left(\hspace{0.1cm}y_{1}^{train},...,y_n^{train}\hspace{0.1cm}\right)^t \\[0.4cm]\]</span></p>
<ul>
<li><strong>Train-set</strong> :</li>
</ul>
<p><span class="math display">\[D_{train}\hspace{0.1cm}=\hspace{0.1cm}[\hspace{0.1cm}X_1^{train}\hspace{0.03cm},...,\hspace{0.03cm}X_p^{train} \hspace{0.03cm},\hspace{0.03cm} Y^{train}\hspace{0.1cm}]\hspace{0.1cm} = \\[1cm] =\hspace{0.1cm}  \begin{pmatrix}
    x_{11}^{train} &amp;x_{12}^{train}&amp;...&amp;x_{1p}^{train}&amp; y_1^{train}\\
    x_{21}^{train}&amp;x_{22}^{train}&amp;...&amp;x_{2p}^{train} &amp; y_2^{train}\\
    &amp;...&amp;\\
    x_{n1}^{train}&amp;x_{n2}^{train}&amp;...&amp;x_{np}^{train}&amp; y_n^{train}
    \end{pmatrix}= \begin{pmatrix}
    x_{1}^{train}&amp; y_1^{train}\\
    x_{2}^{train}&amp; y_2^{train}\\
    ...&amp;...\\
    x_{n}^{train}&amp; y_n^{train}
    \end{pmatrix} \\\]</span></p>
</p>
</p>
<p></span></p>
</div>
<p><br></p>
<p><strong>Observaciones:</strong></p>
<ul>
<li><p>La fila <span class="math inline">\(i\)</span> de <span class="math inline">\(D_{train}\)</span> , es decir, <span class="math inline">\(\left(x_i^{train},y_i^{train}\right) = \left(x_{i1}^{train}, x_{i2}^{train},...,x_{ip}^{train}, y_i^{train}\right)\hspace{0.1cm}\)</span>, es la <span class="math inline">\(\hspace{0.1cm}i\)</span>-esima <strong>observación de train</strong> de los predictores y la respuesta <span class="math inline">\(\hspace{0.1cm}\mathcal{X}_1,...,\mathcal{X}_p \hspace{0.1cm},\hspace{0.1cm} \mathcal{Y}\)</span>.</p></li>
<li><p><span class="math inline">\(D_{train}\)</span> también es llamada simplemente <strong>observaciones de train</strong> de <span class="math inline">\(\mathcal{X}_1,...,\mathcal{X}_p\hspace{0.1cm},\hspace{0.1cm} \mathcal{Y}\)</span>.</p></li>
</ul>
<p><br></p>
</div>
<div id="predicciones-de-train" class="section level2 hasAnchor" number="2.2">
<h2><span class="header-section-number">2.2</span> Predicciones de train<a href="muestras-de-train-y-test.html#predicciones-de-train" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Como <span class="math inline">\(M\)</span> es un modelo de aprendizaje supervisado es capaz de, una vez es entrenado con las observaciones de <span class="math inline">\(D_{train}=[X_1^{train},...,X_p^{train}, Y^{train}]\)</span> , generar predicciones de la variable respuesta <span class="math inline">\(\mathcal{Y}\)</span>, tanto para las <strong>observaciones de train</strong> de los predictores como para <strong>nuevas observaciones</strong>.</p>
<p>Notese que <span class="math inline">\(M\)</span> nos interesa realmente para predecir la variable respuesta para <strong>nuevas observaciones</strong> de los predictores, es decir, para predecir la respuesta para individuos/elementos de los que solo tenemos información de los predictores.</p>
<p><br></p>
<div class="warning" style="background-color:#F7EBE8; color: #030000; border-left: solid #CA0B0B 7px; border-radius: 3px; size:1px ; padding:0.1em;">
<p><span></p>
<p style="margin-left:1em;">
<p><span class="math inline">\(\hspace{0.2cm}\)</span> Las <strong>predicciones de train</strong> de la respuesta <span class="math inline">\(\hspace{0.1cm}\mathcal{Y}\hspace{0.1cm}\)</span> , son obtenidas aplicando el modelo de aprendizaje supervisado ya <strong>entrenado</strong> a las <strong>observaciones de train</strong> de los <strong>predictores</strong>:</p>
<p><span class="math display">\[\widehat{\hspace{0.08cm} Y}^{\hspace{0.1cm} train} \hspace{0.1cm} = \hspace{0.1cm}  M\left(\hspace{0.1cm} X_1^{train},...,X_p^{train} \hspace{0.15cm}|\hspace{0.15cm} X_1^{train},...,X_p^{train}, Y^{train} \hspace{0.1cm}\right)\]</span></p>
</p>
</p>
<p></span></p>
</div>
<p><br></p>
<p><strong>Observaciones:</strong></p>
<ul>
<li><p>Aqui <span class="math inline">\(\hspace{0.08cm}M(\hspace{0.1cm} z \hspace{0.1cm}|\hspace{0.1cm} w\hspace{0.1cm})\hspace{0.08cm}\)</span> representa una función de dos argumentos, el argumento posterior a <span class="math inline">\(\hspace{0.1cm}|\hspace{0.1cm}\)</span> , es decir <span class="math inline">\(\hspace{0.1cm}w\hspace{0.1cm}\)</span>, son los datos de predictores y respuestas con los que se entrena el modelo de aprendizaje supervisado <span class="math inline">\(\hspace{0.1cm}M\hspace{0.05cm}\)</span> , y el argumento previo a <span class="math inline">\(\hspace{0.1cm}|\hspace{0.1cm}\)</span> , es decir <span class="math inline">\(\hspace{0.1cm}z\hspace{0.1cm}\)</span>, son los datos de los predictores que el modelo <span class="math inline">\(\hspace{0.1cm}M\hspace{0.05cm}\)</span> usa para generar predicciones de la variable respuesta. Y devuelve un vector con esas predicciones de la respuesta. <span class="math inline">\(\\[0.5cm]\)</span></p></li>
<li><p><span class="math inline">\(\widehat{\hspace{0.08cm} Y}^{\hspace{0.08cm} train}\hspace{0.1cm}=\hspace{0.1cm}(\hat{y}_1^{train},..., \hat{y}_n^{train})^t\hspace{0.15cm}\)</span> es un vector con las predicciones de la respuesta hechas por el modelo entrenado <span class="math inline">\(\hspace{0.08cm}M\hspace{0.1cm}\)</span> para la muestra train de observaciones de los predictores <span class="math inline">\(\hspace{0.1cm}(X_1^{train},...,X_p^{train}) \\\)</span></p></li>
<li><p><span class="math inline">\(\widehat{y}_i^{train} \hspace{0.1cm}=\hspace{0.1cm} M(\hspace{0.1cm} x_i^{train} \hspace{0.1cm}|\hspace{0.1cm} X_1^{train},...,X_p^{train}, Y^{train} \hspace{0.1cm}) \hspace{0.1cm}=\hspace{0.1cm} M(\hspace{0.1cm}x_{i1}^{train},...,x_{ip}^{train} \hspace{0.1cm}|\hspace{0.1cm} X_1^{train},...,X_p^{train}, Y^{train}\hspace{0.1cm})\hspace{0.1cm}\)</span> es la predicción de la variable respuesta generada por el modelo entrenado <span class="math inline">\(\hspace{0.05cm}M\hspace{0.05cm}\)</span> para la observación de train de los predictores <span class="math inline">\(\hspace{0.1cm}x_i^{train}\hspace{0.1cm}=\hspace{0.1cm}(x_{i1}^{train},...,x_{ip}^{train})\)</span></p></li>
</ul>
<p><br></p>
</div>
<div id="test-set" class="section level2 hasAnchor" number="2.3">
<h2><span class="header-section-number">2.3</span> Test-set<a href="muestras-de-train-y-test.html#test-set" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div class="warning" style="background-color:#F7EBE8; color: #030000; border-left: solid #CA0B0B 7px; border-radius: 3px; size:1px ; padding:0.1em;">
<p><span></p>
<p style="margin-left:1em;">
<ul>
<li><strong>Muestra test</strong> de <span class="math inline">\(\hspace{0.08cm}h\hspace{0.08cm}\)</span> observaciones del predictor <span class="math inline">\(\hspace{0.08cm}\mathcal{X}_j\\\)</span></li>
</ul>
<p><span class="math display">\[X_j^{test}=\left(x^{test}_{1j},...,x^{test}_{hj} \right)^t  \hspace{0.3cm} , \hspace{0.3cm} \forall j=1,...,p\\[0.4cm]\]</span></p>
<ul>
<li><strong>Muestra test</strong> de <span class="math inline">\(\hspace{0.1cm}h\hspace{0.1cm}\)</span> observaciones de la respuesta <span class="math inline">\(\hspace{0.08cm}\mathcal{Y}\\\)</span></li>
</ul>
<p><span class="math display">\[Y^{test}=\left(y^{test}_{1},...,y^{test}_{h} \right)^t  \hspace{0.3cm} , \hspace{0.3cm} \forall j=1,...,p \\[0.4cm]\]</span></p>
<ul>
<li><strong>Test-set</strong></li>
</ul>
<p><span class="math display">\[D_{test}  \hspace{0.1cm}=\hspace{0.1cm} [\hspace{0.1cm}X_1^{test},...,X_p^{test}, Y^{test}\hspace{0.1cm}] \hspace{0.1cm}=\hspace{0.1cm} \begin{pmatrix}
    x^{test}_{11}&amp;x^{test}_{12}&amp;...&amp;x^{test}_{1p} &amp; y^{test}_1\\
    x^{test}_{21}&amp;x^{test}_{22}&amp;...&amp;x^{test}_{2p} &amp; y^{test}_2\\
    &amp;...&amp;\\
    x^{test}_{h1}&amp;x^{test}_{h2}&amp;...&amp;x^{test}_{hp} &amp; y^{test}_h
    \end{pmatrix}= \begin{pmatrix}
    x_{1}^{test}&amp; y_1^{test}\\
    x_{2}^{test}&amp; y_2^{test}\\
    ...&amp;...\\
    x_{h}^{test}&amp; y_h^{test}
    \end{pmatrix}\]</span></p>
</p>
</p>
<p></span></p>
</div>
<p><br></p>
<p><strong>Observaciones:</strong></p>
<ul>
<li><p>La fila <span class="math inline">\(\hspace{0.1cm}i\hspace{0.1cm}\)</span> de <span class="math inline">\(\hspace{0.1cm}D_{test}\hspace{0.1cm}\)</span> , es decir, <span class="math inline">\(\hspace{0.1cm}(x_i^{test},y_i^{test})= (x^{test}_{i1}, x^{test}_{i2},...,x^{test}_{ip}, y_i^{test})\hspace{0.1cm}\)</span>, es la <span class="math inline">\(\hspace{0.1cm}i\)</span>-esima <strong>observación de test</strong> de los predictores y la respuesta <span class="math inline">\(\hspace{0.1cm}\mathcal{X}_1,...,\mathcal{X}_p\hspace{0.08cm},\hspace{0.08cm} \mathcal{Y}\\\)</span></p></li>
<li><p><span class="math inline">\(D_{test}\hspace{0.1cm}\)</span> también es llamada simplemente <strong>observaciones de test</strong> de <span class="math inline">\(\hspace{0.1cm}\mathcal{X}_1,...,\mathcal{X}_p, \mathcal{Y}\)</span></p></li>
</ul>
<p><br></p>
</div>
<div id="predicciones-de-test" class="section level2 hasAnchor" number="2.4">
<h2><span class="header-section-number">2.4</span> Predicciones de test <a class="anchor" id="1"></a><a href="muestras-de-train-y-test.html#predicciones-de-test" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Puesto que <span class="math inline">\(\hspace{0.1cm}M\hspace{0.1cm}\)</span> es un modelo predictivo supervisado es capaz de, una vez es entrenado con las observaciones de <span class="math inline">\(\hspace{0.08cm}D_{train}=[X_1^{train},...,X_p^{train}, Y^{train}]\hspace{0.08cm}\)</span> , generar predicciones de la respuesta <span class="math inline">\(\hspace{0.08cm}\mathcal{Y}\hspace{0.08cm}\)</span> , tanto para las <strong>observaciones de train</strong> como para <strong>nuevas observaciones</strong> de los predictores <span class="math inline">\(\hspace{0.08cm}\mathcal{X}_1,...,\mathcal{X}_p\)</span> .</p>
<p>Notese, de nuevo, que <span class="math inline">\(\hspace{0.1cm}M\hspace{0.1cm}\)</span> nos interesa realmente para predecir la respuesta para <strong>nuevas observaciones</strong> de los predictores, es decir, para predecir la respuesta para individuos/elementos de los que tenemos información sobre los predictores pero no sobre la respuesta.</p>
<p><br></p>
<div class="warning" style="background-color:#F7EBE8; color: #030000; border-left: solid #CA0B0B 7px; border-radius: 3px; size:1px ; padding:0.1em;">
<p><span></p>
<p style="margin-left:1em;">
<p><span class="math inline">\(\hspace{0.2cm}\)</span> Las <strong>predicciones de test</strong> de la respuesta <span class="math inline">\(\hspace{0.08cm}\mathcal{Y}\hspace{0.08cm}\)</span> , son obtenidas aplicando el <strong>modelo</strong> predictivo <strong>entrenado</strong> a las observaciones de <strong>test</strong>:</p>
<p><span class="math display">\[\widehat{Y}\hspace{0.08cm}^{test} \hspace{0.1cm} = \hspace{0.1cm} M\left(\hspace{0.1cm} X_1^{test},...,X_p^{test} \hspace{0.15cm}|\hspace{0.15cm} X_1^{train},...,X_p^{train}, Y^{train} \hspace{0.1cm}\right)\]</span></p>
</p>
</p>
<p></span></p>
</div>
<p><br></p>
<p><strong>Observaciones:</strong></p>
<ul>
<li><p>Aqui <span class="math inline">\(\hspace{0.08cm}M(\hspace{0.1cm} z \hspace{0.1cm}|\hspace{0.1cm} w\hspace{0.1cm})\hspace{0.08cm}\)</span> representa una función de dos argumentos, el argumento posterior a <span class="math inline">\(\hspace{0.1cm}|\hspace{0.1cm}\)</span> , es decir <span class="math inline">\(\hspace{0.1cm}w\hspace{0.1cm}\)</span>, son los datos de predictores y respuestas con los que se entrena el modelo <span class="math inline">\(\hspace{0.1cm}M\hspace{0.1cm}\)</span> , y el argumento previo a <span class="math inline">\(\hspace{0.1cm}|\hspace{0.1cm}\)</span> , es decir <span class="math inline">\(\hspace{0.1cm}z\hspace{0.1cm}\)</span>, son los datos de los predictores que el modelo <span class="math inline">\(\hspace{0.1cm}M\hspace{0.1cm}\)</span> usa para generar predicciones de la respuesta. Y devuelve un vector con esas predicciones de la respuesta. <span class="math inline">\(\\[0.5cm]\)</span></p></li>
<li><p><span class="math inline">\(\widehat{\hspace{0.08cm}Y}^{\hspace{0.08cm}test}\hspace{0.08cm}=\hspace{0.08cm} \left(\hat{y}_1^{\hspace{0.08cm}test},..., \hat{y}_h^{\hspace{0.08cm}test}\right)^t\hspace{0.1cm}\)</span> es un vector con las predicciones de la respuesta hechas por el modelo entrenado <span class="math inline">\(\hspace{0.1cm}M\hspace{0.1cm}\)</span> usando la <strong>muestra test</strong> de observaciones de los predictores <span class="math inline">\(\hspace{0.08cm}X_1^{test},...,X_p^{test} \\\)</span></p></li>
<li><p><span class="math inline">\(\hat{y}_i^{test} \hspace{0.1cm}=\hspace{0.1cm} M \left(\hspace{0.1cm} x_i^{test} \hspace{0.15cm}|\hspace{0.15cm} X_1^{train},...,X_p^{train}, Y^{train}\hspace{0.1cm} \right) \hspace{0.1cm}=\hspace{0.1cm} M\left( \hspace{0.08cm} x^{test}_{i1},...,x^{test}_{ip} \hspace{0.15cm}|\hspace{0.15cm} X_1^{train},...,X_p^{train}, Y^{train}\right)\hspace{0.1cm}\)</span> es la predicción de la respuesta que el modelo entrenado <span class="math inline">\(\hspace{0.1cm}M\hspace{0.1cm}\)</span> genera para la observación de test de los predictores <span class="math inline">\(\hspace{0.1cm}x_i^{test}=(x^{test}_{i1},...,x^{test}_{ip})\)</span> .</p></li>
</ul>
<p><br></p>
<p>Teniendo todo lo anterior en cuenta, la evaluación de los modelos de aprendizaje supervisado <span class="math inline">\(\hspace{0.05cm} M\hspace{0.05cm}\)</span> se realiza, sin entrar en particularidades, comparando las <strong>predicciones de test</strong> de la variable respuesta generadas por el modelo <span class="math inline">\(\hspace{0.05cm}M\hspace{0.05cm}\)</span>, es decir, <span class="math inline">\(\hspace{0.08cm}\widehat{\hspace{0.08cm}Y}^{\hspace{0.08cm}test}\hspace{0.08cm}\)</span>, con la muestra de <strong>observaciones test</strong> de la respuesta, <span class="math inline">\(\hspace{0.08cm}Y^{test}\)</span></p>
<p>La muestra test juega el rol de muestra de nuevas observaciones. Y el modelo <span class="math inline">\(\hspace{0.05cm} M\hspace{0.05cm}\)</span> interesa para predecir nuevas observaciones.</p>
<p>Por ello se utiliza la muestra test como muestra para evaluar el rendimiento del modelo al predecir la respuesta para nuevas observaciones de los predictores.</p>
<p><br></p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="index.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="métricas-para-evaluar-modelos-de-regresión.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/USERNAME/REPO/edit/BRANCH/index.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["_main.pdf", "_main.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
