<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Algoritmos de validación de modelos de aprendizaje supervisado</title>
  <meta name="description" content="<p>Esta es una introducción a los algoritmos de validación de modelos de aprendizaje supervisado.</p>" />
  <meta name="generator" content="bookdown #bookdown:version# and GitBook 2.6.7" />

  <meta property="og:title" content="Algoritmos de validación de modelos de aprendizaje supervisado" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="<p>Esta es una introducción a los algoritmos de validación de modelos de aprendizaje supervisado.</p>" />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Algoritmos de validación de modelos de aprendizaje supervisado" />
  
  <meta name="twitter:description" content="<p>Esta es una introducción a los algoritmos de validación de modelos de aprendizaje supervisado.</p>" />
  

<meta name="author" content="Fabio Scielzo Ortiz" />


<meta name="date" content="2023-03-07" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<!--bookdown:link_prev-->
<!--bookdown:link_next-->
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



<!--bookdown:title:start-->
<div id="header">
<h1 class="title">Algoritmos de validación de modelos de aprendizaje supervisado</h1>
<p class="author"><em>Fabio Scielzo Ortiz</em></p>
<p class="date"><em>2023-03-07</em></p>
</div>
<!--bookdown:title:end-->

<!--bookdown:toc:start-->
  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">
<!--bookdown:toc2:start-->
<ul>
<li><a href="#introducción" id="toc-introducción"><span class="toc-section-number">1</span> Introducción</a></li>
<li><a href="#muestras-y-predicciones-de-de-train-y-test" id="toc-muestras-y-predicciones-de-de-train-y-test"><span class="toc-section-number">2</span> Muestras y predicciones de de train y test</a>
<ul>
<li><a href="#train-set" id="toc-train-set"><span class="toc-section-number">2.1</span> Train-set</a></li>
<li><a href="#predicciones-de-train" id="toc-predicciones-de-train"><span class="toc-section-number">2.2</span> Predicciones de train</a></li>
<li><a href="#test-set" id="toc-test-set"><span class="toc-section-number">2.3</span> Test-set</a></li>
<li><a href="#predicciones-de-test" id="toc-predicciones-de-test"><span class="toc-section-number">2.4</span> Predicciones de test</a></li>
</ul></li>
<li><a href="#métricas-para-evaluar-modelos-de-regresión" id="toc-métricas-para-evaluar-modelos-de-regresión"><span class="toc-section-number">3</span> Métricas para evaluar modelos de regresión</a>
<ul>
<li><a href="#error-cuadrático-medio-ecm" id="toc-error-cuadrático-medio-ecm"><span class="toc-section-number">3.1</span> Error cuadrático medio (ECM)</a></li>
<li><a href="#raiz-del-error-cuadrático-medio-recm" id="toc-raiz-del-error-cuadrático-medio-recm"><span class="toc-section-number">3.2</span> Raiz del error cuadrático medio (RECM)</a></li>
<li><a href="#error-cuadratico-relativo-ecr" id="toc-error-cuadratico-relativo-ecr"><span class="toc-section-number">3.3</span> Error cuadratico relativo (ECR)</a></li>
<li><a href="#coeficiente-de-determinación" id="toc-coeficiente-de-determinación"><span class="toc-section-number">3.4</span> Coeficiente de determinación</a></li>
<li><a href="#error-absoluto-medio-eam" id="toc-error-absoluto-medio-eam"><span class="toc-section-number">3.5</span> Error absoluto medio (EAM)</a></li>
<li><a href="#error-absoluto-relativo-ear" id="toc-error-absoluto-relativo-ear"><span class="toc-section-number">3.6</span> Error absoluto relativo (EAR)</a></li>
</ul></li>
<li><a href="#métricas-para-evaluar-modelos-de-clasificación-supervisada" id="toc-métricas-para-evaluar-modelos-de-clasificación-supervisada"><span class="toc-section-number">4</span> Métricas para evaluar modelos de clasificación supervisada</a>
<ul>
<li><a href="#tasa-de-acierto-en-la-clasificación-tac" id="toc-tasa-de-acierto-en-la-clasificación-tac"><span class="toc-section-number">4.1</span> Tasa de acierto en la clasificación (TAC)</a></li>
<li><a href="#tasa-de-error-en-la-clasificación-tec" id="toc-tasa-de-error-en-la-clasificación-tec"><span class="toc-section-number">4.2</span> Tasa de error en la clasificación (TEC)</a></li>
<li><a href="#kappa" id="toc-kappa"><span class="toc-section-number">4.3</span> Kappa</a>
<ul>
<li><a href="#modelo-de-clasificación-aleatoria-uniforme" id="toc-modelo-de-clasificación-aleatoria-uniforme"><span class="toc-section-number">4.3.1</span> Modelo de clasificación aleatoria uniforme</a></li>
</ul></li>
</ul></li>
<li><a href="#algoritmos-de-validación-de-modelos-de-aprendizaje-supervisado" id="toc-algoritmos-de-validación-de-modelos-de-aprendizaje-supervisado"><span class="toc-section-number">5</span> Algoritmos de validación de modelos de aprendizaje supervisado</a>
<ul>
<li><a href="#validación-simple-no-aleatoria" id="toc-validación-simple-no-aleatoria"><span class="toc-section-number">5.1</span> Validación simple no aleatoria</a></li>
<li><a href="#validación-simple-aleatoria" id="toc-validación-simple-aleatoria"><span class="toc-section-number">5.2</span> Validación simple aleatoria</a></li>
<li><a href="#validación-simple-aleatoria-repetida" id="toc-validación-simple-aleatoria-repetida"><span class="toc-section-number">5.3</span> Validación simple aleatoria repetida</a></li>
<li><a href="#leave-one-out" id="toc-leave-one-out"><span class="toc-section-number">5.4</span> Leave-one-out</a></li>
<li><a href="#k-fold" id="toc-k-fold"><span class="toc-section-number">5.5</span> k-fold</a></li>
<li><a href="#repeted-k-fold" id="toc-repeted-k-fold"><span class="toc-section-number">5.6</span> Repeted k-fold</a></li>
</ul></li>
<li><a href="#selección-de-modelos-basada-en-validación-cruzada" id="toc-selección-de-modelos-basada-en-validación-cruzada"><span class="toc-section-number">6</span> Selección de modelos basada en validación cruzada</a></li>
<li><a href="#algoritmos-de-validación-cruzada-programados-en-python" id="toc-algoritmos-de-validación-cruzada-programados-en-python"><span class="toc-section-number">7</span> Algoritmos de validación cruzada programados en <code>Python</code></a>
<ul>
<li><a href="#validación-simple-no-aleatoria-1" id="toc-validación-simple-no-aleatoria-1"><span class="toc-section-number">7.1</span> Validación simple no aleatoria</a>
<ul>
<li><a href="#ejemplo-de-aplicación-a-knn-para-regresión" id="toc-ejemplo-de-aplicación-a-knn-para-regresión"><span class="toc-section-number">7.1.1</span> Ejemplo de aplicación a KNN para regresión</a></li>
<li><a href="#ejemplo-de-aplicación-a-knn-para-clasificación" id="toc-ejemplo-de-aplicación-a-knn-para-clasificación"><span class="toc-section-number">7.1.2</span> Ejemplo de aplicación a KNN para clasificación</a></li>
</ul></li>
<li><a href="#validación-simple-aleatoria-1" id="toc-validación-simple-aleatoria-1"><span class="toc-section-number">7.2</span> Validación simple aleatoria</a>
<ul>
<li><a href="#ejemplo-de-aplicación-a-knn-para-regresión-1" id="toc-ejemplo-de-aplicación-a-knn-para-regresión-1"><span class="toc-section-number">7.2.1</span> Ejemplo de aplicación a KNN para regresión</a></li>
<li><a href="#ejemplo-de-aplicación-a-knn-para-clasifación" id="toc-ejemplo-de-aplicación-a-knn-para-clasifación"><span class="toc-section-number">7.2.2</span> Ejemplo de aplicación a KNN para clasifación</a></li>
</ul></li>
<li><a href="#validación-simple-aleatoria-repetida-1" id="toc-validación-simple-aleatoria-repetida-1"><span class="toc-section-number">7.3</span> Validación simple aleatoria repetida</a>
<ul>
<li><a href="#ejemplo-de-aplicación-a-knn-para-regresión-2" id="toc-ejemplo-de-aplicación-a-knn-para-regresión-2"><span class="toc-section-number">7.3.1</span> Ejemplo de aplicación a KNN para regresión</a></li>
<li><a href="#ejemplo-de-aplicación-a-knn-para-clasificación-1" id="toc-ejemplo-de-aplicación-a-knn-para-clasificación-1"><span class="toc-section-number">7.3.2</span> Ejemplo de aplicación a KNN para clasificación</a></li>
</ul></li>
<li><a href="#leave-one-out-1" id="toc-leave-one-out-1"><span class="toc-section-number">7.4</span> Leave one out</a>
<ul>
<li><a href="#ejemplo-de-aplicación-a-kkn-para-regresión" id="toc-ejemplo-de-aplicación-a-kkn-para-regresión"><span class="toc-section-number">7.4.1</span> Ejemplo de aplicación a KKN para regresión</a></li>
<li><a href="#ejemplo-de-aplicación-a-kkn-para-clasificación" id="toc-ejemplo-de-aplicación-a-kkn-para-clasificación"><span class="toc-section-number">7.4.2</span> Ejemplo de aplicación a KKN para clasificación</a></li>
</ul></li>
<li><a href="#k-fold-1" id="toc-k-fold-1"><span class="toc-section-number">7.5</span> k-fold</a>
<ul>
<li><a href="#ejemplo-de-aplicación-a-kkn-para-regresión-1" id="toc-ejemplo-de-aplicación-a-kkn-para-regresión-1"><span class="toc-section-number">7.5.1</span> Ejemplo de aplicación a KKN para regresión</a></li>
<li><a href="#ejemplo-de-aplicación-a-kkn-para-clasificación-1" id="toc-ejemplo-de-aplicación-a-kkn-para-clasificación-1"><span class="toc-section-number">7.5.2</span> Ejemplo de aplicación a KKN para clasificación</a></li>
</ul></li>
<li><a href="#repeated-k-folds" id="toc-repeated-k-folds"><span class="toc-section-number">7.6</span> Repeated k-folds</a>
<ul>
<li><a href="#ejemplo-de-aplicación-a-kkn-para-regresión-2" id="toc-ejemplo-de-aplicación-a-kkn-para-regresión-2"><span class="toc-section-number">7.6.1</span> Ejemplo de aplicación a KKN para regresión</a></li>
<li><a href="#ejemplo-de-aplicación-a-kkn-para-clasificación-2" id="toc-ejemplo-de-aplicación-a-kkn-para-clasificación-2"><span class="toc-section-number">7.6.2</span> Ejemplo de aplicación a KKN para clasificación</a></li>
</ul></li>
</ul></li>
<li><a href="#algoritmos-de-valicación-cruzada-con-sklearn" id="toc-algoritmos-de-valicación-cruzada-con-sklearn"><span class="toc-section-number">8</span> Algoritmos de valicación cruzada con <code>Sklearn</code></a>
<ul>
<li><a href="#k-fold-2" id="toc-k-fold-2"><span class="toc-section-number">8.1</span> k-fold</a>
<ul>
<li><a href="#aplicación-a-knn-para-regresión" id="toc-aplicación-a-knn-para-regresión"><span class="toc-section-number">8.1.1</span> Aplicación a KNN para regresión</a></li>
<li><a href="#aplicación-a-knn-para-clasificación" id="toc-aplicación-a-knn-para-clasificación"><span class="toc-section-number">8.1.2</span> Aplicación a KNN para clasificación</a></li>
</ul></li>
<li><a href="#repeated-k-fold" id="toc-repeated-k-fold"><span class="toc-section-number">8.2</span> Repeated k-fold</a>
<ul>
<li><a href="#aplicación-a-knn-para-regresión-1" id="toc-aplicación-a-knn-para-regresión-1"><span class="toc-section-number">8.2.1</span> Aplicación a KNN para regresión</a></li>
<li><a href="#aplicación-a-knn-para-regresión-2" id="toc-aplicación-a-knn-para-regresión-2"><span class="toc-section-number">8.2.2</span> Aplicación a KNN para regresión</a></li>
</ul></li>
</ul></li>
<li><a href="#comparación-final" id="toc-comparación-final"><span class="toc-section-number">9</span> Comparación final</a>
<ul>
<li><a href="#visualización-aplicada-a-knn-para-regresión" id="toc-visualización-aplicada-a-knn-para-regresión"><span class="toc-section-number">9.1</span> Visualización aplicada a KNN para regresión</a></li>
<li><a href="#visualización-aplicada-a-knn-para-clasificación" id="toc-visualización-aplicada-a-knn-para-clasificación"><span class="toc-section-number">9.2</span> Visualización aplicada a KNN para clasificación</a></li>
</ul></li>
<li><a href="#bibliografía" id="toc-bibliografía"><span class="toc-section-number">10</span> Bibliografía</a></li>
</ul>
<!--bookdown:toc2:end-->
      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Algoritmos de validación de modelos de aprendizaje supervisado</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<!--bookdown:toc:end-->
<!--bookdown:body:start-->
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
    
 
    table {
     display: block;
     overflow-x: auto;
     border-collapse: collapse;
     border-spacing: 0;
     border: 0px solid;
     color: var(--jp-ui-font-color1);
     font-size: 14px;
     margin-left: auto;
     margin-right: auto;
     
            }
            
</style>
<div id="introducción" class="section level1 hasAnchor" number="1">
<h1 class="hasAnchor"><span class="header-section-number">1</span> Introducción<a href="#introducción" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<center>
<p><img src="validacion_cruzada.jpg" style="width:60.0%" /></p>
</center>
<p><br></p>
<div class="warning" style="background-color:#FCF2EC; color: #000000; border-left: solid #FE9554 7px; border-radius: 3px; size:1px ; padding:0.1em;">
<p><span></p>
<p style="margin-left:10em;">
<ul>
<li><p><strong>Más artículos: <span class="math inline">\(\hspace{0.1cm}\)</span> <a href="https://estadistica4all.com/">Estadistica4all</a></strong></p></li>
<li><p><strong>Autor:</strong> <span class="math inline">\(\hspace{0.1cm}\)</span> <a href="https://estadistica4all.com/creador.html">Fabio Scielzo Ortiz</a></p></li>
<li><p><strong>Si utilizas este artículo, por favor, cítalo:</strong></p></li>
</ul>
<p><span class="math inline">\(\hspace{1.5cm}\)</span> Scielzo Ortiz, F. (2022). Algoritmos de validación cruzada. Estadistica4all.</p>
</p>
</p>
<p></span></p>
</div>
<p><br></p>
<p><strong><em>Se recomienda abrir el artículo en un ordenador, en una tablet o en un móvil en versión de escritorio.</em></strong></p>
<p><br></p>
<p>Los algoritmos de validación son una familia muy importante de algoritmos dentro del aprendizaje estadístico o machine learning que permiten evaluar la capacidad predictiva de un modelo predictivo.</p>
<p>Distinguiremos dos tipos de algoritmos de validación de modelos:</p>
<ul>
<li><p>Métodos de validación de modelos de <strong>aprendizaje supervisado</strong> <span class="math inline">\(\hspace{0.3cm} \Rightarrow\hspace{0.3cm}\)</span> son algoritmos que permiten evaluar modelos de aprendizaje supervisado usando <strong>muestras de test y train de los predictores y la respuesta</strong>, y una <strong>métrica de evaluación</strong>.</p></li>
<li><p>Métodos de evaluación de modelos de <strong>aprendizaje no supervisado</strong> <span class="math inline">\(\hspace{0.3cm}\Rightarrow\hspace{0.3cm}\)</span> son algoritmos que permiten evaluar modelos de aprendizaje no supervisado usando una <strong>muestra de train de los predictores</strong> y una <strong>métrica de evaluación</strong>.</p></li>
</ul>
<p><strong>Observación:</strong></p>
<p>Los métodos de validación de modelos de <strong>aprendizaje supervisado</strong>
también son llamados <strong>métodos de validación cruzada</strong>. Aunque realmente son mucho más conocidos por su nombre en inglés: <strong>cross validation</strong></p>
<p><br></p>
<p><strong>¿Por qué no se aplican los mismos métodos de validación a los modelos de aprendizaje supervisado y no supervisado?</strong></p>
<p>Debido a que tienen unas características diferentes, en particular, en el aprendizaje supervisado se tienen datos de la variable respuesta, mientras que en el no supervisado no se dispone de información alguna.</p>
<p>Si se quiere ver un planteamiento algo más detallado de los problemas de aprendizaje supervisado y no supervisado se recomienda leer el artículo sobre ese tema que tenemos en <a href="https://estadistica4all.com/">Estadistica4all</a>
<br></p>
<p>Los métodos de evaluación son usados para dos propósitos, principalmente:</p>
<ul>
<li><p>Para <strong>seleccionar</strong> modelos.</p></li>
<li><p>Para <strong>optimizar hiper-parametros</strong> de modelos.</p></li>
</ul>
<p>En otros artículos estudiaremos métodos para selección de modelos y ajuste de hiper-parámetros.</p>
<p><br></p>
<p>En este articulo vamos a estudiar los <strong>métodos de validación de modelos de aprendizaje supervisado</strong>. Los métodos de validación de modelos de aprendizaje no supervisado serán estudiados en otro artículo.</p>
<p>Por lo que consideraremos que <span class="math inline">\(\hspace{0.01cm} M \hspace{0.01cm}\)</span> representa un <strong>modelo o algoritmo de aprendizaje supervisado</strong>, como por ejemplo el modelo de regresión lineal, regresión logistica, regresión no lineal, regresión lineal penalizada, arboles de regresión y clasificación, KNN , SVM, redes neuronales …</p>
<p>Notese que en este articulo no se consideran modelos estadísticos predictivos no supervisados como son los modelos de clustering como K-medias, K-medoids, modelos jerarquicos, modelos basados en densidades …</p>
<p>Nos interesa tener un método a través del cual pueda evaluarse la capacidad o poder predictivo del modelo de aprendizaje supervisado <span class="math inline">\(\hspace{0.01cm}M\hspace{0.01cm}\)</span>.</p>
<p>Una aproximación naive es evaluar el poder predictivo del modelo usando dos elementos. Por un lado los datos disponibles de la variable respuesta, y por otro las predicciones que el modelo hace para los datos de los predcitores con los que el modelo ha sido entrenado.</p>
<p>La idea sería comparar los valores reales de la respuesta con los predichos por el modelo, usando alguna métrica.</p>
<p>Esta aproximación tiende a infra-estimar el error de predicción real del modelo, ya que se está prediciendo la respuesta para observaciones de los predictores que ya han sido “vistas” por el modelo, por ello el rendimiento del modelo al predecir la respuesta para estas observaciones tiende a ser mejor que si fueran observaciones con las que el modelo no ha sido entrenado (observaciones que no ha “visto” aún).</p>
<p>Los métodos de validación de modelos predictivos <strong>supervisados</strong> tiene tres elementos:</p>
<ul>
<li><p>Muestras de <strong>train</strong> y <strong>test</strong> de los predictores y la respuesta.</p></li>
<li><p>Una <strong>métrica de evaluación</strong>.</p></li>
<li><p>Un <strong>algoritmo</strong> para <strong>evaluar el modelo</strong> que usa los anteriores dos elementos de algún modo.</p></li>
</ul>
<p>Este artículo es básicamente un tour teórico-práctico sobre estos elementos.</p>
<p><br></p>
</div>
<div id="muestras-y-predicciones-de-de-train-y-test" class="section level1 hasAnchor" number="2">
<h1 class="hasAnchor"><span class="header-section-number">2</span> Muestras y predicciones de de train y test<a href="#muestras-y-predicciones-de-de-train-y-test" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>En esta sección vamos a fijar algunos conceptos y notación que serán usados en las siguientes secciones.</p>
<div class="warning" style="background-color:#F7EBE8; color: #030000; border-left: solid #CA0B0B 7px; border-radius: 3px; size:1px ; padding:0.1em;">
<p><span></p>
<p style="margin-left:1em;">
<ul>
<li><p>Tenemos una muestra de <span class="math inline">\(N\)</span> observaciones de <span class="math inline">\(p\)</span> predictores <span class="math inline">\(\mathcal{X}_1,...,\mathcal{X}_p\)</span> y de una variable respuesta <span class="math inline">\(\mathcal{Y}\)</span> :</p>
<p><span class="math display">\[D=[\hspace{0.1cm} X_1,...,X_p,Y \hspace{0.1cm}]=\begin{pmatrix}
  x_{11}&amp;x_{12}&amp;...&amp;x_{1p}&amp; y_1\\
  x_{21}&amp;x_{22}&amp;...&amp;x_{2p} &amp; y_2\\
  ...&amp;...&amp;...&amp;...\\
  x_{N1}&amp;x_{N2}&amp;...&amp;x_{Np}&amp; y_N
  \end{pmatrix} = \begin{pmatrix}
  x_{1}&amp; y_1\\
  x_{2}&amp; y_2\\
  ...&amp;...\\
  x_{N}&amp; y_N
  \end{pmatrix} \\\]</span></p></li>
</ul>
</p>
</p>
<p></span></p>
</div>
<p><br></p>
<p>Sin entrar aquí en particularidades, para evaluar un modelo de aprendizaje supervisado <span class="math inline">\(M\)</span> este tiene que ser entrenado con un subconjunto de <span class="math inline">\(n\)</span> filas de <span class="math inline">\(D\)</span> , llamado <strong>muestra de entrenamiento</strong> o de <strong>train</strong> <span class="math inline">\(D_{train}\)</span>, y testado con el subconjunto de las <span class="math inline">\(h\)</span> filas restantes de <span class="math inline">\(D\)</span>, llamado <strong>muestra de test</strong> <span class="math inline">\(D_{test}\)</span> , de modo que <span class="math inline">\(n+h=N\)</span></p>
<p>Los métodos de validación típicos usan de algún modo <span class="math inline">\(D_{train}\)</span> y <span class="math inline">\(D_{test}\)</span> , junto con una <strong>métrica de evaluación</strong>, es por ello que vamos a definir estos elementos con mas precisión a continuación.</p>
<p><br></p>
<div id="train-set" class="section level2 hasAnchor" number="2.1">
<h2 class="hasAnchor"><span class="header-section-number">2.1</span> Train-set<a href="#train-set" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Los elementos antes mencionados se definen formalmente como sigue:</p>
<div class="warning" style="background-color:#F7EBE8; color: #030000; border-left: solid #CA0B0B 7px; border-radius: 3px; size:1px ; padding:0.1em;">
<p><span></p>
<p style="margin-left:1em;">
<ul>
<li><strong>Muestra train</strong> de <span class="math inline">\(n\)</span> observaciones del predictor <span class="math inline">\(\mathcal{X}_j\)</span> :</li>
</ul>
<p><span class="math display">\[X_j^{train} \hspace{0.1cm}=\hspace{0.1cm} (\hspace{0.1cm} x_{1j}^{train},...,x_{nj}^{train}\hspace{0.1cm} )^t \hspace{0.3cm} , \hspace{0.3cm} j\in \lbrace 1,...,p \rbrace \\[0.4cm]\]</span></p>
<ul>
<li><strong>Muestra train</strong> de <span class="math inline">\(n\)</span> observaciones de la respuesta <span class="math inline">\(\mathcal{Y}\)</span> :</li>
</ul>
<p><span class="math display">\[Y^{train} \hspace{0.1cm}=\hspace{0.1cm} \left(\hspace{0.1cm}y_{1}^{train},...,y_n^{train}\hspace{0.1cm}\right)^t \\[0.4cm]\]</span></p>
<ul>
<li><strong>Train-set</strong> :</li>
</ul>
<p><span class="math display">\[D_{train}\hspace{0.1cm}=\hspace{0.1cm}[\hspace{0.1cm}X_1^{train}\hspace{0.03cm},...,\hspace{0.03cm}X_p^{train} \hspace{0.03cm},\hspace{0.03cm} Y^{train}\hspace{0.1cm}]\hspace{0.1cm} = \hspace{0.1cm}  \begin{pmatrix}
    x_{11}^{train} &amp;...&amp;x_{1p}^{train}&amp; y_1^{train}\\
    x_{21}^{train}&amp;...&amp;x_{2p}^{train} &amp; y_2^{train}\\
    &amp;...&amp;\\
    x_{n1}^{train}&amp;...&amp;x_{np}^{train}&amp; y_n^{train}
    \end{pmatrix}= \begin{pmatrix}
    x_{1}^{train}&amp; y_1^{train}\\
    x_{2}^{train}&amp; y_2^{train}\\
    ...&amp;...\\
    x_{n}^{train}&amp; y_n^{train}
    \end{pmatrix} \\\]</span></p>
</p>
</p>
<p></span></p>
</div>
<p><br></p>
<p><strong>Observaciones:</strong></p>
<ul>
<li><p>La fila <span class="math inline">\(i\)</span> de <span class="math inline">\(D_{train}\)</span> , es decir, <span class="math inline">\(\left(x_i^{train},y_i^{train}\right) = \left(x_{i1}^{train}, x_{i2}^{train},...,x_{ip}^{train}, y_i^{train}\right)\hspace{0.1cm}\)</span>, es la <span class="math inline">\(\hspace{0.1cm}i\)</span>-esima <strong>observación de train</strong> de los predictores y la respuesta <span class="math inline">\(\hspace{0.1cm}\mathcal{X}_1,...,\mathcal{X}_p \hspace{0.1cm},\hspace{0.1cm} \mathcal{Y}\)</span>.</p></li>
<li><p><span class="math inline">\(D_{train}\)</span> también es llamada simplemente <strong>observaciones de train</strong> de <span class="math inline">\(\mathcal{X}_1,...,\mathcal{X}_p\hspace{0.1cm},\hspace{0.1cm} \mathcal{Y}\)</span>.</p></li>
</ul>
<p><br></p>
</div>
<div id="predicciones-de-train" class="section level2 hasAnchor" number="2.2">
<h2 class="hasAnchor"><span class="header-section-number">2.2</span> Predicciones de train<a href="#predicciones-de-train" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Como <span class="math inline">\(M\)</span> es un modelo de aprendizaje supervisado es capaz de, una vez es entrenado con las observaciones de <span class="math inline">\(D_{train}=[X_1^{train},...,X_p^{train}, Y^{train}]\)</span> , generar predicciones de la variable respuesta <span class="math inline">\(\mathcal{Y}\)</span>, tanto para las <strong>observaciones de train</strong> de los predictores como para <strong>nuevas observaciones</strong>.</p>
<p>Notese que <span class="math inline">\(M\)</span> nos interesa realmente para predecir la variable respuesta para <strong>nuevas observaciones</strong> de los predictores, es decir, para predecir la respuesta para individuos/elementos de los que solo tenemos información de los predictores.</p>
<p><br></p>
<div class="warning" style="background-color:#F7EBE8; color: #030000; border-left: solid #CA0B0B 7px; border-radius: 3px; size:1px ; padding:0.1em;">
<p><span></p>
<p style="margin-left:1em;">
<ul>
<li>Las <strong>predicciones de train</strong> de la respuesta <span class="math inline">\(\hspace{0.1cm}\mathcal{Y}\hspace{0.1cm}\)</span> , son obtenidas aplicando el modelo de aprendizaje supervisado ya <strong>entrenado</strong> a las <strong>observaciones de train</strong> de los <strong>predictores</strong>:</li>
</ul>
<p><span class="math display">\[\widehat{Y}^{\hspace{0.1cm} train} \hspace{0.1cm} = \hspace{0.1cm}  M\left(\hspace{0.1cm} X_1^{train},...,X_p^{train} \hspace{0.2cm}|\hspace{0.2cm} X_1^{train},...,X_p^{train}, Y^{train} \hspace{0.1cm}\right)\]</span></p>
</p>
</p>
<p></span></p>
</div>
<p><br></p>
<p><strong>Observaciones:</strong></p>
<ul>
<li><p>Aqui <span class="math inline">\(M( z \hspace{0.1cm}|\hspace{0.1cm} w)\)</span> representa una función de dos argumentos, el argumento posterior a <span class="math inline">\(\hspace{0.1cm}|\hspace{0.1cm}\)</span> , es decir <span class="math inline">\(w\)</span>, son los datos de predictores y respuestas con los que se entrena el modelo de aprendizaje supervisado <span class="math inline">\(M\)</span> , y el argumento previo a <span class="math inline">\(\hspace{0.1cm}|\hspace{0.1cm}\)</span> , es decir <span class="math inline">\(z\)</span>, son los datos de los predictores que el modelo <span class="math inline">\(M\)</span> usa para generar predicciones de la variable respuesta. Y devuelve un vector con esas predicciones de la respuesta.</p></li>
<li><p><span class="math inline">\(\widehat{\hspace{0.01cm} Y}^{\hspace{0.08cm} train}\hspace{0.1cm}=\hspace{0.1cm}(\hat{y}_1^{train},..., \hat{y}_n^{train})^t\hspace{0.15cm}\)</span> es un vector con las predicciones de la respuesta hechas por el modelo entrenado <span class="math inline">\(\hspace{0.08cm}M\hspace{0.1cm}\)</span> para la muestra train de observaciones de los predictores <span class="math inline">\(\hspace{0.1cm}(X_1^{train},...,X_p^{train}) \\\)</span></p></li>
<li><p><span class="math inline">\(\widehat{y}_i^{train} = M(\hspace{0.1cm} x_i^{train} \hspace{0.15cm}|\hspace{0.15cm} X_1^{train},...,X_p^{train}, Y^{train} \hspace{0.1cm}) = M(\hspace{0.1cm}x_{i1}^{train},...,x_{ip}^{train} \hspace{0.15cm}|\hspace{0.15cm} X_1^{train},...,X_p^{train}, Y^{train}\hspace{0.1cm})\hspace{0.1cm}\)</span> es la predicción de la variable respuesta generada por el modelo entrenado <span class="math inline">\(M\)</span> para la observación de train de los predictores <span class="math inline">\(x_i^{train}=(x_{i1}^{train},...,x_{ip}^{train})\)</span>.</p></li>
</ul>
<p><br></p>
</div>
<div id="test-set" class="section level2 hasAnchor" number="2.3">
<h2 class="hasAnchor"><span class="header-section-number">2.3</span> Test-set<a href="#test-set" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div class="warning" style="background-color:#F7EBE8; color: #030000; border-left: solid #CA0B0B 7px; border-radius: 3px; size:1px ; padding:0.1em;">
<p><span></p>
<p style="margin-left:1em;">
<ul>
<li><strong>Muestra test</strong> de <span class="math inline">\(\hspace{0.08cm}h\hspace{0.08cm}\)</span> observaciones del predictor <span class="math inline">\(\mathcal{X}_j\)</span>:</li>
</ul>
<p><span class="math display">\[X_j^{test}=\left(x^{test}_{1j},...,x^{test}_{hj} \right)^t  \hspace{0.3cm} , \hspace{0.3cm} \forall j=1,...,p\\[0.4cm]\]</span></p>
<ul>
<li><strong>Muestra test</strong> de <span class="math inline">\(\hspace{0.1cm}h\hspace{0.1cm}\)</span> observaciones de la respuesta <span class="math inline">\(\mathcal{Y}\)</span>:</li>
</ul>
<p><span class="math display">\[Y^{test}=\left(y^{test}_{1},...,y^{test}_{h} \right)^t  \hspace{0.3cm} , \hspace{0.3cm} \forall j=1,...,p \\[0.4cm]\]</span></p>
<ul>
<li><strong>Test-set</strong> :</li>
</ul>
<p><span class="math display">\[D_{test}  \hspace{0.1cm}=\hspace{0.1cm} [\hspace{0.1cm}X_1^{test},...,X_p^{test}, Y^{test}\hspace{0.1cm}] \hspace{0.1cm}=\hspace{0.1cm} \begin{pmatrix}
    x^{test}_{11}&amp;x^{test}_{12}&amp;...&amp;x^{test}_{1p} &amp; y^{test}_1\\
    x^{test}_{21}&amp;x^{test}_{22}&amp;...&amp;x^{test}_{2p} &amp; y^{test}_2\\
    &amp;...&amp;\\
    x^{test}_{h1}&amp;x^{test}_{h2}&amp;...&amp;x^{test}_{hp} &amp; y^{test}_h
    \end{pmatrix}= \begin{pmatrix}
    x_{1}^{test}&amp; y_1^{test}\\
    x_{2}^{test}&amp; y_2^{test}\\
    ...&amp;...\\
    x_{h}^{test}&amp; y_h^{test}
    \end{pmatrix}\]</span></p>
</p>
</p>
<p></span></p>
</div>
<p><br></p>
<p><strong>Observaciones:</strong></p>
<ul>
<li><p>La fila <span class="math inline">\(i\)</span> de <span class="math inline">\(D_{test}\)</span> , es decir, <span class="math inline">\((x_i^{test},y_i^{test})= (x^{test}_{i1}, x^{test}_{i2},...,x^{test}_{ip}, y_i^{test})\)</span>, es la <span class="math inline">\(i\)</span>-esima <strong>observación de test</strong> de los predictores y la respuesta <span class="math inline">\(\mathcal{X}_1,...,\mathcal{X}_p\hspace{0.08cm},\hspace{0.08cm} \mathcal{Y}\)</span>.</p></li>
<li><p><span class="math inline">\(D_{test}\)</span> también es llamada simplemente <strong>observaciones de test</strong> de <span class="math inline">\(\mathcal{X}_1,...,\mathcal{X}_p, \mathcal{Y}\)</span>.</p></li>
</ul>
<p><br></p>
</div>
<div id="predicciones-de-test" class="section level2 hasAnchor" number="2.4">
<h2 class="hasAnchor"><span class="header-section-number">2.4</span> Predicciones de test<a href="#predicciones-de-test" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Puesto que <span class="math inline">\(M\)</span> es un modelo predictivo supervisado es capaz de, una vez es entrenado con las observaciones de <span class="math inline">\(D_{train}=[X_1^{train},...,X_p^{train}, Y^{train}]\)</span> , generar predicciones de la respuesta <span class="math inline">\(\mathcal{Y}\)</span> , tanto para las <strong>observaciones de train</strong> como para <strong>nuevas observaciones</strong> de los predictores <span class="math inline">\(\mathcal{X}_1,...,\mathcal{X}_p\)</span> .</p>
<p>Notese, de nuevo, que <span class="math inline">\(M\)</span> nos interesa realmente para predecir la respuesta para <strong>nuevas observaciones</strong> de los predictores, es decir, para predecir la respuesta para individuos/elementos de los que tenemos información sobre los predictores pero no sobre la respuesta.</p>
<p><br></p>
<div class="warning" style="background-color:#F7EBE8; color: #030000; border-left: solid #CA0B0B 7px; border-radius: 3px; size:1px ; padding:0.1em;">
<p><span></p>
<p style="margin-left:1em;">
<ul>
<li>Las <strong>predicciones de test</strong> de la respuesta <span class="math inline">\(\mathcal{Y}\)</span> , son obtenidas aplicando el <strong>modelo</strong> predictivo <strong>entrenado</strong> a las observaciones de <strong>test</strong>:</li>
</ul>
<span class="math display">\[\widehat{Y}\hspace{0.08cm}^{test} \hspace{0.1cm} = \hspace{0.1cm} M\left(\hspace{0.1cm} X_1^{test},...,X_p^{test} \hspace{0.2cm}|\hspace{0.2cm} X_1^{train},...,X_p^{train}, Y^{train} \hspace{0.1cm}\right)\]</span>
</p>
</p>
<p></span></p>
</div>
<p><br></p>
<p><strong>Observaciones:</strong></p>
<ul>
<li><p>Aqui <span class="math inline">\(M( z \hspace{0.1cm}|\hspace{0.1cm} w)\)</span> representa una función de dos argumentos, el argumento posterior a <span class="math inline">\(\hspace{0.1cm}|\hspace{0.1cm}\)</span> , es decir <span class="math inline">\(w\)</span>, son los datos de predictores y respuestas con los que se entrena el modelo <span class="math inline">\(M\)</span> , y el argumento previo a <span class="math inline">\(\hspace{0.1cm}|\hspace{0.1cm}\)</span> , es decir <span class="math inline">\(z\)</span>, son los datos de los predictores que el modelo <span class="math inline">\(M\)</span> usa para generar predicciones de la respuesta. Y devuelve un vector con esas predicciones de la respuesta.</p></li>
<li><p><span class="math inline">\(\widehat{\hspace{0.02cm}Y}^{\hspace{0.1cm}test}= (\hat{y}_1^{\hspace{0.08cm}test},..., \hat{y}_h^{\hspace{0.1cm}test})^t\)</span> es un vector con las predicciones de la respuesta hechas por el modelo entrenado <span class="math inline">\(M\)</span> usando la <strong>muestra test</strong> de observaciones de los predictores <span class="math inline">\(X_1^{test},...,X_p^{test}\)</span>.</p></li>
<li><p><span class="math inline">\(\hat{y}_i^{test} = M \left(\hspace{0.1cm} x_i^{test} \hspace{0.15cm}|\hspace{0.15cm} X_1^{train},...,X_p^{train}, Y^{train}\hspace{0.1cm} \right) = M\left( \hspace{0.08cm} x^{test}_{i1},...,x^{test}_{ip} \hspace{0.15cm}|\hspace{0.15cm} X_1^{train},...,X_p^{train}, Y^{train}\right)\)</span> es la predicción de la respuesta que el modelo entrenado <span class="math inline">\(M\)</span> genera para la observación de test de los predictores <span class="math inline">\(x_i^{test}=(x^{test}_{i1},...,x^{test}_{ip})\)</span> .</p></li>
</ul>
<p><br></p>
<p>Teniendo todo lo anterior en cuenta, la evaluación de los modelos de aprendizaje supervisado <span class="math inline">\(M\)</span> se realiza, sin entrar en particularidades, comparando las <strong>predicciones de test</strong> de la variable respuesta generadas por el modelo <span class="math inline">\(M\)</span>, es decir, <span class="math inline">\(\widehat{\hspace{0.02cm}Y}^{\hspace{0.08cm}test}\)</span>, con la muestra de <strong>observaciones test</strong> de la respuesta, <span class="math inline">\(Y^{test}\)</span></p>
<p>La muestra test juega el rol de muestra de nuevas observaciones. Y el modelo <span class="math inline">\(M\)</span> interesa para predecir nuevas observaciones.</p>
<p>Por ello se utiliza la muestra test como muestra para evaluar el rendimiento del modelo al predecir la respuesta para nuevas observaciones de los predictores.</p>
<p><br></p>
</div>
</div>
<div id="métricas-para-evaluar-modelos-de-regresión" class="section level1 hasAnchor" number="3">
<h1 class="hasAnchor"><span class="header-section-number">3</span> Métricas para evaluar modelos de regresión<a href="#métricas-para-evaluar-modelos-de-regresión" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>Dado un modelo de regresión <span class="math inline">\(M\)</span> , existen varias métricas para evaluar la capacidad predictiva del modelo. Cada una de estas métricas tienen una versión de train (son calculadas usando las predicciones de train) y otra de test (son calculadas usando las predicciones de test).</p>
<p>Se recomienda al lector haber leido previamente el articulo sobre <strong>los problemas de regresión y clasificación supervisada y no supervisada</strong>.</p>
<p>A continuación vamos a exponer las métricas de evaluación más habituales para <strong>modelos de regresión</strong>:</p>
<div id="error-cuadrático-medio-ecm" class="section level2 hasAnchor" number="3.1">
<h2 class="hasAnchor"><span class="header-section-number">3.1</span> Error cuadrático medio (ECM)<a href="#error-cuadrático-medio-ecm" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div class="warning" style="background-color:#F7EBE8; color: #030000; border-left: solid #CA0B0B 7px; border-radius: 3px; size:1px ; padding:0.1em;">
<p><span></p>
<p style="margin-left:1em;">
<ul>
<li><strong>ECM de train</strong>:</li>
</ul>
<p><span class="math display">\[ECM(M)_{train} \hspace{0.15cm}=\hspace{0.15cm} \dfrac{1}{n} \cdot \sum_{i=1}^n \hspace{0.1cm} (\hspace{0.08cm} y_i^{\hspace{0.08cm}train} - \hat{y}_i^{\hspace{0.08cm}train} \hspace{0.08cm} )^2 \\\]</span></p>
</p>
</p>
<p></span></p>
</div>
<p><br></p>
<p>Donde:</p>
<ul>
<li><p><span class="math inline">\(y_i^{test}\)</span> es la <strong>observación de test</strong> <span class="math inline">\(i\)</span>-esima de la variable respuesta, es decir, <span class="math inline">\(y_i^{test} \hspace{0.1cm}=\hspace{0.1cm} Y^{test}[\hspace{0.1cm} i\hspace{0.1cm}]\)</span>.</p></li>
<li><p><span class="math inline">\(\hat{y}_i^{test} \hspace{0.1cm}=\hspace{0.1cm} M\left(\hspace{0.1cm} x_i^{test} \hspace{0.2cm}|\hspace{0.2cm} X_1^{train},...,X_p^{train}, Y^{train}\hspace{0.1cm} \right)\)</span>.</p></li>
<li><p><span class="math inline">\(n \hspace{0.1cm}=\hspace{0.1cm} \# \hspace{0.1cm} Y^{train}\)</span>.</p></li>
</ul>
<p><br></p>
<div class="warning" style="background-color:#F7EBE8; color: #030000; border-left: solid #CA0B0B 7px; border-radius: 3px; size:1px ; padding:0.1em;">
<p><span></p>
<p style="margin-left:1em;">
<ul>
<li><strong>ECM de test</strong></li>
</ul>
<p><span class="math display">\[ECM(M)_{test} \hspace{0.15cm} =\hspace{0.15cm} \dfrac{1}{h} \cdot \sum_{i=1}^h \hspace{0.1cm} (\hspace{0.1cm} y_i^{\hspace{0.1cm}test} - \hat{y}_i^{\hspace{0.1cm}test} \hspace{0.1cm} )^2\]</span></p>
</p>
</p>
<p></span></p>
</div>
<p><br></p>
<p>Donde:</p>
<ul>
<li><p><span class="math inline">\(y_i^{test}\hspace{0.1cm}\)</span> es la observación de test <span class="math inline">\(\hspace{0.1cm}i\)</span>-esima de la variable respuesta, es decir, <span class="math inline">\(\hspace{0.15cm}y_i^{test} \hspace{0.1cm}=\hspace{0.1cm} Y^{test}[\hspace{0.1cm} i \hspace{0.1cm}]\)</span>.</p></li>
<li><p><span class="math inline">\(\hat{y}_i^{test} \hspace{0.1cm}=\hspace{0.1cm} M\left(\hspace{0.1cm} x_i^{test} \hspace{0.15cm}|\hspace{0.15cm} X_1^{train},...,X_p^{train}, Y^{train} \hspace{0.1cm} \right)\)</span>.</p></li>
<li><p><span class="math inline">\(h\hspace{0.1cm}=\hspace{0.1cm}\# \hspace{0.1cm} Y^{test}\)</span></p></li>
</ul>
<p><br></p>
<p><strong>Observación:</strong></p>
<p>El <span class="math inline">\(\hspace{0.08cm} ECM\hspace{0.08cm}\)</span> tiene se mide en la unidad de medida que la respuesta <strong>al cuadrado</strong>.</p>
<p><strong>Interpretación:</strong></p>
<p>Cuanto menor sea <span class="math inline">\(\hspace{0.08cm}ECM(M)_{test}\hspace{0.08cm}\)</span> , mayor capacidad predictiva del modelo <span class="math inline">\(\hspace{0.08cm}M\hspace{0.08cm}\)</span>, y a la inversa.</p>
<p><strong>¿Por qué el ECM es tan usado en la práctica?</strong></p>
<p>Teóricamente puede demostraste que en un modelo de regresión el error cuadrático medio de la predicción puede descomponerse como sigue:</p>
<p><span class="math display">\[ECM(\hspace{0.08cm}\widehat{\mathcal{Y}}\hspace{0.08cm}) = E\hspace{0.1cm}[\hspace{0.1cm}(\mathcal{Y} - \widehat{\mathcal{Y}})^2\hspace{0.1cm}]\hspace{0.1cm} =\hspace{0.1cm} Var(\hspace{0.08cm}\widehat{\mathcal{Y}}\hspace{0.08cm}) \hspace{0.1cm}+\hspace{0.1cm} Sesgo(\hspace{0.08cm}\widehat{\mathcal{Y}}\hspace{0.08cm})^2 \hspace{0.1cm}+\hspace{0.1cm} \sigma_{\varepsilon}^2 \\\]</span></p>
<p>Donde:</p>
<ul>
<li><p><span class="math inline">\(Var(\hspace{0.08cm}\widehat{\mathcal{Y}}\hspace{0.08cm})\hspace{0.1cm} =\hspace{0.1cm} E[\hspace{0.1cm}(\hspace{0.08cm}\widehat{\mathcal{Y}} - E[\hspace{0.08cm}\widehat{\mathcal{Y}}\hspace{0.08cm}]\hspace{0.08cm})^2\hspace{0.1cm}]\hspace{0.1cm}\)</span> es la varianza de las predicciones del modelo.</p></li>
<li><p><span class="math inline">\(Sesgo(\hspace{0.08cm}\widehat{\mathcal{Y}}\hspace{0.08cm})\hspace{0.1cm}=\hspace{0.1cm}E[\hspace{0.08cm}\hspace{0.1cm}\widehat{\mathcal{Y}}\hspace{0.1cm}] \hspace{0.1cm}-\hspace{0.1cm} \mathcal{Y}\hspace{0.15cm}\)</span> es el sesgo de las predicciones del modelo.</p></li>
<li><p><span class="math inline">\(\sigma_{\varepsilon}^2\hspace{0.1cm}\)</span> es la varianza del ruido aleatorio o perturbación del modelo.</p></li>
</ul>
<p>Por tanto, en un modelo de regresion, el ECM del estimador de la respuesta puede descomponerse como la suma de la varianza y sesgo al cuadrado de dicho estimador de la respuesta, y tambien de la varianza del ruido aleatorio del modelo.</p>
<p>Los dos primeros terminos (varianza y sesgo del estimador de la respuesta) pueden se reducidos, en función del modelo utilizado. En cambio el tercer componente (la varianza del ruido) es irreducible, no depende del modelo.</p>
<p>Esta propiedad del ECM es una de las razones por las que es tan usado, ya que nos da información sobre el ratio varianza-sego de las predicciones de un modelo.</p>
<p>Un modelo con baja varianza y sesgo en sus predicciones tendra bajo ECM.</p>
<p>Un modelo con alta varianza o alto sesgo en sus predicciones tendra alto ECM.</p>
<p>Los modelos con menor ECM de entre una colección de modelos serán aquellos con un mayor equilibrio en el ratio varianza-sesgo en sus predicciones.</p>
<p>Un modelo con mucha varianza en sus predicciones es un modelo cuyas predicciones sobre la respuesta varian mucho de una muestra de train a otra. Es decir, al ser entrenado con múltiples muestras, las predicciones que el modelo hace de la respuesta usando una determinada muestra fija de test varían mucho de un modelo entrenado a otro. En un modelo con poca varianza en sus predicciones ocurre al revés, la precisión de sus predicciones es alta en el sentido de que varian poco en funcion de la muestra de train empleada. Otra cuestión es si estas predicciones son mas o menos acertadas (esto tiene que ver mas con el sesgo).</p>
<p>Un modelo con mucho sesgo en sus predicciones es un modelo cuyas predicciones sobre la respuesta están en media muy lejos de los verdaderos valores de la respuesta. Es decir, si el modelo es entrenado con múltiples muestras de train y se predice la respuesta para una muestra fija de test, la media de las predicciones de la respuesta obtenidas con cada uno de los modelos entrenados aleja bastante de la verdadera respuesta.
En cambio un modelo con bajo sesgo genera predicciones que en media son bastante acertadas. Es decir, si se entrena el modelo con múltiples muestras de train y se predice la respuesta usando una muestra fija de test, la media de esas predicciones obtenidas con cada uno de los modelos entrenados es bastante cercana a la respuesta real.</p>
<p><br></p>
</div>
<div id="raiz-del-error-cuadrático-medio-recm" class="section level2 hasAnchor" number="3.2">
<h2 class="hasAnchor"><span class="header-section-number">3.2</span> Raiz del error cuadrático medio (RECM)<a href="#raiz-del-error-cuadrático-medio-recm" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div class="warning" style="background-color:#F7EBE8; color: #030000; border-left: solid #CA0B0B 7px; border-radius: 3px; size:1px ; padding:0.1em;">
<p><span></p>
<p style="margin-left:1em;">
<ul>
<li><strong>RECM de train:</strong></li>
</ul>
<p><span class="math display">\[RECM(M)_{train} \hspace{0.08cm}=\hspace{0.08cm} \sqrt{\dfrac{1}{n} \cdot \sum_{i=1}^n \hspace{0.1cm} (y_i^{train} - \hat{y}_i^{train})^2 \hspace{0.2cm}} \\\]</span></p>
<ul>
<li><strong>RECM de test:</strong></li>
</ul>
<p><span class="math display">\[RECM(M)_{test} \hspace{0.08cm}=\hspace{0.08cm} \sqrt{ \dfrac{1}{h} \cdot \sum_{i=1}^h \hspace{0.1cm} (\hspace{0.1cm} y_i^{\hspace{0.1cm} test} - \hat{y}_{i} ^{\hspace{0.1cm} test} \hspace{0.1cm} )^2 \hspace{0.2cm}} \\[0.2cm]\]</span></p>
</p>
</p>
<p></span></p>
</div>
<p><br></p>
<p><strong>Observación:</strong></p>
<p>El <span class="math inline">\(\hspace{0.08cm}RECM\hspace{0.08cm}\)</span> tiene la misma unidad de medida que la respuesta.</p>
<p><strong>Interpretación:</strong></p>
<p>Cuanto menor sea <span class="math inline">\(\hspace{0.08cm}RECM(M)_{test}\hspace{0.08cm}\)</span> , mayor bondad predictiva del modelo <span class="math inline">\(\hspace{0.08cm}M\hspace{0.08cm}\)</span>, y a la inversa.</p>
<p><br></p>
</div>
<div id="error-cuadratico-relativo-ecr" class="section level2 hasAnchor" number="3.3">
<h2 class="hasAnchor"><span class="header-section-number">3.3</span> Error cuadratico relativo (ECR)<a href="#error-cuadratico-relativo-ecr" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div class="warning" style="background-color:#F7EBE8; color: #030000; border-left: solid #CA0B0B 7px; border-radius: 3px; size:1px ; padding:0.1em;">
<p><span></p>
<p style="margin-left:1em;">
<ul>
<li><strong>ECR de train:</strong></li>
</ul>
<p><span class="math display">\[ECR(M)_{train} \hspace{0.1cm}=\hspace{0.1cm} \dfrac{\hspace{0.5cm} \sum_{i=1}^n \hspace{0.1cm} ( y_i^{train}- \hat{y}_i^{train} )^2 \hspace{0.5cm}}{\sum_{i=1}^n ( y_i^{train} - \overline{Y \hspace{0.1cm}}^{\hspace{0.1cm} train} )^2 }  \\\]</span></p>
<ul>
<li><strong>ECR de test:</strong></li>
</ul>
<p><span class="math display">\[ECR(M)_{test} \hspace{0.1cm}=\hspace{0.1cm} \dfrac{ \hspace{0.5cm} \sum_{i=1}^h \hspace{0.1cm} (\hspace{0.1cm} y_i^{\hspace{0.1cm} test} - \hat{y}_i^{\hspace{0.1cm} test} \hspace{0.1cm})^2 \hspace{0.5cm}    }{\sum_{i=1}^h (\hspace{0.1cm} y_i^{\hspace{0.1cm} test} - \overline{Y \hspace{0.1cm}}^{\hspace{0.1cm} test} \hspace{0.1cm} )^2 } \\\]</span></p>
</p>
</p>
<p></span></p>
</div>
<p><strong>Interpretación:</strong></p>
<p>Cuanto menor sea <span class="math inline">\(\hspace{0.08cm}ECR(M)_{test}\hspace{0.08cm}\)</span> , mayor bondad predictiva del modelo <span class="math inline">\(\hspace{0.08cm}M\hspace{0.08cm}\)</span>, y a la inversa.</p>
<p><br></p>
</div>
<div id="coeficiente-de-determinación" class="section level2 hasAnchor" number="3.4">
<h2 class="hasAnchor"><span class="header-section-number">3.4</span> Coeficiente de determinación<a href="#coeficiente-de-determinación" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div class="warning" style="background-color:#F7EBE8; color: #030000; border-left: solid #CA0B0B 7px; border-radius: 3px; size:1px ; padding:0.1em;">
<p><span></p>
<p style="margin-left:1em;">
<ul>
<li><strong>Coeficiente de determinación de train:</strong></li>
</ul>
<p><span class="math display">\[R(M)^2_{train} \hspace{0.1cm}=\hspace{0.1cm} 1 - ECR(M)_{train} \\\]</span></p>
<ul>
<li><strong>Coeficiente de determinación de train:</strong></li>
</ul>
<p><span class="math display">\[R(M)^2_{test} \hspace{0.1cm}=\hspace{0.1cm} 1 - ECR(M)_{test} \\\]</span></p>
</p>
</p>
<p></span></p>
</div>
<p><br></p>
<p><strong>Interpretación:</strong></p>
<p>Cuanto mayor sea <span class="math inline">\(\hspace{0.05cm}R(M)^2_{test}\hspace{0.05cm}\)</span> , mayor bondad predictiva del modelo <span class="math inline">\(\hspace{0.05cm}M\hspace{0.05cm}\)</span>, y a la inversa.</p>
<p><br></p>
</div>
<div id="error-absoluto-medio-eam" class="section level2 hasAnchor" number="3.5">
<h2 class="hasAnchor"><span class="header-section-number">3.5</span> Error absoluto medio (EAM)<a href="#error-absoluto-medio-eam" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div class="warning" style="background-color:#F7EBE8; color: #030000; border-left: solid #CA0B0B 7px; border-radius: 3px; size:1px ; padding:0.1em;">
<p><span></p>
<p style="margin-left:1em;">
<ul>
<li><strong>EAM de train:</strong></li>
</ul>
<p><span class="math display">\[EAM(M)_{train} \hspace{0.1cm}=\hspace{0.1cm} \dfrac{1}{n} \cdot \sum_{i=1}^n \hspace{0.1cm} \left|\hspace{0.1cm} y_i^{train} - \hat{y}_i^{train} \hspace{0.1cm}\right| \\\]</span></p>
<ul>
<li><strong>EAM de test:</strong></li>
</ul>
<p><span class="math display">\[EAM(M)_{test} \hspace{0.1cm}=\hspace{0.1cm} \dfrac{1}{h} \cdot \sum_{i=1}^h \hspace{0.1cm} \left| \hspace{0.1cm} y_i^{\hspace{0.1cm}test} - \hat{y}_i^{\hspace{0.1cm}test} \hspace{0.1cm} \right|\]</span></p>
</p>
</p>
<p></span></p>
</div>
<p><br></p>
</div>
<div id="error-absoluto-relativo-ear" class="section level2 hasAnchor" number="3.6">
<h2 class="hasAnchor"><span class="header-section-number">3.6</span> Error absoluto relativo (EAR)<a href="#error-absoluto-relativo-ear" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div class="warning" style="background-color:#F7EBE8; color: #030000; border-left: solid #CA0B0B 7px; border-radius: 3px; size:1px ; padding:0.1em;">
<p><span></p>
<p style="margin-left:1em;">
<ul>
<li><strong>EAR de train:</strong></li>
</ul>
<p><span class="math display">\[EAR(M)_{train} \hspace{0.1cm}=\hspace{0.1cm} \dfrac{\sum_{i=1}^n \hspace{0.1cm} \left|\hspace{0.1cm} y_i^{train} - \hat{y}_i^{\hspace{0.08cm} train} \hspace{0.1cm} \right| \hspace{0.2cm} }{\sum_{i=1}^n \hspace{0.1cm} \left| \hspace{0.1cm} y_i^{train} - \overline{y}^{train} \hspace{0.1cm} \right| \hspace{0.1cm}}  \\\]</span></p>
<ul>
<li><strong>EAR de test:</strong></li>
</ul>
<p><span class="math display">\[EAR(M)_{test} \hspace{0.1cm}=\hspace{0.1cm} \dfrac{ \sum_{i=1}^h \hspace{0.1cm} \hspace{0.1cm} \left| \hspace{0.1cm} y_i^{\hspace{0.1cm} test} - \hat{y}_i^{\hspace{0.1cm} test} \hspace{0.1cm} \right| \hspace{0.2cm}  }{\sum_{i=1}^h \hspace{0.1cm}\left|\hspace{0.1cm} y_i^{\hspace{0.1cm} test} - \overline{y}^{\hspace{0.1cm} test} \hspace{0.1cm}\right|\hspace{0.1cm}}\]</span></p>
</p>
</p>
<p></span></p>
</div>
<p><br></p>
</div>
</div>
<div id="métricas-para-evaluar-modelos-de-clasificación-supervisada" class="section level1 hasAnchor" number="4">
<h1 class="hasAnchor"><span class="header-section-number">4</span> Métricas para evaluar modelos de clasificación supervisada<a href="#métricas-para-evaluar-modelos-de-clasificación-supervisada" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>A continuación vamos a exponer las métricas de evaluación más habituales para <strong>modelos de clasificación supervisada</strong>:</p>
<div id="tasa-de-acierto-en-la-clasificación-tac" class="section level2 hasAnchor" number="4.1">
<h2 class="hasAnchor"><span class="header-section-number">4.1</span> Tasa de acierto en la clasificación (TAC)<a href="#tasa-de-acierto-en-la-clasificación-tac" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div class="warning" style="background-color:#F7EBE8; color: #030000; border-left: solid #CA0B0B 7px; border-radius: 3px; size:1px ; padding:0.1em;">
<p><span></p>
<p style="margin-left:1em;">
<ul>
<li><strong>TAC de train:</strong></li>
</ul>
<p><span class="math display">\[TAC(M)_{train} \hspace{0.1cm}=\hspace{0.1cm} \dfrac{1}{n} \cdot \sum_{i=1}^{n} \hspace{0.2cm} \mathbf {I} ( \hspace{0.1cm} \hat{y}_i^{train} = y_i^{train} \hspace{0.1cm} )\\\]</span></p>
<ul>
<li><strong>TAC de test:</strong></li>
</ul>
<p><span class="math display">\[TAC(M)_{train} \hspace{0.1cm}=\hspace{0.1cm} \dfrac{1}{n} \cdot \sum_{i=1}^{n} \hspace{0.2cm} \mathbf{I} ( \hspace{0.1cm} \hat{y}_i^{train} = y_i^{train} \hspace{0.1cm})\]</span></p>
</p>
</p>
<p></span></p>
</div>
<p><br></p>
</div>
<div id="tasa-de-error-en-la-clasificación-tec" class="section level2 hasAnchor" number="4.2">
<h2 class="hasAnchor"><span class="header-section-number">4.2</span> Tasa de error en la clasificación (TEC)<a href="#tasa-de-error-en-la-clasificación-tec" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div class="warning" style="background-color:#F7EBE8; color: #030000; border-left: solid #CA0B0B 7px; border-radius: 3px; size:1px ; padding:0.1em;">
<p><span></p>
<p style="margin-left:1em;">
<ul>
<li><strong>TEC de train:</strong></li>
</ul>
<p><span class="math display">\[TEC(M)_{train} \hspace{0.1cm}=\hspace{0.1cm} \dfrac{1}{n} \cdot \sum_{i=1}^{n} \hspace{0.2cm} \mathbf {I} \left( \hspace{0.05cm} \hat{y}_i^{train} \neq y_i^{train} \hspace{0.05cm} \right)\\\]</span></p>
<ul>
<li><strong>TEC de test:</strong></li>
</ul>
<p><span class="math display">\[TEC(M)_{test} \hspace{0.1cm}=\hspace{0.1cm} \dfrac{1}{h} \cdot \sum_{i=1}^{h} \hspace{0.2cm} \mathbf {I} \left( \hspace{0.1cm} \hat{y}_i^{\hspace{0.05cm} test} \neq y_i^{\hspace{0.05cm} test} \hspace{0.1cm}\right)\]</span></p>
</p>
</p>
<p></span></p>
</div>
<p><br></p>
</div>
<div id="kappa" class="section level2 hasAnchor" number="4.3">
<h2 class="hasAnchor"><span class="header-section-number">4.3</span> Kappa<a href="#kappa" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Suponemos que una variable respuesta tiene <span class="math inline">\(\hspace{0.05cm}k \geq 2\hspace{0.05cm}\)</span> categorias</p>
<p>Si usamos un modelo de clasificación basado en la distribución de probabilidad uniforme discreta, este predice cada categoria de la respuesta con igual probabilidad <span class="math inline">\(\hspace{0.05cm}1/k\hspace{0.05cm}\)</span>, por lo que la tasa de acierto del modelo esperada es <span class="math inline">\(\hspace{0.05cm}1/k\)</span>, es decir, si el modelo se aplica muchas veces, la <span class="math inline">\(\hspace{0.08cm} TAC\hspace{0.08cm}\)</span> <strong>media</strong> será de <span class="math inline">\(1/k\)</span>.</p>
<div class="warning" style="background-color:#F7EBE8; color: #030000; border-left: solid #CA0B0B 7px; border-radius: 3px; size:1px ; padding:0.1em;">
<p><span></p>
<p style="margin-left:1em;">
<ul>
<li><strong>Kappa de train:</strong></li>
</ul>
<p><span class="math display">\[Kappa(M)_{\hspace{0.05cm} train} \hspace{0.1cm} = \hspace{0.1cm} \dfrac{\hspace{0.1cm} TAC_{\hspace{0.05cm} train} \hspace{0.1cm}-\hspace{0.1cm} 1/k \hspace{0.1cm}}{1 \hspace{0.1cm} -\hspace{0.1cm} 1/k} \\\]</span></p>
<ul>
<li><strong>Kappa de test:</strong></li>
</ul>
<p><span class="math display">\[Kappa(M)_{\hspace{0.05cm} test} \hspace{0.1cm}=\hspace{0.1cm} \dfrac{\hspace{0.1cm} TAC_{\hspace{0.05cm} test} \hspace{0.1cm}-\hspace{0.1cm} 1/k \hspace{0.1cm}}{1 \hspace{0.1cm}-\hspace{0.1cm} 1/k}\]</span></p>
</p>
</p>
<p></span></p>
</div>
<p><br></p>
<div id="modelo-de-clasificación-aleatoria-uniforme" class="section level3 hasAnchor" number="4.3.1">
<h3 class="hasAnchor"><span class="header-section-number">4.3.1</span> Modelo de clasificación aleatoria uniforme<a href="#modelo-de-clasificación-aleatoria-uniforme" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Dada una respuesta <span class="math inline">\(\mathcal{Y}\)</span> con <span class="math inline">\(k\geq 2\)</span> categorías y de una serie de predictores <span class="math inline">\(\mathcal{X}_1 , ..., \mathcal{X}_p\)</span>.</p>
<p>Dada una muestra de <span class="math inline">\(n\)</span> observaciones de <span class="math inline">\(Y\)</span> del predictor<br />
y una muestra <span class="math inline">\(X_j\)</span> del predictor <span class="math inline">\(\mathcal{X}_j\)</span>.</p>
<p>Un modelo de clasificación aleatorio basado en la distribución discreta <span class="math inline">\(U\lbrace 0,1,..., k-1 \rbrace\)</span> es un modelo tal que:</p>
<p><span class="math display">\[\widehat{y}_i \sim U\lbrace 0,1,..., k-1 \rbrace\]</span></p>
<p>Por lo que:</p>
<p><span class="math display">\[P(\widehat{y}_i = h) = 1/k = p\]</span></p>
<p>para todo <span class="math inline">\(h=0,1,...,k-1\)</span></p>
<p><br></p>
<p>Por tanto, para cada <span class="math inline">\(\hspace{0.15cm}i=1,...,n\hspace{0.15cm}\)</span> tenemos que: <span class="math inline">\(\\[0.15cm]\)</span></p>
<ul>
<li><p><span class="math inline">\(P\left( \hspace{0.1cm} \mathbf{I}(\hat{y}_i = y_i) = 1\hspace{0.1cm} \right) = P \left( \hspace{0.1cm} \hat{y}_i = y_i \hspace{0.1cm} \right) \hspace{0.1cm}=\hspace{0.1cm} 1/k \hspace{0.1cm}=\hspace{0.1cm} p\)</span>.</p></li>
<li><p><span class="math inline">\(P\left( \hspace{0.1cm} \mathbf{I}(\hat{y}_i = y_i) = 0 \hspace{0.1cm} \right) \hspace{0.1cm} =\hspace{0.1cm} P\left( \hspace{0.1cm} \hat{y}_i \neq y_i \hspace{0.1cm} \right) \hspace{0.1cm}=\hspace{0.1cm} 1- 1/k \hspace{0.1cm}=\hspace{0.1cm} 1 - p\)</span>.</p></li>
</ul>
<p><br></p>
<p>Por lo que <span class="math inline">\(\mathbf{I}(\hat{y}_i = y_i)\)</span> es una variable binaria, con probabilidad de exito <span class="math inline">\(p\)</span> y de fracaso <span class="math inline">\(1-p\)</span>, es decir:</p>
<p><span class="math display">\[\mathbf{I}(\hat{y}_i = y_i)  \hspace{0.1cm}\sim\hspace{0.1cm} Bernoulli\left( \hspace{0.1cm} p=1/k \hspace{0.1cm} \right)\]</span></p>
<p>Por lo tanto:</p>
<p><span class="math display">\[\sum_{i=1}^n \mathbf{I}(\hat{y}_i = y_i) \hspace{0.1cm}\sim\hspace{0.1cm} Binomial(n\cdot p )\]</span>
<br></p>
<p>Así que, la tasa de acierto esperada del modelo de clasificación aleatoria uniforme es: <span class="math inline">\(\\[0.2cm]\)</span></p>
<p><span class="math display">\[E\left[TAC\right] \hspace{0.1cm}=\hspace{0.1cm} E\left[ \dfrac{1}{n} \sum_{i=1}^n \mathbf{I}(\hat{y}_i = y_i) \right] \hspace{0.1cm}=\hspace{0.1cm} E\left[  \dfrac{1}{n} \cdot Binomial(n\cdot p )  \right] \hspace{0.1cm} = \\[1.2cm] = \hspace{0.1cm} \dfrac{1}{n} \cdot E\left[ Binomial(n\cdot p )   \right]  \hspace{0.1cm}=\hspace{0.1cm} \dfrac{1}{n} \cdot (n\cdot p) = p = 1/k\]</span></p>
<p><br></p>
</div>
</div>
</div>
<div id="algoritmos-de-validación-de-modelos-de-aprendizaje-supervisado" class="section level1 hasAnchor" number="5">
<h1 class="hasAnchor"><span class="header-section-number">5</span> Algoritmos de validación de modelos de aprendizaje supervisado<a href="#algoritmos-de-validación-de-modelos-de-aprendizaje-supervisado" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>Los algoritmos de validación de modelos de aprendizaje supervisado permiten medir la capacidad predictiva de dichos modelos. Estoas algoritmos se suelen basar en:</p>
<ul>
<li><p>División del data-set inicial de la respuesta y los predictores en parte de train y parte de test.</p></li>
<li><p>Entrenamiento del modelo con la parte de train.</p></li>
<li><p>Obtención de predicciones de la respuesta con la parte de test.</p></li>
<li><p>Cálculo de una métrica de evaluación usando las predicciones obtenidas en el paso 4) y las observaciones de test de la respuesta. <span class="math inline">\(\\[0.3cm]\)</span></p></li>
</ul>
<p>Tenemos un modelo de aprendizaje supervisado <span class="math inline">\(\hspace{0.1cm}M\hspace{0.1cm}\)</span> y una muestra de <span class="math inline">\(\hspace{0.1cm}N\hspace{0.1cm}\)</span> observaciones de <span class="math inline">\(\hspace{0.1cm}p\hspace{0.1cm}\)</span> predictores <span class="math inline">\(\hspace{0.1cm}\mathcal{X}_1,...,\mathcal{X}_p\hspace{0.1cm}\)</span> y de la respuesta <span class="math inline">\(\hspace{0.1cm}\mathcal{Y}\)</span>.</p>
<p><span class="math display">\[D\hspace{0.1cm}=\hspace{0.1cm}[X_1,...,X_p,Y]\hspace{0.1cm}=\hspace{0.1cm}\begin{pmatrix}
    x_{11}&amp;x_{12}&amp;...&amp;x_{1p}&amp; y_1\\
    x_{21}&amp;x_{22}&amp;...&amp;x_{2p} &amp; y_2\\
    &amp;...&amp;\\
    x_{N1}&amp;x_{N2}&amp;...&amp;x_{Np}&amp; y_N
    \end{pmatrix}=\begin{pmatrix}
    x_{1}&amp; y_1\\
    x_{2}&amp; y_2\\
    ...&amp;...\\
    x_{N}&amp; y_N
    \end{pmatrix}\]</span></p>
<p><br></p>
<p><br></p>
<div id="validación-simple-no-aleatoria" class="section level2 hasAnchor" number="5.1">
<h2 class="hasAnchor"><span class="header-section-number">5.1</span> Validación simple no aleatoria<a href="#validación-simple-no-aleatoria" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p><strong>Descripción no formal del algoritmo:</strong></p>
<p>Este algoritmo de validación consiste en dividir el data-set inicial en una parte de train y otra de test de manera no aleatoria.</p>
<p>El <span class="math inline">\(\hspace{0.1cm} k\% \hspace{0.1cm}\)</span> de las primeras filas del data-set serán la parte de train, y el resto la parte de test.</p>
<p>El modelo es entrenado con la muestra train y testado calculando una métrica de evaluación con la muestra test. Este valor de la métrica de evaluación es el que será usado para medir la capacidad predictiva del modelo y compararlo con otros modelos. <span class="math inline">\(\\[0.4cm]\)</span></p>
<p><strong>Decripción formal del algoritmo:</strong></p>
<p>El algoritmo de validación simple no aleatoria tiene los siguientes pasos: <span class="math inline">\(\\[0.3cm]\)</span></p>
<div class="warning" style="background-color:#F7EBE8; color: #030000; border-left: solid #CA0B0B 7px; border-radius: 3px; size:1px ; padding:0.1em;">
<p><span></p>
<p style="margin-left:1em;">
<ul>
<li><p>Se divide <span class="math inline">\(D\)</span> en parte de train y parte de test del siguiente modo:</p>
<p>Sea <span class="math inline">\(\hspace{0.05cm}k\in (0,1)\hspace{0.05cm}\)</span> la proporción de filas de <span class="math inline">\(D\)</span> que formaran parte del muestra de <strong>train</strong> :</p>
<ul>
<li><p>Las primeras <span class="math inline">\(\hspace{0.2cm}\lfloor k \cdot N \rfloor\hspace{0.2cm}\)</span> observaciones (filas) definen el conjunto de train: <span class="math inline">\(\\[0.15cm]\)</span></p>
<p><span class="math display">\[D_{train}= \begin{pmatrix}
  x_{11}&amp;...&amp;x_{1p}&amp; y_1\\
  x_{21}&amp;...&amp;x_{2p} &amp; y_2\\
  ...&amp;...&amp;...&amp;... \\
  x_{\lfloor k  \cdot N \rfloor1}&amp; ...&amp;x_{\lfloor k  \cdot N \rfloor p}&amp; y_{\lfloor k  \cdot N \rfloor}
  \end{pmatrix}\\\]</span></p>
<p>Donde:</p>
<ul>
<li><span class="math inline">\(\# D_{train}\hspace{0.01cm}\)</span> es el número de <strong>filas</strong> de <span class="math inline">\(\hspace{0.01cm}D_{train}\)</span>. <span class="math inline">\(\\[0.25cm]\)</span></li>
</ul></li>
<li><p>Las siguientes <span class="math inline">\(\hspace{0.2cm} N - \lfloor k \cdot N \rfloor\hspace{0.2cm}\)</span> observaciones definen (filas) el conjunto de test: <span class="math inline">\(\\[0.15cm]\)</span></p>
<p><span class="math display">\[D_{test}= \begin{pmatrix}
x_{(\lfloor k  \cdot N \rfloor + 1) \hspace{0.05cm} 1 } &amp;...&amp;x_{(\lfloor k  \cdot N \rfloor + 1) \hspace{0.05cm} p}&amp; y_{\lfloor k  \cdot N \rfloor + 1} \\
x_{(\lfloor k  \cdot N \rfloor + 2) \hspace{0.05cm} 1 }&amp;...&amp;x_{(\lfloor k  \cdot N \rfloor + 2) \hspace{0.05cm} p}&amp; y_{\lfloor k  \cdot N \rfloor + 2}\\  ...&amp;...&amp;...&amp;... \\
    x_{N \hspace{0.05cm} 1 } &amp;...&amp;x_{N p}&amp; y_{N}
\end{pmatrix} \\\]</span></p>
<p>Donde:</p>
<ul>
<li><p><span class="math inline">\(\# D_{test}\hspace{0.1cm}\)</span> es el número de <strong>filas</strong> de <span class="math inline">\(\hspace{0.1cm}D_{test}\)</span> .</p></li>
<li><p><span class="math inline">\(\lfloor \cdot \rfloor\hspace{0.1cm}\)</span> es la funcion suelo, que dado un número como argumento te devuelve el mayor entero menor que dicho número. <span class="math inline">\(\\[0.15cm]\)</span></p></li>
</ul></li>
</ul></li>
<li><p>Se entrena el modelo <span class="math inline">\(\hspace{0.1cm} M\hspace{0.1cm}\)</span> con la <strong>muestra de train</strong> <span class="math inline">\(\hspace{0.1cm} D_{train}\hspace{0.1cm}\)</span> <span class="math inline">\(\hspace{0.25cm}\Rightarrow\hspace{0.25cm}\)</span> <span class="math inline">\(\widehat{M}\)</span> .</p></li>
<li><p>Se calcula una métrica de evaluación sobre el modelo entrenado <span class="math inline">\(\hspace{0.1cm}\widehat{M}\hspace{0.1cm}\)</span> usando la <strong>muestra de test</strong> <span class="math inline">\(\hspace{0.1cm} D_{test}\hspace{0.1cm}\)</span> <span class="math inline">\(\hspace{0.2cm}\Rightarrow\hspace{0.2cm}\)</span> Si por ejemplo se calcula el <span class="math inline">\(\hspace{0.1cm}ECM\hspace{0.1cm}\)</span> , se obtendria el <span class="math inline">\(\hspace{0.1cm}ECM_{test}\)</span> .</p></li>
<li><p>La métrica de evaluación final del modelo es la obtenida en el paso anterior.</p>
<ul>
<li><p>Si la métrica empleada en el paso anterior es el <span class="math inline">\(\hspace{0.1cm}ECM\hspace{0.1cm}\)</span> , entonces la métrica de evaluación calculada con el algoritmo de validación simple no aleatoria es la siguiente:</p>
<p><span class="math display">\[ECM(M)_{test}^* \hspace{0.1cm}=\hspace{0.1cm} ECM(\widehat{M})_{test} \hspace{0.1cm}=\hspace{0.1cm} \dfrac{1}{\# D_{test}} \cdot \sum_{i=1}^{\# D_{test}} \hspace{0.1cm} ( \hspace{0.1cm} y_i^{test} - \hat{y}_i^{test} \hspace{0.1cm})^2\]</span></p>
<p>Donde:</p>
<ul>
<li><span class="math inline">\(\hat{y}_i^{test} \hspace{0.1cm}=\hspace{0.1cm} \widehat{M}(\hspace{0.1cm} x_i^{test} \hspace{0.1cm}|\hspace{0.1cm} D_{train}) \hspace{0.1cm}=\hspace{0.1cm} M(\hspace{0.1cm} x_i^{test} \hspace{0.1cm}|\hspace{0.1cm} X_1^{train},...,X_p^{train},Y^{train})\hspace{0.1cm}=\hspace{0.1cm} \widehat{M}(\hspace{0.1cm} x_i^{test} \hspace{0.1cm})\)</span></li>
</ul></li>
</ul></li>
</ul>
</p>
</p>
<p></span></p>
</div>
<p><br></p>
<p><strong>Problemas</strong></p>
<p>Toda la validación queda condicionada a solo una muestra de train y otra de test. Si alguna de estas muestras tienen defectos, estos se van a trasladar a la validación, que será por tanto defectuosa. Es la primera aproximación naive a los algoritmos de validación.</p>
<p><br></p>
</div>
<div id="validación-simple-aleatoria" class="section level2 hasAnchor" number="5.2">
<h2 class="hasAnchor"><span class="header-section-number">5.2</span> Validación simple aleatoria<a href="#validación-simple-aleatoria" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p><strong>Decripción no formal del algoritmo:</strong></p>
<p>Este algoritmo de validacion consiste en dividir el data-set inicial en una parte de train y otra de test de manera <strong>aleatoria</strong>.</p>
<p>Se obtiene una muestra aleatoria sin remplazo de un <span class="math inline">\(\hspace{0.1cm} k\% \hspace{0.1cm}\)</span> de las filas del data-set inicial, las cuales serán la parte de train, y el resto la parte de test.</p>
<p>El modelo es entrenado con la muestra train y testado calculando un métrica de evaluación con la muestra de test. Este valor de la métrica de evaluación es el que será usado para medir el poder predictivo del modelo y compararlo con otros modelos.</p>
<p><br></p>
<p><strong>Decripción formal del algoritmo:</strong></p>
<p>El algoritmo de validación simple aleatoria tiene los siguientes pasos:</p>
<div class="warning" style="background-color:#F7EBE8; color: #030000; border-left: solid #CA0B0B 7px; border-radius: 3px; size:1px ; padding:0.1em;">
<p><span></p>
<p style="margin-left:1em;">
<ul>
<li><p>Se divide <span class="math inline">\(\hspace{0.1cm}D\hspace{0.1cm}\)</span> en parte de train y parte de test del siguiente modo:</p>
<p>Sea <span class="math inline">\(\hspace{0.1cm}k\in (0,1)\hspace{0.1cm}\)</span> la proporción de filas de <span class="math inline">\(\hspace{0.1cm}D\hspace{0.1cm}\)</span> que formarán parte de la muestra de <strong>train</strong> (es un hiper-parametro del algoritmo): <span class="math inline">\(\\[0.05cm]\)</span></p>
<ul>
<li>Se genera una muestra aleatoria sin reemplazamiento de tamaño <span class="math inline">\(\lfloor k \cdot N \rfloor\)</span> del vector <span class="math inline">\((\hspace{0.05cm}1,2,...,N\hspace{0.05cm})\)</span> :</li>
</ul>
<p><span class="math display">\[m=(m_1 ,m_2,...,m_{\lfloor k  \cdot N \rfloor}) \\\]</span></p>
<ul>
<li><p>Las observaciones (filas) <span class="math inline">\(\hspace{0.1cm}m=(m_1,m_2 ,...,m_{\lfloor k \cdot N \rfloor})\hspace{0.1cm}\)</span> de <span class="math inline">\(D\)</span> definen la <strong>muestra de train</strong>: <span class="math inline">\(\\[0.15cm]\)</span></p>
<p><span class="math display">\[D_{train}= D[m , :] = \begin{pmatrix}
  x_{m_11}&amp; ...&amp;x_{m_1p}&amp; y_{m_1}\\
  x_{m_21}&amp; ...&amp;x_{m_2p} &amp; y_{m_2}\\
  &amp;...&amp;\\
  x_{m_{\lfloor k  \cdot N \rfloor} 1} &amp;...&amp;x_{m_{\lfloor k  \cdot N \rfloor} p}&amp; y_{m_{\lfloor k  \cdot N \rfloor}}
  \end{pmatrix}  =  \begin{pmatrix}
  x_{1}^{train} &amp; y_{1}^{train}\\
  x_{2}^{train} &amp; y_{2}^{train}\\
  ....&amp;...\\
  x_{\# D_{train}}^{train} &amp; y_{\# D_{train}}^{train}\\
  \end{pmatrix} \\\]</span></p>
<p>Donde:</p>
<ul>
<li><span class="math inline">\(\# D_{train}\hspace{0.1cm}\)</span> es el número de <strong>filas</strong> de <span class="math inline">\(\hspace{0.1cm}D_{train}\)</span> <span class="math inline">\(\\[0.2cm]\)</span></li>
</ul></li>
<li><p>Las observaciones (filas) de <span class="math inline">\(D\)</span> complementarias a <span class="math inline">\(\hspace{0.1cm}m\hspace{0.1cm}\)</span> , es decir, las filas de <span class="math inline">\(D\)</span> que no estan en <span class="math inline">\(D_{train}\)</span>, es decir, las filas de <span class="math inline">\(m^c\)</span>,
definen la <strong>muestra de test</strong>: <span class="math inline">\(\\[0.15cm]\)</span></p>
<p><span class="math display">\[D_{test} = D[m^c , :] =  \begin{pmatrix}
  x_{1}^{test} &amp; y_{1}^{test}\\
  x_{2}^{test} &amp; y_{2}^{test}\\
  ....&amp;...\\
  x_{\# D_{test}}^{test} &amp; y_{\# D_{test}}^{test}\\
  \end{pmatrix} \\\]</span></p>
<p>Donde:</p>
<ul>
<li><p><span class="math inline">\(\# D_{test}\hspace{0.1cm}\)</span> es el número de <strong>filas</strong> de <span class="math inline">\(\hspace{0.1cm}D_{test}\)</span>.</p></li>
<li><p><span class="math inline">\(\lfloor \cdot \rfloor\hspace{0.1cm}\)</span> es la funcion suelo, que dado un número como argumento te devuelve el mayor entero menor que dicho número.</p></li>
<li><p><span class="math inline">\(m^c \hspace{0.1cm}= \hspace{0.1cm}\bigl(\hspace{0.1cm} i =1,...,N \hspace{0.15cm} : \hspace{0.15cm} i\neq m_j \hspace{0.1cm},\hspace{0.1cm} \forall j=1,...,\lfloor k \cdot N \rfloor \hspace{0.1cm} \bigr)\)</span> <span class="math inline">\(\\[0.15cm]\)</span></p></li>
</ul></li>
</ul></li>
<li><p>Se entrena el modelo <span class="math inline">\(\hspace{0.1cm}M\hspace{0.1cm}\)</span> con la <strong>muestra de train</strong> <span class="math inline">\(\hspace{0.1cm}D_{train}\hspace{0.1cm}\)</span> <span class="math inline">\(\hspace{0.1cm}\Rightarrow\hspace{0.2cm}\)</span> <span class="math inline">\(\widehat{M}\)</span>.</p></li>
<li><p>Se calcula una métrica de evaluación sobre el modelo entrenado <span class="math inline">\(\hspace{0.1cm}\widehat{M}\hspace{0.1cm}\)</span> con la <strong>muestra de test</strong> <span class="math inline">\(\hspace{0.1cm}D_{test}\)</span> <span class="math inline">\(\hspace{0.2cm}\Rightarrow\hspace{0.2cm}\)</span>
Si por ejemplo se calcula el <span class="math inline">\(\hspace{0.1cm}ECM\hspace{0.1cm}\)</span> , se obtendria el <span class="math inline">\(\hspace{0.1cm}ECM_{test}(\widehat{M})\)</span>.</p></li>
<li><p>La métrica de evaluación final del modelo es la obtenida en el paso anterior:</p>
<ul>
<li><p>Si la métrica empleada en el paso anterior fue el <span class="math inline">\(\hspace{0.1cm}ECM\hspace{0.1cm}\)</span> , entonces:</p>
<p><span class="math display">\[ECM(M)_{test}^* \hspace{0.1cm}=\hspace{0.1cm} ECM(\widehat{M})_{test} \hspace{0.1cm}=\hspace{0.1cm} \dfrac{1}{\# D_{test}} \cdot \sum_{i=1}^{\# D_{test}} (y_i^{test} - \hat{y}_i^{test})^2\]</span></p>
<p>Donde:</p>
<ul>
<li><span class="math inline">\(\hat{y}_i^{test} \hspace{0.1cm}=\hspace{0.1cm} M(\hspace{0.1cm} x_i^{test} \hspace{0.15cm}|\hspace{0.15cm} D_{train})\hspace{0.1cm}=\hspace{0.1cm} M(\hspace{0.1cm} x_i^{test} \hspace{0.1cm}|\hspace{0.1cm} X_1^{train},...,X_p^{train},Y^{train})\hspace{0.1cm}=\hspace{0.1cm} \widehat{M}(\hspace{0.1cm} x_i^{test} \hspace{0.1cm})\)</span></li>
</ul></li>
</ul></li>
</ul>
</p>
</p>
<p></span></p>
</div>
<p><br></p>
<p><strong>Problemas</strong></p>
<p>Toda la validación queda condicionada a solo una muestra de train y otra de test. Si alguna de estas muestras tienen defectos, estos se van a trasladar a la validación, que será por tanto defectuosa.</p>
<p>Ademas la métrica de evaluacion calculada por validación simple aleatoria tiene generalmente una varianza alta, en comparación con otros métodos de validación. Esto será ilustrado en la práctica.</p>
<p>La varianza de una metrica de evaluación calculada con un algorimo de validación se puede entender como como la varianza de los valores obtenidos de la métrica al ejecutar el algoritmo un número elevado de veces.</p>
<p>Es la segunda aproximación naive a los algoritmos de validación.</p>
<p><br></p>
<p><br></p>
</div>
<div id="validación-simple-aleatoria-repetida" class="section level2 hasAnchor" number="5.3">
<h2 class="hasAnchor"><span class="header-section-number">5.3</span> Validación simple aleatoria repetida<a href="#validación-simple-aleatoria-repetida" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p><strong>Decripción no formal del algoritmo:</strong></p>
<p>Este algoritmo de validacion consiste en dividir el data-set inicial en una parte de train y otra de test de manera aleatoria.</p>
<p>Se obtiene una muestra aleatoria sin remplazo de un <span class="math inline">\(\hspace{0.05cm}k\%\hspace{0.05cm}\)</span> de las filas del data-set inicial, las cuales serán la parte de train, y el resto la parte de test.</p>
<p>El modelo es enetrenado con la muestra train y testado con la muestra test a través de una métrica de evaluación como las vistas en la sección anterior.</p>
<p>Este proceso se repite un número <span class="math inline">\(\hspace{0.03cm}B\hspace{0.03cm}\)</span> de veces, asi se obtienen <span class="math inline">\(\hspace{0.03cm}B\hspace{0.03cm}\)</span> valores de la métrica de evaluación.</p>
<p>La métrica de evaluacion calculada usando este método de validación es la media de dichos <span class="math inline">\(\hspace{0.03cm}B\hspace{0.03cm}\)</span> valores obtenidos para la métrica de evaluación escogida. Este valor medio final es la que será usado para medir el poder predictivo del modelo y compararlo con otros modelos.</p>
<p><br></p>
<p><strong>Decripción formal del algoritmo:</strong></p>
<p>El algoritmo de validación simple aleatoria tiene los siguientes pasos:</p>
<div class="warning" style="background-color:#F7EBE8; color: #030000; border-left: solid #CA0B0B 7px; border-radius: 3px; size:1px ; padding:0.1em;">
<p><span></p>
<p style="margin-left:1em;">
<ul>
<li><p>Se obtienen <span class="math inline">\(B\)</span> particiones de la muestra de observaciones <span class="math inline">\(D\)</span> en parte de <strong>train</strong> y parte de <strong>test</strong> del siguiente modo:</p>
<p>Sea <span class="math inline">\(\hspace{0.05cm}k\in (0,1)\hspace{0.05cm}\)</span> la proporción de filas de <span class="math inline">\(\hspace{0.05cm}D\hspace{0.05cm}\)</span> que formarán parte de la muestra de <strong>train</strong> :</p>
<ul>
<li><p>Se generan <span class="math inline">\(\hspace{0.01cm}B\hspace{0.01cm}\)</span> muestras aleatoria sin reemplazamiento de tamaño <span class="math inline">\(\hspace{0.01cm}\lfloor k \cdot N \rfloor\hspace{0.01cm}\)</span> del vector <span class="math inline">\(\hspace{0.01cm}(1,2,...,N)\hspace{0.1cm}\)</span> :</p>
<p><span class="math display">\[m_1 \hspace{0.1cm},\hspace{0.1cm} m_2 \hspace{0.1cm},\hspace{0.1cm} ...\hspace{0.1cm},\hspace{0.1cm} m_B \\[0.01cm]\]</span></p>
<p>Donde:</p>
<ul>
<li><p><span class="math inline">\(m_r=(m_{r1} ,...,m_{r\lfloor k \cdot N \rfloor})\hspace{0.15cm} \hspace{0.25cm} , \hspace{0.25cm} \forall \hspace{0.1cm} r\in\lbrace 1,...,B\rbrace\)</span></p></li>
<li><p><span class="math inline">\(\lfloor \cdot \rfloor\hspace{0.1cm}\)</span> es la función suelo, que dado un número como argumento devuelve el mayor entero menor que dicho número. <span class="math inline">\(\\[0.08cm]\)</span></p></li>
</ul></li>
<li><p>Se obtienen las siguientes <span class="math inline">\(\hspace{0.05cm}B\hspace{0.05cm}\)</span> <strong>muestras de train</strong> del data-set original <span class="math inline">\(\hspace{0.05cm}D\hspace{0.1cm}\)</span>: <span class="math inline">\(\\[0.03cm]\)</span></p>
<p><span class="math display">\[D_{train, 1}= D[\hspace{0.1cm}m_1\hspace{0.1cm} ,\hspace{0.1cm} :\hspace{0.1cm}] \hspace{0.15cm},\hspace{0.15cm} D_{train, 2}= D[\hspace{0.1cm}m_2\hspace{0.1cm} ,\hspace{0.1cm} :\hspace{0.1cm}] \hspace{0.15cm}, \dots ,\hspace{0.15cm} D_{train, B}= D[\hspace{0.1cm}m_B\hspace{0.1cm} ,\hspace{0.1cm} :\hspace{0.1cm}] \\\]</span></p>
<p>Donde <span class="math inline">\(D_{train, r}\hspace{0.03cm}\)</span> es la submatriz que resulta de quedarse solo con las filas de <span class="math inline">\(D\)</span> definidas por la muestra <span class="math inline">\(m_r\)</span> de <span class="math inline">\((1,...,N) \hspace{0.1cm}\)</span> :</p>
<p><span class="math display">\[D_{train, r} \hspace{0.1cm}=\hspace{0.1cm} D[\hspace{0.1cm}m_r\hspace{0.1cm} ,\hspace{0.1cm} :\hspace{0.1cm}] \hspace{0.1cm}=\hspace{0.1cm} \begin{pmatrix}
  x_{m_{r1},1}  &amp; ... &amp; x_{m_{r1},p} &amp; y_{m_{r1}} \\
  x_{m_{r2},1} &amp;   ... &amp; x_{m_{r2},p} &amp; y_{m_{r2}} \\
  ....&amp;...\\
  x_{m_{r\lfloor k  \cdot N \rfloor} ,1}   &amp; ... &amp; x_{m_{r\lfloor k  \cdot N \rfloor},p} &amp; y_{m_{r\lfloor k  \cdot N \rfloor}} \end{pmatrix}  \\[1.7cm]\]</span></p></li>
<li><p>Se obtienen las siguientes <span class="math inline">\(\hspace{0.01cm}B\hspace{0.01cm}\)</span> <strong>muestras de test</strong> del data-set original <span class="math inline">\(\hspace{0.01cm}D \hspace{0.02cm}:\)</span></p>
<p><span class="math display">\[D_{test, 1}= D[\hspace{0.1cm}m_1^c\hspace{0.1cm} ,\hspace{0.1cm} :\hspace{0.1cm}] \hspace{0.15cm},\hspace{0.15cm} D_{test, 2}= D[\hspace{0.1cm}m_2^c\hspace{0.1cm} ,\hspace{0.1cm} :\hspace{0.1cm}] \hspace{0.15cm}, ... ,\hspace{0.15cm} D_{test, B}= D[\hspace{0.1cm}m_B^c\hspace{0.1cm} , \hspace{0.1cm}:\hspace{0.1cm}] \\\]</span></p>
<p>Donde: <span class="math inline">\(\hspace{0.1cm}D_{test, r} \hspace{0.1cm}=\hspace{0.1cm} D[\hspace{0.1cm}m_r^c\hspace{0.1cm} ,\hspace{0.1cm} :\hspace{0.1cm}]\hspace{0.1cm}\)</span> es la submatriz que resulta de quedarse solo con las filas de <span class="math inline">\(\hspace{0.01cm}D\hspace{0.01cm}\)</span> que no están en <span class="math inline">\(\hspace{0.01cm}D_{train}\hspace{0.01cm}\)</span>, es decir, las filas de <span class="math inline">\(\hspace{0.01cm}m_r^c\)</span>.</p>
<p>Formalmente: <span class="math inline">\(\hspace{0.15cm} m_r^c \hspace{0.1cm}=\hspace{0.1cm}\left(\hspace{0.1cm} i \in \lbrace 1,...,N \rbrace \hspace{0.15cm} / \hspace{0.15cm} i\hspace{0.1cm}\neq\hspace{0.1cm} m_{rj} \hspace{0.15cm} , \hspace{0.15cm} \forall \hspace{0.1cm} j\in \lbrace 1,...,\lfloor k \cdot N \rfloor \rbrace \hspace{0.1cm} \right) \hspace{0.15cm}\)</span> <span class="math inline">\(\\[0.2cm]\)</span></p></li>
<li><p>En conclusión: <span class="math inline">\(\hspace{0.03cm}\)</span> se obtienen <span class="math inline">\(\hspace{0.01cm}B\hspace{0.01cm}\)</span> particiones de <strong>train</strong> y <strong>test</strong> de <span class="math inline">\(\hspace{0.01cm}D\hspace{0.03cm}\)</span> . <span class="math inline">\(\\[0.5cm]\)</span></p></li>
</ul></li>
<li><p>Para cada <span class="math inline">\(\hspace{0.01cm}r\in \lbrace 1,...,B\rbrace\hspace{0.03cm}\)</span> :</p>
<ul>
<li><p>Se entrena el modelo <span class="math inline">\(\hspace{0.01cm}M\hspace{0.01cm}\)</span> con cada una de las <strong>muestras de train</strong> <span class="math inline">\(\hspace{0.01cm} D_{train,r} \hspace{0.1cm}\)</span> <span class="math inline">\(\hspace{0.2cm}\Rightarrow\hspace{0.2cm}\)</span> <span class="math inline">\(\hspace{0.1cm}\widehat{M}_r\hspace{0.03cm}\)</span>.</p></li>
<li><p>Se calcula una misma métrica de evaluación sobre el modelo entrenado <span class="math inline">\(\hspace{0.1cm}\widehat{M}_r\hspace{0.1cm}\)</span> con la <strong>muestra de test</strong> <span class="math inline">\(\hspace{0.01cm}D_{test,r}\hspace{0.03cm}\)</span>.</p>
<ul>
<li><p>Supongamos que la métrica de evaluación usada es el <span class="math inline">\(\hspace{0.1cm}ECM\hspace{0.1cm}\)</span> , entonces se obtienen <span class="math inline">\(\hspace{0.1cm}B\hspace{0.1cm}\)</span> valores de esta métrica : <span class="math inline">\(\\[0.02cm]\)</span></p>
<p><span class="math display">\[ECM_{test }(\widehat{M}_1) \hspace{0.1cm},\hspace{0.1cm}  ECM_{test }(\widehat{M}_2)\hspace{0.1cm} , ... ,\hspace{0.1cm} ECM_{test}(\widehat{M}_B)\]</span></p>
<p>Donde:</p>
<p><span class="math inline">\(\hspace{0.5cm}\)</span> <span class="math inline">\(ECM_{test , r} \hspace{0.1cm}\)</span> es el <span class="math inline">\(\hspace{0.1cm}ECM\hspace{0.1cm}\)</span> calculado sobre <span class="math inline">\(\hspace{0.1cm}\widehat{M}_r\hspace{0.1cm}\)</span> usando <span class="math inline">\(\hspace{0.1cm}D_{test,r}\hspace{0.02cm}\)</span> :</p>
<p><span class="math display">\[ECM_{test }(\widehat{M}_r) \hspace{0.1cm}=\hspace{0.1cm} \dfrac{1}{\# D_{test,r}} \cdot \sum_{i=1}^{\# D_{test,r}} \hspace{0.1cm} (\hspace{0.1cm} y_i^{\hspace{0.1cm}test,r} - \hat{\hspace{0.1cm}y\hspace{0.1cm}}_i^{\hspace{0.1cm}test,r} \hspace{0.1cm})^2 \\\]</span></p>
<p>Teniendo en cuenta que:</p>
<ul>
<li><span class="math inline">\(\hat{y}_i^{test,r} \hspace{0.1cm}=\hspace{0.1cm} M(\hspace{0.1cm} x_i^{test, r} \hspace{0.1cm}|\hspace{0.1cm} D_{train,r}) \hspace{0.1cm}=\hspace{0.1cm} \widehat{M}_r (\hspace{0.1cm} x_i^{test, r} \hspace{0.1cm} )\)</span> <span class="math inline">\(\\[0.4cm]\)</span></li>
</ul></li>
</ul></li>
</ul></li>
<li><p>Se calcula la métrica final de evaluación del modelo como el promedio de las <span class="math inline">\(B\)</span> métricas calculadas en el apartado anterior.</p>
<ul>
<li>Si la métrica usada en el apartado anterior es el <span class="math inline">\(ECM\)</span>, entonces:</li>
</ul>
<p><span class="math display">\[ECM_{test}^{\hspace{0.08cm}*}( {M}) \hspace{0.07cm} = \hspace{0.07cm} \dfrac{1}{B} \cdot \sum_{r=1}^B ECM_{test}(\widehat{M}_r)\]</span></p></li>
</ul>
</p>
</p>
<p></span></p>
</div>
<p><br></p>
<p><strong>Ventajas</strong></p>
<p>Permite reducir la varianza de la métrica de validación. En la validación simple aleatoria no repetida la métrica de validación obtenida usando validacion simple tiene mayor varianza, en el sentido de que si se implementa el algoritmo un número elevado de veces, la varianza de los valores obtenidos de la métrica es mayor si se aplica el mismo procedimiento con validación simple aleatoria repetida. Esto será ilustrado en la práctica.</p>
<p><br></p>
</div>
<div id="leave-one-out" class="section level2 hasAnchor" number="5.4">
<h2 class="hasAnchor"><span class="header-section-number">5.4</span> Leave-one-out<a href="#leave-one-out" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p><strong>Descripción no formal del algoritmo:</strong></p>
<p>Este algoritmo de validación consiste en dividir el data-set inicial en una parte de train y otra de test de una forma tal que la primera observación forma parte del conjunto de test y el resto de la de train. Se entrena el modelo con la muestra de train y se calculan las predicciones de la respuesta para las observaciones de test de los predictores.</p>
<p>Con las observaciones de test de la respuesta y las predicciones de esta misma se calcula una métrica de validación.</p>
<p>Se repite el proceso anterior, pero tomando la segunda observación como muestra de test y las restantes como muestra de train. Se vuelve a repetir con la tercera observación, luego con la cuarta, y asi sucesivamente hasta llegar al punto en el que la última observación es la muestra de test.</p>
<p>Tras este proceso se habrán obtenido <span class="math inline">\(N\)</span> valores de la métrica de validación.</p>
<p>El valor final de la métrica por el algoritmo de validación leave-one-out es la media de esos <span class="math inline">\(N\)</span> valores. <span class="math inline">\(\\[0.05cm]\)</span></p>
<p><strong>Decripción formal del algoritmo:</strong></p>
<p>El algoritmo de validación simple no aleatoria tiene los siguientes pasos:</p>
<div class="warning" style="background-color:#F7EBE8; color: #030000; border-left: solid #CA0B0B 7px; border-radius: 3px; size:1px ; padding:0.1em;">
<p><span></p>
<p style="margin-left:1em;">
<ul>
<li><p>Se obtienen <span class="math inline">\(B\)</span> particiones de <span class="math inline">\(D\)</span> en parte de train y parte de test del siguiente modo:</p>
<ul>
<li><p>Se obtienen las siguientes <span class="math inline">\(B\)</span> <strong>muestras test</strong> del data-set original <span class="math inline">\(D\)</span>.</p>
<p><span class="math display">\[D_{test,1}=D[1, :] \hspace{0.1cm} ,\hspace{0.15cm} D_{test,2}=D[2, :]\hspace{0.15cm},...,\hspace{0.15cm} D_{test,B}=D[B, :] \\\]</span></p>
<ul>
<li><p>Donde :</p>
<p><span class="math inline">\(D_{test,r}=D[\hspace{0.1cm}r\hspace{0.1cm}, \hspace{0.1cm}:\hspace{0.1cm}]\hspace{0.1cm}\)</span> es la submatriz que resulta de considerar solo la fila <span class="math inline">\(r\)</span> de <span class="math inline">\(D\)</span> , es decir, es la observación <span class="math inline">\(r\)</span>-esima del data-set inicial <span class="math inline">\(\hspace{0.1cm}D\hspace{0.03cm}\)</span> :</p>
<p><span class="math display">\[D_{test,r} \hspace{0.1cm}=\hspace{0.1cm} D[\hspace{0.1cm}r\hspace{0.1cm},\hspace{0.1cm} :\hspace{0.1cm}] \hspace{0.1cm}=\hspace{0.1cm} (x_{r1} , ..., x_{rp} , y_r)=(x_r \hspace{0.1cm} ,\hspace{0.1cm}  y_r) \\[0.4cm]\]</span></p></li>
</ul></li>
<li><p>Se obtienen las siguientes <span class="math inline">\(B\)</span> <strong>muestras train</strong> del data-set original <span class="math inline">\(D\hspace{0.03cm}\)</span>:</p>
<p><span class="math display">\[D_{train,1}=D[\hspace{0.1cm}-1 \hspace{0.1cm},\hspace{0.1cm} :\hspace{0.1cm}] \hspace{0.2cm},\hspace{0.2cm} D_{train,2}=D[\hspace{0.1cm}-2\hspace{0.1cm}, \hspace{0.1cm}:\hspace{0.1cm}]\hspace{0.2cm},...,\hspace{0.2cm} D_{train,B}=D[\hspace{0.1cm}-B\hspace{0.1cm},\hspace{0.1cm} :\hspace{0.1cm}] \\\]</span></p>
<ul>
<li><p>Donde:</p>
<p><span class="math inline">\(D_{train,r}\hspace{0.1cm}=\hspace{0.1cm}D[\hspace{0.1cm}-r\hspace{0.1cm},\hspace{0.1cm} :\hspace{0.1cm}]\hspace{0.15cm}\)</span> es la submatriz que resulta de eliminar la fila <span class="math inline">\(i\)</span> de <span class="math inline">\(\hspace{0.1cm} D\hspace{0.1cm}\)</span>, es decir: <span class="math inline">\(\\[0.1cm]\)</span></p></li>
</ul></li>
</ul>
<p><span class="math display">\[D_{train,r}\hspace{0.1cm}=\hspace{0.1cm}D[\hspace{0.1cm}-r\hspace{0.1cm},\hspace{0.1cm} :\hspace{0.1cm}] \hspace{0.1cm}= \hspace{0.1cm}\begin{pmatrix}
  x_{11}&amp;...&amp;x_{1p}&amp; y_1\\
  ...&amp;...&amp;...&amp;...\\
  x_{(r-1)1}&amp;x_{(r-1)2}&amp;...&amp;x_{(r-1)p} &amp; y_{(r-1)}\\
  x_{(r+1)1}&amp;...&amp;x_{(r+1)p} &amp; y_{(r+1)}\\    ...&amp;...&amp;...&amp;...\\
  x_{N1}&amp;...&amp;x_{Np}&amp; y_N
  \end{pmatrix} \\\]</span></p></li>
<li><p>Para <span class="math inline">\(\hspace{0.02cm}r\in \lbrace 1,...,B \rbrace \hspace{0.03cm}\)</span> :</p>
<ul>
<li><p>Se entrena el modelo <span class="math inline">\(\hspace{0.1cm}M\hspace{0.1cm}\)</span> con la <strong>muestra de train</strong> <span class="math inline">\(\hspace{0.1cm} D_{train,r}\hspace{0.1cm}\)</span> <span class="math inline">\(\hspace{0.1cm}\Rightarrow\hspace{0.1cm}\)</span> <span class="math inline">\(\hspace{0.1cm}\widehat{M}_r\hspace{0.02cm}\)</span>.</p></li>
<li><p>Se calcula una misma métrica de evaluación sobre el modelo entrenado <span class="math inline">\(\hspace{0.01cm}\widehat{M}_r\hspace{0.01cm}\)</span> con la <strong>muestra de test</strong> <span class="math inline">\(\hspace{0.01cm}D_{test,r}\hspace{0.02cm}\)</span>.</p>
<ul>
<li><p>Supongamos que la métrica de evaluación usada es el <span class="math inline">\(\hspace{0.01cm}ECM\hspace{0.01cm}\)</span> , entonces se obtienen <span class="math inline">\(\hspace{0.1cm}B\hspace{0.1cm}\)</span> valores de esta métrica :</p>
<p><span class="math display">\[ECM(\widehat{M}_1)_{test } \hspace{0.1cm} ,\hspace{0.1cm}   ECM(\widehat{M}_2)_{test } \hspace{0.1cm} , ... ,\hspace{0.1cm}  ECM(\widehat{M}_B)_{test}\\\]</span></p>
<p>Donde:</p>
<p><span class="math inline">\(\hspace{0.5cm} ECM_{test , r}\hspace{0.01cm}\)</span> es el <span class="math inline">\(\hspace{0.01cm}ECM\hspace{0.01cm}\)</span> calculado sobre <span class="math inline">\(\hspace{0.01cm}\widehat{M}_r\hspace{0.01cm}\)</span> usando <span class="math inline">\(\hspace{0.01cm}D_{test,r}\hspace{0.03cm}\)</span>:</p>
<p><span class="math display">\[ECM(\widehat{M}_r)_{test } =  (\hspace{0.1cm} y_r - \hat{y}_r \hspace{0.1cm})^2\]</span></p>
<p>Teniendo en cuenta que:</p>
<ul>
<li><p><span class="math inline">\(\hat{y}_r \hspace{0.1cm}=\hspace{0.1cm} M(\hspace{0.1cm} x_r \hspace{0.1cm}|\hspace{0.1cm} D_{train,r}) \hspace{0.1cm}=\hspace{0.1cm} \widehat{M}_r (\hspace{0.03cm} x_r \hspace{0.03cm} )\)</span></p></li>
<li><p><span class="math inline">\(y_r\hspace{0.1cm}\)</span> es la única observación de la muestra de test <span class="math inline">\(\hspace{0.1cm} r\)</span>-esima de la variable respuesta. <span class="math inline">\(\\[0.6cm]\)</span></p></li>
</ul></li>
</ul></li>
</ul></li>
<li><p>Se calcula la métrica final de evaluación del modelo como el promedio de las <span class="math inline">\(\hspace{0.01cm}B\hspace{0.01cm}\)</span> métricas calculadas en el paso anterior.</p>
<ul>
<li>Si la métrica usada es el <span class="math inline">\(\hspace{0.1cm}ECM\hspace{0.1cm}\)</span>, entonces:</li>
</ul>
<p><span class="math display">\[ECM( M )_{test}^{\hspace{0.08cm}*} \hspace{0.1cm}=\hspace{0.1cm} \dfrac{1}{B} \cdot \sum_{r=1}^B \hspace{0.1cm} ECM(\widehat{M}_r)_{test}\]</span></p></li>
</ul>
</p>
</p>
<p></span></p>
</div>
<p><br></p>
<p><strong>Ventaja</strong></p>
<p>Una vez aplicado el algoritmo todas las observaciones han formado parte de conjunto de train (en alguna iteracion), y lo mismo para el conjunto de test.</p>
<p><br></p>
<p><strong>Problema</strong></p>
<p>Algunos autores (vease la referencia 1) consideran que, al emplearse todas las observaciones como entrenamiento, se puede estar cayendo en overfitting (sobre-ajuste).</p>
<p><br></p>
<p><br></p>
</div>
<div id="k-fold" class="section level2 hasAnchor" number="5.5">
<h2 class="hasAnchor"><span class="header-section-number">5.5</span> k-fold<a href="#k-fold" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p><strong>Decripción no formal del algoritmo:</strong></p>
<p>Este algoritmo de validación consiste en dividir el data-set inicial en <span class="math inline">\(\hspace{0.01cm} k\hspace{0.01cm}\)</span> partes, y usar de manera secuencial cada una de esas partes como muestra test, y las unión de las partes restantes como muestra train.</p>
<p>Por tanto con este método se usan <span class="math inline">\(\hspace{0.01cm}k\hspace{0.01cm}\)</span> muestras de test y de train.</p>
<p>El modelo es entrenado secuencialmente con cada una de las <span class="math inline">\(\hspace{0.01cm}k\hspace{0.01cm}\)</span> muestras de train disitntas, y se testea con la correspondiente muestra de test (que es el complementario de la de train), usando una métrica de evaluación.</p>
<p>Es decir, tras dividir el data-set inicial en <span class="math inline">\(\hspace{0.01cm}k\hspace{0.01cm}\)</span> partes, la parte 1 se usa como test y el resto como train, se calcula la métrica de evaluación. Luego la parte 2 se usa como test y el resto como train, y se calcula la métrica de evaluación. Asi sucesivamente hasta haber usado las <span class="math inline">\(\hspace{0.1cm}k\hspace{0.1cm}\)</span> partes como muestras de test.</p>
<p>Tras este proceso se habrán obtenido <span class="math inline">\(\hspace{0.1cm}k\hspace{0.1cm}\)</span> valores de dicha métrica de evaluacion.</p>
<p>La métrica de evaluacion calculada usando este método de validación es la media de dichos <span class="math inline">\(\hspace{0.01cm}k\hspace{0.01cm}\)</span> valores obtenidos para la métrica de evaluación escogida. Este valor medio final es la que será usado para medir el poder predictivo del modelo y compararlo con otros modelos.</p>
<p><br></p>
<p><strong>Decripción formal del algoritmo:</strong></p>
<p>El algoritmo de validación k-folds tiene los siguientes pasos:</p>
<div class="warning" style="background-color:#F7EBE8; color: #030000; border-left: solid #CA0B0B 7px; border-radius: 3px; size:1px ; padding:0.1em;">
<p><span></p>
<p style="margin-left:1em;">
<ul>
<li><p>Se divide aleatoriamente el data-set inicial <span class="math inline">\(\hspace{0.01cm}D\hspace{0.01cm}\)</span> en <span class="math inline">\(\hspace{0.01cm}k\hspace{0.01cm}\)</span> partes de manera que cada parte tenga aproximadamente el mismo número de observaciones (sean lo mas balanceadas posibles).</p>
<ul>
<li><p>Existen diferentes métodos para hacer esta división. La problematica de la división es cómo hacer que las partes resultantes estén lo más balanceadas posibles respecto al numero de observaciones que contienen.</p></li>
<li><p>Hemos desarrollado un método basado en cuantiles que permite obtener este balanceo, el cual ha sido implementado en Python con buenos resultados en este aspecto, como se podrá ver posteriormente en la parte de implementación.</p></li>
<li><p>Vamos a explicar la mecánica del método ideado:</p>
<ul>
<li><p>Obtenemos una muestra aleatoria sin remplazamiento <span class="math inline">\(\hspace{0.01cm}m=(m_1,...,m_N)\hspace{0.01cm}\)</span> de tamaño <span class="math inline">\(N\)</span> del vector <span class="math inline">\(\hspace{0.01cm}(1,...,N)\hspace{0.03cm}\)</span>.</p></li>
<li><p>El siguiente paso es dividir la muestra <span class="math inline">\(\hspace{0.01cm}m\hspace{0.01cm}\)</span> en <span class="math inline">\(\hspace{0.01cm}k\hspace{0.01cm}\)</span> partes lo mas balanceadas posibles. No queremos que unas partes tenga muchos elementos, y otras pocos. Queremos que la repartición de los elementos de <span class="math inline">\(\hspace{0.01cm}m\hspace{0.01cm}\)</span> en las <span class="math inline">\(\hspace{0.01cm}k\hspace{0.01cm}\)</span> partes sea lo mas igualitaria posible.</p></li>
<li><p>La idea es que si, por ejemplo <span class="math inline">\(\hspace{0.01cm}k=10\hspace{0.01cm}\)</span>, cada una de las 10 partes en las que dividimos <span class="math inline">\(\hspace{0.01cm}m\hspace{0.01cm}\)</span> tenga un 10% de los elementos totales de <span class="math inline">\(m\)</span>.</p></li>
<li><p>Si <span class="math inline">\(\hspace{0.01cm}k=4\hspace{0.01cm}\)</span> se busca que cada una de las 4 partes en las que dividimos <span class="math inline">\(\hspace{0.1cm}m\hspace{0.1cm}\)</span> tenga el 25% de los elementos de <span class="math inline">\(\hspace{0.01cm}m\)</span>.</p></li>
<li><p>En general, se busca que cada una de las <span class="math inline">\(\hspace{0.01cm} k\hspace{0.01cm}\)</span> partes en las que dividimos <span class="math inline">\(\hspace{0.01cm}m\hspace{0.01cm}\)</span> tengan <span class="math inline">\(\hspace{0.01cm}(1/k)\cdot 100 \%\hspace{0.01cm}\)</span> de elementos de <span class="math inline">\(\hspace{0.01cm}m\hspace{0.01cm}\)</span>, es decir, <span class="math inline">\(\hspace{0.01cm} N/k\hspace{0.01cm}\)</span> elementos de <span class="math inline">\(\hspace{0.01cm}m\hspace{0.01cm}\)</span> , puesto que <span class="math inline">\(m\)</span> tiene <span class="math inline">\(N\)</span> elementos.</p></li>
<li><p>Una forma de hacer esto es usando los cuantiles <span class="math inline">\(\hspace{0.01cm} Q_0 \hspace{0.1cm} , \hspace{0.1cm} Q_{1/k} \hspace{0.1cm} ,\hspace{0.1cm} Q_{2/k} \hspace{0.1cm} ,...,\hspace{0.1cm} Q_{(k-1)/k}\hspace{0.1cm} ,\hspace{0.1cm} Q_1\hspace{0.01cm}\)</span> del vector <span class="math inline">\(\hspace{0.01cm}(1,...,N)\hspace{0.01cm}\)</span> como los limites que definen las partes en las que dividiremos <span class="math inline">\(\hspace{0.01cm} m=(m_1,...,m_N)\hspace{0.01cm}\)</span>.</p></li>
<li><p>Dichos cuantiles permiten separar <span class="math inline">\(\hspace{0.01cm} m \hspace{0.01cm}\)</span> en <span class="math inline">\(\hspace{0.01cm} k \hspace{0.01cm}\)</span> partes de un tamaño aproximadamente igual.</p></li>
<li><p>Si <span class="math inline">\(\hspace{0.01cm} k=10\hspace{0.1cm}\)</span>, entonces esos cuantiles serian <span class="math inline">\(\hspace{0.01cm} Q_0 \hspace{0.1cm},\hspace{0.1cm} Q_{0.1} \hspace{0.1cm},\hspace{0.1cm} Q_{0.2} \hspace{0.1cm}, ...,\hspace{0.1cm} Q_{0.8} \hspace{0.1cm},\hspace{0.1cm} Q_{0.9} \hspace{0.1cm},\hspace{0.1cm} Q_1\hspace{0.01cm}\)</span>.</p></li>
<li><p>Si <span class="math inline">\(\hspace{0.01cm} k=4\hspace{0.1cm}\)</span> , los cuantiles serían <span class="math inline">\(\hspace{0.1cm} Q_0 \hspace{0.1cm},\hspace{0.1cm} Q_{0.25} \hspace{0.1cm},\hspace{0.1cm} Q_{0.5} \hspace{0.1cm},\hspace{0.1cm} Q_{0.75} \hspace{0.1cm},\hspace{0.1cm} Q_1\hspace{0.01cm}\)</span>.</p>
<p>Notese que: <span class="math inline">\(\hspace{0.02cm} Q_0 = Min(1,...,N) = 1\hspace{0.2cm}\)</span> y <span class="math inline">\(\hspace{0.2cm} Q_1=Max(1,...,N)=N \hspace{0.01cm}\)</span>. <span class="math inline">\(\\[0.25cm]\)</span></p></li>
</ul></li>
<li><p>Definimos las <span class="math inline">\(\hspace{0.01cm} k\hspace{0.01cm}\)</span> particiones de <span class="math inline">\(\hspace{0.01cm} m \hspace{0.01cm}\)</span> usando los cuantiles <span class="math inline">\(\hspace{0.01cm} Q_0\hspace{0.01cm},\hspace{0.01cm} Q_{1/k} \hspace{0.01cm},\hspace{0.01cm} Q_{2/k}\hspace{0.01cm},...,\hspace{0.01cm} Q_{(k-1)/k}\hspace{0.01cm},\hspace{0.01cm} Q_1\hspace{0.02cm}\)</span> como sigue:</p>
<p><span class="math inline">\(\hspace{2cm} p_{1,m} \hspace{0.1cm}=\hspace{0.1cm} m\left[\hspace{0.1cm}1:(\lfloor Q_{1/k} \rfloor -1)\hspace{0.1cm}\right]\hspace{0.1cm}=\hspace{0.1cm}(m_1,...,m_{\lfloor Q_{1/k} \rfloor - 1} ) \\\)</span></p>
<p><span class="math inline">\(\hspace{2cm} p_{2,m} \hspace{0.1cm}=\hspace{0.1cm} m\left[\hspace{0.1cm}\lfloor Q_{1/k} \rfloor:(\lfloor Q_{2/k} \rfloor-1)\hspace{0.1cm}\right]\hspace{0.1cm}=\hspace{0.1cm}(m_{\lfloor Q_{1/k} \rfloor},...,m_{\lfloor Q_{2/k} \rfloor - 1})\)</span></p>
<p><span class="math inline">\(\hspace{2cm} \dots \\\)</span></p>
<p><span class="math inline">\(\hspace{2cm} p_{k,m} \hspace{0.1cm}=\hspace{0.1cm} m\left[\hspace{0.1cm}\lfloor Q_{(k-1)/k} \rfloor : N\hspace{0.1cm}\right]\hspace{0.1cm}=\hspace{0.1cm}(m_{\lfloor Q_{(k-1)/k} \rfloor},...,m_{N})\\[0.75cm]\)</span></p></li>
<li><p>Se puede demostrar que <span class="math inline">\(\hspace{0.1cm} p_{1,m}\hspace{0.1cm},...,\hspace{0.1cm} p_{k,m}\hspace{0.1cm}\)</span> tienen un número de elementos aproximadamente igual , por lo que son particiones aproximadamente igualitarias (balanceadas), que era lo que buscabamos.</p></li>
<li><p>La siguiente matriz ilustra por qué este método funciona: <span class="math inline">\(\\[0.02cm]\)</span></p></li>
</ul>
<p><span class="math display">\[\begin{pmatrix}
  1 &amp; m_1\\
  2 &amp; m_2\\
  ... &amp; ... \\
  \lfloor  Q_{1/k} \rfloor - 1  &amp; m_{\lfloor  Q_{1/k} \rfloor - 1} \\
  ----- &amp; ----- \\
  \lfloor  Q_{1/k} \rfloor  &amp; m_{\lfloor  Q_{1/k} \rfloor} \\
  ... &amp; ... \\
  \lfloor  Q_{2/k} \rfloor - 1  &amp; m_{\lfloor  Q_{2/k} \rfloor - 1} \\
  ----- &amp; -----\\
  \lfloor  Q_{2/k} \rfloor  &amp; m_{\lfloor  Q_{2/k} \rfloor} \\
  ... &amp; ... \\
   \lfloor  Q_{3/k} \rfloor - 1  &amp; m_{\lfloor  Q_{3/k} \rfloor - 1} \\
  ----- &amp; -----\\
  ... &amp; ... \\
  ... &amp; ... \\
  ----- &amp; -----\\
  \lfloor  Q_{(k-1)/k} \rfloor  &amp; m_{\lfloor  Q_{(k-1)/k} \rfloor} \\
  ... &amp; ... \\
  N &amp; m_N
  \end{pmatrix}\hspace{0.1cm} = \hspace{0.1cm} \begin{pmatrix}
  ... &amp; ...\\
  ... &amp; ...\\
  \text{Parte 1} \hspace{0.15cm}(p_{1,m})  &amp; \hspace{0.2cm} \approx N/k \hspace{0.15cm} \text{elementos} \\
  ... &amp; ...\\
  ----- &amp; -----\\
  ... &amp; ...\\
  \text{Parte 2}\hspace{0.15cm}(p_{2,m}) &amp; \hspace{0.2cm} \approx N/k \hspace{0.15cm} \text{elementos}  \\
  ... &amp; ...\\
  ----- &amp; -----\\
  ... &amp; ...\\
     \text{Parte 3}\hspace{0.15cm}(p_{3,m}) &amp; \hspace{0.2cm} \approx N/k \hspace{0.15cm} \text{elementos} \\
  ... &amp; ...\\
  ----- &amp; -----\\
  ... &amp; ...\\
  ... &amp; ...\\
  ----- &amp; -----\\
  ... &amp; ...\\
  \text{Parte k}\hspace{0.15cm}(p_{k,m}) &amp; \hspace{0.2cm} \approx N/k \hspace{0.15cm} \text{elementos} \\
  ... &amp; ...\\
  \end{pmatrix}\]</span></p></li>
</ul>
<p><span class="math inline">\(\\[0.35cm]\)</span></p>
<ul>
<li><p>Se obtienen la siguientes <span class="math inline">\(\hspace{0.1cm}k\hspace{0.1cm}\)</span> muestras de test: <span class="math inline">\(\\[0.01cm]\)</span></p>
<p><span class="math inline">\(\hspace{2cm} D_{test, 1} \hspace{0.1cm}=\hspace{0.1cm} D[\hspace{0.1cm} p_{1,m} \hspace{0.1cm} ,\hspace{0.1cm} : \hspace{0.1cm}] \hspace{0.1cm}=\hspace{0.1cm} D[\hspace{0.12cm}m[1:(\lfloor Q_{1/k} \rfloor -1)] \hspace{0.12cm},\hspace{0.12cm} : \hspace{0.12cm}]\)</span></p>
<p><span class="math inline">\(\hspace{2cm}D_{test, 2} \hspace{0.1cm}=\hspace{0.1cm} D[\hspace{0.1cm}p_{2,m} \hspace{0.1cm} ,\hspace{0.1cm} :\hspace{0.1cm}] \hspace{0.1cm}=\hspace{0.1cm} D[\hspace{0.12cm}m[\lfloor Q_{1/k} \rfloor : (\lfloor Q_{2/k} \rfloor - 1 )]\hspace{0.12cm} ,\hspace{0.12cm}:\hspace{0.12cm}]\)</span>$</p>
<p><span class="math inline">\(\hspace{2cm}\dots\)</span></p>
<p><span class="math inline">\(\hspace{2cm}D_{test, k}\hspace{0.1cm} =\hspace{0.1cm} D[\hspace{0.1cm}p_{k,m} \hspace{0.12cm} ,\hspace{0.12cm} :\hspace{0.12cm}] \hspace{0.1cm}=\hspace{0.1cm} D[\hspace{0.12cm}m[\lfloor Q_{(k-1)/k} \rfloor : N]\hspace{0.12cm} ,\hspace{0.12cm} :\hspace{0.12cm}] \\[0.7cm]\)</span></p></li>
<li><p>Se obtiene las siguientes <span class="math inline">\(\hspace{0.01cm}k\hspace{0.01cm}\)</span> muestras de train: <span class="math inline">\(\\[0.01cm]\)</span></p>
<p><span class="math inline">\(\hspace{2cm}D_{train, 1} \hspace{0.1cm}=\hspace{0.1cm} D[\hspace{0.12cm}-\hspace{0.12cm}p_{1,m} \hspace{0.12cm},\hspace{0.12cm} :\hspace{0.12cm}] \hspace{0.1cm}=\hspace{0.1cm} D[\hspace{0.12cm}-\hspace{0.12cm} m[1:(\lfloor Q_{1/k} \rfloor -1)] \hspace{0.12cm},\hspace{0.12cm}:\hspace{0.12cm}]\)</span></p>
<p><span class="math inline">\(\hspace{2cm}D_{train, 2} \hspace{0.1cm}=\hspace{0.1cm} D[\hspace{0.12cm}-\hspace{0.12cm} p_{2,m} \hspace{0.12cm},\hspace{0.12cm} :\hspace{0.12cm}] \hspace{0.1cm}=\hspace{0.1cm} D[\hspace{0.12cm}-\hspace{0.12cm}m[\lfloor Q_{1/k} \rfloor : (\lfloor Q_{2/k} \rfloor - 1 )] \hspace{0.12cm},\hspace{0.12cm}:\hspace{0.12cm}]\)</span></p>
<p><span class="math inline">\(\hspace{2cm} \dots\)</span></p>
<p><span class="math inline">\(\hspace{2cm}D_{train, k} \hspace{0.1cm}=\hspace{0.1cm} D[\hspace{0.12cm}-\hspace{0.12cm} p_{k,m} \hspace{0.12cm},\hspace{0.12cm} : \hspace{0.12cm}] \hspace{0.1cm}=\hspace{0.1cm} D[\hspace{0.12cm}-\hspace{0.12cm} m[\lfloor Q_{(k-1)/k} \rfloor : N] \hspace{0.12cm},\hspace{0.12cm} : \hspace{0.12cm}] \\[0.25cm]\)</span></p></li>
<li><p>Para <span class="math inline">\(\hspace{0.03cm}r \in \lbrace 1,...,k \rbrace\hspace{0.1cm}\)</span> :</p>
<ul>
<li><p>Se entrena el modelo <span class="math inline">\(\hspace{0.01cm}M\hspace{0.01cm}\)</span> con la <strong>muestra de train</strong> <span class="math inline">\(\hspace{0.01cm} D_{train,r}\)</span> <span class="math inline">\(\hspace{0.02cm}\Rightarrow\hspace{0.2cm}\)</span> <span class="math inline">\(\hspace{0.01cm}\widehat{M}_r\hspace{0.02cm}\)</span> .</p></li>
<li><p>Se calcula una misma métrica de evaluación sobre el modelo entrenado <span class="math inline">\(\hspace{0.01cm}\widehat{M}_r\hspace{0.01cm}\)</span> con la <strong>muestra de test</strong> <span class="math inline">\(\hspace{0.01cm}D_{test,r}\hspace{0.02cm}\)</span> .</p>
<ul>
<li><p>Supongamos que la métrica de evaluación usada es el <span class="math inline">\(\hspace{0.1cm}ECM\hspace{0.1cm}\)</span> , entonces se obtienen <span class="math inline">\(\hspace{0.1cm}k\hspace{0.1cm}\)</span> valores de esta métrica :</p>
<p><span class="math display">\[ECM_{test }\left(\widehat{M}_1\right) \hspace{0.1cm},\hspace{0.1cm}  ECM_{test }\left(\widehat{M}_2\right) \hspace{0.1cm}, ... ,\hspace{0.1cm} ECM_{test}\left( \widehat{M}_k \right)\\\]</span></p>
<p>Donde:</p>
<p><span class="math inline">\(\hspace{0.5cm} ECM_{test , r}\hspace{0.1cm}\)</span> es el <span class="math inline">\(\hspace{0.1cm}ECM\hspace{0.1cm}\)</span> calculado sobre <span class="math inline">\(\hspace{0.1cm}\widehat{M}_r\hspace{0.1cm}\)</span> usando <span class="math inline">\(\hspace{0.1cm}D_{test,r}\hspace{0.1cm}\)</span></p>
<p><span class="math display">\[ECM_{test }\left( \hspace{0.05cm} \widehat{M}_r \hspace{0.05cm}\right) \hspace{0.1cm}=\hspace{0.1cm} \dfrac{1}{\# D_{test, r}} \cdot \sum_{i=1}^{\# D_{test, r}} \hspace{0.1cm} \left( \hspace{0.1cm} y_i^{\hspace{0.1cm}test,r} - \hat{\hspace{0.1cm}y\hspace{0.1cm}}_i^{\hspace{0.1cm}test,r} \hspace{0.1cm} \right)^2 \\\]</span></p>
<p>Teniendo en cuenta que :</p>
<ul>
<li><p><span class="math inline">\(\hat{\hspace{0.1cm}y\hspace{0.1cm}}_i^{\hspace{0.1cm}test,r} \hspace{0.1cm}=\hspace{0.1cm} M\left(\hspace{0.1cm} x_i^{test, r} \hspace{0.1cm}|\hspace{0.1cm} D_{train,r} \right) \hspace{0.1cm}=\hspace{0.1cm} \widehat{M}_r \left(\hspace{0.1cm} x_i^{test, r} \hspace{0.1cm} \right)\)</span></p></li>
<li><p><span class="math inline">\(x_i^{\hspace{0.1cm}test,r}\hspace{0.1cm}\)</span> es la observación <span class="math inline">\(\hspace{0.1cm}i\)</span>-esima de la muestra de test <span class="math inline">\(\hspace{0.1cm}r\)</span>-esima de los predictores.</p></li>
<li><p><span class="math inline">\(y_i^{\hspace{0.1cm}test,r}\hspace{0.1cm}\)</span> es la observación <span class="math inline">\(\hspace{0.1cm}i\)</span>-esima de la muestra de test <span class="math inline">\(\hspace{0.1cm}r\)</span>-esima de la variable respuesta. <span class="math inline">\(\\[0.25cm]\)</span></p></li>
</ul></li>
</ul></li>
</ul></li>
<li><p>Se calcula la métrica final de evaluación del modelo como el promedio de las <span class="math inline">\(\hspace{0.01cm}k\hspace{0.01cm}\)</span> métricas calculadas en el paso anterior. Si la métrica usada fuera el ECM, entonces:</p>
<p><span class="math display">\[ECM({M})_{test}^{\hspace{0.08cm}*} \hspace{0.1cm}=\hspace{0.1cm} \dfrac{1}{k} \cdot \sum_{r=1}^k ECM_{test}(\widehat{M}_r)\]</span></p></li>
</ul>
</p>
</p>
<p></span></p>
</div>
<p><br></p>
<p><strong>Ventajas</strong></p>
<p>La metrica de validacion calculada por k-fold tiene menor varianza que con los métodos anteriores, luego es el mas preciso de todos ellos.</p>
<p><br></p>
</div>
<div id="repeted-k-fold" class="section level2 hasAnchor" number="5.6">
<h2 class="hasAnchor"><span class="header-section-number">5.6</span> Repeted k-fold<a href="#repeted-k-fold" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Este algoritmo consiste en <strong>repetir</strong> el algoritmo <strong>k-fold</strong> un número <span class="math inline">\(\hspace{0.01cm} B \hspace{0.01cm}\)</span> de veces.</p>
<p>No vamos a hacer aquí una descripción tan detallada del algoritmo como las anteriores, puesto que buena parte es repetir <span class="math inline">\(\hspace{0.01cm}B\hspace{0.01cm}\)</span> veces la estructura del k-fold. <span class="math inline">\(\\[0.1cm]\)</span></p>
<p>Sintetizando, los pasos del algoritmo <span class="math inline">\(\hspace{0.01cm}B\)</span>-repeated <span class="math inline">\(\hspace{0.01cm}k\)</span>-fold son los siguientes:</p>
<div class="warning" style="background-color:#F7EBE8; color: #030000; border-left: solid #CA0B0B 7px; border-radius: 3px; size:1px ; padding:0.1em;">
<p><span></p>
<p style="margin-left:1em;">
<ul>
<li><p>Se itera el algoritmo <span class="math inline">\(\hspace{0.01cm}k\)</span>-fold un total de <span class="math inline">\(\hspace{0.01cm}B\hspace{0.01cm}\)</span> veces. Con ello se obtienen <span class="math inline">\(\hspace{0.01cm}k\cdot B\hspace{0.01cm}\)</span> valores de la métrica de validacion, ya que cada iteracion del algoritmo k-fold produce <span class="math inline">\(\hspace{0.01cm}k\hspace{0.01cm}\)</span> valores de la métrica, y el algoritmo se itera <span class="math inline">\(\hspace{0.08cm}B\hspace{0.08cm}\)</span> veces. <span class="math inline">\(\\[0.04cm]\)</span></p>
<ul>
<li><p>Si la métrica usada para evaluar el modelo fuera el <span class="math inline">\(\hspace{0.01cm}ECM\hspace{0.01cm}\)</span> , entocnes se obtendrian los siguientes <span class="math inline">\(\hspace{0.01cm}k\cdot B\hspace{0.01cm}\)</span> valores de esta métrica:</p>
<p><span class="math display">\[ECM_{test }(\hspace{0.1cm}\widehat{M}_1^{\hspace{0.1cm}1}\hspace{0.1cm} ) \hspace{0.05cm}, ... ,\hspace{0.05cm} ECM_{test}\left(\hspace{0.1cm}\widehat{M}_k^{\hspace{0.1cm}1}\hspace{0.1cm}\right) \hspace{0.05cm},...,\hspace{0.05cm}ECM_{test }\left(\hspace{0.1cm}\widehat{M}_1^{\hspace{0.1cm}B}\hspace{0.1cm}\right) \hspace{0.05cm}, ... ,\hspace{0.05cm} ECM_{test}\left(\hspace{0.1cm}\widehat{M}_k^{\hspace{0.1cm}B} \hspace{0.1cm} \hspace{0.1cm}\right) \\\]</span></p>
<p>Donde, para <span class="math inline">\(\hspace{0.1cm}r\in \lbrace 1,...,k \rbrace\hspace{0.15cm}\)</span> y <span class="math inline">\(\hspace{0.15cm} j\in \lbrace 1,...,B \rbrace\)</span> :</p>
<ul>
<li><p><span class="math inline">\(\widehat{M}_r^{\hspace{0.1cm}j}\hspace{0.1cm}\)</span> es el modelo <span class="math inline">\(\hspace{0.1cm}M\hspace{0.1cm}\)</span> entrenado con la <strong>muestra de train</strong> <span class="math inline">\(\hspace{0.1cm}r\)</span>-esima obtenida en la iteración <span class="math inline">\(\hspace{0.1cm}j\)</span>-esima del algoritmo k-fold, es decir, es el modelo entrenado con la muestra de train <span class="math inline">\(\hspace{0.1cm}D_{train, r}^{\hspace{0.1cm}j}\)</span> .</p></li>
<li><p><span class="math inline">\(ECM_{test }\left(\hspace{0.1cm}\widehat{M}_r^{\hspace{0.1cm}j} \hspace{0.1cm}\right)\hspace{0.1cm}\)</span> es el <span class="math inline">\(\hspace{0.1cm}ECM\hspace{0.1cm}\)</span> calculado sobre el modelo <span class="math inline">\(\hspace{0.1cm}\widehat{M}_r^{\hspace{0.1cm}j}\hspace{0.1cm}\)</span> con la <strong>muestra de test</strong> <span class="math inline">\(\hspace{0.1cm}r\)</span>-esima obtenida en la repetición <span class="math inline">\(\hspace{0.1cm}j\)</span>-esima del algoritmo k-fold, es decir, con la muestra de test <span class="math inline">\(\hspace{0.1cm}D_{test, r}^{\hspace{0.1cm}j}\)</span> :</p></li>
</ul>
<p><span class="math display">\[ECM_{test }\left( \hspace{0.1cm} \widehat{M}_r^{\hspace{0.1cm}j} \hspace{0.1cm}\right) = \dfrac{1}{\# D_{test, r}^{\hspace{0.1cm}j}} \cdot \sum_{i=1}^{\# D_{test, r}^{\hspace{0.1cm}j}} \hspace{0.1cm} \left(\hspace{0.1cm} y_i^{\hspace{0.1cm}test,r,j} - \hat{\hspace{0.1cm}y\hspace{0.1cm}}_i^{\hspace{0.1cm}test,r,j} \hspace{0.1cm} \right)^2  \\[1cm]\]</span></p>
<p>Considerando lo siguiente :</p>
<ul>
<li><p><span class="math inline">\(\hat{y}_i^{\hspace{0.1cm}test,r,j} \hspace{0.1cm}=\hspace{0.1cm} M(\hspace{0.1cm} x_i^{\hspace{0.1cm}test, r,j} \hspace{0.12cm}|\hspace{0.12cm} D_{train,r}^{\hspace{0.1cm}j}) \hspace{0.1cm}=\hspace{0.1cm} \widehat{M}_r^{\hspace{0.1cm}j} (\hspace{0.1cm} x_i^{test, r,j} \hspace{0.1cm} )\)</span></p></li>
<li><p><span class="math inline">\(( \hspace{0.1cm} x_i^{\hspace{0.1cm} test, r,j} , y_i^{test, r,j} \hspace{0.1cm})\hspace{0.02cm}\)</span> es la observación (fila) <span class="math inline">\(\hspace{0.01cm}i\)</span>-esima de <span class="math inline">\(\hspace{0.01cm}D_{test,r}^{\hspace{0.1cm} j}\)</span></p></li>
<li><p><span class="math inline">\(x_i^{\hspace{0.1cm}test, r,j}\hspace{0.01cm}\)</span> es la observación <span class="math inline">\(\hspace{0.01cm}i\)</span>-esima de la muestra de test <span class="math inline">\(\hspace{0.01cm}r\)</span>-esima de los predictores obtenida en la repetición <span class="math inline">\(\hspace{0.01cm}j\)</span>-esima del algoritmo <span class="math inline">\(k\)</span>-folds.</p></li>
<li><p><span class="math inline">\(y_i^{\hspace{0.1cm}test, r,j}\hspace{0.1cm}\)</span> es la observacion <span class="math inline">\(\hspace{0.1cm}i\)</span>-esima de la muestra de test <span class="math inline">\(\hspace{0.1cm}r\)</span>-esima de la variable respuesta obtenida en la repetición <span class="math inline">\(\hspace{0.1cm}j\)</span>-esima del algoritmo k-folds.</p></li>
</ul>
<p>Nótese que debido al componente aleatorio presente en el algoritmo k-folds, cada vez que se repita el algoritmo se obtendran muestras de train y test diferentes. <span class="math inline">\(\\[0.5cm]\)</span></p></li>
</ul></li>
<li><p>Se calcula la métrica final de evaluación del modelo como el promedio de las <span class="math inline">\(\hspace{0.01cm}k\cdot B\hspace{0.01cm}\)</span> métricas calculadas en el paso anterior. Es decir, como el promedio de las <span class="math inline">\(\hspace{0.01cm}B\hspace{0.01cm}\)</span> metricas obtenidas al iterar <span class="math inline">\(\hspace{0.01cm}B\hspace{0.01cm}\)</span> veces el algoritmo k-fold.</p>
<ul>
<li><p>Si la métrica considerada es el <span class="math inline">\(\hspace{0.1cm}ECM\hspace{0.1cm}\)</span>, entonces:</p>
<p>En la iteración <span class="math inline">\(\hspace{0.01cm}j\)</span>-esima del algoritmo <span class="math inline">\(\hspace{0.01cm}k\)</span>-fold se obtiene como métrica de validación final:</p>
<p><span class="math display">\[ECM( {M})_{test}^{\hspace{0.08cm}j \hspace{0.05cm} *} \hspace{0.13cm} = \hspace{0.13cm}\dfrac{1}{k} \hspace{0.1cm} \cdot\hspace{0.1cm}   \sum_{r=1}^k \hspace{0.15cm}   ECM_{test}\left(\hspace{0.1cm}\widehat{M}_r^{\hspace{0.1cm}j}\hspace{0.1cm}\right) \\\]</span></p>
<p>Por lo tanto, la métrica de validación final obtenida con el algoritmo <span class="math inline">\(\hspace{0.08cm}B\)</span>-repeated <span class="math inline">\(\hspace{0.08cm}k\)</span>-fold es: <span class="math inline">\(\\[0.15cm]\)</span></p>
<p><span class="math display">\[ECM( {M})_{test}^{\hspace{0.08cm}*} \hspace{0.13cm} = \hspace{0.13cm} \dfrac{1}{ B} \hspace{0.1cm} \cdot\hspace{0.1cm} \sum_{j=1}^B ECM( {M})_{test}^{\hspace{0.08cm}j \hspace{0.05cm} *} \hspace{0.13cm} = \hspace{0.13cm}
  \dfrac{1}{k\cdot B} \hspace{0.1cm} \cdot\hspace{0.1cm} \sum_{j=1}^B \hspace{0.1cm} \sum_{r=1}^k \hspace{0.15cm}   ECM_{test}\left(\hspace{0.1cm}\widehat{M}_r^{\hspace{0.1cm}j}\hspace{0.1cm}\right)\\\]</span></p></li>
</ul></li>
</ul>
</p>
</p>
<p></span></p>
</div>
<p><br></p>
<p><strong>Ventajas</strong></p>
<p>La métrica de validación calculada por repeted k-fold tiene menor varianza que con los métodos anteriores, luego es el mas preciso de todos ellos. Este debería ser el método empleado en la práctica, siempre que se pueda, ya que también es el que mas requerimientos computacionales tiene.</p>
<p><br></p>
</div>
</div>
<div id="selección-de-modelos-basada-en-validación-cruzada" class="section level1 hasAnchor" number="6">
<h1 class="hasAnchor"><span class="header-section-number">6</span> Selección de modelos basada en validación cruzada<a href="#selección-de-modelos-basada-en-validación-cruzada" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>Dado un conjunto de modelos de aprendizaje supervisado, nos interesa establecer un criterio para seleccionar uno de ellos como el mejor.</p>
<p>A continuación se expone un criterio basado en las métricas y algoritmos de validación que se han visto anteriormente.</p>
<div class="warning" style="background-color:#F7EBE8; color: #030000; border-left: solid #CA0B0B 7px; border-radius: 3px; size:1px ; padding:0.1em;">
<p><span></p>
<p style="margin-left:1em;">
<ul>
<li><p>Supongamos que estamos ante un problema de regresión o clasificación supervisada.</p>
<ul>
<li>Tenemos <span class="math inline">\(\hspace{0.01cm}h\hspace{0.01cm}\)</span> modelos de aprendizaje supervisado <span class="math inline">\(\hspace{0.01cm}M_1\hspace{0.05cm},\hspace{0.05cm}M_2\hspace{0.05cm},...,\hspace{0.05cm}M_h\hspace{0.02cm}\)</span>.</li>
</ul></li>
<li><p>Se validan estos modelos usando un mismo algoritmo de validación, con una misma métrica de evaluación. Se obtendrán <span class="math inline">\(\hspace{0.01cm}h\hspace{0.01cm}\)</span> valores de la métrica, una para cada modelo.</p>
<ul>
<li>Si la métrica fuera el ECM se tendrian por ejemplo los siguientes valores: <span class="math inline">\(\\[0.05cm]\)</span></li>
</ul>
<p><span class="math display">\[ECM(M_1)_{test}^{\hspace{0.05cm} *} \hspace{0.1cm}, ...,\hspace{0.1cm} ECM(M_h)_{test}^{\hspace{0.05cm} *} \\\]</span></p></li>
<li><p>El criterio es seleccionar el modelo que tienen <strong>mejor</strong> valor de la métrica. Si es una <strong>métrica de error</strong>, el que <strong>menor</strong> valor tiene. Si es una <strong>métrica de acierto</strong>, el que <strong>mayor</strong> valor tiene.</p></li>
<li><p>Si la métrica es de <strong>error</strong>, como por ejemplo el <span class="math inline">\(\hspace{0.1cm}ECM\hspace{0.1cm}\)</span>, entonces:</p>
<ul>
<li>El modelo seleccionado es <span class="math inline">\(\hspace{0.1cm}M_{j^{\hspace{0.08cm}*}}\hspace{0.1cm}\)</span> , donde: <span class="math inline">\(\\[0.01cm]\)</span></li>
</ul>
<p><span class="math display">\[j^{\hspace{0.08cm}*} \hspace{0.1cm}=\hspace{0.1cm} arg \hspace{0.1cm} \underset{j \in \lbrace 1,...,h\rbrace }{Min} \hspace{0.15cm}  ECM(M_j)_{test}^{\hspace{0.05cm} *} \\[1cm]\]</span></p></li>
<li><p>Si la métrica es de <strong>acierto</strong>, como por ejemplo la <span class="math inline">\(\hspace{0.01cm}TAC\hspace{0.01cm}\)</span>, entonces:</p>
<ul>
<li>El modelo seleccionado es <span class="math inline">\(\hspace{0.01cm}M_{j^{\hspace{0.08cm}*}}\hspace{0.01cm}\)</span> , donde: <span class="math inline">\(\\[0.01cm]\)</span></li>
</ul>
<p><span class="math display">\[j^{\hspace{0.08cm}*} \hspace{0.1cm}=\hspace{0.1cm} arg \hspace{0.1cm} \underset{j \in \lbrace 1,...,h\rbrace }{Max} \hspace{0.15cm}  TAC(M_j)_{test}^{\hspace{0.05cm} *} \\\]</span></p></li>
</ul>
</p>
</p>
<p></span></p>
</div>
<p><br></p>
</div>
<div id="algoritmos-de-validación-cruzada-programados-en-python" class="section level1 hasAnchor" number="7">
<h1 class="hasAnchor"><span class="header-section-number">7</span> Algoritmos de validación cruzada programados en <code>Python</code><a href="#algoritmos-de-validación-cruzada-programados-en-python" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>Importamos las librerias que vamos a utilizar:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> math</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> sklearn</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.utils <span class="im">import</span> resample</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.neighbors <span class="im">import</span> NearestNeighbors</span></code></pre></div>
<p><br></p>
<p>Cargamos los datos con los que vamos a trabajar, los cuales fueron detallados en nuestro artículo sobre regresión lineal.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>Data <span class="op">=</span> pd.read_csv(<span class="st">&#39;House_Price_Regression.csv&#39;</span>)</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>Data <span class="op">=</span> Data.loc[:, [<span class="st">&#39;no_of_bedrooms&#39;</span> , <span class="st">&#39;no_of_bathrooms&#39;</span>, <span class="st">&#39;latitude&#39;</span>, <span class="st">&#39;longitude&#39;</span>, <span class="st">&#39;price&#39;</span>, <span class="st">&#39;size_in_m_2&#39;</span>, <span class="st">&#39;balcony_recode&#39;</span>, <span class="st">&#39;private_garden_recode&#39;</span>, <span class="st">&#39;quality_recode&#39;</span>]]</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>Data.head()</span></code></pre></div>
<div style="width: 100%; overflow-x: auto;">
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
no_of_bedrooms
</th>
<th>
no_of_bathrooms
</th>
<th>
latitude
</th>
<th>
longitude
</th>
<th>
price
</th>
<th>
size_in_m_2
</th>
<th>
balcony_recode
</th>
<th>
private_garden_recode
</th>
<th>
quality_recode
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
1
</td>
<td>
2
</td>
<td>
25.113208
</td>
<td>
55.138932
</td>
<td>
2700000
</td>
<td>
100.242337
</td>
<td>
1.0
</td>
<td>
0.0
</td>
<td>
2.0
</td>
</tr>
<tr>
<th>
1
</th>
<td>
2
</td>
<td>
2
</td>
<td>
25.106809
</td>
<td>
55.151201
</td>
<td>
2850000
</td>
<td>
146.972546
</td>
<td>
1.0
</td>
<td>
0.0
</td>
<td>
2.0
</td>
</tr>
<tr>
<th>
2
</th>
<td>
3
</td>
<td>
5
</td>
<td>
25.063302
</td>
<td>
55.137728
</td>
<td>
1150000
</td>
<td>
181.253753
</td>
<td>
1.0
</td>
<td>
0.0
</td>
<td>
2.0
</td>
</tr>
<tr>
<th>
3
</th>
<td>
2
</td>
<td>
3
</td>
<td>
25.227295
</td>
<td>
55.341761
</td>
<td>
2850000
</td>
<td>
187.664060
</td>
<td>
1.0
</td>
<td>
0.0
</td>
<td>
1.0
</td>
</tr>
<tr>
<th>
4
</th>
<td>
0
</td>
<td>
1
</td>
<td>
25.114275
</td>
<td>
55.139764
</td>
<td>
1729200
</td>
<td>
47.101821
</td>
<td>
0.0
</td>
<td>
0.0
</td>
<td>
2.0
</td>
</tr>
</tbody>
</table>
</div>
<p><br></p>
<p>A continuación se van a programar los algoritmos de validación cruzada que se han expuesto a nivel teórico anteriormente.</p>
<p>Además se probarán los algoritmos con el modelo KNN tanto en su versión para regresión como para clasificación.</p>
<p><br></p>
<div id="validación-simple-no-aleatoria-1" class="section level2 hasAnchor" number="7.1">
<h2 class="hasAnchor"><span class="header-section-number">7.1</span> Validación simple no aleatoria<a href="#validación-simple-no-aleatoria-1" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div class="sourceCode" id="cb3"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> NotRandomSimpleValidation :</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>    <span class="co"># D --&gt; have to be a pandas data frame.</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># k --&gt; is the proportion of observation of D that define D_train.</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>    <span class="co"># model --&gt; object containing the initialized model to use.</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># The function has been created thinking that the model to be used will be one from the `sklearn` library.</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># response_name --&gt; have to be a string with the name of the response variable.</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>    <span class="co"># metric --&gt; It&#39;s the name of the validation metric.</span></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, k, metric, model):</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.k <span class="op">=</span> k</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.metric <span class="op">=</span> metric</span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.model <span class="op">=</span> model</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> fit(<span class="va">self</span>, D, response_name):</span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>        N <span class="op">=</span> <span class="bu">len</span>(D)</span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.D_train <span class="op">=</span> D.iloc[<span class="dv">0</span>:(math.floor(<span class="va">self</span>.k <span class="op">*</span> N) <span class="op">+</span> <span class="dv">1</span>), :]</span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.D_test <span class="op">=</span> D.iloc[(math.floor(<span class="va">self</span>.k <span class="op">*</span> N) <span class="op">+</span> <span class="dv">1</span>):N, :]</span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.X_train <span class="op">=</span> <span class="va">self</span>.D_train.loc[:, <span class="va">self</span>.D_train.columns <span class="op">!=</span> response_name]</span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.Y_train <span class="op">=</span> <span class="va">self</span>.D_train.loc[:, response_name]</span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.X_test <span class="op">=</span> <span class="va">self</span>.D_test.loc[:, <span class="va">self</span>.D_test.columns <span class="op">!=</span> response_name]</span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.Y_test <span class="op">=</span> <span class="va">self</span>.D_test.loc[:, response_name]</span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.model.fit(<span class="va">self</span>.X_train, <span class="va">self</span>.Y_train)</span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> predict(<span class="va">self</span>):</span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.Y_predict_test <span class="op">=</span> <span class="va">self</span>.model.predict(<span class="va">self</span>.X_test)</span>
<span id="cb3-26"><a href="#cb3-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-27"><a href="#cb3-27" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> compute_metric(<span class="va">self</span>):</span>
<span id="cb3-28"><a href="#cb3-28" aria-hidden="true" tabindex="-1"></a>         <span class="cf">if</span> <span class="va">self</span>.metric <span class="op">==</span> <span class="st">&#39;ECM&#39;</span>:</span>
<span id="cb3-29"><a href="#cb3-29" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.ECM_test <span class="op">=</span> np.mean((<span class="va">self</span>.Y_predict_test <span class="op">-</span> <span class="va">self</span>.Y_test) <span class="op">**</span> <span class="dv">2</span>)</span>
<span id="cb3-30"><a href="#cb3-30" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> <span class="va">self</span>.ECM_test</span>
<span id="cb3-31"><a href="#cb3-31" aria-hidden="true" tabindex="-1"></a>        <span class="cf">elif</span> <span class="va">self</span>.metric <span class="op">==</span> <span class="st">&#39;TAC&#39;</span>:</span>
<span id="cb3-32"><a href="#cb3-32" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.TAC_test <span class="op">=</span> np.mean((<span class="va">self</span>.Y_predict_test <span class="op">==</span> <span class="va">self</span>.Y_test))</span>
<span id="cb3-33"><a href="#cb3-33" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> <span class="va">self</span>.TAC_test</span></code></pre></div>
<p><br></p>
<div id="ejemplo-de-aplicación-a-knn-para-regresión" class="section level3 hasAnchor" number="7.1.1">
<h3 class="hasAnchor"><span class="header-section-number">7.1.1</span> Ejemplo de aplicación a KNN para regresión<a href="#ejemplo-de-aplicación-a-knn-para-regresión" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Definimos el modelo KNN para regresión con el que vamos a testear el algoritmo que se acaba de programar:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>knn_regression_init <span class="op">=</span> sklearn.neighbors.KNeighborsRegressor(n_neighbors<span class="op">=</span><span class="dv">10</span> ,  p<span class="op">=</span><span class="dv">2</span>, metric<span class="op">=</span><span class="st">&#39;minkowski&#39;</span>)</span></code></pre></div>
<p><br></p>
<p>Aplicamos el algoritmo de validación sobre el modelo KNN para regresión, usando como métrica de validación el error cuadratico medio (ECM):</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>NotRandomSimpleValidation_init <span class="op">=</span> NotRandomSimpleValidation(k<span class="op">=</span><span class="fl">0.75</span>, metric<span class="op">=</span><span class="st">&#39;ECM&#39;</span>, model<span class="op">=</span>knn_regression_init)</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>NotRandomSimpleValidation_init.fit(D<span class="op">=</span>Data, response_name<span class="op">=</span><span class="st">&#39;price&#39;</span>)</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>NotRandomSimpleValidation_init.predict()</span></code></pre></div>
<div class="sourceCode" id="cb6"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>ECM_test_Not_Random_Simple_Validation <span class="op">=</span> NotRandomSimpleValidation_init.compute_metric()</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>ECM_test_Not_Random_Simple_Validation</span></code></pre></div>
<pre><code>2176125958588.6355</code></pre>
<p><br></p>
</div>
<div id="ejemplo-de-aplicación-a-knn-para-clasificación" class="section level3 hasAnchor" number="7.1.2">
<h3 class="hasAnchor"><span class="header-section-number">7.1.2</span> Ejemplo de aplicación a KNN para clasificación<a href="#ejemplo-de-aplicación-a-knn-para-clasificación" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Definimos el modelo KNN para clasificación con el que vamos a testear el algoritmo que se acaba de programar:</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>knn_classification_init <span class="op">=</span> sklearn.neighbors.KNeighborsClassifier(n_neighbors<span class="op">=</span><span class="dv">10</span>,  p<span class="op">=</span><span class="dv">2</span>, metric<span class="op">=</span><span class="st">&#39;minkowski&#39;</span>)</span></code></pre></div>
<p><br></p>
<p>Aplicamos el algoritmo de validación simple no aleatoria sobre el modelo KNN para clasificación, usando como métrica de validación la tasa de acierto (TA):</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>NotRandomSimpleValidation_init <span class="op">=</span> NotRandomSimpleValidation(k<span class="op">=</span><span class="fl">0.75</span>, metric<span class="op">=</span><span class="st">&#39;TAC&#39;</span>, model<span class="op">=</span>knn_classification_init)</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>NotRandomSimpleValidation_init.fit(D<span class="op">=</span>Data, response_name<span class="op">=</span><span class="st">&#39;quality_recode&#39;</span>)</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>NotRandomSimpleValidation_init.predict()</span></code></pre></div>
<div class="sourceCode" id="cb10"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>TAC_test_Not_Random_Simple_Validation <span class="op">=</span> NotRandomSimpleValidation_init.compute_metric()</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>TAC_test_Not_Random_Simple_Validation</span></code></pre></div>
<pre><code>0.5609243697478992</code></pre>
<p><br></p>
</div>
</div>
<div id="validación-simple-aleatoria-1" class="section level2 hasAnchor" number="7.2">
<h2 class="hasAnchor"><span class="header-section-number">7.2</span> Validación simple aleatoria<a href="#validación-simple-aleatoria-1" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div class="sourceCode" id="cb12"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> RandomSimpleValidation :</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>    <span class="co"># D --&gt; have to be a pandas data frame.</span></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># k --&gt; is the proportion of observation of D that define D_train.</span></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>    <span class="co"># response --&gt; have to be a string with the name of the response variable.</span></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># model --&gt; object containing the initialized model to use.</span></span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># The function has been created thinking that the model to be used will be one from the `sklearn` library.</span></span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>    <span class="co"># metric --&gt; It&#39;s the name of the validation metric.</span></span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># random_seed --&gt; seed to replicate the random process.</span></span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, k, metric, model, random_seed):</span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.k <span class="op">=</span> k</span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.metric <span class="op">=</span> metric</span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.model <span class="op">=</span> model</span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.random_seed <span class="op">=</span> random_seed</span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> fit(<span class="va">self</span>, D, response_name):</span>
<span id="cb12-17"><a href="#cb12-17" aria-hidden="true" tabindex="-1"></a>        N <span class="op">=</span> <span class="bu">len</span>(D)</span>
<span id="cb12-18"><a href="#cb12-18" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.D_train <span class="op">=</span> D.sample(frac<span class="op">=</span><span class="va">self</span>.k, replace<span class="op">=</span><span class="va">False</span>, random_state<span class="op">=</span><span class="va">self</span>.random_seed)</span>
<span id="cb12-19"><a href="#cb12-19" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.D_test <span class="op">=</span> D.drop( <span class="va">self</span>.D_train.index , )</span>
<span id="cb12-20"><a href="#cb12-20" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.X_train <span class="op">=</span> <span class="va">self</span>.D_train.loc[: , <span class="va">self</span>.D_train.columns <span class="op">!=</span> response_name]</span>
<span id="cb12-21"><a href="#cb12-21" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.Y_train <span class="op">=</span> <span class="va">self</span>.D_train.loc[: , response_name]</span>
<span id="cb12-22"><a href="#cb12-22" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.X_test <span class="op">=</span> <span class="va">self</span>.D_test.loc[: , <span class="va">self</span>.D_test.columns <span class="op">!=</span> response_name]</span>
<span id="cb12-23"><a href="#cb12-23" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.Y_test <span class="op">=</span> <span class="va">self</span>.D_test.loc[: , response_name]</span>
<span id="cb12-24"><a href="#cb12-24" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.model.fit(<span class="va">self</span>.X_train, <span class="va">self</span>.Y_train)</span>
<span id="cb12-25"><a href="#cb12-25" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb12-26"><a href="#cb12-26" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> predict(<span class="va">self</span>):</span>
<span id="cb12-27"><a href="#cb12-27" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.Y_predict_test <span class="op">=</span> <span class="va">self</span>.model.predict(<span class="va">self</span>.X_test)</span>
<span id="cb12-28"><a href="#cb12-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-29"><a href="#cb12-29" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> compute_metric(<span class="va">self</span>):</span>
<span id="cb12-30"><a href="#cb12-30" aria-hidden="true" tabindex="-1"></a>       <span class="cf">if</span> <span class="va">self</span>.metric <span class="op">==</span> <span class="st">&#39;ECM&#39;</span>:</span>
<span id="cb12-31"><a href="#cb12-31" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.ECM_test <span class="op">=</span> np.mean((<span class="va">self</span>.Y_predict_test <span class="op">-</span> <span class="va">self</span>.Y_test) <span class="op">**</span> <span class="dv">2</span>)</span>
<span id="cb12-32"><a href="#cb12-32" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> <span class="va">self</span>.ECM_test</span>
<span id="cb12-33"><a href="#cb12-33" aria-hidden="true" tabindex="-1"></a>        <span class="cf">elif</span> <span class="va">self</span>.metric <span class="op">==</span> <span class="st">&#39;TAC&#39;</span>:</span>
<span id="cb12-34"><a href="#cb12-34" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.TAC_test <span class="op">=</span> np.mean((<span class="va">self</span>.Y_predict_test <span class="op">==</span> <span class="va">self</span>.Y_test))</span>
<span id="cb12-35"><a href="#cb12-35" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> <span class="va">self</span>.TAC_test</span></code></pre></div>
<p><br></p>
<div id="ejemplo-de-aplicación-a-knn-para-regresión-1" class="section level3 hasAnchor" number="7.2.1">
<h3 class="hasAnchor"><span class="header-section-number">7.2.1</span> Ejemplo de aplicación a KNN para regresión<a href="#ejemplo-de-aplicación-a-knn-para-regresión-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Definimos el modelo KNN para regresión con el que vamos a testear el algoritmo que se acaba de programar:</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>knn_regression_init <span class="op">=</span> sklearn.neighbors.KNeighborsRegressor(n_neighbors<span class="op">=</span><span class="dv">10</span> ,  p<span class="op">=</span><span class="dv">2</span>, metric<span class="op">=</span><span class="st">&#39;minkowski&#39;</span>)</span></code></pre></div>
<p><br></p>
<p>Aplicamos el algoritmo de validación simple aleatoria sobre el modelo KNN para regresión, usando como métrica de validación el error cuadratico medio (ECM):</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>RandomSimpleValidation_init <span class="op">=</span> RandomSimpleValidation(k<span class="op">=</span><span class="fl">0.75</span>, metric<span class="op">=</span><span class="st">&#39;ECM&#39;</span>, model<span class="op">=</span>knn_regression_init, random_seed<span class="op">=</span><span class="dv">123</span>)</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>RandomSimpleValidation_init.fit(D<span class="op">=</span>Data, response_name<span class="op">=</span><span class="st">&#39;price&#39;</span>)</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>RandomSimpleValidation_init.predict()</span></code></pre></div>
<div class="sourceCode" id="cb15"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>ECM_test_Random_Simple_Validation  <span class="op">=</span> RandomSimpleValidation_init.compute_metric()</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>ECM_test_Random_Simple_Validation</span></code></pre></div>
<pre><code>2464363295205.937</code></pre>
<p><br></p>
</div>
<div id="ejemplo-de-aplicación-a-knn-para-clasifación" class="section level3 hasAnchor" number="7.2.2">
<h3 class="hasAnchor"><span class="header-section-number">7.2.2</span> Ejemplo de aplicación a KNN para clasifación<a href="#ejemplo-de-aplicación-a-knn-para-clasifación" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Definimos el modelo KNN para clasificacion con el que vamos a testear el algoritmo que se acaba de programar:</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>knn_classification_init <span class="op">=</span> sklearn.neighbors.KNeighborsClassifier(n_neighbors<span class="op">=</span><span class="dv">10</span> ,  p<span class="op">=</span><span class="dv">2</span>, metric<span class="op">=</span><span class="st">&#39;minkowski&#39;</span>)</span></code></pre></div>
<p><br></p>
<p>Aplicamos el algoritmo de validación simple aleatoria sobre el modelo KNN para clasificación, usando como métrica de validación la tasa de acierto (TA):</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>RandomSimpleValidation_init <span class="op">=</span> RandomSimpleValidation(k<span class="op">=</span><span class="fl">0.75</span>, metric<span class="op">=</span><span class="st">&#39;TAC&#39;</span>, model<span class="op">=</span>knn_classification_init, random_seed<span class="op">=</span><span class="dv">123</span>)</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>RandomSimpleValidation_init.fit(D<span class="op">=</span>Data, reesponse_name<span class="op">=</span><span class="st">&#39;quality_recode&#39;</span>)</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>RandomSimpleValidation_init.predict()</span></code></pre></div>
<div class="sourceCode" id="cb19"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>TAC_test_Random_Simple_Validation <span class="op">=</span> RandomSimpleValidation_init.compute_metric()</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>TAC_test_Random_Simple_Validation</span></code></pre></div>
<pre><code>0.5777310924369747</code></pre>
<p><br></p>
</div>
</div>
<div id="validación-simple-aleatoria-repetida-1" class="section level2 hasAnchor" number="7.3">
<h2 class="hasAnchor"><span class="header-section-number">7.3</span> Validación simple aleatoria repetida<a href="#validación-simple-aleatoria-repetida-1" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div class="sourceCode" id="cb21"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> RepeatedRandomSimpleValidation :</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># D --&gt; It have to be a pandas data frame.</span></span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>    <span class="co"># B --&gt; It&#39;s the number of iterations of the Random Simple Validation algorithm.    </span></span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># k --&gt; It&#39;s the proportion of observation of D that define D_train.</span></span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># response --&gt; It have to be a string with the name of the response variable.</span></span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a>    <span class="co"># model --&gt; It&#39;s an object containing the initialized model to use.</span></span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># The function has been created thinking that the model to be used will be one from the `sklearn` library.</span></span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># metric --&gt; It&#39;s the name of the validation metric.</span></span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># random_seed --&gt; It&#39;s the seed to replicate the random process</span></span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, B, k, metric, model, random_seed):</span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.B <span class="op">=</span> B</span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.k <span class="op">=</span> k</span>
<span id="cb21-15"><a href="#cb21-15" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.metric <span class="op">=</span> metric</span>
<span id="cb21-16"><a href="#cb21-16" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.model <span class="op">=</span> model</span>
<span id="cb21-17"><a href="#cb21-17" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.random_seed <span class="op">=</span> random_seed</span>
<span id="cb21-18"><a href="#cb21-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-19"><a href="#cb21-19" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> fit(<span class="va">self</span>, D, response_name):</span>
<span id="cb21-20"><a href="#cb21-20" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.D <span class="op">=</span> D</span>
<span id="cb21-21"><a href="#cb21-21" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.response_name <span class="op">=</span> response_name</span>
<span id="cb21-22"><a href="#cb21-22" aria-hidden="true" tabindex="-1"></a>        np.random.seed(<span class="va">self</span>.random_seed)    </span>
<span id="cb21-23"><a href="#cb21-23" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.seed_array <span class="op">=</span> np.random.randint(<span class="dv">9999999</span>, size<span class="op">=</span>(<span class="va">self</span>.B))</span>
<span id="cb21-24"><a href="#cb21-24" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb21-25"><a href="#cb21-25" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb21-26"><a href="#cb21-26" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> compute_metric(<span class="va">self</span>):</span>
<span id="cb21-27"><a href="#cb21-27" aria-hidden="true" tabindex="-1"></a>            Metric_test_list <span class="op">=</span> [ ]</span>
<span id="cb21-28"><a href="#cb21-28" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> b <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">0</span>,<span class="va">self</span>.B) :</span>
<span id="cb21-29"><a href="#cb21-29" aria-hidden="true" tabindex="-1"></a>            RandomSimpleValidation_init <span class="op">=</span> RandomSimpleValidation(k<span class="op">=</span><span class="va">self</span>.k, metric<span class="op">=</span><span class="va">self</span>.metric, model<span class="op">=</span><span class="va">self</span>.model, random_seed<span class="op">=</span><span class="va">self</span>.seed_array[b])</span>
<span id="cb21-30"><a href="#cb21-30" aria-hidden="true" tabindex="-1"></a>            RandomSimpleValidation_init.fit(D<span class="op">=</span><span class="va">self</span>.D,  response_name<span class="op">=</span><span class="va">self</span>.response_name)</span>
<span id="cb21-31"><a href="#cb21-31" aria-hidden="true" tabindex="-1"></a>            RandomSimpleValidation_init.predict()</span>
<span id="cb21-32"><a href="#cb21-32" aria-hidden="true" tabindex="-1"></a>            Metric_test_list.append( RandomSimpleValidation_init.compute_metric() )</span>
<span id="cb21-33"><a href="#cb21-33" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.Metric_test <span class="op">=</span> np.mean(Metric_test_list)    </span>
<span id="cb21-34"><a href="#cb21-34" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.Metric_test</span></code></pre></div>
<p><br></p>
<div id="ejemplo-de-aplicación-a-knn-para-regresión-2" class="section level3 hasAnchor" number="7.3.1">
<h3 class="hasAnchor"><span class="header-section-number">7.3.1</span> Ejemplo de aplicación a KNN para regresión<a href="#ejemplo-de-aplicación-a-knn-para-regresión-2" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Definimos el modelo KNN para regresión con el que vamos a testear el algoritmo que se acaba de programar:</p>
<div class="sourceCode" id="cb22"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>knn_regression_init <span class="op">=</span> sklearn.neighbors.KNeighborsRegressor(n_neighbors<span class="op">=</span><span class="dv">10</span> ,  p<span class="op">=</span><span class="dv">2</span>, metric<span class="op">=</span><span class="st">&#39;minkowski&#39;</span>)</span></code></pre></div>
<p><br></p>
<p>Aplicamos el algoritmo de validación simple aleatoria repetida sobre el modelo KNN para regresión, usando como métrica de validación el error cuadrático medio (ECM):</p>
<div class="sourceCode" id="cb23"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>RepeatedRandomSimpleValidation_init <span class="op">=</span> RepeatedRandomSimpleValidation(B<span class="op">=</span><span class="dv">200</span>, k<span class="op">=</span><span class="fl">0.75</span>, metric<span class="op">=</span><span class="st">&#39;ECM&#39;</span>, model<span class="op">=</span>knn_regression_init, random_seed<span class="op">=</span><span class="dv">123</span>)</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>RepeatedRandomSimpleValidation_init.fit(D<span class="op">=</span>Data, response_name<span class="op">=</span><span class="st">&#39;price&#39;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb24"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>ECM_test_Repeated_Random_Simple_Validation <span class="op">=</span> RepeatedRandomSimpleValidation_init.compute_metric()</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>ECM_test_Repeated_Random_Simple_Validation</span></code></pre></div>
<pre><code>2273253730249.1133</code></pre>
<p><br></p>
</div>
<div id="ejemplo-de-aplicación-a-knn-para-clasificación-1" class="section level3 hasAnchor" number="7.3.2">
<h3 class="hasAnchor"><span class="header-section-number">7.3.2</span> Ejemplo de aplicación a KNN para clasificación<a href="#ejemplo-de-aplicación-a-knn-para-clasificación-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Definimos el modelo KNN para clasificación con el que vamos a testear el algoritmo que se acaba de programar:</p>
<div class="sourceCode" id="cb26"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>knn_classification_init <span class="op">=</span> sklearn.neighbors.KNeighborsClassifier(n_neighbors<span class="op">=</span><span class="dv">10</span>,  p<span class="op">=</span><span class="dv">2</span>, metric<span class="op">=</span><span class="st">&#39;minkowski&#39;</span>)</span></code></pre></div>
<p><br></p>
<p>Aplicamos el algoritmo de validación simple aleatoria repetida sobre el modelo KNN para clasificación, usando como métrica de validación la tasa de acierto (TA):</p>
<div class="sourceCode" id="cb27"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>RepeatedRandomSimpleValidation_init <span class="op">=</span> RepeatedRandomSimpleValidation(B<span class="op">=</span><span class="dv">200</span>, k<span class="op">=</span><span class="fl">0.75</span>,  metric<span class="op">=</span><span class="st">&#39;TAC&#39;</span>, model<span class="op">=</span>knn_classification_init, random_seed<span class="op">=</span><span class="dv">123</span>)</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>RepeatedRandomSimpleValidation_init.fit(D<span class="op">=</span>Data, response_name<span class="op">=</span><span class="st">&#39;quality_recode&#39;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb28"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>TAC_test_Repeated_Random_Simple_Validation <span class="op">=</span> RepeatedRandomSimpleValidation_init.compute_metric()</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>TAC_test_Repeated_Random_Simple_Validation</span></code></pre></div>
<pre><code>0.5515546218487395 </code></pre>
<p><br></p>
</div>
</div>
<div id="leave-one-out-1" class="section level2 hasAnchor" number="7.4">
<h2 class="hasAnchor"><span class="header-section-number">7.4</span> Leave one out<a href="#leave-one-out-1" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div class="sourceCode" id="cb30"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> LeaveOneOutValidation:</span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a>  <span class="co"># D --&gt; It have to be a pandas data frame.</span></span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a>    <span class="co"># response_name --&gt; It have to be a string with the name of the response variable.</span></span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># model --&gt; It&#39;s an object containing the initialized model to use.</span></span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># The function has been created thinking that the model to be used will be one from the `sklearn` library.</span></span>
<span id="cb30-7"><a href="#cb30-7" aria-hidden="true" tabindex="-1"></a>    <span class="co"># metric --&gt; It&#39;s the name of the validation metric.</span></span>
<span id="cb30-8"><a href="#cb30-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># random_seed --&gt; It&#39;s the seed to replicate the random process.</span></span>
<span id="cb30-9"><a href="#cb30-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-10"><a href="#cb30-10" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, metric, model):</span>
<span id="cb30-11"><a href="#cb30-11" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.metric <span class="op">=</span> metric</span>
<span id="cb30-12"><a href="#cb30-12" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.model <span class="op">=</span> model</span>
<span id="cb30-13"><a href="#cb30-13" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.ECM_test_list <span class="op">=</span> []</span>
<span id="cb30-14"><a href="#cb30-14" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.TA_test_list <span class="op">=</span> []</span>
<span id="cb30-15"><a href="#cb30-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-16"><a href="#cb30-16" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> fit(<span class="va">self</span>, D, response_name):</span>
<span id="cb30-17"><a href="#cb30-17" aria-hidden="true" tabindex="-1"></a>        N <span class="op">=</span> <span class="bu">len</span>(D)</span>
<span id="cb30-18"><a href="#cb30-18" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> r <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">0</span>, N):</span>
<span id="cb30-19"><a href="#cb30-19" aria-hidden="true" tabindex="-1"></a>            D_test <span class="op">=</span> D.iloc[r, :]</span>
<span id="cb30-20"><a href="#cb30-20" aria-hidden="true" tabindex="-1"></a>            D_train <span class="op">=</span> D.drop(r, )</span>
<span id="cb30-21"><a href="#cb30-21" aria-hidden="true" tabindex="-1"></a>            X_train <span class="op">=</span> D_train.loc[:, D_train.columns <span class="op">!=</span> response_name]</span>
<span id="cb30-22"><a href="#cb30-22" aria-hidden="true" tabindex="-1"></a>            Y_train <span class="op">=</span> D_train.loc[:, response_name]</span>
<span id="cb30-23"><a href="#cb30-23" aria-hidden="true" tabindex="-1"></a>            X_test <span class="op">=</span> D_test.loc[D_test.index <span class="op">!=</span> response_name]</span>
<span id="cb30-24"><a href="#cb30-24" aria-hidden="true" tabindex="-1"></a>            Y_test <span class="op">=</span> D_test.loc[response_name]</span>
<span id="cb30-25"><a href="#cb30-25" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.model.fit(X_train, Y_train)</span>
<span id="cb30-26"><a href="#cb30-26" aria-hidden="true" tabindex="-1"></a>            Y_predict_test <span class="op">=</span> <span class="va">self</span>.model.predict(pd.DataFrame([X_test]))</span>
<span id="cb30-27"><a href="#cb30-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-28"><a href="#cb30-28" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> <span class="va">self</span>.metric <span class="op">==</span> <span class="st">&#39;ECM&#39;</span>:</span>
<span id="cb30-29"><a href="#cb30-29" aria-hidden="true" tabindex="-1"></a>                <span class="va">self</span>.ECM_test_list.append(np.mean((Y_predict_test <span class="op">-</span> Y_test)<span class="op">**</span><span class="dv">2</span>))</span>
<span id="cb30-30"><a href="#cb30-30" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb30-31"><a href="#cb30-31" aria-hidden="true" tabindex="-1"></a>            <span class="cf">elif</span> <span class="va">self</span>.metric <span class="op">==</span> <span class="st">&#39;TAC&#39;</span>:</span>
<span id="cb30-32"><a href="#cb30-32" aria-hidden="true" tabindex="-1"></a>                <span class="va">self</span>.TA_test_list.append(np.mean((Y_predict_test <span class="op">==</span> Y_test)))</span>
<span id="cb30-33"><a href="#cb30-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-34"><a href="#cb30-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-35"><a href="#cb30-35" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> compute_metric(<span class="va">self</span>):</span>
<span id="cb30-36"><a href="#cb30-36" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.metric <span class="op">==</span> <span class="st">&#39;ECM&#39;</span>:</span>
<span id="cb30-37"><a href="#cb30-37" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> np.mean(<span class="va">self</span>.ECM_test_list)</span>
<span id="cb30-38"><a href="#cb30-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-39"><a href="#cb30-39" aria-hidden="true" tabindex="-1"></a>        <span class="cf">elif</span> <span class="va">self</span>.metric <span class="op">==</span> <span class="st">&#39;TAC&#39;</span>:</span>
<span id="cb30-40"><a href="#cb30-40" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> np.mean(<span class="va">self</span>.TA_test_list)</span></code></pre></div>
<p><br></p>
<div id="ejemplo-de-aplicación-a-kkn-para-regresión" class="section level3 hasAnchor" number="7.4.1">
<h3 class="hasAnchor"><span class="header-section-number">7.4.1</span> Ejemplo de aplicación a KKN para regresión<a href="#ejemplo-de-aplicación-a-kkn-para-regresión" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Definimos el modelo KNN para regresión con el que vamos a testear el algoritmo que se acaba de programar:</p>
<div class="sourceCode" id="cb31"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a>knn_regression_init <span class="op">=</span> sklearn.neighbors.KNeighborsRegressor(n_neighbors<span class="op">=</span><span class="dv">10</span>, p<span class="op">=</span><span class="dv">2</span>, metric<span class="op">=</span><span class="st">&#39;minkowski&#39;</span>)</span></code></pre></div>
<p><br></p>
<p>Aplicamos el algoritmo de validación leave one out sobre el modelo KNN para regresión, usando como métrica de validación el error cuadratico medio (ECM):</p>
<div class="sourceCode" id="cb32"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a>LeaveOneOutValidation_init <span class="op">=</span> LeaveOneOutValidation(metric<span class="op">=</span><span class="st">&#39;ECM&#39;</span>, model<span class="op">=</span>knn_regression_init)</span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a>LeaveOneOutValidation_init.fit(D<span class="op">=</span>Data, response_name<span class="op">=</span><span class="st">&#39;price&#39;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb33"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a>ECM_test_leave_one_out <span class="op">=</span> LeaveOneOutValidation_init.compute_metric()</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a>ECM_test_leave_one_out</span></code></pre></div>
<pre><code>2268581861335.2305</code></pre>
<p><br></p>
<p><br></p>
</div>
<div id="ejemplo-de-aplicación-a-kkn-para-clasificación" class="section level3 hasAnchor" number="7.4.2">
<h3 class="hasAnchor"><span class="header-section-number">7.4.2</span> Ejemplo de aplicación a KKN para clasificación<a href="#ejemplo-de-aplicación-a-kkn-para-clasificación" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Definimos el modelo KNN para clasificación con el que vamos a testear el algoritmo que se acaba de programar:</p>
<div class="sourceCode" id="cb35"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>knn_classification_init <span class="op">=</span> sklearn.neighbors.KNeighborsClassifier(n_neighbors<span class="op">=</span><span class="dv">10</span>, p<span class="op">=</span><span class="dv">2</span>, metric<span class="op">=</span><span class="st">&#39;minkowski&#39;</span>)</span></code></pre></div>
<p><br></p>
<p>Aplicamos el algoritmo de validación leave one out sobre el modelo KNN para clasificación, usando como métrica de validación la tasa de acierto (TAC):</p>
<div class="sourceCode" id="cb36"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a>LeaveOneOutValidation_init <span class="op">=</span> LeaveOneOutValidation(metric<span class="op">=</span><span class="st">&#39;TAC&#39;</span>, model<span class="op">=</span>knn_classification_init)</span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a>LeaveOneOutValidation_init.fit(D<span class="op">=</span>Data, response_name<span class="op">=</span><span class="st">&#39;quality_recode&#39;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb37"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a>TAC_test_leave_one_out <span class="op">=</span> LeaveOneOutValidation_init.compute_metric()</span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a>TAC_test_leave_one_out</span></code></pre></div>
<pre><code>0.5511811023622047</code></pre>
<p><br></p>
</div>
</div>
<div id="k-fold-1" class="section level2 hasAnchor" number="7.5">
<h2 class="hasAnchor"><span class="header-section-number">7.5</span> k-fold<a href="#k-fold-1" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div class="sourceCode" id="cb39"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> KFoldCV:</span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># D --&gt; It have to be a pandas data frame.</span></span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a>    <span class="co"># K --&gt; It&#39;s the number of folds of K-fold algorithm..</span></span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># response_name --&gt; It have to be a string with the name of the response variable.</span></span>
<span id="cb39-6"><a href="#cb39-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># model --&gt; It&#39;s an object containing the initialized model to use.</span></span>
<span id="cb39-7"><a href="#cb39-7" aria-hidden="true" tabindex="-1"></a>    <span class="co"># The function has been created thinking that the model to be used will be one from the `sklearn` library.</span></span>
<span id="cb39-8"><a href="#cb39-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># metric --&gt; It&#39;s the name of the validation metric.</span></span>
<span id="cb39-9"><a href="#cb39-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># random_seed --&gt; It&#39;s the seed to replicate the random process.</span></span>
<span id="cb39-10"><a href="#cb39-10" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb39-11"><a href="#cb39-11" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, D, K, response_name, random_seed, metric, model):</span>
<span id="cb39-12"><a href="#cb39-12" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.D <span class="op">=</span> D</span>
<span id="cb39-13"><a href="#cb39-13" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.K <span class="op">=</span> K</span>
<span id="cb39-14"><a href="#cb39-14" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.response_name <span class="op">=</span> response_name</span>
<span id="cb39-15"><a href="#cb39-15" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.random_seed <span class="op">=</span> random_seed</span>
<span id="cb39-16"><a href="#cb39-16" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.metric <span class="op">=</span> metric</span>
<span id="cb39-17"><a href="#cb39-17" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.model <span class="op">=</span> model</span>
<span id="cb39-18"><a href="#cb39-18" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.ECM_K_FOLDS_vector <span class="op">=</span> []</span>
<span id="cb39-19"><a href="#cb39-19" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.TA_K_FOLDS_vector <span class="op">=</span> []</span>
<span id="cb39-20"><a href="#cb39-20" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.df_sample <span class="op">=</span> <span class="va">None</span></span>
<span id="cb39-21"><a href="#cb39-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-22"><a href="#cb39-22" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> __resample_df(<span class="va">self</span>):</span>
<span id="cb39-23"><a href="#cb39-23" aria-hidden="true" tabindex="-1"></a>        np.random.seed(<span class="va">self</span>.random_seed)</span>
<span id="cb39-24"><a href="#cb39-24" aria-hidden="true" tabindex="-1"></a>        sample <span class="op">=</span> resample(<span class="bu">range</span>(<span class="dv">0</span>, <span class="bu">len</span>(<span class="va">self</span>.D)), n_samples<span class="op">=</span><span class="bu">len</span>(<span class="va">self</span>.D), replace<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb39-25"><a href="#cb39-25" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.df_sample <span class="op">=</span> pd.DataFrame({<span class="st">&#39;index&#39;</span>: <span class="bu">range</span>(<span class="dv">0</span>,<span class="bu">len</span>(<span class="va">self</span>.D)) , <span class="st">&#39;sample&#39;</span>:sample})</span>
<span id="cb39-26"><a href="#cb39-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-27"><a href="#cb39-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-28"><a href="#cb39-28" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> __get_quantiles(<span class="va">self</span>):</span>
<span id="cb39-29"><a href="#cb39-29" aria-hidden="true" tabindex="-1"></a>        Q <span class="op">=</span> []</span>
<span id="cb39-30"><a href="#cb39-30" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> q <span class="kw">in</span> np.arange(<span class="dv">0</span> , <span class="dv">1</span> <span class="op">+</span> <span class="dv">1</span><span class="op">/</span><span class="va">self</span>.K , <span class="dv">1</span><span class="op">/</span><span class="va">self</span>.K):</span>
<span id="cb39-31"><a href="#cb39-31" aria-hidden="true" tabindex="-1"></a>            Q.append( np.quantile( <span class="bu">range</span>(<span class="dv">0</span>, <span class="bu">len</span>(<span class="va">self</span>.D)) , q ).<span class="bu">round</span>(<span class="dv">0</span>) )</span>
<span id="cb39-32"><a href="#cb39-32" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> Q</span>
<span id="cb39-33"><a href="#cb39-33" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb39-34"><a href="#cb39-34" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb39-35"><a href="#cb39-35" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> __train_test_split(<span class="va">self</span>, q, Q):</span>
<span id="cb39-36"><a href="#cb39-36" aria-hidden="true" tabindex="-1"></a>        X_test <span class="op">=</span> <span class="va">self</span>.D.loc[<span class="va">self</span>.df_sample.loc[Q[q]:(math.floor(Q[q<span class="op">+</span><span class="dv">1</span>])<span class="op">-</span><span class="dv">1</span>), <span class="st">&#39;sample&#39;</span>] , <span class="va">self</span>.D.columns <span class="op">!=</span> <span class="va">self</span>.response_name ] </span>
<span id="cb39-37"><a href="#cb39-37" aria-hidden="true" tabindex="-1"></a>        Y_test <span class="op">=</span> <span class="va">self</span>.D.loc[<span class="va">self</span>.df_sample.loc[Q[q]:(math.floor(Q[q<span class="op">+</span><span class="dv">1</span>])<span class="op">-</span><span class="dv">1</span>), <span class="st">&#39;sample&#39;</span>] , <span class="va">self</span>.D.columns <span class="op">==</span> <span class="va">self</span>.response_name ]</span>
<span id="cb39-38"><a href="#cb39-38" aria-hidden="true" tabindex="-1"></a>        X_train <span class="op">=</span> <span class="va">self</span>.D.loc[ : , <span class="va">self</span>.D.columns <span class="op">!=</span> <span class="va">self</span>.response_name ].drop(<span class="va">self</span>.df_sample.loc[Q[q]:(math.floor(Q[q<span class="op">+</span><span class="dv">1</span>])<span class="op">-</span><span class="dv">1</span>), <span class="st">&#39;sample&#39;</span>] )        Y_train <span class="op">=</span> <span class="va">self</span>.D.loc[ : , <span class="va">self</span>.D.columns <span class="op">==</span> <span class="va">self</span>.response_name ].drop(<span class="va">self</span>.df_sample.loc[Q[q]:(math.floor(Q[q<span class="op">+</span><span class="dv">1</span>])<span class="op">-</span><span class="dv">1</span>), <span class="st">&#39;sample&#39;</span>])</span>
<span id="cb39-39"><a href="#cb39-39" aria-hidden="true" tabindex="-1"></a>        Y_test <span class="op">=</span> Y_test.to_numpy()</span>
<span id="cb39-40"><a href="#cb39-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-41"><a href="#cb39-41" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> X_test, Y_test, X_train, Y_train</span>
<span id="cb39-42"><a href="#cb39-42" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb39-43"><a href="#cb39-43" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb39-44"><a href="#cb39-44" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> fit(<span class="va">self</span>):</span>
<span id="cb39-45"><a href="#cb39-45" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb39-46"><a href="#cb39-46" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.__resample_df()</span>
<span id="cb39-47"><a href="#cb39-47" aria-hidden="true" tabindex="-1"></a>        Q <span class="op">=</span> <span class="va">self</span>.__get_quantiles()</span>
<span id="cb39-48"><a href="#cb39-48" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb39-49"><a href="#cb39-49" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">0</span>, <span class="bu">len</span>(Q)<span class="op">-</span><span class="dv">1</span>):</span>
<span id="cb39-50"><a href="#cb39-50" aria-hidden="true" tabindex="-1"></a>            X_test, Y_test, X_train, Y_train <span class="op">=</span> <span class="va">self</span>.__train_test_split(j, Q)</span>
<span id="cb39-51"><a href="#cb39-51" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.model.fit(X_train, Y_train)</span>
<span id="cb39-52"><a href="#cb39-52" aria-hidden="true" tabindex="-1"></a>            Y_predict_test <span class="op">=</span> <span class="va">self</span>.model.predict(X_test)</span>
<span id="cb39-53"><a href="#cb39-53" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb39-54"><a href="#cb39-54" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> <span class="va">self</span>.metric <span class="op">==</span> <span class="st">&#39;ECM&#39;</span>:</span>
<span id="cb39-55"><a href="#cb39-55" aria-hidden="true" tabindex="-1"></a>                 <span class="va">self</span>.ECM_K_FOLDS_vector.append(np.mean((Y_predict_test <span class="op">-</span> Y_test)<span class="op">**</span><span class="dv">2</span>))</span>
<span id="cb39-56"><a href="#cb39-56" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb39-57"><a href="#cb39-57" aria-hidden="true" tabindex="-1"></a>            <span class="cf">elif</span> <span class="va">self</span>.metric <span class="op">==</span> <span class="st">&#39;TAC&#39;</span>:</span>
<span id="cb39-58"><a href="#cb39-58" aria-hidden="true" tabindex="-1"></a>                 <span class="va">self</span>.TA_K_FOLDS_vector.append(np.mean((Y_predict_test <span class="op">==</span> Y_test)))</span>
<span id="cb39-59"><a href="#cb39-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-60"><a href="#cb39-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-61"><a href="#cb39-61" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> get_metric(<span class="va">self</span>):</span>
<span id="cb39-62"><a href="#cb39-62" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.metric <span class="op">==</span> <span class="st">&#39;ECM&#39;</span>:</span>
<span id="cb39-63"><a href="#cb39-63" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> np.mean(<span class="va">self</span>.ECM_K_FOLDS_vector)</span>
<span id="cb39-64"><a href="#cb39-64" aria-hidden="true" tabindex="-1"></a>        <span class="cf">elif</span> <span class="va">self</span>.metric <span class="op">==</span> <span class="st">&#39;TAC&#39;</span>:</span>
<span id="cb39-65"><a href="#cb39-65" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> np.mean(<span class="va">self</span>.TA_K_FOLDS_vector)</span></code></pre></div>
<p><br></p>
<div id="ejemplo-de-aplicación-a-kkn-para-regresión-1" class="section level3 hasAnchor" number="7.5.1">
<h3 class="hasAnchor"><span class="header-section-number">7.5.1</span> Ejemplo de aplicación a KKN para regresión<a href="#ejemplo-de-aplicación-a-kkn-para-regresión-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Definimos el modelo KNN para regresión con el que vamos a testear el algoritmo que se acaba de programar:</p>
<div class="sourceCode" id="cb40"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a>knn_regression_init <span class="op">=</span> sklearn.neighbors.KNeighborsRegressor(n_neighbors<span class="op">=</span><span class="dv">10</span> ,  p<span class="op">=</span><span class="dv">2</span>, metric<span class="op">=</span><span class="st">&#39;minkowski&#39;</span>)</span></code></pre></div>
<p><br></p>
<p>Aplicamos el algoritmo de validación cruzada K-fold sobre el modelo KNN para regresión, usando como métrica de validación el error cuadrático medio (ECM):</p>
<div class="sourceCode" id="cb41"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a>KFoldCV_init <span class="op">=</span> KFoldCV(D<span class="op">=</span>Data, K<span class="op">=</span><span class="dv">10</span>, response_name<span class="op">=</span><span class="st">&#39;price&#39;</span>, random_seed<span class="op">=</span><span class="dv">123</span>, metric<span class="op">=</span><span class="st">&#39;ECM&#39;</span>, model<span class="op">=</span>knn_regression_init)</span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a>KFoldCV_init.fit()</span></code></pre></div>
<div class="sourceCode" id="cb42"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a>ECM_K_Folds <span class="op">=</span> KFoldCV_init.get_metric()</span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a>ECM_K_Folds</span></code></pre></div>
<pre><code>2220503635404.005</code></pre>
<p><br></p>
</div>
<div id="ejemplo-de-aplicación-a-kkn-para-clasificación-1" class="section level3 hasAnchor" number="7.5.2">
<h3 class="hasAnchor"><span class="header-section-number">7.5.2</span> Ejemplo de aplicación a KKN para clasificación<a href="#ejemplo-de-aplicación-a-kkn-para-clasificación-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Definimos el modelo KNN para clasificación con el que vamos a testear el algoritmo que se acaba de programar:</p>
<div class="sourceCode" id="cb44"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a>knn_classification_init <span class="op">=</span> sklearn.neighbors.KNeighborsClassifier(n_neighbors<span class="op">=</span><span class="dv">10</span> ,  p<span class="op">=</span><span class="dv">2</span>, metric<span class="op">=</span><span class="st">&#39;minkowski&#39;</span>)</span></code></pre></div>
<p><br></p>
<p>Aplicamos el algoritmo de validación cruzada K-fold sobre el modelo KNN para clasificación, usando como métrica de validación la tasa de acierto (TA):</p>
<div class="sourceCode" id="cb45"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a>KFoldCV_init <span class="op">=</span> KFoldCV(D<span class="op">=</span>Data, K<span class="op">=</span><span class="dv">10</span>, response_name<span class="op">=</span><span class="st">&#39;quality_recode&#39;</span>, random_seed<span class="op">=</span><span class="dv">123</span>, metric<span class="op">=</span><span class="st">&#39;TAC&#39;</span>, model<span class="op">=</span>knn_classification_init)</span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-3"><a href="#cb45-3" aria-hidden="true" tabindex="-1"></a>KFoldCV_init.fit()</span></code></pre></div>
<div class="sourceCode" id="cb46"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a>TAC_K_Folds <span class="op">=</span> KFoldCV_init.get_metric()</span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a>TAC_K_Folds</span></code></pre></div>
<pre><code>0.5363984159477089</code></pre>
<p><br></p>
</div>
</div>
<div id="repeated-k-folds" class="section level2 hasAnchor" number="7.6">
<h2 class="hasAnchor"><span class="header-section-number">7.6</span> Repeated k-folds<a href="#repeated-k-folds" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div class="sourceCode" id="cb48"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> RepeatedKFoldCV:</span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-3"><a href="#cb48-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># D --&gt; It have to be a pandas data frame.</span></span>
<span id="cb48-4"><a href="#cb48-4" aria-hidden="true" tabindex="-1"></a>    <span class="co"># B --&gt; It&#39;s the number of iterations of the K-Fold algorithm.    </span></span>
<span id="cb48-5"><a href="#cb48-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># K --&gt; It&#39;s the number of folds of K-fold algorithm..</span></span>
<span id="cb48-6"><a href="#cb48-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># response_name --&gt; It have to be a string with the name of the response variable.</span></span>
<span id="cb48-7"><a href="#cb48-7" aria-hidden="true" tabindex="-1"></a>    <span class="co"># model --&gt; It&#39;s an object containing the initialized model to use.</span></span>
<span id="cb48-8"><a href="#cb48-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># The function has been created thinking that the model to be used will be one from the `sklearn` library.</span></span>
<span id="cb48-9"><a href="#cb48-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># metric --&gt; It&#39;s the name of the validation metric.</span></span>
<span id="cb48-10"><a href="#cb48-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># random_seed --&gt; It&#39;s the seed to replicate the random process.</span></span>
<span id="cb48-11"><a href="#cb48-11" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb48-12"><a href="#cb48-12" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, B, K, random_seed, metric, model):</span>
<span id="cb48-13"><a href="#cb48-13" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.B <span class="op">=</span> B</span>
<span id="cb48-14"><a href="#cb48-14" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.K <span class="op">=</span> K</span>
<span id="cb48-15"><a href="#cb48-15" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.random_seed <span class="op">=</span> random_seed</span>
<span id="cb48-16"><a href="#cb48-16" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.metric <span class="op">=</span> metric</span>
<span id="cb48-17"><a href="#cb48-17" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.model <span class="op">=</span> model</span>
<span id="cb48-18"><a href="#cb48-18" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb48-19"><a href="#cb48-19" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> fit(<span class="va">self</span>, D, response_name):</span>
<span id="cb48-20"><a href="#cb48-20" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.Metric_Repeted_K_Folds_list <span class="op">=</span> [ ]</span>
<span id="cb48-21"><a href="#cb48-21" aria-hidden="true" tabindex="-1"></a>        np.random.seed(<span class="va">self</span>.random_seed)</span>
<span id="cb48-22"><a href="#cb48-22" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb48-23"><a href="#cb48-23" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> b <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">0</span>, <span class="va">self</span>.B):</span>
<span id="cb48-24"><a href="#cb48-24" aria-hidden="true" tabindex="-1"></a>              KFoldCV_init <span class="op">=</span> KFoldCV(D<span class="op">=</span>D, K<span class="op">=</span><span class="va">self</span>.K, response_name<span class="op">=</span>response_name, random_seed<span class="op">=</span><span class="dv">123</span>, metric<span class="op">=</span><span class="va">self</span>.metric, model<span class="op">=</span><span class="va">self</span>.model)</span>
<span id="cb48-25"><a href="#cb48-25" aria-hidden="true" tabindex="-1"></a>            KFoldCV_init.fit()</span>
<span id="cb48-26"><a href="#cb48-26" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.Metric_Repeted_K_Folds_list.append( KFoldCV_init.get_metric() )</span>
<span id="cb48-27"><a href="#cb48-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-28"><a href="#cb48-28" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> get_metric(<span class="va">self</span>):</span>
<span id="cb48-29"><a href="#cb48-29" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span>  np.mean(<span class="va">self</span>.Metric_Repeted_K_Folds_list)</span></code></pre></div>
<p><br></p>
<div id="ejemplo-de-aplicación-a-kkn-para-regresión-2" class="section level3 hasAnchor" number="7.6.1">
<h3 class="hasAnchor"><span class="header-section-number">7.6.1</span> Ejemplo de aplicación a KKN para regresión<a href="#ejemplo-de-aplicación-a-kkn-para-regresión-2" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Definimos el modelo KNN para regresión con el que vamos a testear el algoritmo que se acaba de programar:</p>
<div class="sourceCode" id="cb49"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a>knn_regression_init <span class="op">=</span> sklearn.neighbors.KNeighborsRegressor(n_neighbors<span class="op">=</span><span class="dv">10</span>, p<span class="op">=</span><span class="dv">2</span>, metric<span class="op">=</span><span class="st">&#39;minkowski&#39;</span>)</span></code></pre></div>
<p><br></p>
<p>Aplicamos el algoritmo de validación cruzada K-fold repetida sobre el modelo KNN para regresión, usando como métrica de validación el error cuadrático medio (ECM):</p>
<div class="sourceCode" id="cb50"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a>RepeatedKFoldCV_init <span class="op">=</span> RepeatedKFoldCV(B<span class="op">=</span><span class="dv">100</span>, K<span class="op">=</span><span class="dv">10</span>, random_seed<span class="op">=</span><span class="dv">123</span>, metric<span class="op">=</span><span class="st">&#39;ECM&#39;</span>, model<span class="op">=</span>knn_regression_init)</span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-3"><a href="#cb50-3" aria-hidden="true" tabindex="-1"></a>RepeatedKFoldCV_init.fit(D<span class="op">=</span>Data, response_name<span class="op">=</span><span class="st">&#39;price&#39;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb51"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a>ECM_repeated_K_Folds <span class="op">=</span> RepeatedKFoldCV_init.get_metric()</span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-3"><a href="#cb51-3" aria-hidden="true" tabindex="-1"></a>ECM_repeated_K_Folds</span></code></pre></div>
<pre><code>2220503635404.004</code></pre>
<p><br></p>
</div>
<div id="ejemplo-de-aplicación-a-kkn-para-clasificación-2" class="section level3 hasAnchor" number="7.6.2">
<h3 class="hasAnchor"><span class="header-section-number">7.6.2</span> Ejemplo de aplicación a KKN para clasificación<a href="#ejemplo-de-aplicación-a-kkn-para-clasificación-2" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Definimos el modelo KNN para clasificación con el que vamos a testear el algoritmo que se acaba de programar:</p>
<div class="sourceCode" id="cb53"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a>knn_classification_init <span class="op">=</span> sklearn.neighbors.KNeighborsClassifier(n_neighbors<span class="op">=</span><span class="dv">10</span> ,  p<span class="op">=</span><span class="dv">2</span>, metric<span class="op">=</span><span class="st">&#39;minkowski&#39;</span>)</span></code></pre></div>
<p><br></p>
<p>Aplicamos el algoritmo de validación cruzada K-fold repetida sobre el modelo KNN para clasificación, usando como métrica la tasa de acierto (TA):</p>
<div class="sourceCode" id="cb54"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a>RepeatedKFoldCV_init <span class="op">=</span> RepeatedKFoldCV(B<span class="op">=</span><span class="dv">100</span>, K<span class="op">=</span><span class="dv">10</span>, random_seed<span class="op">=</span><span class="dv">123</span>, metric<span class="op">=</span><span class="st">&#39;TAC&#39;</span>, model<span class="op">=</span>knn_classification_init)</span>
<span id="cb54-2"><a href="#cb54-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-3"><a href="#cb54-3" aria-hidden="true" tabindex="-1"></a>RepeatedKFoldCV_init.fit(D<span class="op">=</span>Data, response_name<span class="op">=</span><span class="st">&#39;quality_recode&#39;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb55"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a>TAC_repeated_K_Folds <span class="op">=</span> RepeatedKFoldCV_init.get_metric()</span>
<span id="cb55-2"><a href="#cb55-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-3"><a href="#cb55-3" aria-hidden="true" tabindex="-1"></a>TAC_repeated_K_Folds</span></code></pre></div>
<pre><code> 0.5363984159477088</code></pre>
<p><br></p>
</div>
</div>
</div>
<div id="algoritmos-de-valicación-cruzada-con-sklearn" class="section level1 hasAnchor" number="8">
<h1 class="hasAnchor"><span class="header-section-number">8</span> Algoritmos de valicación cruzada con <code>Sklearn</code><a href="#algoritmos-de-valicación-cruzada-con-sklearn" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>Importamos los módulos que usaremos en esta sección:</p>
<div class="sourceCode" id="cb57"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> cross_val_score</span>
<span id="cb57-2"><a href="#cb57-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> RepeatedKFold</span>
<span id="cb57-3"><a href="#cb57-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> KFold</span></code></pre></div>
<div id="k-fold-2" class="section level2 hasAnchor" number="8.1">
<h2 class="hasAnchor"><span class="header-section-number">8.1</span> k-fold<a href="#k-fold-2" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Inicializamos el algoritmo k-fold. Usaremos los parámetros k=10 y un inicio aleatorio del algoritmo con semilla 123.</p>
<div class="sourceCode" id="cb58"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a>cv_k_fold <span class="op">=</span> KFold(n_splits<span class="op">=</span><span class="dv">10</span>, random_state<span class="op">=</span><span class="dv">123</span>, shuffle<span class="op">=</span><span class="va">True</span>)</span></code></pre></div>
<p><br></p>
<div id="aplicación-a-knn-para-regresión" class="section level3 hasAnchor" number="8.1.1">
<h3 class="hasAnchor"><span class="header-section-number">8.1.1</span> Aplicación a KNN para regresión<a href="#aplicación-a-knn-para-regresión" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Vamos a aplicar el algoritmo de validación k-fold a un problema de regresión usando la métrica ECM.</p>
<p>Creamos por un lado el vector de la respuesta y por otro la matriz de los predictores. En este caso la respuesta es la variable <em>price</em>, y los predictores son el resto de variables.</p>
<div class="sourceCode" id="cb59"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a>Y_reg <span class="op">=</span> Data.loc[:,<span class="st">&#39;price&#39;</span>]</span>
<span id="cb59-2"><a href="#cb59-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-3"><a href="#cb59-3" aria-hidden="true" tabindex="-1"></a>X_reg <span class="op">=</span> Data.loc[:, Data.columns <span class="op">!=</span> <span class="st">&#39;price&#39;</span>]</span></code></pre></div>
<p>Calculamos la métrica ECM usando el algoritmo de validación cruzada k-folds con k=10:</p>
<div class="sourceCode" id="cb60"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a>ECM_K_Folds_sklearn <span class="op">=</span> cross_val_score(knn_regression, X_reg, Y_reg, cv<span class="op">=</span>cv_k_fold, scoring<span class="op">=</span><span class="st">&#39;neg_mean_squared_error&#39;</span>)</span>
<span id="cb60-2"><a href="#cb60-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-3"><a href="#cb60-3" aria-hidden="true" tabindex="-1"></a>ECM_K_Folds_sklearn <span class="op">=</span> np.mean( <span class="op">-</span> ECM_K_Folds_sklearn )</span>
<span id="cb60-4"><a href="#cb60-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-5"><a href="#cb60-5" aria-hidden="true" tabindex="-1"></a>ECM_K_Folds_sklearn</span></code></pre></div>
<pre><code>2220103512647.2095</code></pre>
<p><br></p>
</div>
<div id="aplicación-a-knn-para-clasificación" class="section level3 hasAnchor" number="8.1.2">
<h3 class="hasAnchor"><span class="header-section-number">8.1.2</span> Aplicación a KNN para clasificación<a href="#aplicación-a-knn-para-clasificación" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Vamos a aplicar el algoritmo de validación k-fold a un problema de clasificación supervisada usando la métrica TAC.</p>
<p>Creamos por un lado el vector de la respuesta y por otro la matriz de los predictores. En este caso la respuesta es la variable <em>quality_recode</em>, y los predictores son el resto de variables.</p>
<div class="sourceCode" id="cb62"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a>Y_class <span class="op">=</span> Data.loc[:,<span class="st">&#39;quality_recode&#39;</span>]</span>
<span id="cb62-2"><a href="#cb62-2" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb62-3"><a href="#cb62-3" aria-hidden="true" tabindex="-1"></a>X_class <span class="op">=</span> Data.loc[:, Data.columns <span class="op">!=</span> <span class="st">&#39;quality_recode&#39;</span>]</span></code></pre></div>
<div class="sourceCode" id="cb63"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a>TAC_K_Folds_sklearn <span class="op">=</span> cross_val_score(knn_classification, X_class, Y_class, cv<span class="op">=</span>cv_k_fold, scoring<span class="op">=</span><span class="st">&#39;accuracy&#39;</span>)</span>
<span id="cb63-2"><a href="#cb63-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-3"><a href="#cb63-3" aria-hidden="true" tabindex="-1"></a>TAC_K_Folds_sklearn <span class="op">=</span> np.mean( TAC_K_Folds_sklearn )</span>
<span id="cb63-4"><a href="#cb63-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-5"><a href="#cb63-5" aria-hidden="true" tabindex="-1"></a>TAC_K_Folds_sklearn</span></code></pre></div>
<pre><code>0.5606558280518048</code></pre>
<p><br></p>
</div>
</div>
<div id="repeated-k-fold" class="section level2 hasAnchor" number="8.2">
<h2 class="hasAnchor"><span class="header-section-number">8.2</span> Repeated k-fold<a href="#repeated-k-fold" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Inicializamos el algoritmo repeated k-fold. Usaremos los parámetros k=10, un número de 100 repeticiones y un inicio aleatorio con semilla 123.</p>
<div class="sourceCode" id="cb65"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a>cv_repeated_k_fold <span class="op">=</span> RepeatedKFold(n_splits<span class="op">=</span><span class="dv">10</span>, n_repeats<span class="op">=</span><span class="dv">100</span>, random_state<span class="op">=</span><span class="dv">123</span>)</span></code></pre></div>
<p><br></p>
<div id="aplicación-a-knn-para-regresión-1" class="section level3 hasAnchor" number="8.2.1">
<h3 class="hasAnchor"><span class="header-section-number">8.2.1</span> Aplicación a KNN para regresión<a href="#aplicación-a-knn-para-regresión-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Vamos a aplicar el algoritmo de validacion k-fold a un problema de <strong>regresión</strong> usando la métrica TAC.</p>
<p>Calculamos la métrica ECM usando el algoritmo de validación cruzada repeated-k-folds con k=10 y B=100 repeticiones:</p>
<div class="sourceCode" id="cb66"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb66-1"><a href="#cb66-1" aria-hidden="true" tabindex="-1"></a>ECM_repeated_K_Folds_sklearn <span class="op">=</span> cross_val_score(knn_regression, X_reg, Y_reg, cv<span class="op">=</span>cv_repeated_k_fold, scoring<span class="op">=</span><span class="st">&#39;neg_mean_squared_error&#39;</span>)</span>
<span id="cb66-2"><a href="#cb66-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-3"><a href="#cb66-3" aria-hidden="true" tabindex="-1"></a>ECM_repeated_K_Folds_sklearn <span class="op">=</span> np.mean( <span class="op">-</span> ECM_repeated_K_Folds_sklearn )</span>
<span id="cb66-4"><a href="#cb66-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-5"><a href="#cb66-5" aria-hidden="true" tabindex="-1"></a>ECM_repeated_K_Folds_sklearn</span></code></pre></div>
<pre><code>2269036673148.278</code></pre>
<p><br></p>
</div>
<div id="aplicación-a-knn-para-regresión-2" class="section level3 hasAnchor" number="8.2.2">
<h3 class="hasAnchor"><span class="header-section-number">8.2.2</span> Aplicación a KNN para regresión<a href="#aplicación-a-knn-para-regresión-2" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Vamos a aplicar el algoritmo de validacion repeated k-fold a un problema de <strong>clasificación supervisada</strong> usando la métrica TAC.</p>
<p>Calculamos la métrica TAC usando el algoritmo de validación cruzada repeated-k-folds con k=10 y B=100 repeticiones:</p>
<div class="sourceCode" id="cb68"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb68-1"><a href="#cb68-1" aria-hidden="true" tabindex="-1"></a>TAC_repeated_K_Folds_sklearn <span class="op">=</span> cross_val_score(knn_classification, X_class, Y_class, cv<span class="op">=</span>cv_repeated_k_fold, scoring<span class="op">=</span><span class="st">&#39;accuracy&#39;</span>)</span>
<span id="cb68-2"><a href="#cb68-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-3"><a href="#cb68-3" aria-hidden="true" tabindex="-1"></a>TAC_repeated_K_Folds_sklearn <span class="op">=</span> np.mean( TAC_repeated_K_Folds_sklearn )</span>
<span id="cb68-4"><a href="#cb68-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-5"><a href="#cb68-5" aria-hidden="true" tabindex="-1"></a>TAC_repeated_K_Folds_sklearn</span></code></pre></div>
<pre><code>0.554644943510609</code></pre>
<p><br></p>
</div>
</div>
</div>
<div id="comparación-final" class="section level1 hasAnchor" number="9">
<h1 class="hasAnchor"><span class="header-section-number">9</span> Comparación final<a href="#comparación-final" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>Importamos las librerias de visualización de datos que usaremos para realizar la comparación final.</p>
<div class="sourceCode" id="cb70"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb70-1"><a href="#cb70-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb70-2"><a href="#cb70-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span></code></pre></div>
<p><br></p>
<div id="visualización-aplicada-a-knn-para-regresión" class="section level2 hasAnchor" number="9.1">
<h2 class="hasAnchor"><span class="header-section-number">9.1</span> Visualización aplicada a KNN para regresión<a href="#visualización-aplicada-a-knn-para-regresión" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Creamos un data-frame con los distintos valores de la métrica ECM obtenidos con los distintos algoritmos de validación utilizados:</p>
<div class="sourceCode" id="cb71"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb71-1"><a href="#cb71-1" aria-hidden="true" tabindex="-1"></a>ECM_df <span class="op">=</span> pd.DataFrame({<span class="st">&#39;ECM&#39;</span> : [ECM_test_Simple_Validation_not_random , ECM_test_Simple_Validation_random, ECM_test_Simple_Validation_repeated, ECM_test_leave_one_out, ECM_K_Folds, ECM_K_Folds_sklearn , ECM_repeated_K_Folds, ECM_repeated_K_Folds_sklearn],</span>
<span id="cb71-2"><a href="#cb71-2" aria-hidden="true" tabindex="-1"></a> <span class="st">&#39;names&#39;</span> : [<span class="st">&#39;Simple validation (not random)&#39;</span> , <span class="st">&#39;Simple validation (random)&#39;</span>, <span class="st">&#39;Simple validation (repeted)&#39;</span>, <span class="st">&#39;Leave one out&#39;</span>, <span class="st">&#39;k-folds&#39;</span>, <span class="st">&#39;k-folds (sklearn)&#39;</span>, <span class="st">&#39;repeted-k-folds&#39;</span>, <span class="st">&#39;repeted-k-folds (sklearn)&#39;</span>]})</span></code></pre></div>
<div class="sourceCode" id="cb72"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb72-1"><a href="#cb72-1" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb72-2"><a href="#cb72-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-3"><a href="#cb72-3" aria-hidden="true" tabindex="-1"></a>p3 <span class="op">=</span> sns.barplot(x<span class="op">=</span><span class="st">&quot;ECM&quot;</span>, y <span class="op">=</span><span class="st">&#39;names&#39;</span> , data<span class="op">=</span>ECM_df)</span>
<span id="cb72-4"><a href="#cb72-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-5"><a href="#cb72-5" aria-hidden="true" tabindex="-1"></a>fig.savefig(<span class="st">&#39;p3.jpg&#39;</span>, <span class="bu">format</span><span class="op">=</span><span class="st">&#39;jpg&#39;</span>, dpi<span class="op">=</span><span class="dv">1200</span>)</span></code></pre></div>
<p><br></p>
<center>
<p><img src="p3.jpg" style="width:60.0%" /></p>
</center>
<p><br></p>
</div>
<div id="visualización-aplicada-a-knn-para-clasificación" class="section level2 hasAnchor" number="9.2">
<h2 class="hasAnchor"><span class="header-section-number">9.2</span> Visualización aplicada a KNN para clasificación<a href="#visualización-aplicada-a-knn-para-clasificación" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Creamos un data-frame con los distintos valores de la métrica TAC obtenidos con los distintos algoritmos de validación utilizados:</p>
<div class="sourceCode" id="cb73"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb73-1"><a href="#cb73-1" aria-hidden="true" tabindex="-1"></a>TAC_df <span class="op">=</span> pd.DataFrame({<span class="st">&#39;TAC&#39;</span> : [TAC_test_Simple_Validation_not_random , TAC_test_Simple_Validation_random, TAC_test_Simple_Validation_repeated, TAC_test_leave_one_out, TAC_K_Folds, TAC_K_Folds_sklearn, TAC_repeated_K_Folds, TAC_repeated_K_Folds_sklearn],</span>
<span id="cb73-2"><a href="#cb73-2" aria-hidden="true" tabindex="-1"></a> <span class="st">&#39;names&#39;</span> : [<span class="st">&#39;Simple validation (not random)&#39;</span> , <span class="st">&#39;Simple validation (random)&#39;</span>, <span class="st">&#39;Simple validation (repeted)&#39;</span>, <span class="st">&#39;Leave one out&#39;</span>, <span class="st">&#39;k-folds&#39;</span>, <span class="st">&#39;k-folds (sklearn)&#39;</span>, <span class="st">&#39;repeted-k-folds&#39;</span>, <span class="st">&#39;repeted-k-folds (sklearn)&#39;</span>]})</span></code></pre></div>
<div class="sourceCode" id="cb74"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb74-1"><a href="#cb74-1" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb74-2"><a href="#cb74-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-3"><a href="#cb74-3" aria-hidden="true" tabindex="-1"></a>p4 <span class="op">=</span> sns.barplot(x<span class="op">=</span><span class="st">&quot;TAC&quot;</span>, y <span class="op">=</span><span class="st">&#39;names&#39;</span> , data<span class="op">=</span>TAC_df)</span>
<span id="cb74-4"><a href="#cb74-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-5"><a href="#cb74-5" aria-hidden="true" tabindex="-1"></a>fig.savefig(<span class="st">&#39;p4.jpg&#39;</span>, <span class="bu">format</span><span class="op">=</span><span class="st">&#39;jpg&#39;</span>, dpi<span class="op">=</span><span class="dv">1200</span>)</span></code></pre></div>
<p><br></p>
<center>
<p><img src="p4.jpg" style="width:60.0%" /></p>
</center>
<p><br></p>
</div>
</div>
<div id="bibliografía" class="section level1 hasAnchor" number="10">
<h1 class="hasAnchor"><span class="header-section-number">10</span> Bibliografía<a href="#bibliografía" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<ul>
<li><p>Amat Rodrigo, J. (Noviembre 2020). Validación de modelos predictivos: Cross-validation, OneLeaveOut, Bootstraping. <em>Cienciadedatos</em>.<br />
<a href="https://www.cienciadedatos.net/documentos/30_cross-validation_oneleaveout_bootstrap" class="uri">https://www.cienciadedatos.net/documentos/30_cross-validation_oneleaveout_bootstrap</a></p></li>
<li><p>Aler Mur, Ricardo. (2022). <em>Metodología: evaluación de modelos.</em> [Presentación de PowerPoint]. Aula Global UC3M.</p></li>
</ul>
<p><br></p>
<!--chapter:end:index.Rmd-->
</div>
<!--bookdown:body:end-->
            </section>

          </div>
        </div>
      </div>
<!--bookdown:link_prev-->
<!--bookdown:link_next-->
    </div>
  </div>
<!--bookdown:config-->

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
