{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para usar los métodos de regresion lineal penalizada, la respuesta y los predictores deben estandarizarse para que tengan media 0 y varianza 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consideremos el típico modelo de regresión lineal: \n",
    "\n",
    "$$y_i = \\beta_0 + \\beta_1 \\cdot x_{i1} + \\beta_2 \\cdot x_{i2} + ... +  \\beta_p \\cdot x_{ip} + \\epsilon$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estandarizamos los predictores $X_1,...,X_p$ y la respuesta $Y$:\n",
    "\n",
    "$$\\widetilde{Y} = \\dfrac{Y - \\overline{y}}{\\sigma_Y} \\\\[0.5cm]$$\n",
    "\n",
    "$$\\widetilde{X_j} = \\dfrac{X_j - \\overline{x_j}}{\\sigma_{X_j}}$$ \n",
    "\n",
    "para $j=1,..,p$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo estandarizado es:\n",
    "\n",
    "$$\\widetilde{y}_i = \\beta_0 + \\widetilde{\\beta}_1 \\cdot \\widetilde{x}_{i1} + \\widetilde{\\beta}_2 \\cdot \\widetilde{x}_{i2} + ... +  \\widetilde{\\beta}_p \\cdot \\widetilde{x}_{ip} + \\widetilde{\\epsilon}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Donde:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "$\\widetilde{\\beta_j} = \\dfrac{\\sigma_{X_j}}{\\sigma_{Y}}\\cdot \\beta_j \\hspace{0.5cm}$  , para $j=1,...,p$\n",
    "\n",
    "$\\beta_0 = \\overline{y} - \\sum_{j=1}^{p} \\overline{x}_j \\cdot \\beta_j$\n",
    "\n",
    "$\\widetilde{\\epsilon} = \\dfrac{\\epsilon}{\\sigma_{Y}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo estandarizado estimado es:\n",
    "\n",
    "$$\\widehat{\\widetilde{y}}_i = \\widehat{\\beta}_0 + \\widehat{\\widetilde{\\beta}}_1 \\cdot  \\widetilde{x}_{i1} + \\widehat{\\widetilde{\\beta}}_2 \\cdot \\widetilde{x}_{i2} + ... +  \\widehat{\\widetilde{\\beta}}_p \\cdot \\widetilde{x}_{ip}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora los coeficientes betas estimados $\\widehat{\\widetilde{\\beta}}_1, \\widehat{\\widetilde{\\beta}}_2 , ..., \\widehat{\\widetilde{\\beta}}_p$ son directamente comparables ya que no dependen de las unidades de medida de los predictores, puesto que al haber estandarizado estos las unidades de medida se eliminan.\n",
    "\n",
    "Ahora si que se cumple que dados dos betas estimados si  $\\widehat{\\widetilde{\\beta}}_r > \\widehat{\\widetilde{\\beta}}_h$ , entonces $X_r$ es mas relevante como predictor de $Y$ (tiene más peso) que $X_h$\n",
    "\n",
    "Esto no se cumplia en la regresion lineal ordinaria puesto que las estimaciones de los betas no eran directamente comparables al depender de las unidades de medida. Por ello betas estimados cercanos a cero no implicaban necesariamente que el predictor asociado fuese no significativo, ya que si ese predictor se media, por ejemplo, en millones de euros, un beta estimado de 0.001 serian 1000 euros (0.001 millones de euros), si se cambia la unidad de medida de dicho predictor de millones de euros a simplmenente euros entonces dicho beta estimado cambiaria de 0.001 a 1000 lo cual ya no es cercano a cero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresión Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo de regresión Ridge es básicamente un modelo de regresión lineal en el que la respuesta y los predictores están estandarizados y la estimacion de los coeficientes betas se hace resolviendo el siguiente problema de optimización :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sea $\\hspace{0.1cm}\\widetilde{\\beta}= (\\widetilde{\\beta}_1,\\widetilde{\\beta}_2,...,\\widetilde{\\beta}_p)$ , $\\hspace{0.15cm} \\widetilde{x}_i = (\\widetilde{x}_{i1},...,\\widetilde{x}_{ip})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\\begin{gather*}\n",
    "  \\underset{\\widetilde{\\beta}}{Min} \\hspace{0.2cm}  \\biggl\\{ \\hspace{0.1cm} RSS(\\widetilde{\\beta}) \\hspace{0.1cm} +\\hspace{0.1cm}  \\lambda \\cdot | | \\hspace{0.06cm}\\widetilde{\\beta} \\hspace{0.06cm}||^2_2 \\hspace{0.1cm} \\biggl\\} \\hspace{0.2cm} = \\hspace{0.2cm}  \\underset{\\widetilde{\\beta}}{Min} \\hspace{0.2cm} \\biggl\\{ \\hspace{0.1cm} \\sum_{i=1}^{n} \\hspace{0.1cm}(y_i - \\beta_0 - \\widetilde{x}_i\\hspace{0.05cm}^t \\cdot \\beta)\\hspace{0.02cm}^2 \\hspace{0.1cm} + \\hspace{0.1cm}  \\lambda \\cdot | | \\hspace{0.06cm}\\widetilde{\\beta} \\hspace{0.06cm}||^2_2  \\hspace{0.1cm} \\biggl\\} \\hspace{0.2cm} =  \\\\[0.8cm]\n",
    "  = \\hspace{0.2cm} \\underset{\\widetilde{\\beta}_1,...,\\widetilde{\\beta}_p}{Min} \\hspace{0.2cm} \\biggl\\{ \\hspace{0.1cm} \\sum_{i=1}^{n} \\hspace{0.1cm}(y_i - \\beta_0 - \\widetilde{\\beta}_1 \\cdot x_{i1} - \\dots - \\widetilde{\\beta}_p \\cdot x_{ip})\\hspace{0.02cm}^2  \\hspace{0.1cm} + \\hspace{0.1cm}  \\lambda \\cdot | | \\hspace{0.06cm}\\widetilde{\\beta} \\hspace{0.06cm}||^2_2 \\hspace{0.1cm} \\biggl\\}\n",
    "\\end{gather*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Donde: \n",
    "\n",
    "$\\lambda \\geq 0$ es un parámetro de penalización\n",
    "\n",
    "$| | \\hspace{0.06cm}\\widetilde{\\beta} \\hspace{0.06cm}||^2_2 \\hspace{0.1cm} = \\hspace{0.1cm} \\sum_{j=1}^p \\hspace{0.1cm} \\widetilde{\\beta}_j\\hspace{0.01cm}^2\\hspace{0.15cm}$ es la norma Euclidea del vector $\\hspace{0.15cm}\\widetilde{\\beta}\\hspace{0.15cm}$, la cual es una medida del tamaño del vector.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observaciones :**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La expresión $\\hspace{0.15cm}\\lambda \\cdot | | \\hspace{0.06cm}\\widetilde{\\beta} \\hspace{0.06cm}||^2_2\\hspace{0.15cm}$ penaliza el tamaño del vector $\\hspace{0.15cm}\\widetilde{\\beta}$ \n",
    "\n",
    "Cuanto mayor sea $\\hspace{0.15cm}\\lambda\\hspace{0.15cm}$ mayor es la penalización impuesta al tamaño del vector $\\hspace{0.15cm}\\widetilde{\\beta} \\hspace{0.15cm}$  en el problema de optimización.\n",
    "\n",
    "Si $\\hspace{0.15cm}\\lambda = 0\\hspace{0.15cm}$ el problema de optimizacion es el de minimos cuadrados ordinarios, propio del modelo de regresion lineal ordinario.\n",
    "\n",
    "Si $\\hspace{0.15cm}\\lambda\\hspace{0.15cm}$ es grande  la solucion del problema $\\hspace{0.15cm}\\widehat{\\widetilde{\\beta}}\\hspace{0.05cm}^{Ridge} \\hspace{0.15cm}$  tendra un tamaño (norma Euclidea) pequeño, es decir, los  $\\hspace{0.15cm}\\widehat{\\widetilde{\\beta}}_1, \\widehat{\\widetilde{\\beta}}_2,..., \\widehat{\\widetilde{\\beta}}_p\\hspace{0.15cm}$ estarán cerca de $0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\lambda$ debe ser seleccionado a priori de la resolucion del problema de optimización."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ventajas de la regresion Ridge sobre la regresion de minimos cuadrados ordinarios:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Las predicciones de la regresion por minimos cuadrados ordinarios son insesgadas pero tiene alta varianza, especialmente si $p \\approx n$. Además si $p>n$ no se puede estimar la regresion por minimos cuadrados ordinarios.\n",
    "\n",
    "-  La regresión Ridge se basa en el equilibrio entre sesgo y varianza. Disminuye sustancialmente la varianza de las predicciones a costa de aumentar un poco su sesgo. Además, incluso si $\\hspace{0.1cm}p \\approx n \\hspace{0.1cm}$ o $\\hspace{0.1cm} p>n\\hspace{0.1cm}$ , la regresion Ridge puede funcionar bien.\n",
    "\n",
    "- Esto lleva a que si $\\lambda$ es seleccionado correctamente, el error cuadratico medio de prediccion $(ECMP)$es menor en la regresion Ridge que en la de minimos cuadrados ordinarios, lo que conduce a mayor capacidad predictiva de Ridge sobre minimos cuadrados ordinarios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 1\n",
    "\n",
    "Indicar cuál de los siguientes puntos es correcto, justificando tu respuesta. Regresión ridge y regresión lasso, relativa a mínimos cuadrados, son:\n",
    "\n",
    "- Más flexibles y, por lo tanto, brindarán una mejora en la precisión de las predicciones cuando su aumento en sesgo sea menor que su disminución en varianza\n",
    "\n",
    "- Más flexibles y, por lo tanto, brindarán una mejora en la precisión de las predicciones cuando su aumento en varianza sea menor que su disminución en sesgo.\n",
    "\n",
    "- Menos flexibles y, por lo tanto, brindarán una mejora en la precisión de las predicciones cuando su aumento en sesgo sea menor que su disminución en varianza. **CORRECTO**\n",
    "\n",
    "- Menos flexibles y, por lo tanto, brindarán una mejora en la precisión de las predicciones cuando su aumento en varianza sea menor que su disminución en sesgo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Razonamiento:\n",
    "\n",
    "- Las predicciones de la regresion por minimos cuadrados ordinarios son insesgadas pero tiene alta varianza, especialmente si $p \\approx n$. Además si $p>n$ no se puede estimar la regresion por minimos cuadrados ordinarios.\n",
    "\n",
    "-  La regresión Ridge se basa en el equilibrio entre sesgo y varianza. Disminuye sustancialmente la varianza de las predicciones a costa de aumentar un poco su sesgo (es por ello un método menos flexible, que genera menos sobre-ajuste). Además, incluso si $\\hspace{0.1cm}p \\approx n \\hspace{0.1cm}$ o $\\hspace{0.1cm} p>n\\hspace{0.1cm}$ , la regresion Ridge puede funcionar bien.\n",
    "\n",
    "- Esto lleva a que si $\\lambda$ es seleccionado correctamente, el error cuadratico medio de prediccion $(ECMP)$es menor en la regresion Ridge que en la de minimos cuadrados ordinarios, lo que conduce a mayor capacidad predictiva de Ridge sobre minimos cuadrados ordinarios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 6\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "En este ejercicio, se pide obtener predicciones del logaritmo de la variable crim del conjunto de datos Boston de la librería ISLR2 utilizando el resto de variables como predictores, mediante los siguientes métodos:\n",
    "\n",
    "Regresión ridge.\n",
    "\n",
    "Regresión lasso.\n",
    "\n",
    "Para ello, por sencillez utilizar una muestra de entrenamiento y de test y obtener los correspondientes valores del error cuadrático medio test. Comparar los resultados y explicar las conclusiones más relevantes. Para crear la muestra de entrenamiento, con 355 observaciones seleccionadas al azar, y la muestra test, con las 151 observaciones restantes, fijar la semilla mediante la orden set.seed(1). Esto es importante para poder comparar los resultados con otros procedimientos que veremos en la hoja de la semana que viene."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El mejor modelo de regresion de minimos cuadrados ordinarios por validación simple usando algoritmos de selección de predictores (practica anterior) es:\n",
    "\n",
    "crim ~ zn + indus + nox + age + ptratio + lstat + medv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/JWarmenhoven/ISLR-python/master/Notebooks/Data/Boston.csv'\n",
    "\n",
    "Boston = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Boston_Train = Boston.sample(frac=0.70, replace=False, weights=None, random_state=1, axis=None, ignore_index=False)\n",
    "\n",
    "Boston_Test = Boston.drop( Boston_Train.index , )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TEST\n",
    "\n",
    "X_test = Boston_Test.loc[: , Boston_Test.columns != 'crim']\n",
    "Y_test = Boston_Test.loc[: , 'crim']\n",
    "\n",
    "##############################################################\n",
    "\n",
    "## TRAIN\n",
    "\n",
    "X_train = Boston_Train.loc[: , Boston_Train.columns != 'crim']\n",
    "Y_train = Boston_Train.loc[: , 'crim']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   crim   R-squared:                       0.275\n",
      "Model:                            OLS   Adj. R-squared:                  0.261\n",
      "Method:                 Least Squares   F-statistic:                     18.78\n",
      "Date:                Mon, 17 Oct 2022   Prob (F-statistic):           3.18e-21\n",
      "Time:                        11:38:25   Log-Likelihood:                -1210.3\n",
      "No. Observations:                 354   AIC:                             2437.\n",
      "Df Residuals:                     346   BIC:                             2467.\n",
      "Df Model:                           7                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept    -20.6700      6.406     -3.227      0.001     -33.269      -8.071\n",
      "zn             0.0516      0.022      2.311      0.021       0.008       0.095\n",
      "indus          0.0871      0.100      0.873      0.383      -0.109       0.283\n",
      "nox           22.9160      6.753      3.393      0.001       9.634      36.198\n",
      "age            0.0022      0.023      0.095      0.924      -0.043       0.048\n",
      "ptratio        0.5345      0.234      2.282      0.023       0.074       0.995\n",
      "lstat          0.1843      0.096      1.916      0.056      -0.005       0.374\n",
      "medv          -0.0978      0.071     -1.378      0.169      -0.237       0.042\n",
      "==============================================================================\n",
      "Omnibus:                      465.684   Durbin-Watson:                   2.092\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            47990.978\n",
      "Skew:                           6.282   Prob(JB):                         0.00\n",
      "Kurtosis:                      58.639   Cond. No.                     1.63e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.63e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "mejor_modelo_MCO = smf.ols(formula = 'crim ~ zn + indus + nox + age + ptratio + lstat + medv', data =Boston_Train)\n",
    "\n",
    "mejor_modelo_MCO = mejor_modelo_MCO.fit()\n",
    " \n",
    "print(mejor_modelo_MCO.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ECM_test_mejor_MCO = ( ( mejor_modelo_MCO.predict(X_test) - Y_test )**2 ).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7867.080915965136"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ECM_test_mejor_MCO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ridge_sklearn = sklearn.linear_model.Ridge( alpha=1.0 , fit_intercept=True)\n",
    "\n",
    "Ridge_sklearn.fit(X_train, Y_train)  # No es necesario escalar los datos.\n",
    "\n",
    "ECM_test_Ridge = sum( ( Ridge_sklearn.predict(X_test) - Y_test)**2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5666.860672620652"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ECM_test_Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.23473200e-02, -7.22827801e-02, -5.51352723e-01, -5.38213841e+00,\n",
       "        1.03064070e+00, -1.24862668e-03, -1.01009089e+00,  5.46937705e-01,\n",
       "       -3.93065520e-03, -2.37125405e-01, -7.85708737e-03,  4.66262130e-02,\n",
       "       -2.50284966e-01])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ridge_sklearn.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['zn', 'indus', 'chas', 'nox', 'rm', 'age', 'dis', 'rad', 'tax',\n",
       "       'ptratio', 'black', 'lstat', 'medv'], dtype=object)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ridge_sklearn.feature_names_in_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.891905577088338"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ridge_sklearn.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "ECM_test_Ridge_vector = []\n",
    "\n",
    "for alpha in range(1, 10000):\n",
    "\n",
    "    Ridge_sklearn = sklearn.linear_model.Ridge( alpha=alpha )\n",
    "\n",
    "    Ridge_sklearn.fit(X_train, Y_train)\n",
    "\n",
    "    ECM_test_Ridge_vector.append( sum( ( Ridge_sklearn.predict(X_test) - Y_test)**2 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_optimo_Ridge_df = pd.DataFrame({ 'ECM test':ECM_test_Ridge_vector , 'lambda': range(1, 10000) }).sort_values(by=[\"ECM test\"]).reset_index(drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>ECM test</th>\n",
       "      <th>lambda</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>241</td>\n",
       "      <td>5619.442044</td>\n",
       "      <td>242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>240</td>\n",
       "      <td>5619.442332</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>242</td>\n",
       "      <td>5619.442493</td>\n",
       "      <td>243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>239</td>\n",
       "      <td>5619.443366</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>243</td>\n",
       "      <td>5619.443674</td>\n",
       "      <td>244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9994</th>\n",
       "      <td>9994</td>\n",
       "      <td>6168.475129</td>\n",
       "      <td>9995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>9995</td>\n",
       "      <td>6168.504909</td>\n",
       "      <td>9996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>9996</td>\n",
       "      <td>6168.534686</td>\n",
       "      <td>9997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9997</td>\n",
       "      <td>6168.564461</td>\n",
       "      <td>9998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9998</td>\n",
       "      <td>6168.594232</td>\n",
       "      <td>9999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9999 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index     ECM test  lambda\n",
       "0       241  5619.442044     242\n",
       "1       240  5619.442332     241\n",
       "2       242  5619.442493     243\n",
       "3       239  5619.443366     240\n",
       "4       243  5619.443674     244\n",
       "...     ...          ...     ...\n",
       "9994   9994  6168.475129    9995\n",
       "9995   9995  6168.504909    9996\n",
       "9996   9996  6168.534686    9997\n",
       "9997   9997  6168.564461    9998\n",
       "9998   9998  6168.594232    9999\n",
       "\n",
       "[9999 rows x 3 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_optimo_Ridge_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ridge_sklearn = sklearn.linear_model.Ridge( alpha=lambda_optimo_Ridge_df['lambda'][0] )\n",
    "\n",
    "Ridge_sklearn.fit(X_train, Y_train)\n",
    "\n",
    "ECM_Ridge_lambda_optimo = sum( ( Ridge_sklearn.predict(X_test) - Y_test)**2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5619.442043973381"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ECM_Ridge_lambda_optimo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lasso_sklearn = sklearn.linear_model.Lasso( alpha=1.0 )\n",
    "\n",
    "Lasso_sklearn.fit(X_train, Y_train)\n",
    "\n",
    "ECM_test_Lasso = sum( ( Lasso_sklearn.predict(X_test) - Y_test)**2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5801.12558607471"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ECM_test_Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.84504306e-02, -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        0.00000000e+00,  1.98584279e-02, -0.00000000e+00,  4.58247135e-01,\n",
       "        4.08914174e-04, -0.00000000e+00, -1.10474218e-02,  2.96267659e-02,\n",
       "       -1.01826815e-01])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Lasso_sklearn.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['zn', 'indus', 'chas', 'nox', 'rm', 'age', 'dis', 'rad', 'tax',\n",
       "       'ptratio', 'black', 'lstat', 'medv'], dtype=object)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Lasso_sklearn.feature_names_in_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.304381019549772"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Lasso_sklearn.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "ECM_test_Lasso_vector = []\n",
    "\n",
    "for alpha in range(1, 10000):\n",
    "\n",
    "    Lasso_sklearn = sklearn.linear_model.Lasso( alpha=alpha )\n",
    "\n",
    "    Lasso_sklearn.fit(X_train, Y_train)\n",
    "\n",
    "    ECM_test_Lasso_vector.append( sum( ( Lasso_sklearn.predict(X_test) - Y_test)**2 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_optimo_Lasso_df = pd.DataFrame({ 'ECM test':ECM_test_Lasso_vector , 'lambda': range(1, 10000) }).sort_values(by=[\"ECM test\"]).reset_index(drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>ECM test</th>\n",
       "      <th>lambda</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5801.125586</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5953.405700</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>6128.040393</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>6314.516768</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>6518.583052</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9994</th>\n",
       "      <td>3900</td>\n",
       "      <td>10699.536010</td>\n",
       "      <td>3901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>3901</td>\n",
       "      <td>10699.536010</td>\n",
       "      <td>3902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>3902</td>\n",
       "      <td>10699.536010</td>\n",
       "      <td>3903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>3896</td>\n",
       "      <td>10699.536010</td>\n",
       "      <td>3897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9998</td>\n",
       "      <td>10699.536010</td>\n",
       "      <td>9999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9999 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index      ECM test  lambda\n",
       "0         0   5801.125586       1\n",
       "1         1   5953.405700       2\n",
       "2         2   6128.040393       3\n",
       "3         3   6314.516768       4\n",
       "4         4   6518.583052       5\n",
       "...     ...           ...     ...\n",
       "9994   3900  10699.536010    3901\n",
       "9995   3901  10699.536010    3902\n",
       "9996   3902  10699.536010    3903\n",
       "9997   3896  10699.536010    3897\n",
       "9998   9998  10699.536010    9999\n",
       "\n",
       "[9999 rows x 3 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_optimo_Lasso_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lasso_sklearn = sklearn.linear_model.Lasso( alpha=lambda_optimo_Lasso_df['lambda'][0] )\n",
    "\n",
    "Lasso_sklearn.fit(X_train, Y_train)\n",
    "\n",
    "ECM_Lasso_lambda_optimo = sum( ( Lasso_sklearn.predict(X_test) - Y_test)**2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5801.12558607471"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ECM_Lasso_lambda_optimo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora usando `statmodels` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ridge_sm = sm.OLS(Y_train , X_train)\n",
    "\n",
    "Ridge_sm = Ridge_sm.fit_regularized(method='elastic_net', alpha=1 , L1_wt=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.03519808, -0.05998695, -0.0394689 ,  0.0027158 ,  0.33639808,\n",
       "        0.01432283, -0.36256383,  0.44804175,  0.00117177,  0.07795305,\n",
       "       -0.00806175,  0.09304388, -0.10808265])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ridge_sm.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['zn', 'indus', 'chas', 'nox', 'rm', 'age', 'dis', 'rad', 'tax',\n",
       "       'ptratio', 'black', 'lstat', 'medv'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "ECM_test_Ridge_sm = (( Ridge_sm.predict(X_test) - Y_test)**2 ).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5631.359218424218"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ECM_test_Ridge_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lasso_sm = sm.OLS(Y_train , X_train)\n",
    "\n",
    "Lasso_sm = Lasso_sm.fit_regularized(method='elastic_net', alpha=1 , L1_wt=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "zn         0.030556\n",
       "indus      0.000000\n",
       "chas       0.000000\n",
       "nox        0.000000\n",
       "rm         0.000000\n",
       "age        0.039617\n",
       "dis        0.000000\n",
       "rad        0.469794\n",
       "tax        0.001634\n",
       "ptratio    0.000000\n",
       "black     -0.007778\n",
       "lstat      0.011535\n",
       "medv      -0.090279\n",
       "dtype: float64"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Lasso_sm.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "ECM_test_Lasso_sm = (( Lasso_sm.predict(X_test) - Y_test)**2 ).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5829.240987022078"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ECM_test_Lasso_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c63d8c7d738c2960218a10995aedf0a7f67a49a231e71037adf0440953cdb45b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
