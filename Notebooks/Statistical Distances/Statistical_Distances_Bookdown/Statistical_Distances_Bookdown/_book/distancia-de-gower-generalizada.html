<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 11 Distancia de Gower Generalizada | Distancias Estadísticas</title>
  <meta name="description" content="Esta es una introducción a las distancias estadísticas." />
  <meta name="generator" content="bookdown 0.32 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 11 Distancia de Gower Generalizada | Distancias Estadísticas" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="Esta es una introducción a las distancias estadísticas." />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 11 Distancia de Gower Generalizada | Distancias Estadísticas" />
  
  <meta name="twitter:description" content="Esta es una introducción a las distancias estadísticas." />
  

<meta name="author" content="Fabio Scielzo Ortiz" />


<meta name="date" content="2023-03-25" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="anexo.html"/>
<link rel="next" href="distancia-de-mahalanobis-robusta.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Distancias Estadísticas</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introducción</a></li>
<li class="chapter" data-level="2" data-path="data-sets.html"><a href="data-sets.html"><i class="fa fa-check"></i><b>2</b> Data-sets</a></li>
<li class="chapter" data-level="3" data-path="distancias.html"><a href="distancias.html"><i class="fa fa-check"></i><b>3</b> Distancias</a>
<ul>
<li class="chapter" data-level="3.1" data-path="distancias.html"><a href="distancias.html#casi-métrica"><i class="fa fa-check"></i><b>3.1</b> Casi-métrica</a></li>
<li class="chapter" data-level="3.2" data-path="distancias.html"><a href="distancias.html#semi-métrica"><i class="fa fa-check"></i><b>3.2</b> Semi-métrica</a></li>
<li class="chapter" data-level="3.3" data-path="distancias.html"><a href="distancias.html#métrica"><i class="fa fa-check"></i><b>3.3</b> Métrica</a></li>
<li class="chapter" data-level="3.4" data-path="distancias.html"><a href="distancias.html#distancia"><i class="fa fa-check"></i><b>3.4</b> Distancia</a></li>
<li class="chapter" data-level="3.5" data-path="distancias.html"><a href="distancias.html#matriz-de-distancias"><i class="fa fa-check"></i><b>3.5</b> Matriz de distancias</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="distancias-con-variables-estadísticas-cuantitativas.html"><a href="distancias-con-variables-estadísticas-cuantitativas.html"><i class="fa fa-check"></i><b>4</b> Distancias con variables estadísticas cuantitativas</a>
<ul>
<li class="chapter" data-level="4.1" data-path="distancias-con-variables-estadísticas-cuantitativas.html"><a href="distancias-con-variables-estadísticas-cuantitativas.html#distancia-euclidea"><i class="fa fa-check"></i><b>4.1</b> Distancia Euclidea</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="distancias-con-variables-estadísticas-cuantitativas.html"><a href="distancias-con-variables-estadísticas-cuantitativas.html#distancia-euclidea-en-python"><i class="fa fa-check"></i><b>4.1.1</b> Distancia Euclidea en <code>Python</code></a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="distancias-con-variables-estadísticas-cuantitativas.html"><a href="distancias-con-variables-estadísticas-cuantitativas.html#distancia-de-minkowski"><i class="fa fa-check"></i><b>4.2</b> Distancia de Minkowski</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="distancias-con-variables-estadísticas-cuantitativas.html"><a href="distancias-con-variables-estadísticas-cuantitativas.html#casos-particulares-de-la-distancia-de-minkowski"><i class="fa fa-check"></i><b>4.2.1</b> Casos particulares de la distancia de Minkowski</a></li>
<li class="chapter" data-level="4.2.2" data-path="distancias-con-variables-estadísticas-cuantitativas.html"><a href="distancias-con-variables-estadísticas-cuantitativas.html#distancia-de-minkowski-en-python"><i class="fa fa-check"></i><b>4.2.2</b> Distancia de Minkowski en <code>Python</code></a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="distancias-con-variables-estadísticas-cuantitativas.html"><a href="distancias-con-variables-estadísticas-cuantitativas.html#distancia-de-canberra"><i class="fa fa-check"></i><b>4.3</b> Distancia de Canberra</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="distancias-con-variables-estadísticas-cuantitativas.html"><a href="distancias-con-variables-estadísticas-cuantitativas.html#distancia-de-canberra-en-python"><i class="fa fa-check"></i><b>4.3.1</b> Distancia de Canberra en <code>Python</code></a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="distancias-con-variables-estadísticas-cuantitativas.html"><a href="distancias-con-variables-estadísticas-cuantitativas.html#distancia-de-pearson"><i class="fa fa-check"></i><b>4.4</b> Distancia de Pearson</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="distancias-con-variables-estadísticas-cuantitativas.html"><a href="distancias-con-variables-estadísticas-cuantitativas.html#distancia-de-pearson-en-python"><i class="fa fa-check"></i><b>4.4.1</b> Distancia de Pearson en <code>Python</code></a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="distancias-con-variables-estadísticas-cuantitativas.html"><a href="distancias-con-variables-estadísticas-cuantitativas.html#distancia-de-mahalanobis"><i class="fa fa-check"></i><b>4.5</b> Distancia de Mahalanobis</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="distancias-con-variables-estadísticas-cuantitativas.html"><a href="distancias-con-variables-estadísticas-cuantitativas.html#distancia-de-mahalanobis-en-python"><i class="fa fa-check"></i><b>4.5.1</b> Distancia de Mahalanobis en <code>Python</code></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="similaridades.html"><a href="similaridades.html"><i class="fa fa-check"></i><b>5</b> Similaridades</a>
<ul>
<li class="chapter" data-level="5.1" data-path="similaridades.html"><a href="similaridades.html#similaridad"><i class="fa fa-check"></i><b>5.1</b> Similaridad</a></li>
<li class="chapter" data-level="5.2" data-path="similaridades.html"><a href="similaridades.html#pasar-de-similaridad-a-distancia"><i class="fa fa-check"></i><b>5.2</b> Pasar de similaridad a distancia</a></li>
<li class="chapter" data-level="5.3" data-path="similaridades.html"><a href="similaridades.html#matriz-de-similaridades"><i class="fa fa-check"></i><b>5.3</b> Matriz de Similaridades</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="similaridades-con-variables-categoricas-binarias.html"><a href="similaridades-con-variables-categoricas-binarias.html"><i class="fa fa-check"></i><b>6</b> Similaridades con variables categoricas binarias</a>
<ul>
<li class="chapter" data-level="6.1" data-path="similaridades-con-variables-categoricas-binarias.html"><a href="similaridades-con-variables-categoricas-binarias.html#parámetros-a-b-c-y-d"><i class="fa fa-check"></i><b>6.1</b> Parámetros a, b , c y d</a></li>
<li class="chapter" data-level="6.2" data-path="similaridades-con-variables-categoricas-binarias.html"><a href="similaridades-con-variables-categoricas-binarias.html#matrices-con-los-parámetros-a-b-c-y-d"><i class="fa fa-check"></i><b>6.2</b> Matrices con los parámetros a, b, c y d</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="similaridades-con-variables-categoricas-binarias.html"><a href="similaridades-con-variables-categoricas-binarias.html#cálculo-de-las-matrices-a-b-c-y-d-en-python"><i class="fa fa-check"></i><b>6.2.1</b> Cálculo de las matrices a, b , c y d en <code>Python</code></a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="similaridades-con-variables-categoricas-binarias.html"><a href="similaridades-con-variables-categoricas-binarias.html#similaridad-de-sokal"><i class="fa fa-check"></i><b>6.3</b> Similaridad de Sokal</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="similaridades-con-variables-categoricas-binarias.html"><a href="similaridades-con-variables-categoricas-binarias.html#distancia-de-sokal"><i class="fa fa-check"></i><b>6.3.1</b> Distancia de Sokal</a></li>
<li class="chapter" data-level="6.3.2" data-path="similaridades-con-variables-categoricas-binarias.html"><a href="similaridades-con-variables-categoricas-binarias.html#similaridad-de-sokal-en-python"><i class="fa fa-check"></i><b>6.3.2</b> Similaridad de Sokal en <code>Python</code></a></li>
<li class="chapter" data-level="6.3.3" data-path="similaridades-con-variables-categoricas-binarias.html"><a href="similaridades-con-variables-categoricas-binarias.html#distancia-de-sokal-en-python"><i class="fa fa-check"></i><b>6.3.3</b> Distancia de Sokal en <code>Python</code></a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="similaridades-con-variables-categoricas-binarias.html"><a href="similaridades-con-variables-categoricas-binarias.html#similaridad-de-jaccard"><i class="fa fa-check"></i><b>6.4</b> Similaridad de Jaccard</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="similaridades-con-variables-categoricas-binarias.html"><a href="similaridades-con-variables-categoricas-binarias.html#distancia-de-jaccard"><i class="fa fa-check"></i><b>6.4.1</b> Distancia de Jaccard</a></li>
<li class="chapter" data-level="6.4.2" data-path="similaridades-con-variables-categoricas-binarias.html"><a href="similaridades-con-variables-categoricas-binarias.html#similaridad-de-jaccard-en-python"><i class="fa fa-check"></i><b>6.4.2</b> Similaridad de Jaccard en <code>Python</code></a></li>
<li class="chapter" data-level="6.4.3" data-path="similaridades-con-variables-categoricas-binarias.html"><a href="similaridades-con-variables-categoricas-binarias.html#distancia-de-jaccard-en-python"><i class="fa fa-check"></i><b>6.4.3</b> Distancia de Jaccard en <code>Python</code></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="similaridades-con-variables-categoricas-multiclase.html"><a href="similaridades-con-variables-categoricas-multiclase.html"><i class="fa fa-check"></i><b>7</b> Similaridades con variables categoricas multiclase</a>
<ul>
<li class="chapter" data-level="7.1" data-path="similaridades-con-variables-categoricas-multiclase.html"><a href="similaridades-con-variables-categoricas-multiclase.html#parámetro-alpha"><i class="fa fa-check"></i><b>7.1</b> Parámetro alpha</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="similaridades-con-variables-categoricas-multiclase.html"><a href="similaridades-con-variables-categoricas-multiclase.html#parámetro-alpha-en-python"><i class="fa fa-check"></i><b>7.1.1</b> Parámetro alpha en <code>Python</code></a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="similaridades-con-variables-categoricas-multiclase.html"><a href="similaridades-con-variables-categoricas-multiclase.html#similaridad-simple-matching"><i class="fa fa-check"></i><b>7.2</b> Similaridad simple matching</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="similaridades-con-variables-categoricas-multiclase.html"><a href="similaridades-con-variables-categoricas-multiclase.html#distancia-simple-matching"><i class="fa fa-check"></i><b>7.2.1</b> Distancia simple matching</a></li>
<li class="chapter" data-level="7.2.2" data-path="similaridades-con-variables-categoricas-multiclase.html"><a href="similaridades-con-variables-categoricas-multiclase.html#similaridad-simple-matching-en-python"><i class="fa fa-check"></i><b>7.2.2</b> Similaridad simple matching en <code>Python</code></a></li>
<li class="chapter" data-level="7.2.3" data-path="similaridades-con-variables-categoricas-multiclase.html"><a href="similaridades-con-variables-categoricas-multiclase.html#distancia-simple-matching-en-python"><i class="fa fa-check"></i><b>7.2.3</b> Distancia simple matching en <code>Python</code></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="conjuntos-de-variables-estadisticas-de-tipo-mixto.html"><a href="conjuntos-de-variables-estadisticas-de-tipo-mixto.html"><i class="fa fa-check"></i><b>8</b> Conjuntos de variables estadisticas de tipo mixto</a></li>
<li class="chapter" data-level="9" data-path="distancias-con-conjuntos-de-variables-de-tipo-cuantitativo-binario-multiclase.html"><a href="distancias-con-conjuntos-de-variables-de-tipo-cuantitativo-binario-multiclase.html"><i class="fa fa-check"></i><b>9</b> Distancias con conjuntos de variables de tipo cuantitativo-binario-multiclase</a>
<ul>
<li class="chapter" data-level="9.1" data-path="distancias-con-conjuntos-de-variables-de-tipo-cuantitativo-binario-multiclase.html"><a href="distancias-con-conjuntos-de-variables-de-tipo-cuantitativo-binario-multiclase.html#similaridad-de-gower"><i class="fa fa-check"></i><b>9.1</b> Similaridad de Gower</a>
<ul>
<li class="chapter" data-level="9.1.1" data-path="distancias-con-conjuntos-de-variables-de-tipo-cuantitativo-binario-multiclase.html"><a href="distancias-con-conjuntos-de-variables-de-tipo-cuantitativo-binario-multiclase.html#distancia-de-gower"><i class="fa fa-check"></i><b>9.1.1</b> Distancia de Gower</a></li>
<li class="chapter" data-level="9.1.2" data-path="distancias-con-conjuntos-de-variables-de-tipo-cuantitativo-binario-multiclase.html"><a href="distancias-con-conjuntos-de-variables-de-tipo-cuantitativo-binario-multiclase.html#similaridad-de-gower-en-python"><i class="fa fa-check"></i><b>9.1.2</b> Similaridad de Gower en <code>Python</code></a></li>
<li class="chapter" data-level="9.1.3" data-path="distancias-con-conjuntos-de-variables-de-tipo-cuantitativo-binario-multiclase.html"><a href="distancias-con-conjuntos-de-variables-de-tipo-cuantitativo-binario-multiclase.html#distancia-de-gower-en-python"><i class="fa fa-check"></i><b>9.1.3</b> Distancia de Gower en <code>Python</code></a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="distancias-con-conjuntos-de-variables-de-tipo-cuantitativo-binario-multiclase.html"><a href="distancias-con-conjuntos-de-variables-de-tipo-cuantitativo-binario-multiclase.html#similaridad-de-gower-mahalanobis"><i class="fa fa-check"></i><b>9.2</b> Similaridad de Gower-Mahalanobis</a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="distancias-con-conjuntos-de-variables-de-tipo-cuantitativo-binario-multiclase.html"><a href="distancias-con-conjuntos-de-variables-de-tipo-cuantitativo-binario-multiclase.html#distancia-de-gower-mahalanobis"><i class="fa fa-check"></i><b>9.2.1</b> Distancia de Gower-Mahalanobis</a></li>
<li class="chapter" data-level="9.2.2" data-path="distancias-con-conjuntos-de-variables-de-tipo-cuantitativo-binario-multiclase.html"><a href="distancias-con-conjuntos-de-variables-de-tipo-cuantitativo-binario-multiclase.html#similaridad-de-gower-mahalanobis-en-python"><i class="fa fa-check"></i><b>9.2.2</b> Similaridad de Gower-Mahalanobis en <code>Python</code></a></li>
<li class="chapter" data-level="9.2.3" data-path="distancias-con-conjuntos-de-variables-de-tipo-cuantitativo-binario-multiclase.html"><a href="distancias-con-conjuntos-de-variables-de-tipo-cuantitativo-binario-multiclase.html#distancia-de-gower-mahalanobis-en-python"><i class="fa fa-check"></i><b>9.2.3</b> Distancia de Gower-Mahalanobis en <code>Python</code></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="anexo.html"><a href="anexo.html"><i class="fa fa-check"></i><b>10</b> Anexo</a></li>
<li class="chapter" data-level="11" data-path="distancia-de-gower-generalizada.html"><a href="distancia-de-gower-generalizada.html"><i class="fa fa-check"></i><b>11</b> Distancia de Gower Generalizada</a>
<ul>
<li class="chapter" data-level="11.1" data-path="distancia-de-gower-generalizada.html"><a href="distancia-de-gower-generalizada.html#versión-simple"><i class="fa fa-check"></i><b>11.1</b> Versión simple</a></li>
<li class="chapter" data-level="11.2" data-path="distancia-de-gower-generalizada.html"><a href="distancia-de-gower-generalizada.html#versión-related-metric-scaling"><i class="fa fa-check"></i><b>11.2</b> Versión related metric scaling</a></li>
<li class="chapter" data-level="11.3" data-path="distancia-de-gower-generalizada.html"><a href="distancia-de-gower-generalizada.html#distancia-de-gower-generalizada-en-python"><i class="fa fa-check"></i><b>11.3</b> Distancia de Gower Generalizada en <code>Python</code></a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="distancia-de-mahalanobis-robusta.html"><a href="distancia-de-mahalanobis-robusta.html"><i class="fa fa-check"></i><b>12</b> Distancia de Mahalanobis Robusta</a>
<ul>
<li class="chapter" data-level="12.1" data-path="distancia-de-mahalanobis-robusta.html"><a href="distancia-de-mahalanobis-robusta.html#definición"><i class="fa fa-check"></i><b>12.1</b> Definición</a></li>
<li class="chapter" data-level="12.2" data-path="distancia-de-mahalanobis-robusta.html"><a href="distancia-de-mahalanobis-robusta.html#estimación-robusta-de-la-matriz-de-covarianzas"><i class="fa fa-check"></i><b>12.2</b> Estimación robusta de la matriz de covarianzas</a>
<ul>
<li class="chapter" data-level="12.2.1" data-path="distancia-de-mahalanobis-robusta.html"><a href="distancia-de-mahalanobis-robusta.html#estimación-robusta-de-la-varianza"><i class="fa fa-check"></i><b>12.2.1</b> Estimación robusta de la varianza</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="distancia-de-mahalanobis-robusta.html"><a href="distancia-de-mahalanobis-robusta.html#estimación-robusta-de-la-correlación"><i class="fa fa-check"></i><b>12.3</b> Estimación robusta de la correlación</a></li>
<li class="chapter" data-level="12.4" data-path="distancia-de-mahalanobis-robusta.html"><a href="distancia-de-mahalanobis-robusta.html#estimación-robusta-de-la-covarianza"><i class="fa fa-check"></i><b>12.4</b> Estimación robusta de la covarianza</a></li>
<li class="chapter" data-level="12.5" data-path="distancia-de-mahalanobis-robusta.html"><a href="distancia-de-mahalanobis-robusta.html#estimación-robusta-de-la-matriz-de-correlaciones"><i class="fa fa-check"></i><b>12.5</b> Estimación robusta de la matriz de correlaciones</a></li>
<li class="chapter" data-level="12.6" data-path="distancia-de-mahalanobis-robusta.html"><a href="distancia-de-mahalanobis-robusta.html#estimación-robusta-de-la-matriz-de-covarianzas-1"><i class="fa fa-check"></i><b>12.6</b> Estimación robusta de la matriz de covarianzas</a></li>
<li class="chapter" data-level="12.7" data-path="distancia-de-mahalanobis-robusta.html"><a href="distancia-de-mahalanobis-robusta.html#inversa-de-la-estimación-robusta-de-la-matriz-de-covarianzas"><i class="fa fa-check"></i><b>12.7</b> Inversa de la estimación robusta de la matriz de covarianzas</a>
<ul>
<li class="chapter" data-level="12.7.1" data-path="distancia-de-mahalanobis-robusta.html"><a href="distancia-de-mahalanobis-robusta.html#pseudo-inversa-de-moore-penrose"><i class="fa fa-check"></i><b>12.7.1</b> Pseudo inversa de Moore-Penrose</a></li>
</ul></li>
<li class="chapter" data-level="12.8" data-path="distancia-de-mahalanobis-robusta.html"><a href="distancia-de-mahalanobis-robusta.html#transformación-de-delvin-para-obtener-s_r-definida-positiva"><i class="fa fa-check"></i><b>12.8</b> Transformación de Delvin para obtener <span class="math inline">\(S_R\)</span> definida positiva</a>
<ul>
<li class="chapter" data-level="12.8.1" data-path="distancia-de-mahalanobis-robusta.html"><a href="distancia-de-mahalanobis-robusta.html#algoritmo-de-delvin-para-obtener-s_r-definida-positiva"><i class="fa fa-check"></i><b>12.8.1</b> Algoritmo de Delvin para obtener <span class="math inline">\(S_R\)</span> definida positiva</a></li>
<li class="chapter" data-level="12.8.2" data-path="distancia-de-mahalanobis-robusta.html"><a href="distancia-de-mahalanobis-robusta.html#distancia-de-mahalanobis-robusta-en-python"><i class="fa fa-check"></i><b>12.8.2</b> Distancia de Mahalanobis Robusta en <code>Python</code></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="13" data-path="bibliografía.html"><a href="bibliografía.html"><i class="fa fa-check"></i><b>13</b> Bibliografía</a></li>
<li class="divider"></li>
<li><a href="https://estadistica4all.com" target="blank">Estadistica4all.com</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Distancias Estadísticas</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="distancia-de-gower-generalizada" class="section level1 hasAnchor" number="11">
<h1><span class="header-section-number">Chapter 11</span> Distancia de Gower Generalizada<a href="distancia-de-gower-generalizada.html#distancia-de-gower-generalizada" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>Tenemos un conjunto de variables estadísticas <span class="math inline">\(\hspace{0.03cm}(\mathcal{X}_1,...,\mathcal{X}_p )\hspace{0.03cm}\)</span> tales que las <span class="math inline">\(\hspace{0.03cm}p_1\hspace{0.03cm}\)</span> primeras son cuantitativas, las <span class="math inline">\(\hspace{0.03cm}p_2\hspace{0.03cm}\)</span> siguientes son binarias y las últimas <span class="math inline">\(\hspace{0.03cm}p_3\hspace{0.03cm}\)</span> son multiclase, es decir: <span class="math inline">\(\\\)</span></p>
<ul>
<li><p><span class="math inline">\(\mathcal{X}_1,...,\mathcal{X}_{p_1} \hspace{0.05cm}\)</span> son <strong>cuantitativas</strong>.</p></li>
<li><p><span class="math inline">\(\mathcal{X}_{p_1 + 1},...,\mathcal{X}_{p_1 + p_2} \hspace{0.05cm}\)</span> son <strong>binarias</strong>.</p></li>
<li><p><span class="math inline">\(\mathcal{X}_{p_1 + p_2 + 1},...,\mathcal{X}_{p_1 + p_2 + p_3} \hspace{0.05cm}\)</span> son <strong>multiclase</strong> (no binarias). <span class="math inline">\(\\\)</span></p></li>
</ul>
<p>Donde: <span class="math inline">\(\hspace{0.1cm} p=p_1 + p_2 + p_3\hspace{0.08cm}.\)</span> <span class="math inline">\(\\\)</span></p>
<p>Además, tenemos las siguientes muestras de datos para cada uno de los tipos de variables estadísticas:</p>
<ul>
<li><p>Conjunto de datos de las variables <strong>cuantitativas</strong>:</p>
<p><span class="math display">\[X_Q = (X_1,...,X_{p_1}) = ( x_i^Q \hspace{0.05cm}:\hspace{0.05cm} i=1,...,n )\]</span></p>
<ul>
<li><span class="math inline">\(\hspace{0.03cm}x_i^Q= (x_{i, 1},....,x_{i p_1})\hspace{0.1cm}\)</span> es <span class="math inline">\(i\)</span>-esimo vector de observaciones de las variables <strong>cuantitativas</strong>. <span class="math inline">\(\\[0.75cm]\)</span></li>
</ul></li>
<li><p>Conjunto de datos de las variables <strong>binarias</strong>:</p>
<p><span class="math display">\[X_B = (X_{p_1 +1},..., X_{p_1+p_2})= ( x_i^B \hspace{0.05cm}:\hspace{0.05cm} i=1,...,n )\]</span></p>
<ul>
<li><span class="math inline">\(\hspace{0.03cm}x_i^B= (x_{i, (p_1+1)},....,x_{i (p_1+p_2)})\hspace{0.1cm}\)</span> es el <span class="math inline">\(i\)</span>-esimo vector de observaciones de las variables <strong>binarias</strong>. <span class="math inline">\(\\[0.75cm]\)</span></li>
</ul></li>
<li><p>Conjunto de datos de las variables <strong>multiclase</strong>:</p>
<p><span class="math display">\[X_M = (X_{p_1+p_2+1},...,X_{p_1+p_2+p_3})= ( x_i^M   \hspace{0.05cm}: \hspace{0.05cm}  i=1,...,n )\]</span></p>
<ul>
<li><span class="math inline">\(\hspace{0.03cm}x_i^M= (x_{i, (p_1+p_2+1)},....,x_{i (p_1+p_2+p_3)})\hspace{0.1cm}\)</span> es el <span class="math inline">\(i\)</span>-esimo vector de observaciones de las variables <strong>multiclase</strong>. <span class="math inline">\(\\\)</span></li>
</ul></li>
</ul>
<p>Donde <span class="math inline">\(\hspace{0.02cm} X_j = (x_{1j},...,x_{nj})^t\hspace{0.04cm}\)</span> es una muestra de <span class="math inline">\(n\)</span> observaciones de la variable <span class="math inline">\(X_j\hspace{0.06cm},\)</span> para <span class="math inline">\(\hspace{0.03cm}j=1,...,p\hspace{0.08cm}\)</span>.</p>
<p><br></p>
<p><strong>Observación:</strong></p>
<p><span class="math inline">\(\mathcal{X}_1,...,\mathcal{X}_p \hspace{0.1cm}\)</span> forman un conjunto de variables de tipo <strong>cuantitativo-binario-multiclase</strong>.</p>
<p><br></p>
<div id="versión-simple" class="section level2 hasAnchor" number="11.1">
<h2><span class="header-section-number">11.1</span> Versión simple<a href="distancia-de-gower-generalizada.html#versión-simple" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>El algoritmo que define la versión simple de la distancia de Gower generalizada es el siguiente:</p>
<ul>
<li><p>Se calcula una matriz de distancias para cada conjunto de datos <span class="math inline">\(X_Q\)</span> , <span class="math inline">\(\hspace{0.05cm}X_B\hspace{0.06cm}\)</span> y <span class="math inline">\(\hspace{0.05cm}X_M\hspace{0.05cm}\)</span>.</p>
<ul>
<li><span class="math inline">\(D_1\hspace{0.05cm}\)</span> es la matriz de distancias <span class="math inline">\(\hspace{0.05cm}\delta_1\hspace{0.05cm}\)</span> entre las observaciones de las variables cuantitativas, es decir, las observaciones de <span class="math inline">\(\hspace{0.02cm}X_Q\hspace{0.05cm}\)</span>.</li>
</ul>
<p><span class="math display">\[D_1 \hspace{0.03cm}=\hspace{0.03cm} \Bigl( \hspace{0.05cm} \delta_1(x_i^Q, x_r^Q) \hspace{0.07cm} : \hspace{0.07cm} i,r=1,...,n \hspace{0.05cm}\Bigr)\\\]</span></p>
<ul>
<li><span class="math inline">\(D_2\hspace{0.05cm}\)</span> es la matriz de distancias <span class="math inline">\(\hspace{0.05cm}\delta_2\hspace{0.05cm}\)</span> entre las observaciones de las variables cuantitativas, es decir, las observaciones de <span class="math inline">\(\hspace{0.02cm}X_B\hspace{0.05cm}\)</span>.</li>
</ul>
<p><span class="math display">\[D_2 \hspace{0.03cm}=\hspace{0.03cm} \Bigl( \hspace{0.05cm} \delta_2(x_i^B, x_r^B) \hspace{0.07cm} : \hspace{0.07cm} i,r=1,...,n \hspace{0.05cm}\Bigr)\\\]</span></p>
<ul>
<li><span class="math inline">\(D_3\hspace{0.05cm}\)</span> es la matriz de distancias <span class="math inline">\(\hspace{0.05cm}\delta_3\hspace{0.05cm}\)</span> entre las observaciones de las variables cuantitativas, es decir, las observaciones de <span class="math inline">\(\hspace{0.02cm}X_M\hspace{0.05cm}\)</span>.</li>
</ul>
<p><span class="math display">\[D_3 \hspace{0.03cm}=\hspace{0.03cm} \Bigl( \hspace{0.05cm} \delta_3(x_i^M, x_r^M) \hspace{0.07cm} : \hspace{0.07cm} i,r=1,...,n \hspace{0.05cm}\Bigr)\]</span></p></li>
</ul>
<p><br></p>
<ul>
<li><p>Se calculan las variabilidades geométricas
para cada una de las matrices de distancias <span class="math inline">\(D_1\)</span>, <span class="math inline">\(D_2\)</span> y <span class="math inline">\(D_3\)</span> .</p>
<ul>
<li>La variabilidad geométrica de <span class="math inline">\(D_1\)</span> es:</li>
</ul>
<p><span class="math display">\[VG_1  \hspace{0.05cm}=\hspace{0.05cm} \dfrac{1}{2\cdot n^2} \cdot \sum_{i=1}^n \sum_{r=1}^n \hspace{0.03cm}\delta_1^2 (x_i^Q , x_r^Q) \\\]</span></p>
<ul>
<li>La variabilidad geométrica de <span class="math inline">\(D_2\)</span> es:</li>
</ul>
<p><span class="math display">\[VG_2  \hspace{0.05cm}=\hspace{0.05cm} \dfrac{1}{2\cdot n^2} \cdot \sum_{i=1}^n \sum_{r=1}^n \hspace{0.03cm}\delta_2^2 (x_i^B , x_r^B) \\\]</span></p>
<ul>
<li>La variabilidad geométrica de <span class="math inline">\(D_3\)</span> es:</li>
</ul>
<p><span class="math display">\[VG_3  \hspace{0.05cm}=\hspace{0.05cm}\dfrac{1}{2\cdot n^2} \cdot \sum_{i=1}^n \sum_{r=1}^n \hspace{0.03cm}\delta_3^2 (x_i^M , x_r^M)\]</span></p></li>
</ul>
<p><br></p>
<ul>
<li><p>Se estandarizan las matrices de distancias al cuadrado <span class="math inline">\(\hspace{0.02cm} D_j^{(2)} \hspace{0.02cm}\)</span> a variabilidad geométrica uno, para <span class="math inline">\(\hspace{0.03cm} j =1,2,3 \hspace{0.05cm} .\)</span></p>
<ul>
<li>La estandarización de <span class="math inline">\(\hspace{0.02cm} D_1^{(2)} \hspace{0.02cm}\)</span> es :</li>
</ul>
<p><span class="math display">\[D_1^{(2)&#39;} \hspace{0.05cm}=\hspace{0.05cm} \dfrac{1}{VG_1} \cdot D_1^{(2)} \hspace{0.05cm}=\hspace{0.05cm}  \Bigl( \hspace{0.05cm} \delta_1^2(x_i^Q,x_r^Q) \hspace{0.04cm}/\hspace{0.04cm} VG_1  \hspace{0.1cm}:\hspace{0.1cm} i,r=1,...,n \hspace{0.05cm}\Bigr)\\\]</span></p>
<ul>
<li>La estandarización de <span class="math inline">\(\hspace{0.02cm} D_2^{(2)} \hspace{0.02cm}\)</span> es :</li>
</ul>
<p><span class="math display">\[D_2^{(2)&#39;} \hspace{0.05cm}=\hspace{0.05cm} \dfrac{1}{VG_2} \cdot D_2^{(2)} \hspace{0.05cm}=\hspace{0.05cm}  \Bigl( \hspace{0.05cm} \delta_2^2(x_i^B,x_r^B) \hspace{0.04cm}/\hspace{0.04cm} VG_2  \hspace{0.1cm}:\hspace{0.1cm} i,r=1,...,n \hspace{0.05cm}\Bigr)\\\]</span></p>
<ul>
<li>La estandarización de <span class="math inline">\(\hspace{0.02cm} D_3^{(2)} \hspace{0.02cm}\)</span> es :</li>
</ul>
<p><span class="math display">\[D_3^{(2)&#39;} \hspace{0.05cm}=\hspace{0.05cm} \dfrac{1}{VG_3} \cdot D_3^{(2)} \hspace{0.05cm}=\hspace{0.05cm} \Bigl( \hspace{0.05cm} \delta_3^2(x_i^M,x_r^M) \hspace{0.04cm}/\hspace{0.04cm} VG_3  \hspace{0.1cm}:\hspace{0.1cm} i,r=1,...,n \hspace{0.05cm}\Bigr)\\\]</span></p></li>
</ul>
<p><br></p>
<ul>
<li><p>Se combinan las <span class="math inline">\(D_j^{(2)&#39;}\)</span> , para <span class="math inline">\(j=1,2,3,\)</span> para obtener la <strong>matriz de cuadrados de distancias de Gower Generalizada simple</strong> para el conjunto de datos <span class="math inline">\(X=(X_Q,X_B,X_M)\)</span> :</p>
<p><span class="math display">\[D_{GG}^{(2)} \hspace{0.13cm}=\hspace{0.13cm} \sum_{j=1}^n \hspace{0.03cm} D_j^{(2)&#39;} \hspace{0.13cm}=\hspace{0.13cm} \Bigl(\hspace{0.05cm} \delta^2_{GG}(x_i,x_r) \hspace{0.06cm}:\hspace{0.06cm} i,r=1,...,n \hspace{0.05cm}\Bigr) \\\]</span></p>
<p>La <strong>distancia de Gower Generalizada simple al cuadrado</strong> es :</p>
<p><span class="math display">\[\delta^2_{GG}(x_i,x_r) \hspace{0.12cm}=\hspace{0.12cm}  \dfrac{ \delta_1^2(x_i^Q,x_r^Q)}{VG_1} \hspace{0.08cm}+\hspace{0.08cm} \dfrac{ \delta_2^2(x_i^B,x_r^B)}{VG_2} \hspace{0.08cm}+\hspace{0.08cm} \dfrac{ \delta_3^2(x_i^M,x_r^M)}{VG_3} \hspace{0.4cm} , \hspace{0.4cm} i,r = 1,...,n \\\]</span></p>
<p>La <strong>distancia de Gower Generalizada simple</strong> es :</p>
<p><span class="math display">\[\delta_{GG}(x_i,x_r) \hspace{0.12cm}=\hspace{0.12cm} \sqrt{\hspace{0.1cm}  \dfrac{ \delta_1^2(x_i^Q,x_r^Q)}{VG_1} \hspace{0.07cm}+\hspace{0.07cm} \dfrac{ \delta_2^2(x_i^B,x_r^B)}{VG_2} \hspace{0.07cm}+\hspace{0.07cm} \dfrac{ \delta_3^2(x_i^M,x_r^M)}{VG_3} \hspace{0.03cm}}  \hspace{0.4cm} , \hspace{0.4cm} i,r = 1,...,n\]</span></p></li>
</ul>
<p><br></p>
<p><strong>¿Por qué estandarizamos usando la variabilidad geométrica?</strong></p>
<p>Para que todas las matrices de distancia que se combinan sean directamente comparables, es decir, que todas tengan la misma dispersión.</p>
<p><br></p>
<p><strong>Observación:</strong></p>
<p>Hay que notar que el algoritmo anterior requiere que las medidas de similitud empleadas para las variables binarias y multiclase sean transformadas a medidas de distancia, puesto que el algoritmo considera de partida matrices de distancia. Se puede ver como paso previo a la aplicación del algoritmo esta transformación de similaridades a distancias para el caso de las binarias y multiclase.</p>
<p><br></p>
</div>
<div id="versión-related-metric-scaling" class="section level2 hasAnchor" number="11.2">
<h2><span class="header-section-number">11.2</span> Versión related metric scaling<a href="distancia-de-gower-generalizada.html#versión-related-metric-scaling" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>El algoritmo que define la versión simple de la distancia de Gower generalizada es el siguiente:</p>
<ul>
<li><p>Se calcula una matriz de distancias para cada conjunto de datos <span class="math inline">\(X_Q\)</span> , <span class="math inline">\(\hspace{0.05cm}X_B\hspace{0.06cm}\)</span> y <span class="math inline">\(\hspace{0.05cm}X_M\hspace{0.05cm}\)</span>.</p>
<ul>
<li><span class="math inline">\(D_1\hspace{0.05cm}\)</span> es la matriz de distancias <span class="math inline">\(\hspace{0.05cm}\delta_1\hspace{0.05cm}\)</span> entre las observaciones de las variables cuantitativas, es decir, las observaciones de <span class="math inline">\(\hspace{0.02cm}X_Q\hspace{0.05cm}\)</span>.</li>
</ul>
<p><span class="math display">\[D_1 \hspace{0.03cm}=\hspace{0.03cm} \Bigl( \hspace{0.05cm} \delta_1(x_i^Q, x_r^Q) \hspace{0.07cm} : \hspace{0.07cm} i,r=1,...,n \hspace{0.05cm}\Bigr)\\\]</span></p>
<ul>
<li><span class="math inline">\(D_2\hspace{0.05cm}\)</span> es la matriz de distancias <span class="math inline">\(\hspace{0.05cm}\delta_2\hspace{0.05cm}\)</span> entre las observaciones de las variables cuantitativas, es decir, las observaciones de <span class="math inline">\(\hspace{0.02cm}X_B\hspace{0.05cm}\)</span>.</li>
</ul>
<p><span class="math display">\[D_2 \hspace{0.03cm}=\hspace{0.03cm} \Bigl( \hspace{0.05cm} \delta_2(x_i^B, x_r^B) \hspace{0.07cm} : \hspace{0.07cm} i,r=1,...,n \hspace{0.05cm}\Bigr)\\\]</span></p>
<ul>
<li><span class="math inline">\(D_3\hspace{0.05cm}\)</span> es la matriz de distancias <span class="math inline">\(\hspace{0.05cm}\delta_3\hspace{0.05cm}\)</span> entre las observaciones de las variables cuantitativas, es decir, las observaciones de <span class="math inline">\(\hspace{0.02cm}X_M\hspace{0.05cm}\)</span>.</li>
</ul>
<p><span class="math display">\[D_3 \hspace{0.03cm}=\hspace{0.03cm} \Bigl( \hspace{0.05cm} \delta_3(x_i^M, x_r^M) \hspace{0.07cm} : \hspace{0.07cm} i,r=1,...,n \hspace{0.05cm}\Bigr)\]</span></p></li>
</ul>
<p><br></p>
<ul>
<li><p>Se calculan las variabilidades geométricas
para cada una de las matrices de distancias <span class="math inline">\(D_1\)</span>, <span class="math inline">\(D_2\)</span> y <span class="math inline">\(D_3\)</span> .</p>
<ul>
<li>La variabilidad geométrica de <span class="math inline">\(D_1\)</span> es:</li>
</ul>
<p><span class="math display">\[VG_1  \hspace{0.05cm}=\hspace{0.05cm} \dfrac{1}{2\cdot n^2} \cdot \sum_{i=1}^n \sum_{r=1}^n \hspace{0.03cm}\delta_1^2 (x_i^Q , x_r^Q) \\\]</span></p>
<ul>
<li>La variabilidad geométrica de <span class="math inline">\(D_2\)</span> es:</li>
</ul>
<p><span class="math display">\[VG_2  \hspace{0.05cm}=\hspace{0.05cm} \dfrac{1}{2\cdot n^2} \cdot \sum_{i=1}^n \sum_{r=1}^n \hspace{0.03cm}\delta_2^2 (x_i^B , x_r^B) \\\]</span></p>
<ul>
<li>La variabilidad geométrica de <span class="math inline">\(D_3\)</span> es:</li>
</ul>
<p><span class="math display">\[VG_3  \hspace{0.05cm}=\hspace{0.05cm}\dfrac{1}{2\cdot n^2} \cdot \sum_{i=1}^n \sum_{r=1}^n \hspace{0.03cm}\delta_3^2 (x_i^M , x_r^M)\]</span></p></li>
</ul>
<p><br></p>
<ul>
<li><p>Se estandarizan las matrices de distancias al cuadrado <span class="math inline">\(\hspace{0.02cm} D_j^{(2)} \hspace{0.02cm}\)</span> a variabilidad geométrica uno, para <span class="math inline">\(\hspace{0.03cm} j =1,2,3 \hspace{0.05cm} .\)</span></p>
<ul>
<li>La estandarización de <span class="math inline">\(\hspace{0.02cm} D_1^{(2)} \hspace{0.02cm}\)</span> es :</li>
</ul>
<p><span class="math display">\[D_1^{(2)&#39;} \hspace{0.05cm}=\hspace{0.05cm} \dfrac{1}{VG_1} \cdot D_1^{(2)} \hspace{0.05cm}=\hspace{0.05cm}  \Bigl( \hspace{0.05cm} \delta_1^2(x_i^Q,x_r^Q) \hspace{0.04cm}/\hspace{0.04cm} VG_1  \hspace{0.1cm}:\hspace{0.1cm} i,r=1,...,n \hspace{0.05cm}\Bigr)\\\]</span></p>
<ul>
<li>La estandarización de <span class="math inline">\(\hspace{0.02cm} D_2^{(2)} \hspace{0.02cm}\)</span> es :</li>
</ul>
<p><span class="math display">\[D_2^{(2)&#39;} \hspace{0.05cm}=\hspace{0.05cm} \dfrac{1}{VG_2} \cdot D_2^{(2)} \hspace{0.05cm}=\hspace{0.05cm}  \Bigl( \hspace{0.05cm} \delta_2^2(x_i^B,x_r^B) \hspace{0.04cm}/\hspace{0.04cm} VG_2  \hspace{0.1cm}:\hspace{0.1cm} i,r=1,...,n \hspace{0.05cm}\Bigr)\\\]</span></p>
<ul>
<li>La estandarización de <span class="math inline">\(\hspace{0.02cm} D_3^{(2)} \hspace{0.02cm}\)</span> es :</li>
</ul>
<p><span class="math display">\[D_3^{(2)&#39;} \hspace{0.05cm}=\hspace{0.05cm} \dfrac{1}{VG_3} \cdot D_3^{(2)} \hspace{0.05cm}=\hspace{0.05cm} \Bigl( \hspace{0.05cm} \delta_3^2(x_i^M,x_r^M) \hspace{0.04cm}/\hspace{0.04cm} VG_3  \hspace{0.1cm}:\hspace{0.1cm} i,r=1,...,n \hspace{0.05cm}\Bigr)\\\]</span></p></li>
</ul>
<p><br></p>
<ul>
<li><p>Se calculan las matrices de Gram, <span class="math inline">\(G_j\)</span>, de las matrices de distancias al cuadrado estandarizadas <span class="math inline">\(\hspace{0.03cm}D_j^{(2)&#39;}\hspace{0.03cm},\)</span> para <span class="math inline">\(\hspace{0.03cm}j =1,2,3 \hspace{0.03cm}.\)</span></p>
<p><span class="math display">\[G_j \hspace{0.1cm}=\hspace{0.1cm}  -\dfrac{1}{2} \cdot H \cdot D_j^{(2)&#39;} \cdot H \hspace{0.4cm} ,  \hspace{0.4cm} j=1,2,3 \]</span></p>
<p>Donde: <span class="math inline">\(\hspace{0.1cm} H \hspace{0.1cm}=\hspace{0.1cm} I \hspace{0.03cm}-\hspace{0.03cm} \dfrac{1}{n}\cdot \mathbf{1}\cdot \mathbf{1}^t\hspace{0.08cm}\)</span> es la matriz de centrado.</p></li>
</ul>
<p><br></p>
<ul>
<li><p>Se calcula la matriz <span class="math inline">\(\hspace{0.03cm}G\hspace{0.03cm}\)</span> combinando las matrices <span class="math inline">\(\hspace{0.03cm}G_1\hspace{0.03cm}\)</span>, <span class="math inline">\(\hspace{0.03cm}G_2\hspace{0.03cm}\)</span> y <span class="math inline">\(\hspace{0.03cm}G_3\hspace{0.03cm}\)</span> del siguiente modo:</p>
<p><span class="math display">\[G \hspace{0.12cm}=\hspace{0.12cm}  \sum_{j=1}^3 \hspace{0.03cm} G_j  \hspace{0.05cm}-\hspace{0.05cm} \dfrac{1}{3} \cdot \sum_{k\neq j = 1}^3 G_k^{1/2} \cdot G_j^{1/2}\]</span></p>
<p>Donde:</p>
<p><span class="math display">\[\sum_{k\neq j =1}^{3}  G_k^{1/2} \cdot G_j^{1/2} \hspace{0.2cm}=\hspace{0.2cm} G_1^{1/2} \cdot G_2^{1/2} \hspace{0.07cm}+\hspace{0.07cm} G_1^{1/2} \cdot G_3^{1/2} \hspace{0.07cm} + \hspace{0.07cm} G_2^{1/2} \cdot G_1^{1/2} \hspace{0.05cm}+ \\[0.6cm] +\hspace{0.1cm} G_2^{1/2} \cdot G_3^{1/2} \hspace{0.07cm} +\hspace{0.07cm} G_3^{1/2} \cdot G_1^{1/2} \hspace{0.07cm}+\hspace{0.07cm} G_3^{1/2} \cdot G_2^{1/2}\]</span></p></li>
</ul>
<p><br></p>
<ul>
<li><p>Se calcula la <strong>matriz de cuadrados de distancias de Gower Generalizada related metric scaling</strong> para el conjunto de datos <span class="math inline">\(X=(X_Q,X_B,X_M)\)</span>, del siguiente modo:</p>
<p><span class="math display">\[D^{(2)}_{GG} \hspace{0.13cm} = \hspace{0.13cm} \mathbf{g} \cdot \mathbf{1}^t + \mathbf{1}\cdot \mathbf{g}^t - 2\cdot G \hspace{0.13cm}=\hspace{0.13cm} \Bigl(\hspace{0.07cm} \delta^2_{GG}(x_i,x_r) \hspace{0.12cm}:\hspace{0.12cm} i,r=1,...,n \hspace{0.07cm}\Bigr)\]</span></p>
<p>Donde: <span class="math inline">\(\hspace{0.1cm}\mathbf{g} \hspace{0.07cm}=\hspace{0.07cm} diag(G)\hspace{0.03cm}.\)</span></p>
<p>A partir de esta matriz de cuadrados de distancias podemos obtener la <strong>distancia de Gower Generalizada related metric scaling al cuadrado</strong> del siguiente modo:</p>
<p><span class="math display">\[\delta^2_{GG}(x_i,x_r) \hspace{0.07cm}=\hspace{0.07cm} D^{(2)}_{GG}[i,r] \hspace{0.4cm} , \hspace{0.4cm} i,r = 1,...,n\]</span></p>
<p>A partir de esta matriz de cuadrados de distancias podemos obtener la <strong>distancia de Gower Generalizada related metric scaling</strong> del siguiente modo:</p>
<p><span class="math display">\[\delta_{GG}(x_i,x_r) \hspace{0.07cm}=\hspace{0.07cm} \sqrt{\hspace{0.07cm}D^{(2)}_{GG}[i,r]\hspace{0.1cm}} \hspace{0.4cm} , \hspace{0.4cm} i,r = 1,...,n\]</span></p></li>
</ul>
<p><br></p>
<p><strong>¿Por que related metric scaling?</strong></p>
<p>Este procedimiento permite eliminar redundancia de información entre grupos de variables.</p>
<p><br></p>
<p><strong>¿Cómo calcular <span class="math inline">\(G^{1/2}_j\)</span>?</strong></p>
<ul>
<li><p><strong><em>Usando la descomposición en valores singulares (SVD)</em></strong></p>
<p><span class="math inline">\(G_j\)</span> debe ser simétrica <span class="math inline">\((G_j = G_j^t)\)</span> y semi-definida positiva (autovalores de <span class="math inline">\(G_j\)</span> son <span class="math inline">\(&gt; 0\)</span> y alguno <span class="math inline">\(=0\)</span>).</p>
<p>En este caso, como <span class="math inline">\(G_j\)</span> es una matriz <span class="math inline">\(n\text{x}n\)</span>, entonces:</p>
<p>La <strong>descomposición en valores singulares</strong> (SVD) de <span class="math inline">\(G_j\)</span> es:</p>
<p><span class="math display">\[G_j \hspace{0.05cm} = \hspace{0.05cm} U \cdot \Sigma \cdot V^t\]</span>
Usando la descomposición en valores singulares <span class="math inline">\(\hspace{0.02cm}G_j\hspace{0.02cm}\)</span> puede calcularse <span class="math inline">\(\hspace{0.04cm}G_j^{1/2}\hspace{0.04cm}\)</span> del siguiente modo:</p>
<p><span class="math display">\[G_j^{1/2} \hspace{0.05cm} = \hspace{0.05cm} U \cdot \Sigma^{1/2} \cdot V^t \\\]</span></p>
<p>Donde:</p>
<p>Si <span class="math inline">\(\hspace{0.03cm}\lambda_1 \geq \lambda_2 \geq \dots \geq \lambda_n\hspace{0.03cm}\)</span> son los autovalores de <span class="math inline">\(\hspace{0.03cm}G_j\hspace{0.02cm}^t \cdot G_j\hspace{0.03cm}\)</span> ordenados de mayor a menor, y <span class="math inline">\(\hspace{0.02cm}w(\lambda_i)\hspace{0.02cm}\)</span> es el autovector asociado al autovalor <span class="math inline">\(\hspace{0.02cm}\lambda_i\hspace{0.02cm}\)</span>, entonces:</p>
<ul>
<li><p>Los valores singulares de <span class="math inline">\(\hspace{0.02cm}G_j\hspace{0.02cm}\)</span> son <span class="math inline">\(\hspace{0.02cm}\sqrt{\lambda_1},...,\sqrt{\lambda_n}\hspace{0.02cm}\)</span>.</p></li>
<li><p>La matriz <span class="math inline">\(\hspace{0.02cm}\Sigma\hspace{0.02cm}\)</span> se define como:</p></li>
</ul>
<p><span class="math display">\[\Sigma \hspace{0.04cm} = \hspace{0.04cm}  diag\bigl( \hspace{0.04cm}\sqrt{\lambda_1}\hspace{0.02cm},...,\hspace{0.02cm}\sqrt{\lambda_n} \hspace{0.04cm} \bigr)\]</span></p>
<ul>
<li>La matriz <span class="math inline">\(\hspace{0.02cm}V\hspace{0.02cm}\)</span> se define como:</li>
</ul>
<p><span class="math display">\[V \hspace{0.04cm} = \hspace{0.04cm} \Bigl(\hspace{0.03cm} w(\lambda_1) \hspace{0.02cm}\dots\hspace{0.02cm} w(\lambda_n) \hspace{0.03cm}\Bigr)\]</span></p>
<ul>
<li>La matriz <span class="math inline">\(\hspace{0.02cm}U\hspace{0.02cm}\)</span> se define como:</li>
</ul>
<p><span class="math display">\[U \hspace{0.04cm} = \hspace{0.04cm} G\cdot V \cdot \Sigma^{-1/2}\]</span></p></li>
</ul>
<p><br></p>
<ul>
<li><p><strong><em>Usando la descomposición espectral</em></strong></p>
<p><span class="math inline">\(G_j\hspace{0.02cm}\)</span> debe ser cuadrada <span class="math inline">\((n\text{x}n)\)</span>, simétrica, es decir <span class="math inline">\(G_j = G_j^t\)</span>, y semi-definida positiva, es decir autovalores de <span class="math inline">\(\hspace{0.02cm}G_j\hspace{0.02cm}\)</span> son <span class="math inline">\(\hspace{0.02cm}&gt; 0\hspace{0.02cm}\)</span> excepto alguno que es <span class="math inline">\(=0\)</span> .</p>
<p>La <strong>descomposición espectral</strong> de <span class="math inline">\(\hspace{0.02cm}G_j\hspace{0.02cm}\)</span> es:</p>
<p><span class="math display">\[G_j \hspace{0.05cm} = \hspace{0.05cm} Q \cdot \Lambda \cdot Q^t\]</span>
Usando la descomposición espectral <span class="math inline">\(\hspace{0.02cm}G_j\hspace{0.02cm}\)</span> puede calcularse <span class="math inline">\(\hspace{0.033cm}G_j^{1/2}\hspace{0.033cm}\)</span> del siguiente modo:</p>
<p><span class="math display">\[G_j^{1/2} \hspace{0.05cm} = \hspace{0.05cm} Q\cdot \Lambda^{1/2} \cdot Q^t\]</span></p>
<p>Donde:</p>
<p>Si <span class="math inline">\(\hspace{0.03cm}\lambda_1 \geq \lambda_2 \geq \dots \geq \lambda_n\hspace{0.03cm}\)</span> son los autovalores de <span class="math inline">\(\hspace{0.03cm}G_j\hspace{0.03cm}\)</span> ordenados de mayor a menor, y <span class="math inline">\(\hspace{0.02cm}w(\lambda_i)\hspace{0.02cm}\)</span> es el autovector asociado al autovalor <span class="math inline">\(\hspace{0.02cm}\lambda_i\hspace{0.02cm}\)</span>, entonces:</p>
<p>La matriz <span class="math inline">\(\hspace{0.02cm}\Lambda\hspace{0.02cm}\)</span> se define como:</p>
<p><span class="math display">\[\Lambda \hspace{0.05cm}=\hspace{0.05cm} diag\bigl( \hspace{0.04cm} \lambda_1,...,\lambda_n \hspace{0.04cm}\bigr)\]</span></p>
<p>La matriz <span class="math inline">\(\hspace{0.02cm}Q\hspace{0.02cm}\)</span> se define como:</p>
<p><span class="math display">\[Q \hspace{0.05cm}=\hspace{0.05cm} \Bigl(\hspace{0.05cm} w(\lambda_1) \dots w(\lambda_n) \hspace{0.05cm}\Bigr)\]</span></p></li>
</ul>
<p><br></p>
<p><br></p>
</div>
<div id="distancia-de-gower-generalizada-en-python" class="section level2 hasAnchor" number="11.3">
<h2><span class="header-section-number">11.3</span> Distancia de Gower Generalizada en <code>Python</code><a href="distancia-de-gower-generalizada.html#distancia-de-gower-generalizada-en-python" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p><br></p>
<p><br></p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="anexo.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="distancia-de-mahalanobis-robusta.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://estadistica4all.com/index.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["_main.pdf", "_main.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
